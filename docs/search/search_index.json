{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Ragora Documentation","text":"<p>Ragora is a Retrieval-Augmented Generation toolkit for building document-centric knowledge bases. This site combines authored guides with API reference pages generated from the project docstrings so the published docs align with the latest release.</p>"},{"location":"#start-here","title":"\ud83d\ude80 Start Here","text":"<ul> <li>Getting Started \u2013 Install Ragora, create a knowledge   base, and run your first queries.</li> <li>DevContainer Setup \u2013 Spin up the ready-to-use development   container.</li> <li>Development Workflow \u2013 Branching model, tooling, and coding   conventions.</li> </ul>"},{"location":"#learn-more","title":"\ud83d\udcda Learn More","text":"<ul> <li>Release Process \u2013 Milestone-driven release automation and the   documentation publishing workflow.</li> <li>Deployment \u2013 Production deployment patterns and   infrastructure guidance.</li> <li>Testing \u2013 Testing strategy, coverage goals, and helper tooling.</li> <li>Design Decisions \u2013 Architectural rationale behind core   components.</li> </ul>"},{"location":"#reference","title":"\ud83e\uddf0 Reference","text":"<ul> <li>API Reference \u2013 Auto-generated module documentation built   from Ragora docstrings via mkdocstrings.</li> <li>Contributing Guide \u2013 Steps for proposing changes and   collaborating on reviews.</li> </ul>"},{"location":"#release-documentation-flow","title":"\ud83d\udd04 Release &amp; Documentation Flow","text":"<ol> <li>Conventional commits land on <code>main</code>.</li> <li>Closing a milestone (or a manual dispatch) creates a release.</li> <li>The <code>Generate Documentation</code> GitHub Action rebuilds this site and pushes the    static output to <code>docs/</code> on <code>main</code>.</li> <li>GitHub Pages publishes the updated docs at    https://vahidlari.github.io/aiApps.</li> </ol> <p>Need something else? File an issue on GitHub or start a discussion with the team!</p>"},{"location":"api-reference/","title":"API Reference","text":"<p>This reference is generated automatically from the Ragora docstrings during the release workflow. Each section below maps to a core module in the project. If you add or update public APIs, make sure the corresponding docstrings stay in sync so the published documentation reflects the latest release.</p>"},{"location":"api-reference/#cli","title":"CLI","text":"<p>Entry points for the <code>kbm</code> command-line interface.</p>"},{"location":"api-reference/#ragora.cli.main.create_parser","title":"<code>create_parser()</code>","text":"<p>Create the top-level CLI parser.</p> <p>Returns:</p> Type Description <code>ArgumentParser</code> <p>argparse.ArgumentParser: Configured parser instance.</p> <p>Examples:</p> <pre><code>parser = create_parser()\nparser.parse_args([\"process\", \"docs/paper.tex\"])\n</code></pre> Source code in <code>ragora/ragora/cli/main.py</code> <pre><code>def create_parser() -&gt; argparse.ArgumentParser:\n    \"\"\"Create the top-level CLI parser.\n\n    Returns:\n        argparse.ArgumentParser: Configured parser instance.\n\n    Examples:\n        ```python\n        parser = create_parser()\n        parser.parse_args([\"process\", \"docs/paper.tex\"])\n        ```\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        description=\"Knowledge Base Manager CLI - LaTeX Document Knowledge Base Manager\",\n        formatter_class=argparse.RawDescriptionHelpFormatter,\n        epilog=\"\"\"\nExamples:\n  # Process a LaTeX document\n  kbm process document.tex\n\n  # Query the knowledge base\n  kbm query \"What is the main equation in chapter 2?\"\n\n  # Check system status\n  kbm status\n        \"\"\",\n    )\n\n    # Global options\n    parser.add_argument(\n        \"--weaviate-url\",\n        default=\"http://localhost:8080\",\n        help=\"Weaviate server URL (default: http://localhost:8080)\",\n    )\n    parser.add_argument(\n        \"--class-name\",\n        default=\"Document\",\n        help=\"Weaviate class name (default: Document)\",\n    )\n    parser.add_argument(\n        \"--embedding-model\",\n        default=\"all-mpnet-base-v2\",\n        help=\"Embedding model name (default: all-mpnet-base-v2)\",\n    )\n\n    subparsers = parser.add_subparsers(dest=\"command\", help=\"Available commands\")\n\n    # Process document command\n    process_parser = subparsers.add_parser(\"process\", help=\"Process a LaTeX document\")\n    process_parser.add_argument(\"document\", help=\"Path to LaTeX document\")\n    process_parser.add_argument(\n        \"--chunk-size\",\n        type=int,\n        default=768,\n        help=\"Chunk size in tokens (default: 768)\",\n    )\n    process_parser.add_argument(\n        \"--overlap\",\n        type=int,\n        default=100,\n        help=\"Chunk overlap in tokens (default: 100)\",\n    )\n    process_parser.set_defaults(func=process_document_command)\n\n    # Query command\n    query_parser = subparsers.add_parser(\"query\", help=\"Query the knowledge base\")\n    query_parser.add_argument(\"question\", help=\"Question to ask\")\n    query_parser.add_argument(\n        \"--search-type\",\n        choices=[\"similar\", \"hybrid\"],\n        default=\"hybrid\",\n        help=\"Type of search to perform (default: hybrid)\",\n    )\n    query_parser.add_argument(\n        \"--top-k\", type=int, default=5, help=\"Number of results to return (default: 5)\"\n    )\n    query_parser.set_defaults(func=query_command)\n\n    # Status command\n    status_parser = subparsers.add_parser(\"status\", help=\"Check system status\")\n    status_parser.set_defaults(func=status_command)\n\n    return parser\n</code></pre>"},{"location":"api-reference/#ragora.cli.main.main","title":"<code>main()</code>","text":"<p>Main CLI entry point.</p> Source code in <code>ragora/ragora/cli/main.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Main CLI entry point.\"\"\"\n    parser = create_parser()\n    args = parser.parse_args()\n\n    setup_logging(args.verbose if hasattr(args, \"verbose\") else False)\n\n    if not hasattr(args, \"func\"):\n        parser.print_help()\n        sys.exit(1)\n\n    try:\n        args.func(args)\n    except KnowledgeBaseManagerError as e:\n        print(f\"\u274c Knowledge Base Manager Error: {e}\", file=sys.stderr)\n        sys.exit(1)\n    except KeyboardInterrupt:\n        print(\"\\n\u23f9\ufe0f  Operation cancelled by user\", file=sys.stderr)\n        sys.exit(1)\n    except Exception as e:\n        print(f\"\u274c Unexpected error: {e}\", file=sys.stderr)\n        sys.exit(1)\n</code></pre>"},{"location":"api-reference/#ragora.cli.main.process_document_command","title":"<code>process_document_command(args)</code>","text":"<p>Process a document specified via CLI arguments.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>Namespace</code> <p>Parsed CLI namespace with <code>document</code>, <code>chunk_size</code>, <code>overlap</code>, <code>embedding_model</code>, and <code>weaviate_url</code>.</p> required <p>Raises:</p> Type Description <code>SystemExit</code> <p>When processing fails (exit code 1).</p> <p>Examples:</p> <pre><code>kbm process docs/sample.tex --chunk-size 600 --overlap 80\n</code></pre> Source code in <code>ragora/ragora/cli/main.py</code> <pre><code>def process_document_command(args: Namespace) -&gt; None:\n    \"\"\"Process a document specified via CLI arguments.\n\n    Args:\n        args: Parsed CLI namespace with `document`, `chunk_size`, `overlap`,\n            `embedding_model`, and `weaviate_url`.\n\n    Raises:\n        SystemExit: When processing fails (exit code 1).\n\n    Examples:\n        ```bash\n        kbm process docs/sample.tex --chunk-size 600 --overlap 80\n        ```\n    \"\"\"\n    try:\n        config = KnowledgeBaseManagerConfig(\n            chunk_config=ChunkConfig(\n                chunk_size=args.chunk_size, overlap_size=args.overlap\n            ),\n            embedding_config=EmbeddingConfig(model_name=args.embedding_model),\n            database_manager_config=DatabaseManagerConfig(url=args.weaviate_url),\n        )\n\n        kbm = KnowledgeBaseManager(config=config)\n        chunk_ids = kbm.process_document(args.document)\n        print(f\"\u2705 Processed document: {args.document}\")\n        print(f\"\ud83d\udcc4 Stored {len(chunk_ids)} chunks\")\n\n    except Exception as e:\n        print(f\"\u274c Error processing document: {e}\", file=sys.stderr)\n        sys.exit(1)\n</code></pre>"},{"location":"api-reference/#ragora.cli.main.query_command","title":"<code>query_command(args)</code>","text":"<p>Execute a semantic or hybrid search.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>Namespace</code> <p>Parsed CLI namespace containing the query options.</p> required <p>Raises:</p> Type Description <code>SystemExit</code> <p>When querying fails (exit code 1).</p> <p>Examples:</p> <pre><code>kbm query \"Explain theorem 3\" --search-type similar --top-k 3\n</code></pre> Source code in <code>ragora/ragora/cli/main.py</code> <pre><code>def query_command(args: Namespace) -&gt; None:\n    \"\"\"Execute a semantic or hybrid search.\n\n    Args:\n        args: Parsed CLI namespace containing the query options.\n\n    Raises:\n        SystemExit: When querying fails (exit code 1).\n\n    Examples:\n        ```bash\n        kbm query \"Explain theorem 3\" --search-type similar --top-k 3\n        ```\n    \"\"\"\n    try:\n        config = KnowledgeBaseManagerConfig(\n            chunk_config=ChunkConfig(),\n            embedding_config=EmbeddingConfig(model_name=args.embedding_model),\n            database_manager_config=DatabaseManagerConfig(url=args.weaviate_url),\n        )\n\n        kbm = KnowledgeBaseManager(config=config)\n        response = kbm.query(\n            args.question, search_type=args.search_type, top_k=args.top_k\n        )\n\n        print(f\"\u2753 Question: {response['question']}\")\n        print(f\"\ud83d\udd0d Search type: {response['search_type']}\")\n        print(f\"\ud83d\udcca Retrieved {response['num_chunks']} chunks:\")\n        print()\n\n        for i, chunk in enumerate(response[\"retrieved_chunks\"], 1):\n            print(f\"{i}. \ud83d\udcdd {chunk['content'][:100]}...\")\n            if \"similarity_score\" in chunk:\n                print(f\"   \ud83d\udcc8 Similarity: {chunk['similarity_score']:.3f}\")\n            print()\n\n    except Exception as e:\n        print(f\"\u274c Error querying system: {e}\", file=sys.stderr)\n        sys.exit(1)\n</code></pre>"},{"location":"api-reference/#ragora.cli.main.setup_logging","title":"<code>setup_logging(verbose=False)</code>","text":"<p>Configure application logging.</p> <p>Parameters:</p> Name Type Description Default <code>verbose</code> <code>bool</code> <p>When <code>True</code> raises the log level to <code>DEBUG</code>.</p> <code>False</code> Source code in <code>ragora/ragora/cli/main.py</code> <pre><code>def setup_logging(verbose: bool = False) -&gt; None:\n    \"\"\"Configure application logging.\n\n    Args:\n        verbose: When ``True`` raises the log level to ``DEBUG``.\n    \"\"\"\n    level = logging.DEBUG if verbose else logging.INFO\n    logging.basicConfig(\n        level=level, format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n    )\n</code></pre>"},{"location":"api-reference/#ragora.cli.main.status_command","title":"<code>status_command(args)</code>","text":"<p>Display status information for the knowledge base manager.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>Namespace</code> <p>Parsed CLI namespace (unused).</p> required <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the status request fails.</p> Source code in <code>ragora/ragora/cli/main.py</code> <pre><code>def status_command(args: Namespace) -&gt; None:\n    \"\"\"Display status information for the knowledge base manager.\n\n    Args:\n        args: Parsed CLI namespace (unused).\n\n    Raises:\n        SystemExit: If the status request fails.\n    \"\"\"\n    try:\n        config = KnowledgeBaseManagerConfig.default()\n        kbm = KnowledgeBaseManager(config=config)\n        stats = kbm.get_system_stats()\n\n        print(\"\ud83d\udd0d Knowledge Base Manager Status:\")\n        print(f\"\u2705 Initialized: {stats['system_initialized']}\")\n        print(f\"\ud83d\udcca Total objects: {stats['vector_store']['total_objects']}\")\n        print(f\"\ud83e\udd16 Embedding model: {stats['embedding_engine']['model_name']}\")\n        print(f\"\ud83d\udce6 Chunk size: {stats['data_chunker']['chunk_size']}\")\n\n    except Exception as e:\n        print(f\"\u274c Error checking status: {e}\", file=sys.stderr)\n        sys.exit(1)\n</code></pre>"},{"location":"api-reference/#core","title":"Core","text":""},{"location":"api-reference/#knowledge-base-manager","title":"Knowledge Base Manager","text":"<p>High-level orchestration entry point for the Ragora knowledge base.</p> <p>The module exposes the <code>KnowledgeBaseManager</code> which connects the ingestion, chunking, vector store, and retrieval layers into a single cohesive API. It is typically the only component application code needs to instantiate when working with Ragora programmatically.</p>"},{"location":"api-reference/#ragora.core.knowledge_base_manager.KnowledgeBaseManager","title":"<code>KnowledgeBaseManager</code>","text":"<p>High-level fa\u00e7ade for document ingestion and retrieval.</p> <p>The manager wires together the lower-level components (preprocessors, chunkers, embedding engine, vector store, retriever) and exposes a compact API for turning raw files and emails into searchable chunks.</p> <p>Attributes:</p> Name Type Description <code>db_manager</code> <p>Component that maintains the connection to Weaviate.</p> <code>vector_store</code> <p>Storage layer responsible for persisting chunks.</p> <code>retriever</code> <p>Retrieval layer used to execute search strategies.</p> <code>embedding_engine</code> <p>Optional embedding engine used for semantic search.</p> <code>document_preprocessor</code> <p>Parser that converts documents into chunks.</p> <code>data_chunker</code> <p>Chunking configuration used by preprocessors.</p> <code>logger</code> <p>Module logger for diagnostics.</p> <code>is_initialized</code> <p>Whether the manager completed initialization.</p> <p>Examples:</p> <p>Create a manager with default settings and ingest a LaTeX document:</p> <pre><code>from ragora.core.knowledge_base_manager import KnowledgeBaseManager\n\nkb = KnowledgeBaseManager()\nchunk_ids = kb.process_document(\"docs/paper.tex\", document_type=\"latex\")\nresults = kb.search(\"neural networks\", collection=\"Document\")\n</code></pre> Source code in <code>ragora/ragora/core/knowledge_base_manager.py</code> <pre><code>class KnowledgeBaseManager:\n    \"\"\"High-level fa\u00e7ade for document ingestion and retrieval.\n\n    The manager wires together the lower-level components (preprocessors,\n    chunkers, embedding engine, vector store, retriever) and exposes a compact\n    API for turning raw files and emails into searchable chunks.\n\n    Attributes:\n        db_manager: Component that maintains the connection to Weaviate.\n        vector_store: Storage layer responsible for persisting chunks.\n        retriever: Retrieval layer used to execute search strategies.\n        embedding_engine: Optional embedding engine used for semantic search.\n        document_preprocessor: Parser that converts documents into chunks.\n        data_chunker: Chunking configuration used by preprocessors.\n        logger: Module logger for diagnostics.\n        is_initialized: Whether the manager completed initialization.\n\n    Examples:\n        Create a manager with default settings and ingest a LaTeX document:\n\n        ```python\n        from ragora.core.knowledge_base_manager import KnowledgeBaseManager\n\n        kb = KnowledgeBaseManager()\n        chunk_ids = kb.process_document(\"docs/paper.tex\", document_type=\"latex\")\n        results = kb.search(\"neural networks\", collection=\"Document\")\n        ```\n    \"\"\"\n\n    def __init__(\n        self,\n        config: Optional[KnowledgeBaseManagerConfig] = None,\n        weaviate_url: str = \"http://localhost:8080\",\n    ):\n        \"\"\"Initialize the knowledge base manager.\n\n        Args:\n            config: RagoraConfig object with system configuration (optional)\n            weaviate_url: Weaviate server URL (used if config not provided)\n\n        Raises:\n            ConnectionError: If unable to connect to Weaviate\n            ValueError: If invalid parameters are provided\n        \"\"\"\n        self.is_initialized = False\n        self.logger = logging.getLogger(__name__)\n\n        try:\n            self.embedding_engine = None\n            self.data_chunker = None\n            self.db_manager = None\n            self.vector_store = None\n            self.retriever = None\n            self.document_preprocessor = None\n            self.email_preprocessor = None\n\n            # Handle configuration - use provided config or create from individual parameters\n            if config is not None:\n                if config.embedding_config:\n                    # Initialize embedding engine\n                    self.embedding_engine = EmbeddingEngine(\n                        model_name=config.embedding_config.model_name,\n                        device=(\n                            config.embedding_config.device\n                            if config.embedding_config.device\n                            else None\n                        ),\n                    )\n                if config.database_manager_config:\n                    weaviate_url = config.database_manager_config.url\n                if config.chunk_config:\n                    from .chunking import DocumentChunkingStrategy\n\n                    custom_strategy = DocumentChunkingStrategy(\n                        chunk_size=config.chunk_config.chunk_size,\n                        overlap_size=config.chunk_config.overlap_size,\n                    )\n                    self.data_chunker = DataChunker(default_strategy=custom_strategy)\n\n            # Initialize database manager (infrastructure layer)\n            self.logger.info(f\"Initializing database manager at {weaviate_url}\")\n            self.db_manager = DatabaseManager(url=weaviate_url)\n\n            # Initialize vector store (storage layer)\n            self.logger.info(\"Initializing vector store\")\n            self.vector_store = VectorStore(\n                db_manager=self.db_manager,\n                embedding_engine=(\n                    self.embedding_engine if self.embedding_engine else None\n                ),\n            )\n\n            # Initialize retriever (search layer)\n            self.logger.info(\"Initializing retriever\")\n            self.retriever = Retriever(\n                db_manager=self.db_manager,\n                embedding_engine=(\n                    self.embedding_engine if self.embedding_engine else None\n                ),\n            )\n\n            # Initialize document preprocessor with chunking parameters\n            self.logger.info(\"Initializing document preprocessor\")\n            self.document_preprocessor = DocumentPreprocessor(\n                chunker=(self.data_chunker if self.data_chunker else None)\n            )\n\n            # Initialize email preprocessor with chunking parameters\n            self.logger.info(\"Initializing email preprocessor\")\n            self.email_preprocessor = EmailPreprocessor(\n                chunker=(self.data_chunker if self.data_chunker else None)\n            )\n\n            self.is_initialized = True\n            self.logger.info(\"Knowledge base manager initialized successfully\")\n\n        except Exception as e:\n            self.logger.error(f\"Failed to initialize knowledge base manager: {str(e)}\")\n            raise\n\n    def process_documents(\n        self,\n        document_paths: List[str],\n        document_type: str = \"latex\",\n        collection: str = \"Document\",\n    ) -&gt; List[str]:\n        \"\"\"Process a list of documents and store them in the vector database.\n\n        Args:\n            document_paths: List of paths to the documents to ingest\n            document_type: Type of document to process (\"latex\", \"markdown\", \"text\")\n            collection: Collection name to store the documents\n        Returns:\n            List[str]: List of chunk IDs that were stored\n\n        Raises:\n            RuntimeError: If the manager is not initialized\n            Exception: If the documents cannot be processed\n\n        Examples:\n            ```python\n            kb = KnowledgeBaseManager()\n            kb.process_documents([\"notes.md\", \"report.tex\"], document_type=\"markdown\")\n            ```\n\n        \"\"\"\n        if not self.is_initialized:\n            raise RuntimeError(\"Knowledge base manager not initialized\")\n\n        try:\n            self.logger.info(f\"Processing {len(document_paths)} documents\")\n            chunks = self.document_preprocessor.preprocess_documents(\n                document_paths, document_type\n            )\n            self.logger.info(f\"Storing {len(chunks)} chunks in vector database\")\n            stored_uuids = self.vector_store.store_chunks(chunks, collection=collection)\n            self.logger.info(f\"Successfully processed {len(document_paths)} documents\")\n            self.logger.info(f\"Stored {len(stored_uuids)} chunks\")\n            return stored_uuids\n        except Exception as e:\n            self.logger.error(f\"Failed to process documents: {str(e)}\")\n            raise\n\n    def process_document(\n        self,\n        document_path: str,\n        document_type: str = \"latex\",\n        collection: str = \"Document\",\n    ) -&gt; List[str]:\n        \"\"\"Process a single document and store it in the vector database.\n\n        Args:\n            document_path: Path to the document file\n            document_type: Type of document to process (\"latex\", \"markdown\", \"text\")\n            collection: Collection name to store the document\n        Returns:\n            List[str]: List of chunk IDs that were stored\n\n        Raises:\n            FileNotFoundError: If document file doesn't exist\n            ValueError: If document processing fails\n        Examples:\n            ```python\n            kb = KnowledgeBaseManager()\n            kb.process_document(\"docs/tutorial.md\", document_type=\"markdown\")\n            ```\n\n        \"\"\"\n        if not self.is_initialized:\n            raise RuntimeError(\"Knowledge base manager not initialized\")\n\n        try:\n            self.logger.info(f\"Processing document: {document_path}\")\n\n            # Step 1: Preprocess the LaTeX document\n            self.logger.debug(f\"Step 1: Preprocessing {document_type} document\")\n            chunks = self.document_preprocessor.preprocess_document(\n                document_path, document_type\n            )\n\n            # Step 2: Store chunks in vector database\n            self.logger.debug(\n                f\"Step 2: Storing {len(chunks)} chunks in vector database\"\n            )\n            stored_uuids = self.vector_store.store_chunks(chunks, collection=collection)\n\n            self.logger.info(f\"Successfully processed document: {document_path}\")\n            self.logger.info(f\"Stored {len(stored_uuids)} chunks\")\n\n            return stored_uuids\n\n        except Exception as e:\n            self.logger.error(f\"Failed to process document {document_path}: {str(e)}\")\n            raise\n\n    def search(\n        self,\n        query: str,\n        collection: str = \"Document\",\n        strategy: SearchStrategy = SearchStrategy.HYBRID,\n        top_k: int = 5,\n        filter: Optional[Filter] = None,\n        **strategy_kwargs,\n    ) -&gt; SearchResult:\n        \"\"\"Unified search interface for all data types and strategies.\n\n        Args:\n            query: Search query text\n            collection: Collection name to search in\n            strategy: Search strategy to use\n            top_k: Number of results to return\n            filter: Optional Weaviate Filter to filter results by properties\n            **strategy_kwargs: Strategy-specific parameters\n                (alpha, score_threshold, etc.)\n\n        Returns:\n            SearchResult: Structured search results with metadata\n\n        Raises:\n            RuntimeError: If system not initialized\n            ValueError: If invalid strategy or empty query\n\n        Examples:\n            ```python\n            kb = KnowledgeBaseManager()\n            kb.process_document(\"docs/tutorial.md\", document_type=\"markdown\")\n            result = kb.search(\"introduction\", strategy=SearchStrategy.HYBRID, top_k=3)\n            for hit in result.results:\n                print(hit.metadata.title, hit.similarity_score)\n            ```\n        \"\"\"\n        if not self.is_initialized:\n            raise RuntimeError(\"Knowledge base manager not initialized\")\n\n        if not query or not query.strip():\n            raise ValueError(\"Query cannot be empty\")\n\n        start_time = time.time()\n\n        try:\n            self.logger.info(\n                f\"Processing search: '{query}' \"\n                f\"(strategy: {strategy.value if hasattr(strategy, 'value') else strategy}, collection: {collection})\"\n            )\n\n            # Execute search based on strategy\n            if strategy == SearchStrategy.SIMILAR:\n                results = self.retriever.search_similar(\n                    query,\n                    collection=collection,\n                    top_k=top_k,\n                    filter=filter,\n                    **strategy_kwargs,\n                )\n            elif strategy == SearchStrategy.KEYWORD:\n                results = self.retriever.search_keyword(\n                    query,\n                    collection=collection,\n                    top_k=top_k,\n                    filter=filter,\n                    **strategy_kwargs,\n                )\n            elif strategy == SearchStrategy.HYBRID:\n                results = self.retriever.search_hybrid(\n                    query,\n                    collection=collection,\n                    top_k=top_k,\n                    filter=filter,\n                    **strategy_kwargs,\n                )\n            elif strategy == SearchStrategy.AUTO:\n                # For now, default to hybrid.\n                # Could be enhanced with automatic strategy selection\n                results = self.retriever.search_hybrid(\n                    query,\n                    collection=collection,\n                    top_k=top_k,\n                    filter=filter,\n                    **strategy_kwargs,\n                )\n            else:\n                raise ValueError(f\"Invalid search strategy: {strategy}\")\n\n            execution_time = time.time() - start_time\n\n            # Prepare metadata\n            metadata = {\n                \"chunk_sources\": list(\n                    set(\n                        result.properties.get(\"source_document\", \"\")\n                        or result.metadata.source_document\n                        or \"\"\n                        for result in results\n                    )\n                ),\n                \"chunk_types\": list(\n                    set(\n                        result.properties.get(\"chunk_type\", \"\")\n                        or result.metadata.chunk_type\n                        or \"\"\n                        for result in results\n                    )\n                ),\n            }\n\n            # Add similarity scores if available\n            similarity_scores = [\n                result.similarity_score\n                for result in results\n                if result.similarity_score is not None\n            ]\n\n            if similarity_scores:\n                metadata[\"avg_similarity\"] = sum(similarity_scores) / len(\n                    similarity_scores\n                )\n                metadata[\"max_similarity\"] = max(similarity_scores)\n\n            self.logger.info(\n                f\"Search completed: {len(results)} results in {execution_time:.3f}s\"\n            )\n\n            # Convert strategy enum to string for SearchResult\n            strategy_str = (\n                strategy.value if hasattr(strategy, \"value\") else str(strategy)\n            )\n\n            results_dicts = [item.model_dump() for item in results]\n\n            # Use model_validate for proper nested model validation in Pydantic 2.x\n            return SearchResult.model_validate(\n                {\n                    \"query\": query,\n                    \"strategy\": strategy_str,\n                    \"collection\": collection,\n                    \"results\": results_dicts,\n                    \"total_found\": len(results),\n                    \"execution_time\": execution_time,\n                    \"metadata\": metadata,\n                }\n            )\n\n        except Exception as e:\n            self.logger.error(f\"Search failed: {str(e)}\")\n            raise\n\n    def get_chunk(\n        self, chunk_id: str, collection: str\n    ) -&gt; Optional[RetrievalResultItem]:\n        \"\"\"Retrieve a specific chunk by its ID.\n\n        Args:\n            chunk_id: Unique identifier of the chunk\n            collection: Collection name\n        Returns:\n            Optional[RetrievalResultItem]: Chunk data if found, None otherwise\n        \"\"\"\n        return self.vector_store.get_chunk_by_id(chunk_id, collection=collection)\n\n    def delete_chunk(self, chunk_id: str, collection: str) -&gt; bool:\n        \"\"\"Delete a chunk by its ID.\n\n        Args:\n            chunk_id: Unique identifier of the chunk to delete\n            collection: Collection name\n        Returns:\n            bool: True if deletion was successful, False otherwise\n        \"\"\"\n        return self.vector_store.delete_chunk(chunk_id, collection=collection)\n\n    def list_collections(self) -&gt; List[str]:\n        \"\"\"List all available collections.\n\n        Returns:\n            List[str]: List of collection names\n        \"\"\"\n        return self.db_manager.list_collections()\n\n    def create_collection(self, name: str, force_recreate: bool = False) -&gt; bool:\n        \"\"\"Create a new collection.\n\n        Args:\n            name: Collection name\n            force_recreate: Whether to recreate if collection exists\n\n        Returns:\n            bool: True if creation was successful, False otherwise\n        \"\"\"\n        try:\n            self.vector_store.create_schema(name, force_recreate=force_recreate)\n            return True\n        except Exception as e:\n            self.logger.error(f\"Failed to create collection {name}: {e}\")\n            return False\n\n    def delete_collection(self, name: str) -&gt; bool:\n        \"\"\"Delete a collection and all its data.\n\n        Args:\n            name: Collection name\n\n        Returns:\n            bool: True if deletion was successful, False otherwise\n        \"\"\"\n        try:\n            self.vector_store.clear_all(collection=name)\n            # Note: Weaviate doesn't have direct collection deletion\n            # This clears all data, effectively \"deleting\" the collection\n            return True\n        except Exception as e:\n            self.logger.error(f\"Failed to delete collection {name}: {e}\")\n            return False\n\n    def clear_collection(self, collection: str) -&gt; None:\n        \"\"\"Clear all data from a collection.\n\n        Args:\n            collection: Collection name\n\n        Raises:\n            RuntimeError: If system not initialized\n        \"\"\"\n        if not self.is_initialized:\n            raise RuntimeError(\"Knowledge base manager not initialized\")\n\n        try:\n            self.logger.warning(f\"Clearing all data from collection: {collection}\")\n            self.vector_store.clear_all(collection=collection)\n            self.logger.info(f\"Collection {collection} cleared successfully\")\n        except Exception as e:\n            self.logger.error(f\"Failed to clear collection {collection}: {str(e)}\")\n            raise\n\n    def get_collection_stats(self, collection: str) -&gt; Dict[str, Any]:\n        \"\"\"Get statistics for a specific collection.\n\n        Args:\n            collection: Collection name\n\n        Returns:\n            Dict[str, Any]: Collection statistics\n        \"\"\"\n        try:\n            # Get vector store stats\n            vector_stats = self.vector_store.get_stats(collection=collection)\n\n            # Get retrieval stats\n            retrieval_stats = self.retriever.get_retrieval_stats(collection=collection)\n\n            # Get embedding engine info\n            embedding_info = (\n                self.embedding_engine.get_model_info()\n                if self.embedding_engine\n                else {\"model_name\": \"Not initialized\", \"dimension\": None}\n            )\n\n            # Get chunker configuration\n            chunker_config = (\n                {\n                    \"chunk_size\": self.data_chunker.default_strategy.chunk_size,\n                    \"overlap_size\": self.data_chunker.default_strategy.overlap_size,\n                    \"chunk_type\": \"custom\",\n                }\n                if self.data_chunker\n                else {\n                    \"chunk_size\": \"Not initialized\",\n                    \"overlap_size\": \"Not initialized\",\n                    \"chunk_type\": \"Not initialized\",\n                }\n            )\n\n            return {\n                \"collection\": collection,\n                \"system_initialized\": self.is_initialized,\n                \"database_manager\": {\n                    \"url\": self.db_manager.url,\n                    \"is_connected\": self.db_manager.is_connected,\n                    \"collections\": self.db_manager.list_collections(),\n                },\n                \"vector_store\": vector_stats,\n                \"retrieval\": retrieval_stats,\n                \"embedding_engine\": embedding_info,\n                \"data_chunker\": chunker_config,\n                \"components\": {\n                    \"database_manager\": \"Weaviate Infrastructure\",\n                    \"vector_store\": \"Weaviate Storage\",\n                    \"retriever\": \"Weaviate Search APIs\",\n                    \"embedding_engine\": embedding_info[\"model_name\"],\n                    \"document_preprocessor\": \"LaTeX Parser\",\n                },\n                \"architecture\": \"Three-Layer (DatabaseManager -&gt; VectorStore -&gt; Retriever)\",\n            }\n\n        except Exception as e:\n            self.logger.error(f\"Failed to get collection stats: {str(e)}\")\n            raise\n\n    def close(self) -&gt; None:\n        \"\"\"Close all system connections and cleanup resources.\"\"\"\n        try:\n            if hasattr(self, \"vector_store\"):\n                self.vector_store.close()\n            self.is_initialized = False\n            self.logger.info(\"Knowledge base manager closed successfully\")\n        except Exception as e:\n            self.logger.error(f\"Error closing knowledge base manager: {str(e)}\")\n\n    # Email processing methods\n\n    def _ensure_email_connection(self, email_provider: EmailProvider) -&gt; bool:\n        \"\"\"Ensure email provider is connected.\n\n        Returns True if we connected it, False if already connected.\n        \"\"\"\n        if not email_provider.is_connected:\n            self.logger.debug(\"Email provider not connected, connecting...\")\n            email_provider.connect()\n            return True\n        return False\n\n    def check_new_emails(\n        self,\n        email_provider: EmailProvider,\n        folder: Optional[str] = None,\n        include_body: bool = True,\n        limit: int = 50,\n    ) -&gt; EmailListResult:\n        \"\"\"Check for new unread emails without storing them.\n\n        Args:\n            email_provider: Email provider instance\n            folder: Optional folder to check (None = all folders)\n            include_body: Include email body content (default: True)\n            limit: Maximum number of emails to return\n\n        Returns:\n            EmailListResult: Structured result with email items and metadata\n\n        Raises:\n            RuntimeError: If system not initialized\n        \"\"\"\n        if not self.is_initialized:\n            raise RuntimeError(\"Knowledge base manager not initialized\")\n\n        start_time = time.time()\n\n        try:\n            # Auto-connect if needed\n            self._ensure_email_connection(email_provider)\n\n            # Fetch unread messages\n            new_emails = email_provider.fetch_messages(\n                limit=limit, folder=folder, unread_only=True\n            )\n\n            # Convert EmailMessage objects to EmailMessageModel\n            email_items = [\n                EmailMessageModel.from_email_message(email) for email in new_emails\n            ]\n\n            # Clear body fields if include_body is False\n            if not include_body:\n                for email_item in email_items:\n                    email_item.body_text = None\n                    email_item.body_html = None\n\n            execution_time = time.time() - start_time\n\n            # Build metadata\n            metadata = {\n                \"include_body\": include_body,\n                \"limit\": limit,\n                \"unread_only\": True,\n            }\n\n            result = EmailListResult(\n                emails=email_items,\n                count=len(new_emails),\n                folder=folder,\n                execution_time=execution_time,\n                metadata=metadata,\n            )\n\n            self.logger.info(f\"Found {len(new_emails)} new emails\")\n            return result\n\n        except Exception as e:\n            self.logger.error(f\"Failed to check new emails: {str(e)}\")\n            raise\n\n    def process_new_emails(\n        self,\n        email_provider: EmailProvider,\n        email_ids: List[str],\n        collection: str = \"Email\",\n    ) -&gt; List[str]:\n        \"\"\"Process and store specific emails by their IDs.\n\n        This method processes emails that have been identified by the user\n        through check_new_emails() and filtered as needed.\n\n        Args:\n            email_provider: Email provider instance\n            email_ids: List of email IDs to process (required)\n            collection: Collection name to store the emails\n\n        Returns:\n            List of stored chunk IDs\n        \"\"\"\n        if not self.is_initialized:\n            raise RuntimeError(\"Knowledge base manager not initialized\")\n\n        if not email_ids:\n            self.logger.warning(\"No email IDs provided\")\n            return []\n\n        try:\n            # Auto-connect if needed\n            self._ensure_email_connection(email_provider)\n\n            # Fetch specific emails by ID\n            emails = []\n            for email_id in email_ids:\n                email = email_provider.fetch_message_by_id(email_id)\n                if email:\n                    emails.append(email)\n                else:\n                    self.logger.warning(f\"Email {email_id} not found\")\n\n            if not emails:\n                self.logger.info(\"No emails found to process\")\n                return []\n\n            # Preprocess emails\n            self.logger.info(f\"Preprocessing {len(emails)} emails\")\n            chunks = self.email_preprocessor.preprocess_emails(emails)\n\n            # Store chunks\n            self.logger.info(f\"Storing {len(chunks)} chunks\")\n            stored_uuids = self.vector_store.store_chunks(chunks, collection=collection)\n\n            self.logger.info(f\"Successfully processed {len(emails)} emails\")\n            return stored_uuids\n\n        except Exception as e:\n            self.logger.error(f\"Failed to process new emails: {str(e)}\")\n            raise\n\n    def process_email_account(\n        self,\n        email_provider: EmailProvider,\n        folder: Optional[str] = None,\n        unread_only: bool = False,\n        collection: str = \"Email\",\n    ) -&gt; List[str]:\n        \"\"\"Process emails from an email account.\n\n        Args:\n            email_provider: Email provider instance\n            folder: Optional folder to process (None = all folders)\n            unread_only: If True, only process unread emails\n            collection: Collection name to store the emails\n\n        Returns:\n            List of stored chunk IDs\n        \"\"\"\n        if not self.is_initialized:\n            raise RuntimeError(\"Knowledge base manager not initialized\")\n\n        try:\n            # Auto-connect if needed\n            self._ensure_email_connection(email_provider)\n\n            # Fetch emails\n            emails = email_provider.fetch_messages(\n                limit=None, folder=folder, unread_only=unread_only\n            )\n\n            if not emails:\n                self.logger.info(\"No emails to process\")\n                return []\n\n            # Preprocess emails\n            self.logger.info(f\"Preprocessing {len(emails)} emails\")\n            chunks = self.email_preprocessor.preprocess_emails(emails)\n\n            # Store chunks\n            self.logger.info(f\"Storing {len(chunks)} chunks\")\n            stored_uuids = self.vector_store.store_chunks(chunks, collection=collection)\n\n            self.logger.info(f\"Successfully processed {len(emails)} emails\")\n            return stored_uuids\n\n        except Exception as e:\n            self.logger.error(f\"Failed to process email account: {str(e)}\")\n            raise\n\n    def process_emails(\n        self,\n        email_provider: EmailProvider,\n        email_ids: List[str],\n        collection: str = \"Email\",\n    ) -&gt; List[str]:\n        \"\"\"Process specific emails by their IDs.\n\n        Args:\n            email_provider: Email provider instance\n            email_ids: List of email IDs to process\n            collection: Collection name to store the emails\n\n        Returns:\n            List of stored chunk IDs\n        \"\"\"\n        if not self.is_initialized:\n            raise RuntimeError(\"Knowledge base manager not initialized\")\n\n        try:\n            # Auto-connect if needed\n            self._ensure_email_connection(email_provider)\n\n            # Fetch emails\n            emails = []\n            for email_id in email_ids:\n                email = email_provider.fetch_message_by_id(email_id)\n                if email:\n                    emails.append(email)\n\n            if not emails:\n                self.logger.info(\"No emails found to process\")\n                return []\n\n            # Preprocess emails\n            self.logger.info(f\"Preprocessing {len(emails)} emails\")\n            chunks = self.email_preprocessor.preprocess_emails(emails)\n\n            # Store chunks\n            self.logger.info(f\"Storing {len(chunks)} chunks\")\n            stored_uuids = self.vector_store.store_chunks(chunks, collection=collection)\n\n            self.logger.info(f\"Successfully processed {len(emails)} emails\")\n            return stored_uuids\n\n        except Exception as e:\n            self.logger.error(f\"Failed to process emails: {str(e)}\")\n            raise\n\n    def __enter__(self):\n        \"\"\"Context manager entry.\"\"\"\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        \"\"\"Context manager exit.\"\"\"\n        self.close()\n</code></pre>"},{"location":"api-reference/#ragora.core.knowledge_base_manager.KnowledgeBaseManager._ensure_email_connection","title":"<code>_ensure_email_connection(email_provider)</code>","text":"<p>Ensure email provider is connected.</p> <p>Returns True if we connected it, False if already connected.</p> Source code in <code>ragora/ragora/core/knowledge_base_manager.py</code> <pre><code>def _ensure_email_connection(self, email_provider: EmailProvider) -&gt; bool:\n    \"\"\"Ensure email provider is connected.\n\n    Returns True if we connected it, False if already connected.\n    \"\"\"\n    if not email_provider.is_connected:\n        self.logger.debug(\"Email provider not connected, connecting...\")\n        email_provider.connect()\n        return True\n    return False\n</code></pre>"},{"location":"api-reference/#ragora.core.knowledge_base_manager.KnowledgeBaseManager.check_new_emails","title":"<code>check_new_emails(email_provider, folder=None, include_body=True, limit=50)</code>","text":"<p>Check for new unread emails without storing them.</p> <p>Parameters:</p> Name Type Description Default <code>email_provider</code> <code>EmailProvider</code> <p>Email provider instance</p> required <code>folder</code> <code>Optional[str]</code> <p>Optional folder to check (None = all folders)</p> <code>None</code> <code>include_body</code> <code>bool</code> <p>Include email body content (default: True)</p> <code>True</code> <code>limit</code> <code>int</code> <p>Maximum number of emails to return</p> <code>50</code> <p>Returns:</p> Name Type Description <code>EmailListResult</code> <code>EmailListResult</code> <p>Structured result with email items and metadata</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If system not initialized</p> Source code in <code>ragora/ragora/core/knowledge_base_manager.py</code> <pre><code>def check_new_emails(\n    self,\n    email_provider: EmailProvider,\n    folder: Optional[str] = None,\n    include_body: bool = True,\n    limit: int = 50,\n) -&gt; EmailListResult:\n    \"\"\"Check for new unread emails without storing them.\n\n    Args:\n        email_provider: Email provider instance\n        folder: Optional folder to check (None = all folders)\n        include_body: Include email body content (default: True)\n        limit: Maximum number of emails to return\n\n    Returns:\n        EmailListResult: Structured result with email items and metadata\n\n    Raises:\n        RuntimeError: If system not initialized\n    \"\"\"\n    if not self.is_initialized:\n        raise RuntimeError(\"Knowledge base manager not initialized\")\n\n    start_time = time.time()\n\n    try:\n        # Auto-connect if needed\n        self._ensure_email_connection(email_provider)\n\n        # Fetch unread messages\n        new_emails = email_provider.fetch_messages(\n            limit=limit, folder=folder, unread_only=True\n        )\n\n        # Convert EmailMessage objects to EmailMessageModel\n        email_items = [\n            EmailMessageModel.from_email_message(email) for email in new_emails\n        ]\n\n        # Clear body fields if include_body is False\n        if not include_body:\n            for email_item in email_items:\n                email_item.body_text = None\n                email_item.body_html = None\n\n        execution_time = time.time() - start_time\n\n        # Build metadata\n        metadata = {\n            \"include_body\": include_body,\n            \"limit\": limit,\n            \"unread_only\": True,\n        }\n\n        result = EmailListResult(\n            emails=email_items,\n            count=len(new_emails),\n            folder=folder,\n            execution_time=execution_time,\n            metadata=metadata,\n        )\n\n        self.logger.info(f\"Found {len(new_emails)} new emails\")\n        return result\n\n    except Exception as e:\n        self.logger.error(f\"Failed to check new emails: {str(e)}\")\n        raise\n</code></pre>"},{"location":"api-reference/#ragora.core.knowledge_base_manager.KnowledgeBaseManager.clear_collection","title":"<code>clear_collection(collection)</code>","text":"<p>Clear all data from a collection.</p> <p>Parameters:</p> Name Type Description Default <code>collection</code> <code>str</code> <p>Collection name</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If system not initialized</p> Source code in <code>ragora/ragora/core/knowledge_base_manager.py</code> <pre><code>def clear_collection(self, collection: str) -&gt; None:\n    \"\"\"Clear all data from a collection.\n\n    Args:\n        collection: Collection name\n\n    Raises:\n        RuntimeError: If system not initialized\n    \"\"\"\n    if not self.is_initialized:\n        raise RuntimeError(\"Knowledge base manager not initialized\")\n\n    try:\n        self.logger.warning(f\"Clearing all data from collection: {collection}\")\n        self.vector_store.clear_all(collection=collection)\n        self.logger.info(f\"Collection {collection} cleared successfully\")\n    except Exception as e:\n        self.logger.error(f\"Failed to clear collection {collection}: {str(e)}\")\n        raise\n</code></pre>"},{"location":"api-reference/#ragora.core.knowledge_base_manager.KnowledgeBaseManager.close","title":"<code>close()</code>","text":"<p>Close all system connections and cleanup resources.</p> Source code in <code>ragora/ragora/core/knowledge_base_manager.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Close all system connections and cleanup resources.\"\"\"\n    try:\n        if hasattr(self, \"vector_store\"):\n            self.vector_store.close()\n        self.is_initialized = False\n        self.logger.info(\"Knowledge base manager closed successfully\")\n    except Exception as e:\n        self.logger.error(f\"Error closing knowledge base manager: {str(e)}\")\n</code></pre>"},{"location":"api-reference/#ragora.core.knowledge_base_manager.KnowledgeBaseManager.create_collection","title":"<code>create_collection(name, force_recreate=False)</code>","text":"<p>Create a new collection.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Collection name</p> required <code>force_recreate</code> <code>bool</code> <p>Whether to recreate if collection exists</p> <code>False</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if creation was successful, False otherwise</p> Source code in <code>ragora/ragora/core/knowledge_base_manager.py</code> <pre><code>def create_collection(self, name: str, force_recreate: bool = False) -&gt; bool:\n    \"\"\"Create a new collection.\n\n    Args:\n        name: Collection name\n        force_recreate: Whether to recreate if collection exists\n\n    Returns:\n        bool: True if creation was successful, False otherwise\n    \"\"\"\n    try:\n        self.vector_store.create_schema(name, force_recreate=force_recreate)\n        return True\n    except Exception as e:\n        self.logger.error(f\"Failed to create collection {name}: {e}\")\n        return False\n</code></pre>"},{"location":"api-reference/#ragora.core.knowledge_base_manager.KnowledgeBaseManager.delete_chunk","title":"<code>delete_chunk(chunk_id, collection)</code>","text":"<p>Delete a chunk by its ID.</p> <p>Parameters:</p> Name Type Description Default <code>chunk_id</code> <code>str</code> <p>Unique identifier of the chunk to delete</p> required <code>collection</code> <code>str</code> <p>Collection name</p> required <p>Returns:     bool: True if deletion was successful, False otherwise</p> Source code in <code>ragora/ragora/core/knowledge_base_manager.py</code> <pre><code>def delete_chunk(self, chunk_id: str, collection: str) -&gt; bool:\n    \"\"\"Delete a chunk by its ID.\n\n    Args:\n        chunk_id: Unique identifier of the chunk to delete\n        collection: Collection name\n    Returns:\n        bool: True if deletion was successful, False otherwise\n    \"\"\"\n    return self.vector_store.delete_chunk(chunk_id, collection=collection)\n</code></pre>"},{"location":"api-reference/#ragora.core.knowledge_base_manager.KnowledgeBaseManager.delete_collection","title":"<code>delete_collection(name)</code>","text":"<p>Delete a collection and all its data.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Collection name</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if deletion was successful, False otherwise</p> Source code in <code>ragora/ragora/core/knowledge_base_manager.py</code> <pre><code>def delete_collection(self, name: str) -&gt; bool:\n    \"\"\"Delete a collection and all its data.\n\n    Args:\n        name: Collection name\n\n    Returns:\n        bool: True if deletion was successful, False otherwise\n    \"\"\"\n    try:\n        self.vector_store.clear_all(collection=name)\n        # Note: Weaviate doesn't have direct collection deletion\n        # This clears all data, effectively \"deleting\" the collection\n        return True\n    except Exception as e:\n        self.logger.error(f\"Failed to delete collection {name}: {e}\")\n        return False\n</code></pre>"},{"location":"api-reference/#ragora.core.knowledge_base_manager.KnowledgeBaseManager.get_chunk","title":"<code>get_chunk(chunk_id, collection)</code>","text":"<p>Retrieve a specific chunk by its ID.</p> <p>Parameters:</p> Name Type Description Default <code>chunk_id</code> <code>str</code> <p>Unique identifier of the chunk</p> required <code>collection</code> <code>str</code> <p>Collection name</p> required <p>Returns:     Optional[RetrievalResultItem]: Chunk data if found, None otherwise</p> Source code in <code>ragora/ragora/core/knowledge_base_manager.py</code> <pre><code>def get_chunk(\n    self, chunk_id: str, collection: str\n) -&gt; Optional[RetrievalResultItem]:\n    \"\"\"Retrieve a specific chunk by its ID.\n\n    Args:\n        chunk_id: Unique identifier of the chunk\n        collection: Collection name\n    Returns:\n        Optional[RetrievalResultItem]: Chunk data if found, None otherwise\n    \"\"\"\n    return self.vector_store.get_chunk_by_id(chunk_id, collection=collection)\n</code></pre>"},{"location":"api-reference/#ragora.core.knowledge_base_manager.KnowledgeBaseManager.get_collection_stats","title":"<code>get_collection_stats(collection)</code>","text":"<p>Get statistics for a specific collection.</p> <p>Parameters:</p> Name Type Description Default <code>collection</code> <code>str</code> <p>Collection name</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict[str, Any]: Collection statistics</p> Source code in <code>ragora/ragora/core/knowledge_base_manager.py</code> <pre><code>def get_collection_stats(self, collection: str) -&gt; Dict[str, Any]:\n    \"\"\"Get statistics for a specific collection.\n\n    Args:\n        collection: Collection name\n\n    Returns:\n        Dict[str, Any]: Collection statistics\n    \"\"\"\n    try:\n        # Get vector store stats\n        vector_stats = self.vector_store.get_stats(collection=collection)\n\n        # Get retrieval stats\n        retrieval_stats = self.retriever.get_retrieval_stats(collection=collection)\n\n        # Get embedding engine info\n        embedding_info = (\n            self.embedding_engine.get_model_info()\n            if self.embedding_engine\n            else {\"model_name\": \"Not initialized\", \"dimension\": None}\n        )\n\n        # Get chunker configuration\n        chunker_config = (\n            {\n                \"chunk_size\": self.data_chunker.default_strategy.chunk_size,\n                \"overlap_size\": self.data_chunker.default_strategy.overlap_size,\n                \"chunk_type\": \"custom\",\n            }\n            if self.data_chunker\n            else {\n                \"chunk_size\": \"Not initialized\",\n                \"overlap_size\": \"Not initialized\",\n                \"chunk_type\": \"Not initialized\",\n            }\n        )\n\n        return {\n            \"collection\": collection,\n            \"system_initialized\": self.is_initialized,\n            \"database_manager\": {\n                \"url\": self.db_manager.url,\n                \"is_connected\": self.db_manager.is_connected,\n                \"collections\": self.db_manager.list_collections(),\n            },\n            \"vector_store\": vector_stats,\n            \"retrieval\": retrieval_stats,\n            \"embedding_engine\": embedding_info,\n            \"data_chunker\": chunker_config,\n            \"components\": {\n                \"database_manager\": \"Weaviate Infrastructure\",\n                \"vector_store\": \"Weaviate Storage\",\n                \"retriever\": \"Weaviate Search APIs\",\n                \"embedding_engine\": embedding_info[\"model_name\"],\n                \"document_preprocessor\": \"LaTeX Parser\",\n            },\n            \"architecture\": \"Three-Layer (DatabaseManager -&gt; VectorStore -&gt; Retriever)\",\n        }\n\n    except Exception as e:\n        self.logger.error(f\"Failed to get collection stats: {str(e)}\")\n        raise\n</code></pre>"},{"location":"api-reference/#ragora.core.knowledge_base_manager.KnowledgeBaseManager.list_collections","title":"<code>list_collections()</code>","text":"<p>List all available collections.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: List of collection names</p> Source code in <code>ragora/ragora/core/knowledge_base_manager.py</code> <pre><code>def list_collections(self) -&gt; List[str]:\n    \"\"\"List all available collections.\n\n    Returns:\n        List[str]: List of collection names\n    \"\"\"\n    return self.db_manager.list_collections()\n</code></pre>"},{"location":"api-reference/#ragora.core.knowledge_base_manager.KnowledgeBaseManager.process_document","title":"<code>process_document(document_path, document_type='latex', collection='Document')</code>","text":"<p>Process a single document and store it in the vector database.</p> <p>Parameters:</p> Name Type Description Default <code>document_path</code> <code>str</code> <p>Path to the document file</p> required <code>document_type</code> <code>str</code> <p>Type of document to process (\"latex\", \"markdown\", \"text\")</p> <code>'latex'</code> <code>collection</code> <code>str</code> <p>Collection name to store the document</p> <code>'Document'</code> <p>Returns:     List[str]: List of chunk IDs that were stored</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If document file doesn't exist</p> <code>ValueError</code> <p>If document processing fails</p> <p>Examples:     <pre><code>kb = KnowledgeBaseManager()\nkb.process_document(\"docs/tutorial.md\", document_type=\"markdown\")\n</code></pre></p> Source code in <code>ragora/ragora/core/knowledge_base_manager.py</code> <pre><code>def process_document(\n    self,\n    document_path: str,\n    document_type: str = \"latex\",\n    collection: str = \"Document\",\n) -&gt; List[str]:\n    \"\"\"Process a single document and store it in the vector database.\n\n    Args:\n        document_path: Path to the document file\n        document_type: Type of document to process (\"latex\", \"markdown\", \"text\")\n        collection: Collection name to store the document\n    Returns:\n        List[str]: List of chunk IDs that were stored\n\n    Raises:\n        FileNotFoundError: If document file doesn't exist\n        ValueError: If document processing fails\n    Examples:\n        ```python\n        kb = KnowledgeBaseManager()\n        kb.process_document(\"docs/tutorial.md\", document_type=\"markdown\")\n        ```\n\n    \"\"\"\n    if not self.is_initialized:\n        raise RuntimeError(\"Knowledge base manager not initialized\")\n\n    try:\n        self.logger.info(f\"Processing document: {document_path}\")\n\n        # Step 1: Preprocess the LaTeX document\n        self.logger.debug(f\"Step 1: Preprocessing {document_type} document\")\n        chunks = self.document_preprocessor.preprocess_document(\n            document_path, document_type\n        )\n\n        # Step 2: Store chunks in vector database\n        self.logger.debug(\n            f\"Step 2: Storing {len(chunks)} chunks in vector database\"\n        )\n        stored_uuids = self.vector_store.store_chunks(chunks, collection=collection)\n\n        self.logger.info(f\"Successfully processed document: {document_path}\")\n        self.logger.info(f\"Stored {len(stored_uuids)} chunks\")\n\n        return stored_uuids\n\n    except Exception as e:\n        self.logger.error(f\"Failed to process document {document_path}: {str(e)}\")\n        raise\n</code></pre>"},{"location":"api-reference/#ragora.core.knowledge_base_manager.KnowledgeBaseManager.process_documents","title":"<code>process_documents(document_paths, document_type='latex', collection='Document')</code>","text":"<p>Process a list of documents and store them in the vector database.</p> <p>Parameters:</p> Name Type Description Default <code>document_paths</code> <code>List[str]</code> <p>List of paths to the documents to ingest</p> required <code>document_type</code> <code>str</code> <p>Type of document to process (\"latex\", \"markdown\", \"text\")</p> <code>'latex'</code> <code>collection</code> <code>str</code> <p>Collection name to store the documents</p> <code>'Document'</code> <p>Returns:     List[str]: List of chunk IDs that were stored</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the manager is not initialized</p> <code>Exception</code> <p>If the documents cannot be processed</p> <p>Examples:</p> <pre><code>kb = KnowledgeBaseManager()\nkb.process_documents([\"notes.md\", \"report.tex\"], document_type=\"markdown\")\n</code></pre> Source code in <code>ragora/ragora/core/knowledge_base_manager.py</code> <pre><code>def process_documents(\n    self,\n    document_paths: List[str],\n    document_type: str = \"latex\",\n    collection: str = \"Document\",\n) -&gt; List[str]:\n    \"\"\"Process a list of documents and store them in the vector database.\n\n    Args:\n        document_paths: List of paths to the documents to ingest\n        document_type: Type of document to process (\"latex\", \"markdown\", \"text\")\n        collection: Collection name to store the documents\n    Returns:\n        List[str]: List of chunk IDs that were stored\n\n    Raises:\n        RuntimeError: If the manager is not initialized\n        Exception: If the documents cannot be processed\n\n    Examples:\n        ```python\n        kb = KnowledgeBaseManager()\n        kb.process_documents([\"notes.md\", \"report.tex\"], document_type=\"markdown\")\n        ```\n\n    \"\"\"\n    if not self.is_initialized:\n        raise RuntimeError(\"Knowledge base manager not initialized\")\n\n    try:\n        self.logger.info(f\"Processing {len(document_paths)} documents\")\n        chunks = self.document_preprocessor.preprocess_documents(\n            document_paths, document_type\n        )\n        self.logger.info(f\"Storing {len(chunks)} chunks in vector database\")\n        stored_uuids = self.vector_store.store_chunks(chunks, collection=collection)\n        self.logger.info(f\"Successfully processed {len(document_paths)} documents\")\n        self.logger.info(f\"Stored {len(stored_uuids)} chunks\")\n        return stored_uuids\n    except Exception as e:\n        self.logger.error(f\"Failed to process documents: {str(e)}\")\n        raise\n</code></pre>"},{"location":"api-reference/#ragora.core.knowledge_base_manager.KnowledgeBaseManager.process_email_account","title":"<code>process_email_account(email_provider, folder=None, unread_only=False, collection='Email')</code>","text":"<p>Process emails from an email account.</p> <p>Parameters:</p> Name Type Description Default <code>email_provider</code> <code>EmailProvider</code> <p>Email provider instance</p> required <code>folder</code> <code>Optional[str]</code> <p>Optional folder to process (None = all folders)</p> <code>None</code> <code>unread_only</code> <code>bool</code> <p>If True, only process unread emails</p> <code>False</code> <code>collection</code> <code>str</code> <p>Collection name to store the emails</p> <code>'Email'</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of stored chunk IDs</p> Source code in <code>ragora/ragora/core/knowledge_base_manager.py</code> <pre><code>def process_email_account(\n    self,\n    email_provider: EmailProvider,\n    folder: Optional[str] = None,\n    unread_only: bool = False,\n    collection: str = \"Email\",\n) -&gt; List[str]:\n    \"\"\"Process emails from an email account.\n\n    Args:\n        email_provider: Email provider instance\n        folder: Optional folder to process (None = all folders)\n        unread_only: If True, only process unread emails\n        collection: Collection name to store the emails\n\n    Returns:\n        List of stored chunk IDs\n    \"\"\"\n    if not self.is_initialized:\n        raise RuntimeError(\"Knowledge base manager not initialized\")\n\n    try:\n        # Auto-connect if needed\n        self._ensure_email_connection(email_provider)\n\n        # Fetch emails\n        emails = email_provider.fetch_messages(\n            limit=None, folder=folder, unread_only=unread_only\n        )\n\n        if not emails:\n            self.logger.info(\"No emails to process\")\n            return []\n\n        # Preprocess emails\n        self.logger.info(f\"Preprocessing {len(emails)} emails\")\n        chunks = self.email_preprocessor.preprocess_emails(emails)\n\n        # Store chunks\n        self.logger.info(f\"Storing {len(chunks)} chunks\")\n        stored_uuids = self.vector_store.store_chunks(chunks, collection=collection)\n\n        self.logger.info(f\"Successfully processed {len(emails)} emails\")\n        return stored_uuids\n\n    except Exception as e:\n        self.logger.error(f\"Failed to process email account: {str(e)}\")\n        raise\n</code></pre>"},{"location":"api-reference/#ragora.core.knowledge_base_manager.KnowledgeBaseManager.process_emails","title":"<code>process_emails(email_provider, email_ids, collection='Email')</code>","text":"<p>Process specific emails by their IDs.</p> <p>Parameters:</p> Name Type Description Default <code>email_provider</code> <code>EmailProvider</code> <p>Email provider instance</p> required <code>email_ids</code> <code>List[str]</code> <p>List of email IDs to process</p> required <code>collection</code> <code>str</code> <p>Collection name to store the emails</p> <code>'Email'</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of stored chunk IDs</p> Source code in <code>ragora/ragora/core/knowledge_base_manager.py</code> <pre><code>def process_emails(\n    self,\n    email_provider: EmailProvider,\n    email_ids: List[str],\n    collection: str = \"Email\",\n) -&gt; List[str]:\n    \"\"\"Process specific emails by their IDs.\n\n    Args:\n        email_provider: Email provider instance\n        email_ids: List of email IDs to process\n        collection: Collection name to store the emails\n\n    Returns:\n        List of stored chunk IDs\n    \"\"\"\n    if not self.is_initialized:\n        raise RuntimeError(\"Knowledge base manager not initialized\")\n\n    try:\n        # Auto-connect if needed\n        self._ensure_email_connection(email_provider)\n\n        # Fetch emails\n        emails = []\n        for email_id in email_ids:\n            email = email_provider.fetch_message_by_id(email_id)\n            if email:\n                emails.append(email)\n\n        if not emails:\n            self.logger.info(\"No emails found to process\")\n            return []\n\n        # Preprocess emails\n        self.logger.info(f\"Preprocessing {len(emails)} emails\")\n        chunks = self.email_preprocessor.preprocess_emails(emails)\n\n        # Store chunks\n        self.logger.info(f\"Storing {len(chunks)} chunks\")\n        stored_uuids = self.vector_store.store_chunks(chunks, collection=collection)\n\n        self.logger.info(f\"Successfully processed {len(emails)} emails\")\n        return stored_uuids\n\n    except Exception as e:\n        self.logger.error(f\"Failed to process emails: {str(e)}\")\n        raise\n</code></pre>"},{"location":"api-reference/#ragora.core.knowledge_base_manager.KnowledgeBaseManager.process_new_emails","title":"<code>process_new_emails(email_provider, email_ids, collection='Email')</code>","text":"<p>Process and store specific emails by their IDs.</p> <p>This method processes emails that have been identified by the user through check_new_emails() and filtered as needed.</p> <p>Parameters:</p> Name Type Description Default <code>email_provider</code> <code>EmailProvider</code> <p>Email provider instance</p> required <code>email_ids</code> <code>List[str]</code> <p>List of email IDs to process (required)</p> required <code>collection</code> <code>str</code> <p>Collection name to store the emails</p> <code>'Email'</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of stored chunk IDs</p> Source code in <code>ragora/ragora/core/knowledge_base_manager.py</code> <pre><code>def process_new_emails(\n    self,\n    email_provider: EmailProvider,\n    email_ids: List[str],\n    collection: str = \"Email\",\n) -&gt; List[str]:\n    \"\"\"Process and store specific emails by their IDs.\n\n    This method processes emails that have been identified by the user\n    through check_new_emails() and filtered as needed.\n\n    Args:\n        email_provider: Email provider instance\n        email_ids: List of email IDs to process (required)\n        collection: Collection name to store the emails\n\n    Returns:\n        List of stored chunk IDs\n    \"\"\"\n    if not self.is_initialized:\n        raise RuntimeError(\"Knowledge base manager not initialized\")\n\n    if not email_ids:\n        self.logger.warning(\"No email IDs provided\")\n        return []\n\n    try:\n        # Auto-connect if needed\n        self._ensure_email_connection(email_provider)\n\n        # Fetch specific emails by ID\n        emails = []\n        for email_id in email_ids:\n            email = email_provider.fetch_message_by_id(email_id)\n            if email:\n                emails.append(email)\n            else:\n                self.logger.warning(f\"Email {email_id} not found\")\n\n        if not emails:\n            self.logger.info(\"No emails found to process\")\n            return []\n\n        # Preprocess emails\n        self.logger.info(f\"Preprocessing {len(emails)} emails\")\n        chunks = self.email_preprocessor.preprocess_emails(emails)\n\n        # Store chunks\n        self.logger.info(f\"Storing {len(chunks)} chunks\")\n        stored_uuids = self.vector_store.store_chunks(chunks, collection=collection)\n\n        self.logger.info(f\"Successfully processed {len(emails)} emails\")\n        return stored_uuids\n\n    except Exception as e:\n        self.logger.error(f\"Failed to process new emails: {str(e)}\")\n        raise\n</code></pre>"},{"location":"api-reference/#ragora.core.knowledge_base_manager.KnowledgeBaseManager.search","title":"<code>search(query, collection='Document', strategy=SearchStrategy.HYBRID, top_k=5, filter=None, **strategy_kwargs)</code>","text":"<p>Unified search interface for all data types and strategies.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>Search query text</p> required <code>collection</code> <code>str</code> <p>Collection name to search in</p> <code>'Document'</code> <code>strategy</code> <code>SearchStrategy</code> <p>Search strategy to use</p> <code>HYBRID</code> <code>top_k</code> <code>int</code> <p>Number of results to return</p> <code>5</code> <code>filter</code> <code>Optional[Filter]</code> <p>Optional Weaviate Filter to filter results by properties</p> <code>None</code> <code>**strategy_kwargs</code> <p>Strategy-specific parameters (alpha, score_threshold, etc.)</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>SearchResult</code> <code>SearchResult</code> <p>Structured search results with metadata</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If system not initialized</p> <code>ValueError</code> <p>If invalid strategy or empty query</p> <p>Examples:</p> <pre><code>kb = KnowledgeBaseManager()\nkb.process_document(\"docs/tutorial.md\", document_type=\"markdown\")\nresult = kb.search(\"introduction\", strategy=SearchStrategy.HYBRID, top_k=3)\nfor hit in result.results:\n    print(hit.metadata.title, hit.similarity_score)\n</code></pre> Source code in <code>ragora/ragora/core/knowledge_base_manager.py</code> <pre><code>def search(\n    self,\n    query: str,\n    collection: str = \"Document\",\n    strategy: SearchStrategy = SearchStrategy.HYBRID,\n    top_k: int = 5,\n    filter: Optional[Filter] = None,\n    **strategy_kwargs,\n) -&gt; SearchResult:\n    \"\"\"Unified search interface for all data types and strategies.\n\n    Args:\n        query: Search query text\n        collection: Collection name to search in\n        strategy: Search strategy to use\n        top_k: Number of results to return\n        filter: Optional Weaviate Filter to filter results by properties\n        **strategy_kwargs: Strategy-specific parameters\n            (alpha, score_threshold, etc.)\n\n    Returns:\n        SearchResult: Structured search results with metadata\n\n    Raises:\n        RuntimeError: If system not initialized\n        ValueError: If invalid strategy or empty query\n\n    Examples:\n        ```python\n        kb = KnowledgeBaseManager()\n        kb.process_document(\"docs/tutorial.md\", document_type=\"markdown\")\n        result = kb.search(\"introduction\", strategy=SearchStrategy.HYBRID, top_k=3)\n        for hit in result.results:\n            print(hit.metadata.title, hit.similarity_score)\n        ```\n    \"\"\"\n    if not self.is_initialized:\n        raise RuntimeError(\"Knowledge base manager not initialized\")\n\n    if not query or not query.strip():\n        raise ValueError(\"Query cannot be empty\")\n\n    start_time = time.time()\n\n    try:\n        self.logger.info(\n            f\"Processing search: '{query}' \"\n            f\"(strategy: {strategy.value if hasattr(strategy, 'value') else strategy}, collection: {collection})\"\n        )\n\n        # Execute search based on strategy\n        if strategy == SearchStrategy.SIMILAR:\n            results = self.retriever.search_similar(\n                query,\n                collection=collection,\n                top_k=top_k,\n                filter=filter,\n                **strategy_kwargs,\n            )\n        elif strategy == SearchStrategy.KEYWORD:\n            results = self.retriever.search_keyword(\n                query,\n                collection=collection,\n                top_k=top_k,\n                filter=filter,\n                **strategy_kwargs,\n            )\n        elif strategy == SearchStrategy.HYBRID:\n            results = self.retriever.search_hybrid(\n                query,\n                collection=collection,\n                top_k=top_k,\n                filter=filter,\n                **strategy_kwargs,\n            )\n        elif strategy == SearchStrategy.AUTO:\n            # For now, default to hybrid.\n            # Could be enhanced with automatic strategy selection\n            results = self.retriever.search_hybrid(\n                query,\n                collection=collection,\n                top_k=top_k,\n                filter=filter,\n                **strategy_kwargs,\n            )\n        else:\n            raise ValueError(f\"Invalid search strategy: {strategy}\")\n\n        execution_time = time.time() - start_time\n\n        # Prepare metadata\n        metadata = {\n            \"chunk_sources\": list(\n                set(\n                    result.properties.get(\"source_document\", \"\")\n                    or result.metadata.source_document\n                    or \"\"\n                    for result in results\n                )\n            ),\n            \"chunk_types\": list(\n                set(\n                    result.properties.get(\"chunk_type\", \"\")\n                    or result.metadata.chunk_type\n                    or \"\"\n                    for result in results\n                )\n            ),\n        }\n\n        # Add similarity scores if available\n        similarity_scores = [\n            result.similarity_score\n            for result in results\n            if result.similarity_score is not None\n        ]\n\n        if similarity_scores:\n            metadata[\"avg_similarity\"] = sum(similarity_scores) / len(\n                similarity_scores\n            )\n            metadata[\"max_similarity\"] = max(similarity_scores)\n\n        self.logger.info(\n            f\"Search completed: {len(results)} results in {execution_time:.3f}s\"\n        )\n\n        # Convert strategy enum to string for SearchResult\n        strategy_str = (\n            strategy.value if hasattr(strategy, \"value\") else str(strategy)\n        )\n\n        results_dicts = [item.model_dump() for item in results]\n\n        # Use model_validate for proper nested model validation in Pydantic 2.x\n        return SearchResult.model_validate(\n            {\n                \"query\": query,\n                \"strategy\": strategy_str,\n                \"collection\": collection,\n                \"results\": results_dicts,\n                \"total_found\": len(results),\n                \"execution_time\": execution_time,\n                \"metadata\": metadata,\n            }\n        )\n\n    except Exception as e:\n        self.logger.error(f\"Search failed: {str(e)}\")\n        raise\n</code></pre>"},{"location":"api-reference/#ragora.core.knowledge_base_manager.SearchResult","title":"<code>SearchResult</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Container for search results with query metadata.</p> <p>Provides a structured container for search results including the query, strategy, results list, and execution metadata.</p> Source code in <code>ragora/ragora/core/knowledge_base_manager.py</code> <pre><code>class SearchResult(BaseModel):\n    \"\"\"Container for search results with query metadata.\n\n    Provides a structured container for search results including\n    the query, strategy, results list, and execution metadata.\n    \"\"\"\n\n    query: str = Field(..., description=\"Search query text\")\n    strategy: str = Field(..., description=\"Search strategy used\")\n    collection: str = Field(..., description=\"Collection searched\")\n    results: List[SearchResultItem] = Field(\n        default_factory=list, description=\"List of search result items\"\n    )\n    total_found: int = Field(..., ge=0, description=\"Total number of results found\")\n    execution_time: float = Field(..., ge=0.0, description=\"Execution time in seconds\")\n    metadata: Dict[str, Any] = Field(\n        default_factory=dict,\n        description=\"Additional metadata about the search\",\n    )\n</code></pre>"},{"location":"api-reference/#ragora.core.knowledge_base_manager.SearchStrategy","title":"<code>SearchStrategy</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Search strategy enumeration.</p> Source code in <code>ragora/ragora/core/knowledge_base_manager.py</code> <pre><code>class SearchStrategy(Enum):\n    \"\"\"Search strategy enumeration.\"\"\"\n\n    SIMILAR = \"similar\"  # Vector similarity only\n    KEYWORD = \"keyword\"  # BM25 keyword search only\n    HYBRID = \"hybrid\"  # Combined vector + keyword\n    AUTO = \"auto\"  # Automatically choose best strategy\n</code></pre>"},{"location":"api-reference/#models","title":"Models","text":"<p>Domain models for retrieval results.</p> <p>This module contains the core data models used for retrieval operations in the RAG system. These models represent the structured data returned from search and retrieval operations, providing type-safe access to chunk content, metadata, and search scores.</p> <p>Key Models: - RetrievalMetadata: Structured metadata extracted from stored properties - RetrievalResultItem: Base class for all chunk retrieval results - SearchResultItem: Search results with scores (extends RetrievalResultItem) - EmailMessageModel: Pydantic model for email messages (compatible with EmailMessage) - EmailListResult: Container for email list results with metadata</p>"},{"location":"api-reference/#ragora.core.models.EmailAddressModel","title":"<code>EmailAddressModel</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Pydantic model for email address representation.</p> <p>This model ensures 'email' is always required and non-null, while 'name' remains optional. Provides validation and a rich data model interface similar to EmailAddress dataclass.</p> <p>Attributes:</p> Name Type Description <code>email</code> <code>str</code> <p>Required, non-null email address</p> <code>name</code> <code>Optional[str]</code> <p>Optional display name</p> Source code in <code>ragora/ragora/core/models.py</code> <pre><code>class EmailAddressModel(BaseModel):\n    \"\"\"Pydantic model for email address representation.\n\n    This model ensures 'email' is always required and non-null,\n    while 'name' remains optional. Provides validation and a rich\n    data model interface similar to EmailAddress dataclass.\n\n    Attributes:\n        email: Required, non-null email address\n        name: Optional display name\n    \"\"\"\n\n    email: str = Field(..., description=\"Email address (required)\")\n    name: Optional[str] = Field(default=None, description=\"Display name (optional)\")\n\n    def __str__(self) -&gt; str:\n        \"\"\"String representation matching EmailAddress format.\"\"\"\n        if self.name:\n            return f\"{self.name} &lt;{self.email}&gt;\"\n        return self.email\n\n    def to_email_address(self) -&gt; \"EmailAddress\":\n        \"\"\"Convert to EmailAddress dataclass.\n\n        Returns:\n            EmailAddress: EmailAddress dataclass instance\n        \"\"\"\n        return EmailAddress(email=self.email, name=self.name)\n\n    @classmethod\n    def from_email_address(cls, address: \"EmailAddress\") -&gt; \"EmailAddressModel\":\n        \"\"\"Create EmailAddressModel from EmailAddress dataclass.\n\n        Args:\n            address: EmailAddress dataclass instance\n\n        Returns:\n            EmailAddressModel: EmailAddressModel instance\n        \"\"\"\n        return cls(email=address.email, name=address.name)\n</code></pre>"},{"location":"api-reference/#ragora.core.models.EmailAddressModel.from_email_address","title":"<code>from_email_address(address)</code>  <code>classmethod</code>","text":"<p>Create EmailAddressModel from EmailAddress dataclass.</p> <p>Parameters:</p> Name Type Description Default <code>address</code> <code>EmailAddress</code> <p>EmailAddress dataclass instance</p> required <p>Returns:</p> Name Type Description <code>EmailAddressModel</code> <code>EmailAddressModel</code> <p>EmailAddressModel instance</p> Source code in <code>ragora/ragora/core/models.py</code> <pre><code>@classmethod\ndef from_email_address(cls, address: \"EmailAddress\") -&gt; \"EmailAddressModel\":\n    \"\"\"Create EmailAddressModel from EmailAddress dataclass.\n\n    Args:\n        address: EmailAddress dataclass instance\n\n    Returns:\n        EmailAddressModel: EmailAddressModel instance\n    \"\"\"\n    return cls(email=address.email, name=address.name)\n</code></pre>"},{"location":"api-reference/#ragora.core.models.EmailAddressModel.to_email_address","title":"<code>to_email_address()</code>","text":"<p>Convert to EmailAddress dataclass.</p> <p>Returns:</p> Name Type Description <code>EmailAddress</code> <code>EmailAddress</code> <p>EmailAddress dataclass instance</p> Source code in <code>ragora/ragora/core/models.py</code> <pre><code>def to_email_address(self) -&gt; \"EmailAddress\":\n    \"\"\"Convert to EmailAddress dataclass.\n\n    Returns:\n        EmailAddress: EmailAddress dataclass instance\n    \"\"\"\n    return EmailAddress(email=self.email, name=self.name)\n</code></pre>"},{"location":"api-reference/#ragora.core.models.EmailListResult","title":"<code>EmailListResult</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Container for email list results with metadata.</p> <p>Provides a structured container for email list results including the list of emails, count, folder searched, and execution metadata. Similar pattern to SearchResult for consistency.</p> Source code in <code>ragora/ragora/core/models.py</code> <pre><code>class EmailListResult(BaseModel):\n    \"\"\"Container for email list results with metadata.\n\n    Provides a structured container for email list results including\n    the list of emails, count, folder searched, and execution metadata.\n    Similar pattern to SearchResult for consistency.\n    \"\"\"\n\n    emails: List[EmailMessageModel] = Field(\n        default_factory=list, description=\"List of email items\"\n    )\n    count: int = Field(..., ge=0, description=\"Total number of emails found\")\n    folder: Optional[str] = Field(\n        default=None, description=\"Folder that was searched (None = all folders)\"\n    )\n    execution_time: float = Field(..., ge=0.0, description=\"Execution time in seconds\")\n    metadata: Dict[str, Any] = Field(\n        default_factory=dict,\n        description=\"Additional metadata about the email fetch operation\",\n    )\n\n    @model_validator(mode=\"after\")\n    def validate_count_matches_emails(self) -&gt; \"EmailListResult\":\n        \"\"\"Validate that count matches the actual number of emails.\n\n        This ensures data consistency and prevents mismatched counts.\n        \"\"\"\n        if self.count != len(self.emails):\n            raise ValueError(\n                f\"Count ({self.count}) does not match the number of emails \"\n                f\"({len(self.emails)})\"\n            )\n        return self\n\n    @property\n    def email_messages(self) -&gt; List[\"EmailMessage\"]:\n        \"\"\"Convert EmailMessageModel list to EmailMessage list for compatibility.\n\n        Returns:\n            List[EmailMessage]: List of EmailMessage dataclass instances\n\n        Raises:\n            ImportError: If email_utils.models cannot be imported\n        \"\"\"\n        return [email_item.to_email_message() for email_item in self.emails]\n</code></pre>"},{"location":"api-reference/#ragora.core.models.EmailListResult.email_messages","title":"<code>email_messages</code>  <code>property</code>","text":"<p>Convert EmailMessageModel list to EmailMessage list for compatibility.</p> <p>Returns:</p> Type Description <code>List[EmailMessage]</code> <p>List[EmailMessage]: List of EmailMessage dataclass instances</p> <p>Raises:</p> Type Description <code>ImportError</code> <p>If email_utils.models cannot be imported</p>"},{"location":"api-reference/#ragora.core.models.EmailListResult.validate_count_matches_emails","title":"<code>validate_count_matches_emails()</code>","text":"<p>Validate that count matches the actual number of emails.</p> <p>This ensures data consistency and prevents mismatched counts.</p> Source code in <code>ragora/ragora/core/models.py</code> <pre><code>@model_validator(mode=\"after\")\ndef validate_count_matches_emails(self) -&gt; \"EmailListResult\":\n    \"\"\"Validate that count matches the actual number of emails.\n\n    This ensures data consistency and prevents mismatched counts.\n    \"\"\"\n    if self.count != len(self.emails):\n        raise ValueError(\n            f\"Count ({self.count}) does not match the number of emails \"\n            f\"({len(self.emails)})\"\n        )\n    return self\n</code></pre>"},{"location":"api-reference/#ragora.core.models.EmailMessageModel","title":"<code>EmailMessageModel</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Pydantic model for email messages, compatible with EmailMessage dataclass.</p> <p>This model provides the same interface as EmailMessage but as a Pydantic model for better serialization, validation, and integration with other Pydantic-based APIs in the system.</p> <p>The model can be converted to/from EmailMessage dataclass for compatibility with EmailPreprocessor and other components that expect EmailMessage.</p> Source code in <code>ragora/ragora/core/models.py</code> <pre><code>class EmailMessageModel(BaseModel):\n    \"\"\"Pydantic model for email messages, compatible with EmailMessage dataclass.\n\n    This model provides the same interface as EmailMessage but as a Pydantic\n    model for better serialization, validation, and integration with other\n    Pydantic-based APIs in the system.\n\n    The model can be converted to/from EmailMessage dataclass for compatibility\n    with EmailPreprocessor and other components that expect EmailMessage.\n    \"\"\"\n\n    message_id: str = Field(..., description=\"Unique email message identifier\")\n    subject: str = Field(..., description=\"Email subject line\")\n    sender: EmailAddressModel = Field(\n        ...,\n        description=\"Email sender with required 'email' and optional 'name'\",\n    )\n    recipients: List[EmailAddressModel] = Field(\n        default_factory=list,\n        description=\"List of recipient email addresses\",\n    )\n    cc_recipients: List[EmailAddressModel] = Field(\n        default_factory=list, description=\"CC recipients\"\n    )\n    bcc_recipients: List[EmailAddressModel] = Field(\n        default_factory=list, description=\"BCC recipients\"\n    )\n    body_text: Optional[str] = Field(default=None, description=\"Plain text email body\")\n    body_html: Optional[str] = Field(default=None, description=\"HTML email body\")\n    date_sent: Optional[datetime] = Field(default=None, description=\"Email send date\")\n    date_received: Optional[datetime] = Field(\n        default=None, description=\"Email received date\"\n    )\n    status: str = Field(\n        default=\"unread\", description=\"Email status (unread, read, draft, sent, trash)\"\n    )\n    attachments: List[Dict[str, Any]] = Field(\n        default_factory=list, description=\"Email attachments as list of dicts\"\n    )\n    thread_id: Optional[str] = Field(default=None, description=\"Email thread ID\")\n    conversation_id: Optional[str] = Field(\n        default=None, description=\"Email conversation ID\"\n    )\n    folder: Optional[str] = Field(default=None, description=\"Email folder/path\")\n    metadata: Dict[str, Any] = Field(\n        default_factory=dict, description=\"Additional email metadata\"\n    )\n\n    def get_body(self) -&gt; str:\n        \"\"\"Get the best available body content (HTML preferred, fallback to text).\n\n        This method matches the EmailMessage.get_body() interface for compatibility.\n\n        Returns:\n            str: Email body content (HTML if available, otherwise text)\n        \"\"\"\n        return self.body_html if self.body_html else (self.body_text or \"\")\n\n    def get_all_recipients(self) -&gt; List[EmailAddressModel]:\n        \"\"\"Get all recipients including CC and BCC.\n\n        Returns:\n            List of EmailAddressModel instances (recipients + cc_recipients + bcc_recipients)\n        \"\"\"\n        return self.recipients + self.cc_recipients + self.bcc_recipients\n\n    def to_email_message(self) -&gt; \"EmailMessage\":\n        \"\"\"Convert EmailMessageModel to EmailMessage dataclass.\n\n        Returns:\n            EmailMessage: EmailMessage dataclass instance\n\n        Raises:\n            ImportError: If email_utils.models cannot be imported\n        \"\"\"\n\n        # Convert sender EmailAddressModel to EmailAddress\n        sender_addr = self.sender.to_email_address()\n\n        # Convert recipients\n        recipients_list = [r.to_email_address() for r in self.recipients]\n        cc_list = [r.to_email_address() for r in self.cc_recipients]\n        bcc_list = [r.to_email_address() for r in self.bcc_recipients]\n\n        # Convert attachments\n        attachments_list = []\n        for att in self.attachments:\n            attachments_list.append(\n                EmailAttachment(\n                    filename=att.get(\"filename\", \"\"),\n                    content_type=att.get(\"content_type\", \"\"),\n                    size=att.get(\"size\", 0),\n                    content=att.get(\"content\"),\n                    content_id=att.get(\"content_id\"),\n                )\n            )\n\n        # Convert status string to enum\n        status_enum = MessageStatus.UNREAD\n        if self.status:\n            try:\n                status_enum = MessageStatus(self.status.lower())\n            except ValueError:\n                status_enum = MessageStatus.UNREAD\n\n        return EmailMessage(\n            message_id=self.message_id,\n            subject=self.subject,\n            sender=sender_addr,\n            recipients=recipients_list,\n            cc_recipients=cc_list,\n            bcc_recipients=bcc_list,\n            body_text=self.body_text,\n            body_html=self.body_html,\n            date_sent=self.date_sent,\n            date_received=self.date_received,\n            status=status_enum,\n            attachments=attachments_list,\n            thread_id=self.thread_id,\n            conversation_id=self.conversation_id,\n            folder=self.folder,\n            metadata=self.metadata,\n        )\n\n    @classmethod\n    def from_email_message(cls, email: \"EmailMessage\") -&gt; \"EmailMessageModel\":\n        \"\"\"Create EmailMessageModel from EmailMessage dataclass.\n\n        Args:\n            email: EmailMessage dataclass instance\n\n        Returns:\n            EmailMessageModel: EmailMessageModel Pydantic model instance\n        \"\"\"\n        # Convert sender EmailAddress to EmailAddressModel\n        sender_model = EmailAddressModel.from_email_address(email.sender)\n\n        # Convert recipients\n        recipients_list = [\n            EmailAddressModel.from_email_address(r) for r in email.recipients\n        ]\n        cc_list = [EmailAddressModel.from_email_address(r) for r in email.cc_recipients]\n        bcc_list = [\n            EmailAddressModel.from_email_address(r) for r in email.bcc_recipients\n        ]\n\n        # Convert attachments\n        attachments_list = [\n            {\n                \"filename\": att.filename,\n                \"content_type\": att.content_type,\n                \"size\": att.size,\n                \"content\": att.content,\n                \"content_id\": att.content_id,\n            }\n            for att in email.attachments\n        ]\n\n        return cls(\n            message_id=email.message_id,\n            subject=email.subject,\n            sender=sender_model,\n            recipients=recipients_list,\n            cc_recipients=cc_list,\n            bcc_recipients=bcc_list,\n            body_text=email.body_text,\n            body_html=email.body_html,\n            date_sent=email.date_sent,\n            date_received=email.date_received,\n            status=email.status.value if email.status else \"unread\",\n            attachments=attachments_list,\n            thread_id=email.thread_id,\n            conversation_id=email.conversation_id,\n            folder=email.folder,\n            metadata=email.metadata,\n        )\n</code></pre>"},{"location":"api-reference/#ragora.core.models.EmailMessageModel.from_email_message","title":"<code>from_email_message(email)</code>  <code>classmethod</code>","text":"<p>Create EmailMessageModel from EmailMessage dataclass.</p> <p>Parameters:</p> Name Type Description Default <code>email</code> <code>EmailMessage</code> <p>EmailMessage dataclass instance</p> required <p>Returns:</p> Name Type Description <code>EmailMessageModel</code> <code>EmailMessageModel</code> <p>EmailMessageModel Pydantic model instance</p> Source code in <code>ragora/ragora/core/models.py</code> <pre><code>@classmethod\ndef from_email_message(cls, email: \"EmailMessage\") -&gt; \"EmailMessageModel\":\n    \"\"\"Create EmailMessageModel from EmailMessage dataclass.\n\n    Args:\n        email: EmailMessage dataclass instance\n\n    Returns:\n        EmailMessageModel: EmailMessageModel Pydantic model instance\n    \"\"\"\n    # Convert sender EmailAddress to EmailAddressModel\n    sender_model = EmailAddressModel.from_email_address(email.sender)\n\n    # Convert recipients\n    recipients_list = [\n        EmailAddressModel.from_email_address(r) for r in email.recipients\n    ]\n    cc_list = [EmailAddressModel.from_email_address(r) for r in email.cc_recipients]\n    bcc_list = [\n        EmailAddressModel.from_email_address(r) for r in email.bcc_recipients\n    ]\n\n    # Convert attachments\n    attachments_list = [\n        {\n            \"filename\": att.filename,\n            \"content_type\": att.content_type,\n            \"size\": att.size,\n            \"content\": att.content,\n            \"content_id\": att.content_id,\n        }\n        for att in email.attachments\n    ]\n\n    return cls(\n        message_id=email.message_id,\n        subject=email.subject,\n        sender=sender_model,\n        recipients=recipients_list,\n        cc_recipients=cc_list,\n        bcc_recipients=bcc_list,\n        body_text=email.body_text,\n        body_html=email.body_html,\n        date_sent=email.date_sent,\n        date_received=email.date_received,\n        status=email.status.value if email.status else \"unread\",\n        attachments=attachments_list,\n        thread_id=email.thread_id,\n        conversation_id=email.conversation_id,\n        folder=email.folder,\n        metadata=email.metadata,\n    )\n</code></pre>"},{"location":"api-reference/#ragora.core.models.EmailMessageModel.get_all_recipients","title":"<code>get_all_recipients()</code>","text":"<p>Get all recipients including CC and BCC.</p> <p>Returns:</p> Type Description <code>List[EmailAddressModel]</code> <p>List of EmailAddressModel instances (recipients + cc_recipients + bcc_recipients)</p> Source code in <code>ragora/ragora/core/models.py</code> <pre><code>def get_all_recipients(self) -&gt; List[EmailAddressModel]:\n    \"\"\"Get all recipients including CC and BCC.\n\n    Returns:\n        List of EmailAddressModel instances (recipients + cc_recipients + bcc_recipients)\n    \"\"\"\n    return self.recipients + self.cc_recipients + self.bcc_recipients\n</code></pre>"},{"location":"api-reference/#ragora.core.models.EmailMessageModel.get_body","title":"<code>get_body()</code>","text":"<p>Get the best available body content (HTML preferred, fallback to text).</p> <p>This method matches the EmailMessage.get_body() interface for compatibility.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Email body content (HTML if available, otherwise text)</p> Source code in <code>ragora/ragora/core/models.py</code> <pre><code>def get_body(self) -&gt; str:\n    \"\"\"Get the best available body content (HTML preferred, fallback to text).\n\n    This method matches the EmailMessage.get_body() interface for compatibility.\n\n    Returns:\n        str: Email body content (HTML if available, otherwise text)\n    \"\"\"\n    return self.body_html if self.body_html else (self.body_text or \"\")\n</code></pre>"},{"location":"api-reference/#ragora.core.models.EmailMessageModel.to_email_message","title":"<code>to_email_message()</code>","text":"<p>Convert EmailMessageModel to EmailMessage dataclass.</p> <p>Returns:</p> Name Type Description <code>EmailMessage</code> <code>EmailMessage</code> <p>EmailMessage dataclass instance</p> <p>Raises:</p> Type Description <code>ImportError</code> <p>If email_utils.models cannot be imported</p> Source code in <code>ragora/ragora/core/models.py</code> <pre><code>def to_email_message(self) -&gt; \"EmailMessage\":\n    \"\"\"Convert EmailMessageModel to EmailMessage dataclass.\n\n    Returns:\n        EmailMessage: EmailMessage dataclass instance\n\n    Raises:\n        ImportError: If email_utils.models cannot be imported\n    \"\"\"\n\n    # Convert sender EmailAddressModel to EmailAddress\n    sender_addr = self.sender.to_email_address()\n\n    # Convert recipients\n    recipients_list = [r.to_email_address() for r in self.recipients]\n    cc_list = [r.to_email_address() for r in self.cc_recipients]\n    bcc_list = [r.to_email_address() for r in self.bcc_recipients]\n\n    # Convert attachments\n    attachments_list = []\n    for att in self.attachments:\n        attachments_list.append(\n            EmailAttachment(\n                filename=att.get(\"filename\", \"\"),\n                content_type=att.get(\"content_type\", \"\"),\n                size=att.get(\"size\", 0),\n                content=att.get(\"content\"),\n                content_id=att.get(\"content_id\"),\n            )\n        )\n\n    # Convert status string to enum\n    status_enum = MessageStatus.UNREAD\n    if self.status:\n        try:\n            status_enum = MessageStatus(self.status.lower())\n        except ValueError:\n            status_enum = MessageStatus.UNREAD\n\n    return EmailMessage(\n        message_id=self.message_id,\n        subject=self.subject,\n        sender=sender_addr,\n        recipients=recipients_list,\n        cc_recipients=cc_list,\n        bcc_recipients=bcc_list,\n        body_text=self.body_text,\n        body_html=self.body_html,\n        date_sent=self.date_sent,\n        date_received=self.date_received,\n        status=status_enum,\n        attachments=attachments_list,\n        thread_id=self.thread_id,\n        conversation_id=self.conversation_id,\n        folder=self.folder,\n        metadata=self.metadata,\n    )\n</code></pre>"},{"location":"api-reference/#ragora.core.models.RetrievalMetadata","title":"<code>RetrievalMetadata</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Structured metadata for search results.</p> <p>Extracts and organizes metadata fields from stored properties, providing type-safe access to chunk, document, and email metadata.</p> Source code in <code>ragora/ragora/core/models.py</code> <pre><code>class RetrievalMetadata(BaseModel):\n    \"\"\"Structured metadata for search results.\n\n    Extracts and organizes metadata fields from stored properties,\n    providing type-safe access to chunk, document, and email metadata.\n    \"\"\"\n\n    # Chunk metadata\n    chunk_idx: Optional[int] = Field(default=None, description=\"Chunk index\")\n    chunk_size: Optional[int] = Field(default=None, description=\"Chunk size\")\n    total_chunks: Optional[int] = Field(\n        default=None, description=\"Total chunks in document\"\n    )\n    created_at: Optional[str] = Field(default=None, description=\"Creation timestamp\")\n\n    # Document metadata\n    source_document: Optional[str] = Field(\n        default=None, description=\"Source document filename\"\n    )\n    page_number: Optional[int] = Field(default=None, description=\"Page number\")\n    section_title: Optional[str] = Field(\n        default=None, description=\"Section or chapter title\"\n    )\n    chunk_type: Optional[str] = Field(\n        default=None,\n        description=\"Type of chunk (text, citation, equation, etc.)\",\n    )\n\n    # Email metadata\n    email_subject: Optional[str] = Field(default=None, description=\"Email subject line\")\n    email_sender: Optional[str] = Field(\n        default=None, description=\"Email sender address\"\n    )\n    email_recipient: Optional[str] = Field(\n        default=None, description=\"Email recipient address\"\n    )\n    email_date: Optional[str] = Field(default=None, description=\"Email timestamp\")\n    email_id: Optional[str] = Field(default=None, description=\"Unique email identifier\")\n    email_folder: Optional[str] = Field(default=None, description=\"Email folder/path\")\n\n    # Custom metadata\n    custom_metadata: Optional[Dict[str, Any]] = Field(\n        default=None, description=\"Custom metadata dictionary\"\n    )\n    language: Optional[str] = Field(\n        default=None, description=\"Content language (e.g., en, es, fr)\"\n    )\n    domain: Optional[str] = Field(\n        default=None,\n        description=\"Content domain (e.g., scientific, legal, medical)\",\n    )\n    confidence: Optional[float] = Field(\n        default=None, description=\"Processing confidence score (0.0-1.0)\"\n    )\n    tags: Optional[str] = Field(\n        default=None, description=\"Comma-separated tags/categories\"\n    )\n    priority: Optional[int] = Field(\n        default=None, description=\"Content priority/importance level\"\n    )\n    content_category: Optional[str] = Field(\n        default=None, description=\"Fine-grained content categorization\"\n    )\n\n    @classmethod\n    def from_properties(cls, properties: Dict[str, Any]) -&gt; \"RetrievalMetadata\":\n        \"\"\"Create RetrievalMetadata from properties dictionary.\n\n        Args:\n            properties: Dictionary containing stored properties\n\n        Returns:\n            RetrievalMetadata instance\n        \"\"\"\n        # Parse custom_metadata JSON string if present\n        custom_meta = properties.get(\"custom_metadata\")\n        if custom_meta:\n            if isinstance(custom_meta, str):\n                try:\n                    custom_meta = json.loads(custom_meta) if custom_meta else None\n                except (json.JSONDecodeError, TypeError):\n                    custom_meta = None\n            elif not isinstance(custom_meta, dict):\n                custom_meta = None\n        else:\n            custom_meta = None\n\n        return cls(\n            chunk_idx=properties.get(\"metadata_chunk_idx\"),\n            chunk_size=properties.get(\"metadata_chunk_size\"),\n            total_chunks=properties.get(\"metadata_total_chunks\"),\n            created_at=properties.get(\"metadata_created_at\")\n            or properties.get(\"created_at\"),\n            source_document=properties.get(\"source_document\"),\n            page_number=properties.get(\"page_number\"),\n            section_title=properties.get(\"section_title\"),\n            chunk_type=properties.get(\"chunk_type\"),\n            email_subject=properties.get(\"email_subject\"),\n            email_sender=properties.get(\"email_sender\"),\n            email_recipient=properties.get(\"email_recipient\"),\n            email_date=properties.get(\"email_date\"),\n            email_id=properties.get(\"email_id\"),\n            email_folder=properties.get(\"email_folder\"),\n            custom_metadata=custom_meta,\n            language=properties.get(\"language\"),\n            domain=properties.get(\"domain\"),\n            confidence=properties.get(\"confidence\"),\n            tags=properties.get(\"tags\"),\n            priority=properties.get(\"priority\"),\n            content_category=properties.get(\"content_category\"),\n        )\n</code></pre>"},{"location":"api-reference/#ragora.core.models.RetrievalMetadata.from_properties","title":"<code>from_properties(properties)</code>  <code>classmethod</code>","text":"<p>Create RetrievalMetadata from properties dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>properties</code> <code>Dict[str, Any]</code> <p>Dictionary containing stored properties</p> required <p>Returns:</p> Type Description <code>RetrievalMetadata</code> <p>RetrievalMetadata instance</p> Source code in <code>ragora/ragora/core/models.py</code> <pre><code>@classmethod\ndef from_properties(cls, properties: Dict[str, Any]) -&gt; \"RetrievalMetadata\":\n    \"\"\"Create RetrievalMetadata from properties dictionary.\n\n    Args:\n        properties: Dictionary containing stored properties\n\n    Returns:\n        RetrievalMetadata instance\n    \"\"\"\n    # Parse custom_metadata JSON string if present\n    custom_meta = properties.get(\"custom_metadata\")\n    if custom_meta:\n        if isinstance(custom_meta, str):\n            try:\n                custom_meta = json.loads(custom_meta) if custom_meta else None\n            except (json.JSONDecodeError, TypeError):\n                custom_meta = None\n        elif not isinstance(custom_meta, dict):\n            custom_meta = None\n    else:\n        custom_meta = None\n\n    return cls(\n        chunk_idx=properties.get(\"metadata_chunk_idx\"),\n        chunk_size=properties.get(\"metadata_chunk_size\"),\n        total_chunks=properties.get(\"metadata_total_chunks\"),\n        created_at=properties.get(\"metadata_created_at\")\n        or properties.get(\"created_at\"),\n        source_document=properties.get(\"source_document\"),\n        page_number=properties.get(\"page_number\"),\n        section_title=properties.get(\"section_title\"),\n        chunk_type=properties.get(\"chunk_type\"),\n        email_subject=properties.get(\"email_subject\"),\n        email_sender=properties.get(\"email_sender\"),\n        email_recipient=properties.get(\"email_recipient\"),\n        email_date=properties.get(\"email_date\"),\n        email_id=properties.get(\"email_id\"),\n        email_folder=properties.get(\"email_folder\"),\n        custom_metadata=custom_meta,\n        language=properties.get(\"language\"),\n        domain=properties.get(\"domain\"),\n        confidence=properties.get(\"confidence\"),\n        tags=properties.get(\"tags\"),\n        priority=properties.get(\"priority\"),\n        content_category=properties.get(\"content_category\"),\n    )\n</code></pre>"},{"location":"api-reference/#ragora.core.models.RetrievalResultItem","title":"<code>RetrievalResultItem</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Base class for all chunk retrieval results.</p> <p>Contains common fields shared by both direct retrieval and search results. This base class provides the core chunk data without retrieval-specific context.</p> Source code in <code>ragora/ragora/core/models.py</code> <pre><code>class RetrievalResultItem(BaseModel):\n    \"\"\"Base class for all chunk retrieval results.\n\n    Contains common fields shared by both direct retrieval and search\n    results. This base class provides the core chunk data without\n    retrieval-specific context.\n    \"\"\"\n\n    # Core content\n    content: str = Field(..., description=\"Text content of the chunk\")\n    chunk_id: str = Field(..., description=\"Unique chunk identifier\")\n\n    # All stored properties (full dict for backward compatibility)\n    properties: Dict[str, Any] = Field(\n        default_factory=dict,\n        description=\"All stored properties from the vector database\",\n    )\n\n    # Structured metadata\n    metadata: RetrievalMetadata = Field(\n        default_factory=RetrievalMetadata,\n        description=\"Structured metadata extracted from properties\",\n    )\n</code></pre>"},{"location":"api-reference/#ragora.core.models.SearchResultItem","title":"<code>SearchResultItem</code>","text":"<p>               Bases: <code>RetrievalResultItem</code></p> <p>Search result item extending base retrieval result.</p> <p>Adds search-specific context: scores, retrieval method, and timestamp. Score fields correspond to Weaviate GraphQL search operators (https://weaviate.io/developers/weaviate/api/graphql/search-operators):</p> <ul> <li><code>distance</code> - metadata from <code>collection.query.near_text</code> (lower is   closer)</li> <li><code>hybrid_score</code> - metadata from <code>collection.query.hybrid</code> (alpha mix)</li> <li><code>bm25_score</code> - metadata from <code>collection.query.bm25</code> (lexical match)</li> <li><code>similarity_score</code> - derived <code>1 - distance</code> for vector/hybrid   results; keyword searches leave it empty</li> </ul> Source code in <code>ragora/ragora/core/models.py</code> <pre><code>class SearchResultItem(RetrievalResultItem):\n    \"\"\"Search result item extending base retrieval result.\n\n    Adds search-specific context: scores, retrieval method, and timestamp.\n    Score fields correspond to Weaviate GraphQL search operators\n    (https://weaviate.io/developers/weaviate/api/graphql/search-operators):\n\n    * ``distance`` - metadata from ``collection.query.near_text`` (lower is\n      closer)\n    * ``hybrid_score`` - metadata from ``collection.query.hybrid`` (alpha mix)\n    * ``bm25_score`` - metadata from ``collection.query.bm25`` (lexical match)\n    * ``similarity_score`` - derived ``1 - distance`` for vector/hybrid\n      results; keyword searches leave it empty\n    \"\"\"\n\n    # Retrieval scores\n    similarity_score: Optional[float] = Field(\n        default=None,\n        ge=0.0,\n        le=1.0,\n        description=(\n            \"Vector similarity in the 0-1 range. Populated for near_text and \"\n            \"hybrid results as 1 - distance. Keyword (BM25) searches leave it \"\n            \"empty.\"\n        ),\n    )\n    distance: Optional[float] = Field(\n        default=None,\n        description=(\n            \"Raw vector distance returned by Weaviate near_text queries. \"\n            \"Lower values indicate higher semantic similarity.\"\n        ),\n    )\n    hybrid_score: Optional[float] = Field(\n        default=None,\n        description=(\n            \"Combined relevance from Weaviate hybrid search. Represents the \"\n            \"alpha-weighted blend of vector similarity and BM25 scores.\"\n        ),\n    )\n    bm25_score: Optional[float] = Field(\n        default=None,\n        description=(\n            \"Unbounded BM25 relevance score returned by Weaviate bm25 queries. \"\n            \"Higher values indicate stronger lexical matches.\"\n        ),\n    )\n\n    # Retrieval context\n    retrieval_method: Literal[\n        \"vector_similarity\", \"hybrid_search\", \"keyword_search\"\n    ] = Field(..., description=\"Method used for retrieval\")\n    retrieval_timestamp: datetime = Field(\n        default_factory=datetime.now,\n        description=\"Timestamp when retrieval occurred\",\n    )\n\n    # Convenience properties for email results\n    @property\n    def subject(self) -&gt; Optional[str]:\n        \"\"\"Email subject (if applicable).\"\"\"\n        return self.properties.get(\"email_subject\") or self.metadata.email_subject\n\n    @property\n    def sender(self) -&gt; Optional[str]:\n        \"\"\"Email sender (if applicable).\"\"\"\n        return self.properties.get(\"email_sender\") or self.metadata.email_sender\n\n    @field_validator(\"retrieval_timestamp\", mode=\"before\")\n    @classmethod\n    def parse_timestamp(cls, v: Any) -&gt; datetime:\n        \"\"\"Parse timestamp from string or datetime.\n\n        Args:\n            v: Timestamp value (datetime or ISO format string)\n\n        Returns:\n            datetime: Parsed datetime object\n\n        Raises:\n            ValueError: If the value cannot be parsed into a valid datetime\n        \"\"\"\n        if isinstance(v, datetime):\n            return v\n        if isinstance(v, str):\n            try:\n                return datetime.fromisoformat(v.replace(\"Z\", \"+00:00\"))\n            except (ValueError, AttributeError) as e:\n                raise ValueError(\n                    f\"Invalid timestamp string format: {v}. \"\n                    f\"Expected ISO 8601 format (e.g., '2024-01-15T14:30:00Z').\"\n                ) from e\n        if v is None:\n            raise ValueError(\n                \"retrieval_timestamp cannot be None. \"\n                \"If not provided, it will default to the current time.\"\n            )\n        raise ValueError(\n            f\"Invalid timestamp type: {type(v).__name__}. \"\n            f\"Expected datetime or ISO 8601 format string.\"\n        )\n</code></pre>"},{"location":"api-reference/#ragora.core.models.SearchResultItem.sender","title":"<code>sender</code>  <code>property</code>","text":"<p>Email sender (if applicable).</p>"},{"location":"api-reference/#ragora.core.models.SearchResultItem.subject","title":"<code>subject</code>  <code>property</code>","text":"<p>Email subject (if applicable).</p>"},{"location":"api-reference/#ragora.core.models.SearchResultItem.parse_timestamp","title":"<code>parse_timestamp(v)</code>  <code>classmethod</code>","text":"<p>Parse timestamp from string or datetime.</p> <p>Parameters:</p> Name Type Description Default <code>v</code> <code>Any</code> <p>Timestamp value (datetime or ISO format string)</p> required <p>Returns:</p> Name Type Description <code>datetime</code> <code>datetime</code> <p>Parsed datetime object</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the value cannot be parsed into a valid datetime</p> Source code in <code>ragora/ragora/core/models.py</code> <pre><code>@field_validator(\"retrieval_timestamp\", mode=\"before\")\n@classmethod\ndef parse_timestamp(cls, v: Any) -&gt; datetime:\n    \"\"\"Parse timestamp from string or datetime.\n\n    Args:\n        v: Timestamp value (datetime or ISO format string)\n\n    Returns:\n        datetime: Parsed datetime object\n\n    Raises:\n        ValueError: If the value cannot be parsed into a valid datetime\n    \"\"\"\n    if isinstance(v, datetime):\n        return v\n    if isinstance(v, str):\n        try:\n            return datetime.fromisoformat(v.replace(\"Z\", \"+00:00\"))\n        except (ValueError, AttributeError) as e:\n            raise ValueError(\n                f\"Invalid timestamp string format: {v}. \"\n                f\"Expected ISO 8601 format (e.g., '2024-01-15T14:30:00Z').\"\n            ) from e\n    if v is None:\n        raise ValueError(\n            \"retrieval_timestamp cannot be None. \"\n            \"If not provided, it will default to the current time.\"\n        )\n    raise ValueError(\n        f\"Invalid timestamp type: {type(v).__name__}. \"\n        f\"Expected datetime or ISO 8601 format string.\"\n    )\n</code></pre>"},{"location":"api-reference/#retriever","title":"Retriever","text":"<p>Search utilities that power Ragora retrieval workflows.</p> <p>The :class:<code>Retriever</code> encapsulates vector, keyword, and hybrid search strategies while delegating persistence to :class:<code>~ragora.core.database_manager.DatabaseManager</code>.</p>"},{"location":"api-reference/#ragora.core.retriever.Retriever","title":"<code>Retriever</code>","text":"<p>Encapsulates reusable retrieval strategies for Ragora.</p> <p>Attributes:</p> Name Type Description <code>db_manager</code> <p>Database access layer.</p> <code>embedding_engine</code> <p>Optional embedding provider for custom workflows.</p> <code>logger</code> <p>Logger used for diagnostic output.</p> <p>Examples:</p> <pre><code>from ragora.core.database_manager import DatabaseManager\nfrom ragora.core.retriever import Retriever\n\ndb = DatabaseManager(url=\"http://localhost:8080\")\nretriever = Retriever(db_manager=db)\nhits = retriever.search_similar(\"neural networks\", collection=\"Document\")\n</code></pre> Source code in <code>ragora/ragora/core/retriever.py</code> <pre><code>class Retriever:\n    \"\"\"Encapsulates reusable retrieval strategies for Ragora.\n\n    Attributes:\n        db_manager: Database access layer.\n        embedding_engine: Optional embedding provider for custom workflows.\n        logger: Logger used for diagnostic output.\n\n    Examples:\n        ```python\n        from ragora.core.database_manager import DatabaseManager\n        from ragora.core.retriever import Retriever\n\n        db = DatabaseManager(url=\"http://localhost:8080\")\n        retriever = Retriever(db_manager=db)\n        hits = retriever.search_similar(\"neural networks\", collection=\"Document\")\n        ```\n    \"\"\"\n\n    def __init__(\n        self,\n        db_manager: DatabaseManager,\n        embedding_engine: Optional[EmbeddingEngine] = None,\n    ):\n        \"\"\"Initialize the Retriever.\n\n        Args:\n            db_manager: DatabaseManager instance for database access\n            embedding_engine: EmbeddingEngine instance\n                (optional, defaults to None)\n\n        Raises:\n            ValueError: If db_manager is None\n        \"\"\"\n        if db_manager is None:\n            raise ValueError(\"DatabaseManager cannot be None\")\n\n        self.db_manager = db_manager\n\n        # Note: Embedding engine is not needed when using Weaviate's\n        # text2vec-transformers. Weaviate handles embeddings server-side.\n        # EmbeddingEngine is only kept for potential future use cases where\n        # client-side embeddings might be needed. DO NOT initialize it by\n        # default to avoid unnecessary model loading.\n        self.embedding_engine = embedding_engine\n\n        self.logger = logging.getLogger(__name__)\n\n    def search_similar(\n        self,\n        query: str,\n        collection: str,\n        top_k: int = 5,\n        score_threshold: float = 0.0,\n        filter: Optional[Filter] = None,\n    ) -&gt; List[SearchResultItem]:\n        \"\"\"Search for similar documents using vector similarity.\n\n        This method performs semantic search using vector embeddings to find\n        documents that are semantically similar to the query.\n\n        Args:\n            query: Search query text\n            collection: Collection name to search\n            top_k: Number of results to return\n            score_threshold: Minimum similarity score threshold\n            filter: Optional Weaviate Filter object to filter results\n\n        Returns:\n            List[SearchResultItem]: List of search result items\n\n        Raises:\n            ValueError: If query is empty\n\n        Examples:\n            ```python\n            hits = retriever.search_similar(\"rag pipeline\", \"Document\", top_k=10)\n            ```\n        \"\"\"\n        if not query or not query.strip():\n            raise ValueError(\"Query cannot be empty\")\n\n        try:\n            self.logger.debug(f\"Performing vector similarity search: '{query}'\")\n\n            # Preprocess query for better results\n            processed_query = self._preprocess_query(query)\n\n            # Get collection and execute search using Weaviate APIs\n            collection = self.db_manager.get_collection(collection)\n\n            # Use Weaviate's native near_text API\n            result = collection.query.near_text(\n                query=processed_query,\n                limit=top_k,\n                return_metadata=MetadataQuery(distance=True),\n                filters=filter,\n            )\n\n            # Process results\n            processed_results = self._process_vector_results(\n                result.objects, score_threshold\n            )\n\n            self.logger.debug(\n                f\"Found {len(processed_results)} similar results for: '{query}'\"\n            )\n            return processed_results\n\n        except Exception as e:\n            self.logger.error(f\"Vector similarity search failed: {str(e)}\")\n            raise\n\n    def search_hybrid(\n        self,\n        query: str,\n        collection: str,\n        top_k: int = 5,\n        alpha: float = 0.5,\n        score_threshold: float = 0.0,\n        filter: Optional[Filter] = None,\n    ) -&gt; List[SearchResultItem]:\n        \"\"\"Perform hybrid search combining vector and keyword search.\n\n        This method combines semantic similarity search with traditional\n        keyword search to provide more comprehensive results.\n\n        Args:\n            query: Search query text\n            collection: Collection name to search\n            top_k: Number of results to return\n            alpha: Weight for vector search (0.0 = keyword only,\n                1.0 = vector only)\n            score_threshold: Minimum similarity score threshold\n            filter: Optional Weaviate Filter object to filter results\n                by properties\n\n        Returns:\n            List[SearchResultItem]: List of search result items\n\n        Raises:\n            ValueError: If query is empty or alpha is out of range\n\n        Examples:\n            ```python\n            hits = retriever.search_hybrid(\n                \"retrieval strategies\",\n                collection=\"Document\",\n                alpha=0.7,\n            )\n            ```\n        \"\"\"\n        if not query or not query.strip():\n            raise ValueError(\"Query cannot be empty\")\n\n        if not 0.0 &lt;= alpha &lt;= 1.0:\n            raise ValueError(\"Alpha must be between 0.0 and 1.0\")\n\n        try:\n            self.logger.debug(f\"Performing hybrid search: '{query}' with alpha={alpha}\")\n\n            # Preprocess query for better results\n            processed_query = self._preprocess_query(query)\n\n            # Get collection and execute hybrid search using Weaviate APIs\n            collection = self.db_manager.get_collection(collection)\n\n            # Use Weaviate's native hybrid API\n            result = collection.query.hybrid(\n                query=processed_query,\n                alpha=alpha,\n                limit=top_k,\n                return_metadata=MetadataQuery(score=True),\n                filters=filter,\n            )\n\n            # Process results\n            processed_results = self._process_hybrid_results(\n                result.objects, score_threshold\n            )\n\n            self.logger.debug(\n                f\"Found {len(processed_results)} hybrid results for: '{query}'\"\n            )\n            return processed_results\n\n        except Exception as e:\n            self.logger.error(f\"Hybrid search failed: {str(e)}\")\n            raise\n\n    def _preprocess_query(self, query: str) -&gt; str:\n        \"\"\"Preprocess query for better search results.\n\n        Args:\n            query: Original query text\n\n        Returns:\n            str: Preprocessed query text\n        \"\"\"\n        # Basic preprocessing - normalize whitespace and case\n        import re\n\n        processed = re.sub(r\"\\s+\", \" \", query.strip())\n        processed = processed.lower()\n\n        return processed\n\n    def search_keyword(\n        self,\n        query: str,\n        collection: str,\n        top_k: int = 5,\n        score_threshold: float = 0.0,\n        filter: Optional[Filter] = None,\n    ) -&gt; List[SearchResultItem]:\n        \"\"\"Perform keyword search using BM25 algorithm.\n\n        This method performs traditional keyword search using BM25 algorithm\n        to find documents containing specific keywords.\n\n        Args:\n            query: Search query text\n            collection: Collection name to search\n            top_k: Number of results to return\n            score_threshold: Minimum similarity score threshold\n            filter: Optional Weaviate Filter object to filter results\n                by properties\n\n        Returns:\n            List[SearchResultItem]: List of search result items\n\n        Raises:\n            ValueError: If query is empty\n\n        Examples:\n            ```python\n            hits = retriever.search_keyword(\"BM25 overview\", \"Document\", top_k=3)\n            ```\n        \"\"\"\n        if not query or not query.strip():\n            raise ValueError(\"Query cannot be empty\")\n\n        try:\n            self.logger.debug(f\"Performing keyword search: '{query}'\")\n\n            # Preprocess query for better results\n            processed_query = self._preprocess_query(query)\n\n            # Get collection and execute keyword search using Weaviate APIs\n            collection = self.db_manager.get_collection(collection)\n\n            # Use Weaviate's native BM25 API\n            result = collection.query.bm25(\n                query=processed_query,\n                limit=top_k,\n                return_metadata=MetadataQuery(score=True),\n                filters=filter,\n            )\n\n            # Process results\n            processed_results = self._process_keyword_results(\n                result.objects, score_threshold\n            )\n\n            self.logger.debug(\n                f\"Found {len(processed_results)} keyword results for: '{query}'\"\n            )\n            return processed_results\n\n        except Exception as e:\n            self.logger.error(f\"Keyword search failed: {str(e)}\")\n            raise\n\n    def _process_vector_results(\n        self, objects: List[Any], score_threshold: float\n    ) -&gt; List[SearchResultItem]:\n        \"\"\"Process vector search results from Weaviate.\n\n        Args:\n            objects: Raw Weaviate objects\n            score_threshold: Minimum score threshold\n\n        Returns:\n            List[SearchResultItem]: Processed results\n        \"\"\"\n        results = []\n        for obj in objects:\n            # Calculate similarity score from distance\n            distance = (\n                obj.metadata.distance if obj.metadata and obj.metadata.distance else 1.0\n            )\n            similarity_score = 1.0 - distance\n\n            if similarity_score &gt;= score_threshold:\n                # Build a consistent result that includes all stored properties\n                properties = dict(obj.properties or {})\n\n                # Create RetrievalMetadata from properties\n                metadata = RetrievalMetadata.from_properties(properties)\n\n                # Build SearchResultItem\n                result = SearchResultItem(\n                    content=properties.get(\"content\", \"\"),\n                    chunk_id=properties.get(\"chunk_id\", \"\"),\n                    properties=properties,\n                    similarity_score=similarity_score,\n                    distance=distance,\n                    retrieval_method=\"vector_similarity\",\n                    retrieval_timestamp=self._get_current_timestamp(),\n                    metadata=metadata,\n                )\n                results.append(result)\n\n        # Sort by similarity score (highest first)\n        results.sort(key=lambda x: x.similarity_score, reverse=True)\n        return results\n\n    def _process_hybrid_results(\n        self, objects: List[Any], score_threshold: float\n    ) -&gt; List[SearchResultItem]:\n        \"\"\"Process hybrid search results from Weaviate.\n\n        Args:\n            objects: Raw Weaviate objects\n            score_threshold: Minimum score threshold\n\n        Returns:\n            List[SearchResultItem]: Processed results\n        \"\"\"\n        results = []\n        for obj in objects:\n            # Get hybrid score\n            hybrid_score = (\n                obj.metadata.score if obj.metadata and obj.metadata.score else 0.0\n            )\n\n            if hybrid_score &gt;= score_threshold:\n                # Build a consistent result that includes all stored properties\n                properties = dict(obj.properties or {})\n\n                # Create RetrievalMetadata from properties\n                metadata = RetrievalMetadata.from_properties(properties)\n\n                # Build SearchResultItem\n                result = SearchResultItem(\n                    content=properties.get(\"content\", \"\"),\n                    chunk_id=properties.get(\"chunk_id\", \"\"),\n                    properties=properties,\n                    similarity_score=hybrid_score,\n                    hybrid_score=hybrid_score,\n                    retrieval_method=\"hybrid_search\",\n                    retrieval_timestamp=self._get_current_timestamp(),\n                    metadata=metadata,\n                )\n                results.append(result)\n\n        # Sort by hybrid score (highest first)\n        results.sort(key=lambda x: x.hybrid_score or 0.0, reverse=True)\n        return results\n\n    def _process_keyword_results(\n        self, objects: List[Any], score_threshold: float\n    ) -&gt; List[SearchResultItem]:\n        \"\"\"Process keyword search results from Weaviate.\n\n        Args:\n            objects: Raw Weaviate objects\n            score_threshold: Minimum score threshold\n\n        Returns:\n            List[SearchResultItem]: Processed results\n        \"\"\"\n        results = []\n        for obj in objects:\n            # Get BM25 score\n            bm25_score = (\n                obj.metadata.score if obj.metadata and obj.metadata.score else 0.0\n            )\n\n            if bm25_score &gt;= score_threshold:\n                # Build a consistent result that includes all stored properties\n                properties = dict(obj.properties or {})\n\n                # Create RetrievalMetadata from properties\n                metadata = RetrievalMetadata.from_properties(properties)\n\n                # Build SearchResultItem\n                result = SearchResultItem(\n                    content=properties.get(\"content\", \"\"),\n                    chunk_id=properties.get(\"chunk_id\", \"\"),\n                    properties=properties,\n                    similarity_score=None,\n                    bm25_score=bm25_score,\n                    retrieval_method=\"keyword_search\",\n                    retrieval_timestamp=self._get_current_timestamp(),\n                    metadata=metadata,\n                )\n                results.append(result)\n\n        # Sort by BM25 score (highest first)\n        results.sort(key=lambda x: x.bm25_score or 0.0, reverse=True)\n        return results\n\n    def _get_current_timestamp(self) -&gt; str:\n        \"\"\"Get current timestamp for result metadata.\n\n        Returns:\n            str: Current timestamp\n        \"\"\"\n        from datetime import datetime\n\n        return datetime.now().isoformat()\n\n    def get_retrieval_stats(self, collection: str) -&gt; Dict[str, Any]:\n        \"\"\"Get retrieval system statistics.\n\n        Returns:\n            Dict[str, Any]: Retrieval statistics\n        \"\"\"\n        try:\n            # Get database manager stats\n            db_stats = {\n                \"is_connected\": self.db_manager.is_connected,\n                \"url\": self.db_manager.url,\n                \"collections\": self.db_manager.list_collections(),\n            }\n\n            # Add retrieval-specific stats\n            embedding_info = (\n                {\n                    \"embedding_model\": self.embedding_engine.model_name,\n                    \"embedding_dimension\": (self.embedding_engine.embedding_dimension),\n                }\n                if self.embedding_engine\n                else {\n                    \"embedding_model\": (\"Weaviate text2vec-transformers (server-side)\"),\n                    \"embedding_dimension\": \"N/A (server-side)\",\n                }\n            )\n\n            retrieval_stats = {\n                \"database_stats\": db_stats,\n                \"collection\": collection,\n                **embedding_info,\n                \"retrieval_methods\": [\n                    \"vector_similarity\",\n                    \"hybrid_search\",\n                    \"keyword_search\",\n                ],\n            }\n\n            return retrieval_stats\n\n        except Exception as e:\n            self.logger.error(f\"Failed to get retrieval stats: {str(e)}\")\n            raise\n</code></pre>"},{"location":"api-reference/#ragora.core.retriever.Retriever._get_current_timestamp","title":"<code>_get_current_timestamp()</code>","text":"<p>Get current timestamp for result metadata.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Current timestamp</p> Source code in <code>ragora/ragora/core/retriever.py</code> <pre><code>def _get_current_timestamp(self) -&gt; str:\n    \"\"\"Get current timestamp for result metadata.\n\n    Returns:\n        str: Current timestamp\n    \"\"\"\n    from datetime import datetime\n\n    return datetime.now().isoformat()\n</code></pre>"},{"location":"api-reference/#ragora.core.retriever.Retriever._preprocess_query","title":"<code>_preprocess_query(query)</code>","text":"<p>Preprocess query for better search results.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>Original query text</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Preprocessed query text</p> Source code in <code>ragora/ragora/core/retriever.py</code> <pre><code>def _preprocess_query(self, query: str) -&gt; str:\n    \"\"\"Preprocess query for better search results.\n\n    Args:\n        query: Original query text\n\n    Returns:\n        str: Preprocessed query text\n    \"\"\"\n    # Basic preprocessing - normalize whitespace and case\n    import re\n\n    processed = re.sub(r\"\\s+\", \" \", query.strip())\n    processed = processed.lower()\n\n    return processed\n</code></pre>"},{"location":"api-reference/#ragora.core.retriever.Retriever._process_hybrid_results","title":"<code>_process_hybrid_results(objects, score_threshold)</code>","text":"<p>Process hybrid search results from Weaviate.</p> <p>Parameters:</p> Name Type Description Default <code>objects</code> <code>List[Any]</code> <p>Raw Weaviate objects</p> required <code>score_threshold</code> <code>float</code> <p>Minimum score threshold</p> required <p>Returns:</p> Type Description <code>List[SearchResultItem]</code> <p>List[SearchResultItem]: Processed results</p> Source code in <code>ragora/ragora/core/retriever.py</code> <pre><code>def _process_hybrid_results(\n    self, objects: List[Any], score_threshold: float\n) -&gt; List[SearchResultItem]:\n    \"\"\"Process hybrid search results from Weaviate.\n\n    Args:\n        objects: Raw Weaviate objects\n        score_threshold: Minimum score threshold\n\n    Returns:\n        List[SearchResultItem]: Processed results\n    \"\"\"\n    results = []\n    for obj in objects:\n        # Get hybrid score\n        hybrid_score = (\n            obj.metadata.score if obj.metadata and obj.metadata.score else 0.0\n        )\n\n        if hybrid_score &gt;= score_threshold:\n            # Build a consistent result that includes all stored properties\n            properties = dict(obj.properties or {})\n\n            # Create RetrievalMetadata from properties\n            metadata = RetrievalMetadata.from_properties(properties)\n\n            # Build SearchResultItem\n            result = SearchResultItem(\n                content=properties.get(\"content\", \"\"),\n                chunk_id=properties.get(\"chunk_id\", \"\"),\n                properties=properties,\n                similarity_score=hybrid_score,\n                hybrid_score=hybrid_score,\n                retrieval_method=\"hybrid_search\",\n                retrieval_timestamp=self._get_current_timestamp(),\n                metadata=metadata,\n            )\n            results.append(result)\n\n    # Sort by hybrid score (highest first)\n    results.sort(key=lambda x: x.hybrid_score or 0.0, reverse=True)\n    return results\n</code></pre>"},{"location":"api-reference/#ragora.core.retriever.Retriever._process_keyword_results","title":"<code>_process_keyword_results(objects, score_threshold)</code>","text":"<p>Process keyword search results from Weaviate.</p> <p>Parameters:</p> Name Type Description Default <code>objects</code> <code>List[Any]</code> <p>Raw Weaviate objects</p> required <code>score_threshold</code> <code>float</code> <p>Minimum score threshold</p> required <p>Returns:</p> Type Description <code>List[SearchResultItem]</code> <p>List[SearchResultItem]: Processed results</p> Source code in <code>ragora/ragora/core/retriever.py</code> <pre><code>def _process_keyword_results(\n    self, objects: List[Any], score_threshold: float\n) -&gt; List[SearchResultItem]:\n    \"\"\"Process keyword search results from Weaviate.\n\n    Args:\n        objects: Raw Weaviate objects\n        score_threshold: Minimum score threshold\n\n    Returns:\n        List[SearchResultItem]: Processed results\n    \"\"\"\n    results = []\n    for obj in objects:\n        # Get BM25 score\n        bm25_score = (\n            obj.metadata.score if obj.metadata and obj.metadata.score else 0.0\n        )\n\n        if bm25_score &gt;= score_threshold:\n            # Build a consistent result that includes all stored properties\n            properties = dict(obj.properties or {})\n\n            # Create RetrievalMetadata from properties\n            metadata = RetrievalMetadata.from_properties(properties)\n\n            # Build SearchResultItem\n            result = SearchResultItem(\n                content=properties.get(\"content\", \"\"),\n                chunk_id=properties.get(\"chunk_id\", \"\"),\n                properties=properties,\n                similarity_score=None,\n                bm25_score=bm25_score,\n                retrieval_method=\"keyword_search\",\n                retrieval_timestamp=self._get_current_timestamp(),\n                metadata=metadata,\n            )\n            results.append(result)\n\n    # Sort by BM25 score (highest first)\n    results.sort(key=lambda x: x.bm25_score or 0.0, reverse=True)\n    return results\n</code></pre>"},{"location":"api-reference/#ragora.core.retriever.Retriever._process_vector_results","title":"<code>_process_vector_results(objects, score_threshold)</code>","text":"<p>Process vector search results from Weaviate.</p> <p>Parameters:</p> Name Type Description Default <code>objects</code> <code>List[Any]</code> <p>Raw Weaviate objects</p> required <code>score_threshold</code> <code>float</code> <p>Minimum score threshold</p> required <p>Returns:</p> Type Description <code>List[SearchResultItem]</code> <p>List[SearchResultItem]: Processed results</p> Source code in <code>ragora/ragora/core/retriever.py</code> <pre><code>def _process_vector_results(\n    self, objects: List[Any], score_threshold: float\n) -&gt; List[SearchResultItem]:\n    \"\"\"Process vector search results from Weaviate.\n\n    Args:\n        objects: Raw Weaviate objects\n        score_threshold: Minimum score threshold\n\n    Returns:\n        List[SearchResultItem]: Processed results\n    \"\"\"\n    results = []\n    for obj in objects:\n        # Calculate similarity score from distance\n        distance = (\n            obj.metadata.distance if obj.metadata and obj.metadata.distance else 1.0\n        )\n        similarity_score = 1.0 - distance\n\n        if similarity_score &gt;= score_threshold:\n            # Build a consistent result that includes all stored properties\n            properties = dict(obj.properties or {})\n\n            # Create RetrievalMetadata from properties\n            metadata = RetrievalMetadata.from_properties(properties)\n\n            # Build SearchResultItem\n            result = SearchResultItem(\n                content=properties.get(\"content\", \"\"),\n                chunk_id=properties.get(\"chunk_id\", \"\"),\n                properties=properties,\n                similarity_score=similarity_score,\n                distance=distance,\n                retrieval_method=\"vector_similarity\",\n                retrieval_timestamp=self._get_current_timestamp(),\n                metadata=metadata,\n            )\n            results.append(result)\n\n    # Sort by similarity score (highest first)\n    results.sort(key=lambda x: x.similarity_score, reverse=True)\n    return results\n</code></pre>"},{"location":"api-reference/#ragora.core.retriever.Retriever.get_retrieval_stats","title":"<code>get_retrieval_stats(collection)</code>","text":"<p>Get retrieval system statistics.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict[str, Any]: Retrieval statistics</p> Source code in <code>ragora/ragora/core/retriever.py</code> <pre><code>def get_retrieval_stats(self, collection: str) -&gt; Dict[str, Any]:\n    \"\"\"Get retrieval system statistics.\n\n    Returns:\n        Dict[str, Any]: Retrieval statistics\n    \"\"\"\n    try:\n        # Get database manager stats\n        db_stats = {\n            \"is_connected\": self.db_manager.is_connected,\n            \"url\": self.db_manager.url,\n            \"collections\": self.db_manager.list_collections(),\n        }\n\n        # Add retrieval-specific stats\n        embedding_info = (\n            {\n                \"embedding_model\": self.embedding_engine.model_name,\n                \"embedding_dimension\": (self.embedding_engine.embedding_dimension),\n            }\n            if self.embedding_engine\n            else {\n                \"embedding_model\": (\"Weaviate text2vec-transformers (server-side)\"),\n                \"embedding_dimension\": \"N/A (server-side)\",\n            }\n        )\n\n        retrieval_stats = {\n            \"database_stats\": db_stats,\n            \"collection\": collection,\n            **embedding_info,\n            \"retrieval_methods\": [\n                \"vector_similarity\",\n                \"hybrid_search\",\n                \"keyword_search\",\n            ],\n        }\n\n        return retrieval_stats\n\n    except Exception as e:\n        self.logger.error(f\"Failed to get retrieval stats: {str(e)}\")\n        raise\n</code></pre>"},{"location":"api-reference/#ragora.core.retriever.Retriever.search_hybrid","title":"<code>search_hybrid(query, collection, top_k=5, alpha=0.5, score_threshold=0.0, filter=None)</code>","text":"<p>Perform hybrid search combining vector and keyword search.</p> <p>This method combines semantic similarity search with traditional keyword search to provide more comprehensive results.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>Search query text</p> required <code>collection</code> <code>str</code> <p>Collection name to search</p> required <code>top_k</code> <code>int</code> <p>Number of results to return</p> <code>5</code> <code>alpha</code> <code>float</code> <p>Weight for vector search (0.0 = keyword only, 1.0 = vector only)</p> <code>0.5</code> <code>score_threshold</code> <code>float</code> <p>Minimum similarity score threshold</p> <code>0.0</code> <code>filter</code> <code>Optional[Filter]</code> <p>Optional Weaviate Filter object to filter results by properties</p> <code>None</code> <p>Returns:</p> Type Description <code>List[SearchResultItem]</code> <p>List[SearchResultItem]: List of search result items</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If query is empty or alpha is out of range</p> <p>Examples:</p> <pre><code>hits = retriever.search_hybrid(\n    \"retrieval strategies\",\n    collection=\"Document\",\n    alpha=0.7,\n)\n</code></pre> Source code in <code>ragora/ragora/core/retriever.py</code> <pre><code>def search_hybrid(\n    self,\n    query: str,\n    collection: str,\n    top_k: int = 5,\n    alpha: float = 0.5,\n    score_threshold: float = 0.0,\n    filter: Optional[Filter] = None,\n) -&gt; List[SearchResultItem]:\n    \"\"\"Perform hybrid search combining vector and keyword search.\n\n    This method combines semantic similarity search with traditional\n    keyword search to provide more comprehensive results.\n\n    Args:\n        query: Search query text\n        collection: Collection name to search\n        top_k: Number of results to return\n        alpha: Weight for vector search (0.0 = keyword only,\n            1.0 = vector only)\n        score_threshold: Minimum similarity score threshold\n        filter: Optional Weaviate Filter object to filter results\n            by properties\n\n    Returns:\n        List[SearchResultItem]: List of search result items\n\n    Raises:\n        ValueError: If query is empty or alpha is out of range\n\n    Examples:\n        ```python\n        hits = retriever.search_hybrid(\n            \"retrieval strategies\",\n            collection=\"Document\",\n            alpha=0.7,\n        )\n        ```\n    \"\"\"\n    if not query or not query.strip():\n        raise ValueError(\"Query cannot be empty\")\n\n    if not 0.0 &lt;= alpha &lt;= 1.0:\n        raise ValueError(\"Alpha must be between 0.0 and 1.0\")\n\n    try:\n        self.logger.debug(f\"Performing hybrid search: '{query}' with alpha={alpha}\")\n\n        # Preprocess query for better results\n        processed_query = self._preprocess_query(query)\n\n        # Get collection and execute hybrid search using Weaviate APIs\n        collection = self.db_manager.get_collection(collection)\n\n        # Use Weaviate's native hybrid API\n        result = collection.query.hybrid(\n            query=processed_query,\n            alpha=alpha,\n            limit=top_k,\n            return_metadata=MetadataQuery(score=True),\n            filters=filter,\n        )\n\n        # Process results\n        processed_results = self._process_hybrid_results(\n            result.objects, score_threshold\n        )\n\n        self.logger.debug(\n            f\"Found {len(processed_results)} hybrid results for: '{query}'\"\n        )\n        return processed_results\n\n    except Exception as e:\n        self.logger.error(f\"Hybrid search failed: {str(e)}\")\n        raise\n</code></pre>"},{"location":"api-reference/#ragora.core.retriever.Retriever.search_keyword","title":"<code>search_keyword(query, collection, top_k=5, score_threshold=0.0, filter=None)</code>","text":"<p>Perform keyword search using BM25 algorithm.</p> <p>This method performs traditional keyword search using BM25 algorithm to find documents containing specific keywords.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>Search query text</p> required <code>collection</code> <code>str</code> <p>Collection name to search</p> required <code>top_k</code> <code>int</code> <p>Number of results to return</p> <code>5</code> <code>score_threshold</code> <code>float</code> <p>Minimum similarity score threshold</p> <code>0.0</code> <code>filter</code> <code>Optional[Filter]</code> <p>Optional Weaviate Filter object to filter results by properties</p> <code>None</code> <p>Returns:</p> Type Description <code>List[SearchResultItem]</code> <p>List[SearchResultItem]: List of search result items</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If query is empty</p> <p>Examples:</p> <pre><code>hits = retriever.search_keyword(\"BM25 overview\", \"Document\", top_k=3)\n</code></pre> Source code in <code>ragora/ragora/core/retriever.py</code> <pre><code>def search_keyword(\n    self,\n    query: str,\n    collection: str,\n    top_k: int = 5,\n    score_threshold: float = 0.0,\n    filter: Optional[Filter] = None,\n) -&gt; List[SearchResultItem]:\n    \"\"\"Perform keyword search using BM25 algorithm.\n\n    This method performs traditional keyword search using BM25 algorithm\n    to find documents containing specific keywords.\n\n    Args:\n        query: Search query text\n        collection: Collection name to search\n        top_k: Number of results to return\n        score_threshold: Minimum similarity score threshold\n        filter: Optional Weaviate Filter object to filter results\n            by properties\n\n    Returns:\n        List[SearchResultItem]: List of search result items\n\n    Raises:\n        ValueError: If query is empty\n\n    Examples:\n        ```python\n        hits = retriever.search_keyword(\"BM25 overview\", \"Document\", top_k=3)\n        ```\n    \"\"\"\n    if not query or not query.strip():\n        raise ValueError(\"Query cannot be empty\")\n\n    try:\n        self.logger.debug(f\"Performing keyword search: '{query}'\")\n\n        # Preprocess query for better results\n        processed_query = self._preprocess_query(query)\n\n        # Get collection and execute keyword search using Weaviate APIs\n        collection = self.db_manager.get_collection(collection)\n\n        # Use Weaviate's native BM25 API\n        result = collection.query.bm25(\n            query=processed_query,\n            limit=top_k,\n            return_metadata=MetadataQuery(score=True),\n            filters=filter,\n        )\n\n        # Process results\n        processed_results = self._process_keyword_results(\n            result.objects, score_threshold\n        )\n\n        self.logger.debug(\n            f\"Found {len(processed_results)} keyword results for: '{query}'\"\n        )\n        return processed_results\n\n    except Exception as e:\n        self.logger.error(f\"Keyword search failed: {str(e)}\")\n        raise\n</code></pre>"},{"location":"api-reference/#ragora.core.retriever.Retriever.search_similar","title":"<code>search_similar(query, collection, top_k=5, score_threshold=0.0, filter=None)</code>","text":"<p>Search for similar documents using vector similarity.</p> <p>This method performs semantic search using vector embeddings to find documents that are semantically similar to the query.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>Search query text</p> required <code>collection</code> <code>str</code> <p>Collection name to search</p> required <code>top_k</code> <code>int</code> <p>Number of results to return</p> <code>5</code> <code>score_threshold</code> <code>float</code> <p>Minimum similarity score threshold</p> <code>0.0</code> <code>filter</code> <code>Optional[Filter]</code> <p>Optional Weaviate Filter object to filter results</p> <code>None</code> <p>Returns:</p> Type Description <code>List[SearchResultItem]</code> <p>List[SearchResultItem]: List of search result items</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If query is empty</p> <p>Examples:</p> <pre><code>hits = retriever.search_similar(\"rag pipeline\", \"Document\", top_k=10)\n</code></pre> Source code in <code>ragora/ragora/core/retriever.py</code> <pre><code>def search_similar(\n    self,\n    query: str,\n    collection: str,\n    top_k: int = 5,\n    score_threshold: float = 0.0,\n    filter: Optional[Filter] = None,\n) -&gt; List[SearchResultItem]:\n    \"\"\"Search for similar documents using vector similarity.\n\n    This method performs semantic search using vector embeddings to find\n    documents that are semantically similar to the query.\n\n    Args:\n        query: Search query text\n        collection: Collection name to search\n        top_k: Number of results to return\n        score_threshold: Minimum similarity score threshold\n        filter: Optional Weaviate Filter object to filter results\n\n    Returns:\n        List[SearchResultItem]: List of search result items\n\n    Raises:\n        ValueError: If query is empty\n\n    Examples:\n        ```python\n        hits = retriever.search_similar(\"rag pipeline\", \"Document\", top_k=10)\n        ```\n    \"\"\"\n    if not query or not query.strip():\n        raise ValueError(\"Query cannot be empty\")\n\n    try:\n        self.logger.debug(f\"Performing vector similarity search: '{query}'\")\n\n        # Preprocess query for better results\n        processed_query = self._preprocess_query(query)\n\n        # Get collection and execute search using Weaviate APIs\n        collection = self.db_manager.get_collection(collection)\n\n        # Use Weaviate's native near_text API\n        result = collection.query.near_text(\n            query=processed_query,\n            limit=top_k,\n            return_metadata=MetadataQuery(distance=True),\n            filters=filter,\n        )\n\n        # Process results\n        processed_results = self._process_vector_results(\n            result.objects, score_threshold\n        )\n\n        self.logger.debug(\n            f\"Found {len(processed_results)} similar results for: '{query}'\"\n        )\n        return processed_results\n\n    except Exception as e:\n        self.logger.error(f\"Vector similarity search failed: {str(e)}\")\n        raise\n</code></pre>"},{"location":"api-reference/#vector-store","title":"Vector Store","text":"<p>Adapter that persists Ragora chunks inside a Weaviate collection.</p>"},{"location":"api-reference/#ragora.core.vector_store.VectorStore","title":"<code>VectorStore</code>","text":"<p>Persist and retrieve :class:<code>DataChunk</code> objects from Weaviate.</p> <p>Attributes:</p> Name Type Description <code>db_manager</code> <p>Database connection manager.</p> <code>collection</code> <p>Weaviate class name that stores chunks.</p> <code>embedding_engine</code> <p>Optional embedding engine for client-side vectors.</p> <code>logger</code> <p>Module logger.</p> <p>Examples:</p> <pre><code>from ragora.core.database_manager import DatabaseManager\nfrom ragora.core.vector_store import VectorStore\n\ndb = DatabaseManager(url=\"http://localhost:8080\")\nstore = VectorStore(db_manager=db, collection=\"Document\")\nstore.create_schema(\"Document\")\n</code></pre> Source code in <code>ragora/ragora/core/vector_store.py</code> <pre><code>class VectorStore:\n    \"\"\"Persist and retrieve :class:`DataChunk` objects from Weaviate.\n\n    Attributes:\n        db_manager: Database connection manager.\n        collection: Weaviate class name that stores chunks.\n        embedding_engine: Optional embedding engine for client-side vectors.\n        logger: Module logger.\n\n    Examples:\n        ```python\n        from ragora.core.database_manager import DatabaseManager\n        from ragora.core.vector_store import VectorStore\n\n        db = DatabaseManager(url=\"http://localhost:8080\")\n        store = VectorStore(db_manager=db, collection=\"Document\")\n        store.create_schema(\"Document\")\n        ```\n    \"\"\"\n\n    def __init__(\n        self,\n        db_manager: DatabaseManager,\n        collection: str = \"Document\",\n        embedding_engine: Optional[EmbeddingEngine] = None,\n    ):\n        \"\"\"Initialize the VectorStore with DatabaseManager.\n\n        Args:\n            db_manager: DatabaseManager instance for database operations\n            collection: Name of the Weaviate class for document storage\n            embedding_engine: EmbeddingEngine instance (optional, defaults to None)\n\n        Raises:\n            ValueError: If invalid parameters are provided\n        \"\"\"\n        if db_manager is None:\n            raise ValueError(\"DatabaseManager cannot be None\")\n\n        self.db_manager = db_manager\n        self.collection = collection\n\n        # Set up logging\n        self.logger = logging.getLogger(__name__)\n\n        # Note: Embedding engine is not needed when using Weaviate's text2vec-transformers\n        # Weaviate handles embeddings server-side. EmbeddingEngine is only kept for\n        # potential future use cases where client-side embeddings might be needed.\n        # DO NOT initialize it by default to avoid unnecessary model loading.\n        self.embedding_engine = embedding_engine\n\n    def is_connected(self) -&gt; bool:\n        \"\"\"Check if the vector store is connected to the database.\n\n        Returns:\n            bool: True if connected\n        \"\"\"\n        return self.db_manager.is_connected\n\n    def create_schema(self, collection: str, force_recreate: bool = False) -&gt; None:\n        \"\"\"Create the Weaviate collection for document storage using V4 API.\n\n        Args:\n            collection: Name of the collection for document storage\n            force_recreate: If True, delete existing collection before\n                creating new one\n\n        Returns:\n            None\n\n        Raises:\n            WeaviateBaseError: If collection creation fails\n        \"\"\"\n        try:\n            # Check if collection already exists\n            collection_exists = self.db_manager.collection_exists(collection)\n\n            if collection_exists:\n                if force_recreate:\n                    self.logger.info(f\"Deleting existing collection: {collection}\")\n                    self.db_manager.delete_collection(collection)\n                else:\n                    self.logger.info(\n                        f\"Collection {collection} already exists returning without creating new one\"\n                    )\n                    return\n            else:\n                self.logger.info(f\"Creating new collection: {collection}\")\n            # Define schema properties\n            properties = [\n                # Core fields\n                Property(\n                    name=\"content\",\n                    data_type=DataType.TEXT,\n                    description=\"The text content of the document chunk\",\n                    vectorize_property_name=False,\n                ),\n                Property(\n                    name=\"chunk_id\",\n                    data_type=DataType.TEXT,\n                    description=\"Unique identifier for the chunk\",\n                    vectorize_property_name=False,\n                ),\n                Property(\n                    name=\"chunk_key\",\n                    data_type=DataType.TEXT,\n                    description=\"Key for the chunk (UUID5)\",\n                    vectorize_property_name=False,\n                ),\n                Property(\n                    name=\"source_document\",\n                    data_type=DataType.TEXT,\n                    description=\"Source document filename\",\n                    vectorize_property_name=False,\n                ),\n                Property(\n                    name=\"chunk_type\",\n                    data_type=DataType.TEXT,\n                    description=\"Type of chunk (text, citation, equation, etc.)\",\n                    vectorize_property_name=False,\n                ),\n                Property(\n                    name=\"created_at\",\n                    data_type=DataType.TEXT,\n                    description=\"Creation timestamp\",\n                    vectorize_property_name=False,\n                ),\n                # Document-specific fields\n                Property(\n                    name=\"metadata_chunk_idx\",\n                    data_type=DataType.INT,\n                    description=\"Chunk index from metadata\",\n                    vectorize_property_name=False,\n                ),\n                Property(\n                    name=\"metadata_chunk_size\",\n                    data_type=DataType.INT,\n                    description=\"Chunk size from metadata\",\n                    vectorize_property_name=False,\n                ),\n                Property(\n                    name=\"metadata_total_chunks\",\n                    data_type=DataType.INT,\n                    description=\"Total chunks from metadata\",\n                    vectorize_property_name=False,\n                ),\n                Property(\n                    name=\"metadata_created_at\",\n                    data_type=DataType.TEXT,\n                    description=\"Created at timestamp from metadata\",\n                    vectorize_property_name=False,\n                ),\n                Property(\n                    name=\"page_number\",\n                    data_type=DataType.INT,\n                    description=\"Page number in source document\",\n                    vectorize_property_name=False,\n                ),\n                Property(\n                    name=\"section_title\",\n                    data_type=DataType.TEXT,\n                    description=\"Section or chapter title\",\n                    vectorize_property_name=False,\n                ),\n                # Email-specific fields\n                Property(\n                    name=\"email_subject\",\n                    data_type=DataType.TEXT,\n                    description=\"Email subject line\",\n                    vectorize_property_name=False,\n                ),\n                Property(\n                    name=\"email_sender\",\n                    data_type=DataType.TEXT,\n                    description=\"Email sender address\",\n                    vectorize_property_name=False,\n                ),\n                Property(\n                    name=\"email_recipient\",\n                    data_type=DataType.TEXT,\n                    description=\"Email recipient address\",\n                    vectorize_property_name=False,\n                ),\n                Property(\n                    name=\"email_date\",\n                    data_type=DataType.TEXT,\n                    description=\"Email timestamp\",\n                    vectorize_property_name=False,\n                ),\n                Property(\n                    name=\"email_id\",\n                    data_type=DataType.TEXT,\n                    description=\"Unique email identifier\",\n                    vectorize_property_name=False,\n                ),\n                Property(\n                    name=\"email_folder\",\n                    data_type=DataType.TEXT,\n                    description=\"Email folder/path\",\n                    vectorize_property_name=False,\n                ),\n                # Custom metadata fields\n                Property(\n                    name=\"custom_metadata\",\n                    data_type=DataType.TEXT,\n                    description=\"Custom metadata as JSON string\",\n                    vectorize_property_name=False,\n                ),\n                Property(\n                    name=\"language\",\n                    data_type=DataType.TEXT,\n                    description=\"Content language (e.g., en, es, fr)\",\n                    vectorize_property_name=False,\n                ),\n                Property(\n                    name=\"domain\",\n                    data_type=DataType.TEXT,\n                    description=\"Content domain (e.g., scientific, legal, medical)\",\n                    vectorize_property_name=False,\n                ),\n                Property(\n                    name=\"confidence\",\n                    data_type=DataType.NUMBER,\n                    description=\"Processing confidence score (0.0-1.0)\",\n                    vectorize_property_name=False,\n                ),\n                Property(\n                    name=\"tags\",\n                    data_type=DataType.TEXT,\n                    description=\"Comma-separated tags/categories\",\n                    vectorize_property_name=False,\n                ),\n                Property(\n                    name=\"priority\",\n                    data_type=DataType.INT,\n                    description=\"Content priority/importance level\",\n                    vectorize_property_name=False,\n                ),\n                Property(\n                    name=\"content_category\",\n                    data_type=DataType.TEXT,\n                    description=\"Fine-grained content categorization\",\n                    vectorize_property_name=False,\n                ),\n            ]\n\n            self.logger.info(f\"Creating collection: {collection}\")\n\n            # Create the collection using DatabaseManager\n            self.db_manager.create_collection(\n                name=collection,\n                description=\"Document chunks with embeddings for RAG system\",\n                vectorizer_config=Configure.Vectorizer.text2vec_transformers(),\n                properties=properties,\n            )\n\n            self.logger.info(f\"Successfully created collection: {collection}\")\n\n        except WeaviateBaseError as e:\n            self.logger.error(f\"Failed to create collection: {str(e)}\")\n            raise\n\n    def store_chunk(self, chunk: DataChunk, collection: str) -&gt; str:\n        \"\"\"Store a single DataChunk in the vector store using V4 API.\n\n        Args:\n            chunk: DataChunk object to store\n            collection: Name of the Weaviate class for document storage\n        Returns:\n            str: UUID of the stored chunk\n\n        Raises:\n            ValueError: If chunk is None or empty\n            WeaviateBaseError: If storage operation fails\n        \"\"\"\n        if chunk is None:\n            raise ValueError(\"Chunk cannot be None\")\n\n        if not chunk.text or not chunk.text.strip():\n            raise ValueError(\"Chunk text cannot be empty\")\n\n        try:\n            # Ensure collection exists before storing chunks\n            self.create_schema(collection)\n\n            # Get the collection\n            collection = self.db_manager.get_collection(collection)\n\n            # Prepare the object data\n            object_data = self.prepare_data_object(chunk)\n\n            # Store the object using V4 API\n            self.logger.debug(f\"Storing chunk: {chunk.chunk_id}\")\n            collection.data.insert(\n                properties=object_data,\n                uuid=object_data[\"chunk_key\"],\n            )\n\n            self.logger.debug(\n                f\"Successfully stored chunk {chunk.chunk_id} with UUID: {object_data['chunk_key']}\"\n            )\n\n            return object_data[\"chunk_key\"]\n\n        except WeaviateBaseError as e:\n            self.logger.error(f\"Failed to store chunk {chunk.chunk_id}: {str(e)}\")\n            raise\n\n    def store_chunks(\n        self, chunks: List[DataChunk], collection: str, batch_size: int = 100\n    ) -&gt; List[str]:\n        \"\"\"Store multiple DataChunks in the vector store using V4 API.\n\n        Args:\n            chunks: List of DataChunk objects to store\n            collection: Name of the Weaviate class for document storage\n            batch_size: Number of chunks to process in each batch\n\n        Returns:\n            List[str]: List of chunk keys (UUIDs) that were stored\n\n        Raises:\n            ValueError: If chunks list is empty or contains invalid chunks\n            WeaviateBaseError: If storage operation fails\n        \"\"\"\n        if not chunks:\n            raise ValueError(\"Chunks list cannot be empty\")\n\n        # Filter out invalid chunks\n        valid_chunks = []\n        for chunk in chunks:\n            if chunk is None or not chunk.text or not chunk.text.strip():\n                self.logger.warning(f\"Skipping invalid chunk: {chunk}\")\n                continue\n            valid_chunks.append(chunk)\n\n        if not valid_chunks:\n            raise ValueError(\"No valid chunks found in the list\")\n\n        total_chunks = len(valid_chunks)\n\n        try:\n            # Ensure collection exists before storing chunks\n            self.create_schema(collection)\n\n            # Get the collection\n            collection = self.db_manager.get_collection(collection)\n\n            self.logger.info(\n                f\"Storing {total_chunks} chunks in batches of {batch_size}\"\n            )\n\n            # Store UUIDs for return\n            stored_uuids = []\n\n            # Process chunks in batches using V4 API\n            for i in range(0, total_chunks, batch_size):\n                batch = valid_chunks[i : i + batch_size]\n\n                # Prepare batch data\n                batch_data = []\n                for chunk in batch:\n                    object_data = self.prepare_data_object(chunk)\n                    batch_data.append(object_data)\n\n                # Store each chunk individually to avoid gRPC issues\n                batch_num = i // batch_size + 1\n                self.logger.debug(f\"Storing batch {batch_num} with {len(batch)} chunks\")\n\n                for object_data in batch_data:\n                    try:\n                        # Insert individual object using V4 API\n                        collection.data.insert(\n                            properties=object_data,\n                            uuid=object_data[\"chunk_key\"],\n                        )\n                        stored_uuids.append(object_data[\"chunk_key\"])\n\n                    except Exception as e:\n                        self.logger.warning(f\"Failed to insert object: {e}\")\n                        continue\n\n            self.logger.info(f\"Successfully stored {total_chunks} chunks\")\n            return stored_uuids\n\n        except WeaviateBaseError as e:\n            self.logger.error(f\"Failed to store chunks: {str(e)}\")\n            raise\n\n    def prepare_data_object(self, chunk: DataChunk) -&gt; Dict[str, Any]:\n        \"\"\"Prepare the data object for the chunk.\n\n        Args:\n            chunk: DataChunk object to prepare\n\n        Returns:\n            Dict[str, Any]: Prepared data object\n        \"\"\"\n        if chunk is None:\n            raise ValueError(\"Chunk cannot be None\")\n\n        if not chunk.text or not chunk.text.strip():\n            raise ValueError(\"Chunk text cannot be empty\")\n\n        if not chunk.chunk_id or not chunk.chunk_id.strip():\n            raise ValueError(\"Chunk ID cannot be empty\")\n\n        custom_meta = chunk.metadata.custom_metadata or {}\n        custom_metadata_json = json.dumps(custom_meta) if custom_meta else \"\"\n\n        # Extract tags value to avoid redundant dictionary lookups\n        tags_value = custom_meta.get(\"tags\", [])\n        tags_string = (\n            \",\".join(tags_value) if isinstance(tags_value, list) else str(tags_value)\n        )\n\n        return {\n            # Core fields\n            \"content\": chunk.text,\n            \"chunk_id\": chunk.chunk_id,\n            \"chunk_key\": generate_uuid5(chunk.chunk_id),\n            \"source_document\": chunk.source_document or \"\",\n            \"chunk_type\": chunk.chunk_type or \"\",\n            \"created_at\": chunk.metadata.created_at or \"\",\n            # Document-specific fields\n            \"metadata_chunk_idx\": chunk.metadata.chunk_idx,\n            \"metadata_chunk_size\": chunk.metadata.chunk_size,\n            \"metadata_total_chunks\": chunk.metadata.total_chunks,\n            \"metadata_created_at\": chunk.metadata.created_at or \"\",\n            \"page_number\": chunk.metadata.page_number or 0,\n            \"section_title\": chunk.metadata.section_title or \"\",\n            # Email-specific fields\n            \"email_subject\": chunk.metadata.email_subject or \"\",\n            \"email_sender\": chunk.metadata.email_sender or \"\",\n            \"email_recipient\": chunk.metadata.email_recipient or \"\",\n            \"email_date\": chunk.metadata.email_date or \"\",\n            \"email_id\": chunk.metadata.email_id or \"\",\n            \"email_folder\": chunk.metadata.email_folder or \"\",\n            # Custom metadata fields\n            \"custom_metadata\": custom_metadata_json,\n            \"language\": custom_meta.get(\"language\", \"\"),\n            \"domain\": custom_meta.get(\"domain\", \"\"),\n            \"confidence\": custom_meta.get(\"confidence\", 0.0),\n            \"tags\": tags_string,\n            \"priority\": custom_meta.get(\"priority\", 0),\n            \"content_category\": custom_meta.get(\"content_category\", \"\"),\n        }\n\n    def get_chunk_by_id(\n        self, chunk_id: str, collection: str\n    ) -&gt; Optional[RetrievalResultItem]:\n        \"\"\"Retrieve a specific chunk by its chunk_id using V4 API.\n\n        Args:\n            chunk_id: ID of the chunk\n            collection: Name of the Weaviate class for document storage\n        Returns:\n            Optional[RetrievalResultItem]: Chunk data if found, None otherwise\n\n        Raises:\n            WeaviateBaseError: If retrieval operation fails\n        \"\"\"\n        try:\n            # Get the collection\n            collection = self.db_manager.get_collection(collection)\n\n            # Query using V4 API\n            result = collection.query.fetch_object_by_id(\n                uuid=generate_uuid5(chunk_id),\n            )\n\n            if result:\n                properties = result.properties\n                # Create RetrievalResultItem with structured metadata\n                return RetrievalResultItem(\n                    content=properties.get(\"content\", \"\"),\n                    chunk_id=properties.get(\"chunk_id\", \"\"),\n                    properties=properties,\n                    metadata=RetrievalMetadata.from_properties(properties),\n                )\n            else:\n                return None\n\n        except WeaviateBaseError as e:\n            self.logger.error(f\"Failed to retrieve chunk {chunk_id}: {str(e)}\")\n            raise\n\n    def delete_chunk(self, chunk_id: str, collection: str) -&gt; bool:\n        \"\"\"Delete a chunk by its chunk_id using V4 API.\n\n        Args:\n            chunk_id: ID of the chunk to delete\n            collection: Name of the Weaviate class for document storage\n        Returns:\n            bool: True if deletion was successful, False otherwise\n\n        Raises:\n            WeaviateBaseError: If deletion operation fails\n        \"\"\"\n        try:\n            # Get the collection\n            collection = self.db_manager.get_collection(collection)\n\n            # Delete by ID\n            collection.data.delete_by_id(uuid=generate_uuid5(chunk_id))\n            self.logger.debug(f\"Successfully deleted chunk: {chunk_id}\")\n            return True\n\n        except WeaviateBaseError as e:\n            self.logger.error(f\"Failed to delete chunk {chunk_id}: {str(e)}\")\n            raise\n\n    def update_chunk(\n        self, chunk_id: str, properties: Dict[str, Any], collection: str\n    ) -&gt; bool:\n        \"\"\"Update a chunk by its chunk_id using V4 API.\n\n        Args:\n            chunk_id: ID of the chunk to update\n            properties: Properties to update\n            collection: Name of the Weaviate class for document storage\n        Returns:\n            bool: True if update was successful, False otherwise\n\n        Raises:\n            WeaviateBaseError: If update operation fails\n        \"\"\"\n\n        try:\n            # Get the collection\n            collection = self.db_manager.get_collection(collection)\n\n            # Update by ID\n            collection.data.update_by_id(\n                uuid=generate_uuid5(chunk_id),\n                properties=properties,\n            )\n            self.logger.debug(f\"Successfully updated chunk: {chunk_id}\")\n            return True\n\n        except WeaviateBaseError as e:\n            self.logger.error(f\"Failed to update chunk {chunk_id}: {str(e)}\")\n            raise\n\n    def chunk_exists(self, chunk_id: str, collection: str) -&gt; bool:\n        \"\"\"Check if a chunk exists by its chunk_id using V4 API.\n\n        Args:\n            chunk_id: ID of the chunk to check\n            collection: Name of the Weaviate class for document storage\n        Returns:\n            bool: True if chunk exists, False otherwise\n\n        Raises:\n            WeaviateBaseError: If check operation fails\n        \"\"\"\n        try:\n            # Get the collection\n            collection = self.db_manager.get_collection(collection)\n\n            # Check if chunk exists by ID\n            return collection.data.exists(uuid=generate_uuid5(chunk_id))\n        except WeaviateBaseError as e:\n            self.logger.error(f\"Failed to check if chunk {chunk_id} exists: {str(e)}\")\n            raise\n\n    def get_stats(self, collection: str) -&gt; Dict[str, Any]:\n        \"\"\"Get statistics about the vector store using V4 API.\n\n        Args:\n            collection: Name of the Weaviate class for document storage\n\n        Returns:\n            Dict[str, Any]: Statistics including total objects, collection\n                info, etc.\n\n        Raises:\n            WeaviateBaseError: If stats retrieval fails\n        \"\"\"\n        try:\n            # Get the collection\n            collection = self.db_manager.get_collection(collection)\n\n            # Get total object count using V4 API\n            result = collection.aggregate.over_all(total_count=True)\n\n            total_objects = result.total_count if result.total_count is not None else 0\n\n            # Get collection information\n            collection_info = {\n                \"name\": collection.name,\n                \"description\": getattr(collection.config, \"description\", \"\"),\n                \"vectorizer\": getattr(collection.config, \"vectorizer_config\", None),\n            }\n\n            return {\n                \"total_objects\": total_objects,\n                \"collection\": collection,\n                \"collection_info\": collection_info,\n                \"is_connected\": self.is_connected(),\n                \"db_manager_url\": self.db_manager.url,\n            }\n\n        except WeaviateBaseError as e:\n            self.logger.error(f\"Failed to get stats: {str(e)}\")\n            raise\n\n    def clear_all(self, collection: str) -&gt; None:\n        \"\"\"Clear all objects from the vector store using V4 API.\n\n        Args:\n            collection: Name of the Weaviate class for document storage\n\n        Returns:\n            None\n\n        Raises:\n            WeaviateBaseError: If clearing operation fails\n        \"\"\"\n        try:\n            self.logger.warning(f\"Clearing all objects from collection: {collection}\")\n            self.db_manager.delete_collection(collection)\n            self.logger.info(\n                f\"Successfully cleared all objects from collection: {collection}\"\n            )\n        except WeaviateBaseError as e:\n            self.logger.error(f\"Failed to clear all objects: {str(e)}\")\n            raise\n\n    def close(self) -&gt; None:\n        \"\"\"Close the connection to Weaviate.\n\n        Returns:\n            None\n\n        Raises:\n            Exception: If closing operation fails\n        \"\"\"\n        try:\n            if hasattr(self, \"db_manager\") and self.db_manager:\n                self.db_manager.close()\n                self.logger.info(\"Vector store connection closed\")\n        except Exception as e:\n            self.logger.error(f\"Error closing vector store: {str(e)}\")\n\n    def __enter__(self):\n        \"\"\"Context manager entry.\"\"\"\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        \"\"\"Context manager exit.\"\"\"\n        self.close()\n</code></pre>"},{"location":"api-reference/#ragora.core.vector_store.VectorStore.chunk_exists","title":"<code>chunk_exists(chunk_id, collection)</code>","text":"<p>Check if a chunk exists by its chunk_id using V4 API.</p> <p>Parameters:</p> Name Type Description Default <code>chunk_id</code> <code>str</code> <p>ID of the chunk to check</p> required <code>collection</code> <code>str</code> <p>Name of the Weaviate class for document storage</p> required <p>Returns:     bool: True if chunk exists, False otherwise</p> <p>Raises:</p> Type Description <code>WeaviateBaseError</code> <p>If check operation fails</p> Source code in <code>ragora/ragora/core/vector_store.py</code> <pre><code>def chunk_exists(self, chunk_id: str, collection: str) -&gt; bool:\n    \"\"\"Check if a chunk exists by its chunk_id using V4 API.\n\n    Args:\n        chunk_id: ID of the chunk to check\n        collection: Name of the Weaviate class for document storage\n    Returns:\n        bool: True if chunk exists, False otherwise\n\n    Raises:\n        WeaviateBaseError: If check operation fails\n    \"\"\"\n    try:\n        # Get the collection\n        collection = self.db_manager.get_collection(collection)\n\n        # Check if chunk exists by ID\n        return collection.data.exists(uuid=generate_uuid5(chunk_id))\n    except WeaviateBaseError as e:\n        self.logger.error(f\"Failed to check if chunk {chunk_id} exists: {str(e)}\")\n        raise\n</code></pre>"},{"location":"api-reference/#ragora.core.vector_store.VectorStore.clear_all","title":"<code>clear_all(collection)</code>","text":"<p>Clear all objects from the vector store using V4 API.</p> <p>Parameters:</p> Name Type Description Default <code>collection</code> <code>str</code> <p>Name of the Weaviate class for document storage</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Raises:</p> Type Description <code>WeaviateBaseError</code> <p>If clearing operation fails</p> Source code in <code>ragora/ragora/core/vector_store.py</code> <pre><code>def clear_all(self, collection: str) -&gt; None:\n    \"\"\"Clear all objects from the vector store using V4 API.\n\n    Args:\n        collection: Name of the Weaviate class for document storage\n\n    Returns:\n        None\n\n    Raises:\n        WeaviateBaseError: If clearing operation fails\n    \"\"\"\n    try:\n        self.logger.warning(f\"Clearing all objects from collection: {collection}\")\n        self.db_manager.delete_collection(collection)\n        self.logger.info(\n            f\"Successfully cleared all objects from collection: {collection}\"\n        )\n    except WeaviateBaseError as e:\n        self.logger.error(f\"Failed to clear all objects: {str(e)}\")\n        raise\n</code></pre>"},{"location":"api-reference/#ragora.core.vector_store.VectorStore.close","title":"<code>close()</code>","text":"<p>Close the connection to Weaviate.</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If closing operation fails</p> Source code in <code>ragora/ragora/core/vector_store.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Close the connection to Weaviate.\n\n    Returns:\n        None\n\n    Raises:\n        Exception: If closing operation fails\n    \"\"\"\n    try:\n        if hasattr(self, \"db_manager\") and self.db_manager:\n            self.db_manager.close()\n            self.logger.info(\"Vector store connection closed\")\n    except Exception as e:\n        self.logger.error(f\"Error closing vector store: {str(e)}\")\n</code></pre>"},{"location":"api-reference/#ragora.core.vector_store.VectorStore.create_schema","title":"<code>create_schema(collection, force_recreate=False)</code>","text":"<p>Create the Weaviate collection for document storage using V4 API.</p> <p>Parameters:</p> Name Type Description Default <code>collection</code> <code>str</code> <p>Name of the collection for document storage</p> required <code>force_recreate</code> <code>bool</code> <p>If True, delete existing collection before creating new one</p> <code>False</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Raises:</p> Type Description <code>WeaviateBaseError</code> <p>If collection creation fails</p> Source code in <code>ragora/ragora/core/vector_store.py</code> <pre><code>def create_schema(self, collection: str, force_recreate: bool = False) -&gt; None:\n    \"\"\"Create the Weaviate collection for document storage using V4 API.\n\n    Args:\n        collection: Name of the collection for document storage\n        force_recreate: If True, delete existing collection before\n            creating new one\n\n    Returns:\n        None\n\n    Raises:\n        WeaviateBaseError: If collection creation fails\n    \"\"\"\n    try:\n        # Check if collection already exists\n        collection_exists = self.db_manager.collection_exists(collection)\n\n        if collection_exists:\n            if force_recreate:\n                self.logger.info(f\"Deleting existing collection: {collection}\")\n                self.db_manager.delete_collection(collection)\n            else:\n                self.logger.info(\n                    f\"Collection {collection} already exists returning without creating new one\"\n                )\n                return\n        else:\n            self.logger.info(f\"Creating new collection: {collection}\")\n        # Define schema properties\n        properties = [\n            # Core fields\n            Property(\n                name=\"content\",\n                data_type=DataType.TEXT,\n                description=\"The text content of the document chunk\",\n                vectorize_property_name=False,\n            ),\n            Property(\n                name=\"chunk_id\",\n                data_type=DataType.TEXT,\n                description=\"Unique identifier for the chunk\",\n                vectorize_property_name=False,\n            ),\n            Property(\n                name=\"chunk_key\",\n                data_type=DataType.TEXT,\n                description=\"Key for the chunk (UUID5)\",\n                vectorize_property_name=False,\n            ),\n            Property(\n                name=\"source_document\",\n                data_type=DataType.TEXT,\n                description=\"Source document filename\",\n                vectorize_property_name=False,\n            ),\n            Property(\n                name=\"chunk_type\",\n                data_type=DataType.TEXT,\n                description=\"Type of chunk (text, citation, equation, etc.)\",\n                vectorize_property_name=False,\n            ),\n            Property(\n                name=\"created_at\",\n                data_type=DataType.TEXT,\n                description=\"Creation timestamp\",\n                vectorize_property_name=False,\n            ),\n            # Document-specific fields\n            Property(\n                name=\"metadata_chunk_idx\",\n                data_type=DataType.INT,\n                description=\"Chunk index from metadata\",\n                vectorize_property_name=False,\n            ),\n            Property(\n                name=\"metadata_chunk_size\",\n                data_type=DataType.INT,\n                description=\"Chunk size from metadata\",\n                vectorize_property_name=False,\n            ),\n            Property(\n                name=\"metadata_total_chunks\",\n                data_type=DataType.INT,\n                description=\"Total chunks from metadata\",\n                vectorize_property_name=False,\n            ),\n            Property(\n                name=\"metadata_created_at\",\n                data_type=DataType.TEXT,\n                description=\"Created at timestamp from metadata\",\n                vectorize_property_name=False,\n            ),\n            Property(\n                name=\"page_number\",\n                data_type=DataType.INT,\n                description=\"Page number in source document\",\n                vectorize_property_name=False,\n            ),\n            Property(\n                name=\"section_title\",\n                data_type=DataType.TEXT,\n                description=\"Section or chapter title\",\n                vectorize_property_name=False,\n            ),\n            # Email-specific fields\n            Property(\n                name=\"email_subject\",\n                data_type=DataType.TEXT,\n                description=\"Email subject line\",\n                vectorize_property_name=False,\n            ),\n            Property(\n                name=\"email_sender\",\n                data_type=DataType.TEXT,\n                description=\"Email sender address\",\n                vectorize_property_name=False,\n            ),\n            Property(\n                name=\"email_recipient\",\n                data_type=DataType.TEXT,\n                description=\"Email recipient address\",\n                vectorize_property_name=False,\n            ),\n            Property(\n                name=\"email_date\",\n                data_type=DataType.TEXT,\n                description=\"Email timestamp\",\n                vectorize_property_name=False,\n            ),\n            Property(\n                name=\"email_id\",\n                data_type=DataType.TEXT,\n                description=\"Unique email identifier\",\n                vectorize_property_name=False,\n            ),\n            Property(\n                name=\"email_folder\",\n                data_type=DataType.TEXT,\n                description=\"Email folder/path\",\n                vectorize_property_name=False,\n            ),\n            # Custom metadata fields\n            Property(\n                name=\"custom_metadata\",\n                data_type=DataType.TEXT,\n                description=\"Custom metadata as JSON string\",\n                vectorize_property_name=False,\n            ),\n            Property(\n                name=\"language\",\n                data_type=DataType.TEXT,\n                description=\"Content language (e.g., en, es, fr)\",\n                vectorize_property_name=False,\n            ),\n            Property(\n                name=\"domain\",\n                data_type=DataType.TEXT,\n                description=\"Content domain (e.g., scientific, legal, medical)\",\n                vectorize_property_name=False,\n            ),\n            Property(\n                name=\"confidence\",\n                data_type=DataType.NUMBER,\n                description=\"Processing confidence score (0.0-1.0)\",\n                vectorize_property_name=False,\n            ),\n            Property(\n                name=\"tags\",\n                data_type=DataType.TEXT,\n                description=\"Comma-separated tags/categories\",\n                vectorize_property_name=False,\n            ),\n            Property(\n                name=\"priority\",\n                data_type=DataType.INT,\n                description=\"Content priority/importance level\",\n                vectorize_property_name=False,\n            ),\n            Property(\n                name=\"content_category\",\n                data_type=DataType.TEXT,\n                description=\"Fine-grained content categorization\",\n                vectorize_property_name=False,\n            ),\n        ]\n\n        self.logger.info(f\"Creating collection: {collection}\")\n\n        # Create the collection using DatabaseManager\n        self.db_manager.create_collection(\n            name=collection,\n            description=\"Document chunks with embeddings for RAG system\",\n            vectorizer_config=Configure.Vectorizer.text2vec_transformers(),\n            properties=properties,\n        )\n\n        self.logger.info(f\"Successfully created collection: {collection}\")\n\n    except WeaviateBaseError as e:\n        self.logger.error(f\"Failed to create collection: {str(e)}\")\n        raise\n</code></pre>"},{"location":"api-reference/#ragora.core.vector_store.VectorStore.delete_chunk","title":"<code>delete_chunk(chunk_id, collection)</code>","text":"<p>Delete a chunk by its chunk_id using V4 API.</p> <p>Parameters:</p> Name Type Description Default <code>chunk_id</code> <code>str</code> <p>ID of the chunk to delete</p> required <code>collection</code> <code>str</code> <p>Name of the Weaviate class for document storage</p> required <p>Returns:     bool: True if deletion was successful, False otherwise</p> <p>Raises:</p> Type Description <code>WeaviateBaseError</code> <p>If deletion operation fails</p> Source code in <code>ragora/ragora/core/vector_store.py</code> <pre><code>def delete_chunk(self, chunk_id: str, collection: str) -&gt; bool:\n    \"\"\"Delete a chunk by its chunk_id using V4 API.\n\n    Args:\n        chunk_id: ID of the chunk to delete\n        collection: Name of the Weaviate class for document storage\n    Returns:\n        bool: True if deletion was successful, False otherwise\n\n    Raises:\n        WeaviateBaseError: If deletion operation fails\n    \"\"\"\n    try:\n        # Get the collection\n        collection = self.db_manager.get_collection(collection)\n\n        # Delete by ID\n        collection.data.delete_by_id(uuid=generate_uuid5(chunk_id))\n        self.logger.debug(f\"Successfully deleted chunk: {chunk_id}\")\n        return True\n\n    except WeaviateBaseError as e:\n        self.logger.error(f\"Failed to delete chunk {chunk_id}: {str(e)}\")\n        raise\n</code></pre>"},{"location":"api-reference/#ragora.core.vector_store.VectorStore.get_chunk_by_id","title":"<code>get_chunk_by_id(chunk_id, collection)</code>","text":"<p>Retrieve a specific chunk by its chunk_id using V4 API.</p> <p>Parameters:</p> Name Type Description Default <code>chunk_id</code> <code>str</code> <p>ID of the chunk</p> required <code>collection</code> <code>str</code> <p>Name of the Weaviate class for document storage</p> required <p>Returns:     Optional[RetrievalResultItem]: Chunk data if found, None otherwise</p> <p>Raises:</p> Type Description <code>WeaviateBaseError</code> <p>If retrieval operation fails</p> Source code in <code>ragora/ragora/core/vector_store.py</code> <pre><code>def get_chunk_by_id(\n    self, chunk_id: str, collection: str\n) -&gt; Optional[RetrievalResultItem]:\n    \"\"\"Retrieve a specific chunk by its chunk_id using V4 API.\n\n    Args:\n        chunk_id: ID of the chunk\n        collection: Name of the Weaviate class for document storage\n    Returns:\n        Optional[RetrievalResultItem]: Chunk data if found, None otherwise\n\n    Raises:\n        WeaviateBaseError: If retrieval operation fails\n    \"\"\"\n    try:\n        # Get the collection\n        collection = self.db_manager.get_collection(collection)\n\n        # Query using V4 API\n        result = collection.query.fetch_object_by_id(\n            uuid=generate_uuid5(chunk_id),\n        )\n\n        if result:\n            properties = result.properties\n            # Create RetrievalResultItem with structured metadata\n            return RetrievalResultItem(\n                content=properties.get(\"content\", \"\"),\n                chunk_id=properties.get(\"chunk_id\", \"\"),\n                properties=properties,\n                metadata=RetrievalMetadata.from_properties(properties),\n            )\n        else:\n            return None\n\n    except WeaviateBaseError as e:\n        self.logger.error(f\"Failed to retrieve chunk {chunk_id}: {str(e)}\")\n        raise\n</code></pre>"},{"location":"api-reference/#ragora.core.vector_store.VectorStore.get_stats","title":"<code>get_stats(collection)</code>","text":"<p>Get statistics about the vector store using V4 API.</p> <p>Parameters:</p> Name Type Description Default <code>collection</code> <code>str</code> <p>Name of the Weaviate class for document storage</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict[str, Any]: Statistics including total objects, collection info, etc.</p> <p>Raises:</p> Type Description <code>WeaviateBaseError</code> <p>If stats retrieval fails</p> Source code in <code>ragora/ragora/core/vector_store.py</code> <pre><code>def get_stats(self, collection: str) -&gt; Dict[str, Any]:\n    \"\"\"Get statistics about the vector store using V4 API.\n\n    Args:\n        collection: Name of the Weaviate class for document storage\n\n    Returns:\n        Dict[str, Any]: Statistics including total objects, collection\n            info, etc.\n\n    Raises:\n        WeaviateBaseError: If stats retrieval fails\n    \"\"\"\n    try:\n        # Get the collection\n        collection = self.db_manager.get_collection(collection)\n\n        # Get total object count using V4 API\n        result = collection.aggregate.over_all(total_count=True)\n\n        total_objects = result.total_count if result.total_count is not None else 0\n\n        # Get collection information\n        collection_info = {\n            \"name\": collection.name,\n            \"description\": getattr(collection.config, \"description\", \"\"),\n            \"vectorizer\": getattr(collection.config, \"vectorizer_config\", None),\n        }\n\n        return {\n            \"total_objects\": total_objects,\n            \"collection\": collection,\n            \"collection_info\": collection_info,\n            \"is_connected\": self.is_connected(),\n            \"db_manager_url\": self.db_manager.url,\n        }\n\n    except WeaviateBaseError as e:\n        self.logger.error(f\"Failed to get stats: {str(e)}\")\n        raise\n</code></pre>"},{"location":"api-reference/#ragora.core.vector_store.VectorStore.is_connected","title":"<code>is_connected()</code>","text":"<p>Check if the vector store is connected to the database.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if connected</p> Source code in <code>ragora/ragora/core/vector_store.py</code> <pre><code>def is_connected(self) -&gt; bool:\n    \"\"\"Check if the vector store is connected to the database.\n\n    Returns:\n        bool: True if connected\n    \"\"\"\n    return self.db_manager.is_connected\n</code></pre>"},{"location":"api-reference/#ragora.core.vector_store.VectorStore.prepare_data_object","title":"<code>prepare_data_object(chunk)</code>","text":"<p>Prepare the data object for the chunk.</p> <p>Parameters:</p> Name Type Description Default <code>chunk</code> <code>DataChunk</code> <p>DataChunk object to prepare</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict[str, Any]: Prepared data object</p> Source code in <code>ragora/ragora/core/vector_store.py</code> <pre><code>def prepare_data_object(self, chunk: DataChunk) -&gt; Dict[str, Any]:\n    \"\"\"Prepare the data object for the chunk.\n\n    Args:\n        chunk: DataChunk object to prepare\n\n    Returns:\n        Dict[str, Any]: Prepared data object\n    \"\"\"\n    if chunk is None:\n        raise ValueError(\"Chunk cannot be None\")\n\n    if not chunk.text or not chunk.text.strip():\n        raise ValueError(\"Chunk text cannot be empty\")\n\n    if not chunk.chunk_id or not chunk.chunk_id.strip():\n        raise ValueError(\"Chunk ID cannot be empty\")\n\n    custom_meta = chunk.metadata.custom_metadata or {}\n    custom_metadata_json = json.dumps(custom_meta) if custom_meta else \"\"\n\n    # Extract tags value to avoid redundant dictionary lookups\n    tags_value = custom_meta.get(\"tags\", [])\n    tags_string = (\n        \",\".join(tags_value) if isinstance(tags_value, list) else str(tags_value)\n    )\n\n    return {\n        # Core fields\n        \"content\": chunk.text,\n        \"chunk_id\": chunk.chunk_id,\n        \"chunk_key\": generate_uuid5(chunk.chunk_id),\n        \"source_document\": chunk.source_document or \"\",\n        \"chunk_type\": chunk.chunk_type or \"\",\n        \"created_at\": chunk.metadata.created_at or \"\",\n        # Document-specific fields\n        \"metadata_chunk_idx\": chunk.metadata.chunk_idx,\n        \"metadata_chunk_size\": chunk.metadata.chunk_size,\n        \"metadata_total_chunks\": chunk.metadata.total_chunks,\n        \"metadata_created_at\": chunk.metadata.created_at or \"\",\n        \"page_number\": chunk.metadata.page_number or 0,\n        \"section_title\": chunk.metadata.section_title or \"\",\n        # Email-specific fields\n        \"email_subject\": chunk.metadata.email_subject or \"\",\n        \"email_sender\": chunk.metadata.email_sender or \"\",\n        \"email_recipient\": chunk.metadata.email_recipient or \"\",\n        \"email_date\": chunk.metadata.email_date or \"\",\n        \"email_id\": chunk.metadata.email_id or \"\",\n        \"email_folder\": chunk.metadata.email_folder or \"\",\n        # Custom metadata fields\n        \"custom_metadata\": custom_metadata_json,\n        \"language\": custom_meta.get(\"language\", \"\"),\n        \"domain\": custom_meta.get(\"domain\", \"\"),\n        \"confidence\": custom_meta.get(\"confidence\", 0.0),\n        \"tags\": tags_string,\n        \"priority\": custom_meta.get(\"priority\", 0),\n        \"content_category\": custom_meta.get(\"content_category\", \"\"),\n    }\n</code></pre>"},{"location":"api-reference/#ragora.core.vector_store.VectorStore.store_chunk","title":"<code>store_chunk(chunk, collection)</code>","text":"<p>Store a single DataChunk in the vector store using V4 API.</p> <p>Parameters:</p> Name Type Description Default <code>chunk</code> <code>DataChunk</code> <p>DataChunk object to store</p> required <code>collection</code> <code>str</code> <p>Name of the Weaviate class for document storage</p> required <p>Returns:     str: UUID of the stored chunk</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If chunk is None or empty</p> <code>WeaviateBaseError</code> <p>If storage operation fails</p> Source code in <code>ragora/ragora/core/vector_store.py</code> <pre><code>def store_chunk(self, chunk: DataChunk, collection: str) -&gt; str:\n    \"\"\"Store a single DataChunk in the vector store using V4 API.\n\n    Args:\n        chunk: DataChunk object to store\n        collection: Name of the Weaviate class for document storage\n    Returns:\n        str: UUID of the stored chunk\n\n    Raises:\n        ValueError: If chunk is None or empty\n        WeaviateBaseError: If storage operation fails\n    \"\"\"\n    if chunk is None:\n        raise ValueError(\"Chunk cannot be None\")\n\n    if not chunk.text or not chunk.text.strip():\n        raise ValueError(\"Chunk text cannot be empty\")\n\n    try:\n        # Ensure collection exists before storing chunks\n        self.create_schema(collection)\n\n        # Get the collection\n        collection = self.db_manager.get_collection(collection)\n\n        # Prepare the object data\n        object_data = self.prepare_data_object(chunk)\n\n        # Store the object using V4 API\n        self.logger.debug(f\"Storing chunk: {chunk.chunk_id}\")\n        collection.data.insert(\n            properties=object_data,\n            uuid=object_data[\"chunk_key\"],\n        )\n\n        self.logger.debug(\n            f\"Successfully stored chunk {chunk.chunk_id} with UUID: {object_data['chunk_key']}\"\n        )\n\n        return object_data[\"chunk_key\"]\n\n    except WeaviateBaseError as e:\n        self.logger.error(f\"Failed to store chunk {chunk.chunk_id}: {str(e)}\")\n        raise\n</code></pre>"},{"location":"api-reference/#ragora.core.vector_store.VectorStore.store_chunks","title":"<code>store_chunks(chunks, collection, batch_size=100)</code>","text":"<p>Store multiple DataChunks in the vector store using V4 API.</p> <p>Parameters:</p> Name Type Description Default <code>chunks</code> <code>List[DataChunk]</code> <p>List of DataChunk objects to store</p> required <code>collection</code> <code>str</code> <p>Name of the Weaviate class for document storage</p> required <code>batch_size</code> <code>int</code> <p>Number of chunks to process in each batch</p> <code>100</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: List of chunk keys (UUIDs) that were stored</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If chunks list is empty or contains invalid chunks</p> <code>WeaviateBaseError</code> <p>If storage operation fails</p> Source code in <code>ragora/ragora/core/vector_store.py</code> <pre><code>def store_chunks(\n    self, chunks: List[DataChunk], collection: str, batch_size: int = 100\n) -&gt; List[str]:\n    \"\"\"Store multiple DataChunks in the vector store using V4 API.\n\n    Args:\n        chunks: List of DataChunk objects to store\n        collection: Name of the Weaviate class for document storage\n        batch_size: Number of chunks to process in each batch\n\n    Returns:\n        List[str]: List of chunk keys (UUIDs) that were stored\n\n    Raises:\n        ValueError: If chunks list is empty or contains invalid chunks\n        WeaviateBaseError: If storage operation fails\n    \"\"\"\n    if not chunks:\n        raise ValueError(\"Chunks list cannot be empty\")\n\n    # Filter out invalid chunks\n    valid_chunks = []\n    for chunk in chunks:\n        if chunk is None or not chunk.text or not chunk.text.strip():\n            self.logger.warning(f\"Skipping invalid chunk: {chunk}\")\n            continue\n        valid_chunks.append(chunk)\n\n    if not valid_chunks:\n        raise ValueError(\"No valid chunks found in the list\")\n\n    total_chunks = len(valid_chunks)\n\n    try:\n        # Ensure collection exists before storing chunks\n        self.create_schema(collection)\n\n        # Get the collection\n        collection = self.db_manager.get_collection(collection)\n\n        self.logger.info(\n            f\"Storing {total_chunks} chunks in batches of {batch_size}\"\n        )\n\n        # Store UUIDs for return\n        stored_uuids = []\n\n        # Process chunks in batches using V4 API\n        for i in range(0, total_chunks, batch_size):\n            batch = valid_chunks[i : i + batch_size]\n\n            # Prepare batch data\n            batch_data = []\n            for chunk in batch:\n                object_data = self.prepare_data_object(chunk)\n                batch_data.append(object_data)\n\n            # Store each chunk individually to avoid gRPC issues\n            batch_num = i // batch_size + 1\n            self.logger.debug(f\"Storing batch {batch_num} with {len(batch)} chunks\")\n\n            for object_data in batch_data:\n                try:\n                    # Insert individual object using V4 API\n                    collection.data.insert(\n                        properties=object_data,\n                        uuid=object_data[\"chunk_key\"],\n                    )\n                    stored_uuids.append(object_data[\"chunk_key\"])\n\n                except Exception as e:\n                    self.logger.warning(f\"Failed to insert object: {e}\")\n                    continue\n\n        self.logger.info(f\"Successfully stored {total_chunks} chunks\")\n        return stored_uuids\n\n    except WeaviateBaseError as e:\n        self.logger.error(f\"Failed to store chunks: {str(e)}\")\n        raise\n</code></pre>"},{"location":"api-reference/#ragora.core.vector_store.VectorStore.update_chunk","title":"<code>update_chunk(chunk_id, properties, collection)</code>","text":"<p>Update a chunk by its chunk_id using V4 API.</p> <p>Parameters:</p> Name Type Description Default <code>chunk_id</code> <code>str</code> <p>ID of the chunk to update</p> required <code>properties</code> <code>Dict[str, Any]</code> <p>Properties to update</p> required <code>collection</code> <code>str</code> <p>Name of the Weaviate class for document storage</p> required <p>Returns:     bool: True if update was successful, False otherwise</p> <p>Raises:</p> Type Description <code>WeaviateBaseError</code> <p>If update operation fails</p> Source code in <code>ragora/ragora/core/vector_store.py</code> <pre><code>def update_chunk(\n    self, chunk_id: str, properties: Dict[str, Any], collection: str\n) -&gt; bool:\n    \"\"\"Update a chunk by its chunk_id using V4 API.\n\n    Args:\n        chunk_id: ID of the chunk to update\n        properties: Properties to update\n        collection: Name of the Weaviate class for document storage\n    Returns:\n        bool: True if update was successful, False otherwise\n\n    Raises:\n        WeaviateBaseError: If update operation fails\n    \"\"\"\n\n    try:\n        # Get the collection\n        collection = self.db_manager.get_collection(collection)\n\n        # Update by ID\n        collection.data.update_by_id(\n            uuid=generate_uuid5(chunk_id),\n            properties=properties,\n        )\n        self.logger.debug(f\"Successfully updated chunk: {chunk_id}\")\n        return True\n\n    except WeaviateBaseError as e:\n        self.logger.error(f\"Failed to update chunk {chunk_id}: {str(e)}\")\n        raise\n</code></pre>"},{"location":"api-reference/#database-manager","title":"Database Manager","text":"<p>Infrastructure helpers for connecting Ragora to Weaviate.</p>"},{"location":"api-reference/#ragora.core.database_manager.DatabaseManager","title":"<code>DatabaseManager</code>","text":"<p>Lightweight fa\u00e7ade over the Weaviate Python client.</p> <p>Attributes:</p> Name Type Description <code>client</code> <p>Low-level Weaviate client instance.</p> <code>url</code> <p>Weaviate HTTP endpoint.</p> <code>grpc_port</code> <p>Optional gRPC port.</p> <code>timeout</code> <p>Request timeout in seconds.</p> <code>retry_attempts</code> <p>How many retries to attempt for transient failures.</p> <code>is_connected</code> <p>Indicates whether :meth:<code>_test_connection</code> succeeded.</p> <code>logger</code> <p>Module logger.</p> <p>Examples:</p> <pre><code>from ragora.core.database_manager import DatabaseManager\n\ndb = DatabaseManager(url=\"http://localhost:8080\")\ncollections = db.list_collections()\n</code></pre> Source code in <code>ragora/ragora/core/database_manager.py</code> <pre><code>class DatabaseManager:\n    \"\"\"Lightweight fa\u00e7ade over the Weaviate Python client.\n\n    Attributes:\n        client: Low-level Weaviate client instance.\n        url: Weaviate HTTP endpoint.\n        grpc_port: Optional gRPC port.\n        timeout: Request timeout in seconds.\n        retry_attempts: How many retries to attempt for transient failures.\n        is_connected: Indicates whether :meth:`_test_connection` succeeded.\n        logger: Module logger.\n\n    Examples:\n        ```python\n        from ragora.core.database_manager import DatabaseManager\n\n        db = DatabaseManager(url=\"http://localhost:8080\")\n        collections = db.list_collections()\n        ```\n    \"\"\"\n\n    def __init__(\n        self,\n        url: str = \"http://localhost:8080\",\n        grpc_port: int = 50051,\n        timeout: int = 60,\n        retry_attempts: int = 3,\n    ):\n        \"\"\"Initialize the DatabaseManager with Weaviate connection.\n\n        Args:\n            url: Weaviate server URL\n            grpc_port: gRPC port for Weaviate connection\n            timeout: Connection timeout in seconds\n            retry_attempts: Number of retry attempts for failed operations\n\n        Raises:\n            ConnectionError: If unable to connect to Weaviate\n            ValueError: If invalid parameters are provided\n        \"\"\"\n        self.url = url\n        self.grpc_port = grpc_port\n        self.timeout = timeout\n        self.retry_attempts = retry_attempts\n        self.is_connected = False\n\n        # Set up logging\n        self.logger = logging.getLogger(__name__)\n\n        # Initialize Weaviate client\n        try:\n            self.logger.info(f\"Connecting to Weaviate at {url}\")\n            # Parse URL to extract host and port\n            connection_param = ConnectionParams.from_url(\n                url=url,\n                # Keep gRPC port but it will fail gracefully\n                grpc_port=grpc_port,\n            )\n            self.client = WeaviateClient(connection_param)\n            self.client.connect()\n            self._test_connection()\n            self.logger.info(\"Successfully connected to Weaviate\")\n\n        except Exception as e:\n            self.logger.error(f\"Failed to connect to Weaviate: {str(e)}\")\n            raise ConnectionError(f\"Could not connect to Weaviate at {url}: {str(e)}\")\n\n    def _test_connection(self) -&gt; bool:\n        \"\"\"Test the connection to Weaviate.\n\n        Returns:\n            bool: True if connection is successful\n\n        Raises:\n            ConnectionError: If connection test fails\n        \"\"\"\n        try:\n            # Test connection by checking if Weaviate is ready\n            if not self.client.is_ready():\n                raise ConnectionError(\"Weaviate is not ready\")\n\n            # Test with a simple query - V4 API\n            self.client.collections.list_all()\n            self.is_connected = True\n            return True\n        except Exception as e:\n            self.is_connected = False\n            raise ConnectionError(f\"Connection test failed: {str(e)}\")\n\n    def _normalize_collection_name(self, name: str) -&gt; str:\n        \"\"\"Normalize collection name to Weaviate's naming convention.\n\n        Weaviate automatically capitalizes the first letter of collection\n        names. This method ensures we match Weaviate's expected format.\n\n        Args:\n            name: The original collection name\n\n        Returns:\n            str: Collection name with first letter capitalized\n\n        Raises:\n            ValueError: If name is empty\n        \"\"\"\n        if not name or not name.strip():\n            raise ValueError(\"Collection name cannot be empty\")\n\n        # Capitalize first letter, keep rest as-is\n        return name[0].upper() + name[1:]\n\n    def is_ready(self) -&gt; bool:\n        \"\"\"Check if the database is ready for operations.\n\n        Returns:\n            bool: True if database is ready\n        \"\"\"\n        try:\n            return self.client.is_ready()\n        except Exception as e:\n            self.logger.error(f\"Database readiness check failed: {str(e)}\")\n            return False\n\n    def get_collection(self, name: str):\n        \"\"\"Get a collection reference by name.\n\n        Args:\n            name: Name of the collection to retrieve\n\n        Returns:\n            Collection object for the specified name\n\n        Raises:\n            ValueError: If collection name is empty\n            WeaviateBaseError: If collection access fails\n        \"\"\"\n        if not name or not name.strip():\n            raise ValueError(\"Collection name cannot be empty\")\n\n        try:\n            # Normalize name to Weaviate's naming convention\n            normalized_name = self._normalize_collection_name(name)\n            collection = self.client.collections.get(normalized_name)\n            self.logger.debug(f\"Retrieved collection: {normalized_name}\")\n            return collection\n        except WeaviateBaseError as e:\n            self.logger.error(f\"Failed to get collection {name}: {str(e)}\")\n            raise\n\n    def create_collection(\n        self,\n        name: str,\n        description: str = \"\",\n        vectorizer_config=None,\n        properties: List[Dict[str, Any]] = None,\n    ):\n        \"\"\"Create a new collection with the specified configuration.\n\n        Args:\n            name: Name of the collection to create\n            description: Description of the collection\n            vectorizer_config: Vectorizer configuration\n            properties: List of property configurations\n\n        Returns:\n            Created collection object\n\n        Raises:\n            ValueError: If collection name is empty\n            WeaviateBaseError: If collection creation fails\n        \"\"\"\n        if not name or not name.strip():\n            raise ValueError(\"Collection name cannot be empty\")\n\n        try:\n            # Normalize name to Weaviate's naming convention\n            normalized_name = self._normalize_collection_name(name)\n            self.logger.info(f\"Creating collection: {normalized_name}\")\n\n            # Create the collection using V4 API\n            collection = self.client.collections.create(\n                name=normalized_name,\n                description=description,\n                vectorizer_config=vectorizer_config,\n                properties=properties or [],\n            )\n\n            self.logger.info(f\"Successfully created collection: {normalized_name}\")\n            return collection\n\n        except WeaviateBaseError as e:\n            self.logger.error(f\"Failed to create collection {name}: {str(e)}\")\n            raise\n\n    def delete_collection(self, name: str) -&gt; bool:\n        \"\"\"Delete a collection by name.\n\n        Args:\n            name: Name of the collection to delete\n\n        Returns:\n            bool: True if deletion was successful\n\n        Raises:\n            ValueError: If collection name is empty\n            WeaviateBaseError: If collection deletion fails\n        \"\"\"\n        if not name or not name.strip():\n            raise ValueError(\"Collection name cannot be empty\")\n\n        try:\n            # Normalize name to Weaviate's naming convention\n            normalized_name = self._normalize_collection_name(name)\n            self.logger.info(f\"Deleting collection: {normalized_name}\")\n            self.client.collections.delete(normalized_name)\n            self.logger.info(f\"Successfully deleted collection: {normalized_name}\")\n            return True\n\n        except WeaviateBaseError as e:\n            self.logger.error(f\"Failed to delete collection {name}: {str(e)}\")\n            raise\n\n    def list_collections(self) -&gt; List[str]:\n        \"\"\"List all available collections.\n\n        Returns:\n            List[str]: List of collection names\n\n        Raises:\n            WeaviateBaseError: If listing collections fails\n        \"\"\"\n        try:\n            collections = self.client.collections.list_all()\n            collection_names = list(collections.keys())\n            self.logger.debug(f\"Found {len(collection_names)} collections\")\n            return collection_names\n        except WeaviateBaseError as e:\n            self.logger.error(f\"Failed to list collections: {str(e)}\")\n            raise\n\n    def collection_exists(self, name: str) -&gt; bool:\n        \"\"\"Check if a collection exists.\n\n        Args:\n            name: Name of the collection to check\n\n        Returns:\n            bool: True if collection exists\n\n        Raises:\n            ValueError: If collection name is empty\n        \"\"\"\n        if not name or not name.strip():\n            raise ValueError(\"Collection name cannot be empty\")\n\n        try:\n            # Normalize the name to Weaviate's naming convention\n            normalized_name = self._normalize_collection_name(name)\n            collections = self.list_collections()\n            return normalized_name in collections\n        except Exception as e:\n            self.logger.error(f\"Failed to check if collection {name} exists: {str(e)}\")\n            return False\n\n    def get_client(self) -&gt; WeaviateClient:\n        \"\"\"Get the underlying Weaviate client.\n\n        Returns:\n            WeaviateClient: The underlying client instance\n        \"\"\"\n        return self.client\n\n    def close(self) -&gt; None:\n        \"\"\"Close the connection to Weaviate.\"\"\"\n        try:\n            if hasattr(self, \"client\") and self.client:\n                # Weaviate client doesn't have an explicit close method\n                # but we can mark the connection as closed\n                self.is_connected = False\n                self.logger.info(\"Database manager connection closed\")\n        except Exception as e:\n            self.logger.error(f\"Error closing database manager: {str(e)}\")\n\n    def __enter__(self):\n        \"\"\"Context manager entry.\"\"\"\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        \"\"\"Context manager exit.\"\"\"\n        self.close()\n</code></pre>"},{"location":"api-reference/#ragora.core.database_manager.DatabaseManager._normalize_collection_name","title":"<code>_normalize_collection_name(name)</code>","text":"<p>Normalize collection name to Weaviate's naming convention.</p> <p>Weaviate automatically capitalizes the first letter of collection names. This method ensures we match Weaviate's expected format.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The original collection name</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Collection name with first letter capitalized</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If name is empty</p> Source code in <code>ragora/ragora/core/database_manager.py</code> <pre><code>def _normalize_collection_name(self, name: str) -&gt; str:\n    \"\"\"Normalize collection name to Weaviate's naming convention.\n\n    Weaviate automatically capitalizes the first letter of collection\n    names. This method ensures we match Weaviate's expected format.\n\n    Args:\n        name: The original collection name\n\n    Returns:\n        str: Collection name with first letter capitalized\n\n    Raises:\n        ValueError: If name is empty\n    \"\"\"\n    if not name or not name.strip():\n        raise ValueError(\"Collection name cannot be empty\")\n\n    # Capitalize first letter, keep rest as-is\n    return name[0].upper() + name[1:]\n</code></pre>"},{"location":"api-reference/#ragora.core.database_manager.DatabaseManager._test_connection","title":"<code>_test_connection()</code>","text":"<p>Test the connection to Weaviate.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if connection is successful</p> <p>Raises:</p> Type Description <code>ConnectionError</code> <p>If connection test fails</p> Source code in <code>ragora/ragora/core/database_manager.py</code> <pre><code>def _test_connection(self) -&gt; bool:\n    \"\"\"Test the connection to Weaviate.\n\n    Returns:\n        bool: True if connection is successful\n\n    Raises:\n        ConnectionError: If connection test fails\n    \"\"\"\n    try:\n        # Test connection by checking if Weaviate is ready\n        if not self.client.is_ready():\n            raise ConnectionError(\"Weaviate is not ready\")\n\n        # Test with a simple query - V4 API\n        self.client.collections.list_all()\n        self.is_connected = True\n        return True\n    except Exception as e:\n        self.is_connected = False\n        raise ConnectionError(f\"Connection test failed: {str(e)}\")\n</code></pre>"},{"location":"api-reference/#ragora.core.database_manager.DatabaseManager.close","title":"<code>close()</code>","text":"<p>Close the connection to Weaviate.</p> Source code in <code>ragora/ragora/core/database_manager.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Close the connection to Weaviate.\"\"\"\n    try:\n        if hasattr(self, \"client\") and self.client:\n            # Weaviate client doesn't have an explicit close method\n            # but we can mark the connection as closed\n            self.is_connected = False\n            self.logger.info(\"Database manager connection closed\")\n    except Exception as e:\n        self.logger.error(f\"Error closing database manager: {str(e)}\")\n</code></pre>"},{"location":"api-reference/#ragora.core.database_manager.DatabaseManager.collection_exists","title":"<code>collection_exists(name)</code>","text":"<p>Check if a collection exists.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the collection to check</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if collection exists</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If collection name is empty</p> Source code in <code>ragora/ragora/core/database_manager.py</code> <pre><code>def collection_exists(self, name: str) -&gt; bool:\n    \"\"\"Check if a collection exists.\n\n    Args:\n        name: Name of the collection to check\n\n    Returns:\n        bool: True if collection exists\n\n    Raises:\n        ValueError: If collection name is empty\n    \"\"\"\n    if not name or not name.strip():\n        raise ValueError(\"Collection name cannot be empty\")\n\n    try:\n        # Normalize the name to Weaviate's naming convention\n        normalized_name = self._normalize_collection_name(name)\n        collections = self.list_collections()\n        return normalized_name in collections\n    except Exception as e:\n        self.logger.error(f\"Failed to check if collection {name} exists: {str(e)}\")\n        return False\n</code></pre>"},{"location":"api-reference/#ragora.core.database_manager.DatabaseManager.create_collection","title":"<code>create_collection(name, description='', vectorizer_config=None, properties=None)</code>","text":"<p>Create a new collection with the specified configuration.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the collection to create</p> required <code>description</code> <code>str</code> <p>Description of the collection</p> <code>''</code> <code>vectorizer_config</code> <p>Vectorizer configuration</p> <code>None</code> <code>properties</code> <code>List[Dict[str, Any]]</code> <p>List of property configurations</p> <code>None</code> <p>Returns:</p> Type Description <p>Created collection object</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If collection name is empty</p> <code>WeaviateBaseError</code> <p>If collection creation fails</p> Source code in <code>ragora/ragora/core/database_manager.py</code> <pre><code>def create_collection(\n    self,\n    name: str,\n    description: str = \"\",\n    vectorizer_config=None,\n    properties: List[Dict[str, Any]] = None,\n):\n    \"\"\"Create a new collection with the specified configuration.\n\n    Args:\n        name: Name of the collection to create\n        description: Description of the collection\n        vectorizer_config: Vectorizer configuration\n        properties: List of property configurations\n\n    Returns:\n        Created collection object\n\n    Raises:\n        ValueError: If collection name is empty\n        WeaviateBaseError: If collection creation fails\n    \"\"\"\n    if not name or not name.strip():\n        raise ValueError(\"Collection name cannot be empty\")\n\n    try:\n        # Normalize name to Weaviate's naming convention\n        normalized_name = self._normalize_collection_name(name)\n        self.logger.info(f\"Creating collection: {normalized_name}\")\n\n        # Create the collection using V4 API\n        collection = self.client.collections.create(\n            name=normalized_name,\n            description=description,\n            vectorizer_config=vectorizer_config,\n            properties=properties or [],\n        )\n\n        self.logger.info(f\"Successfully created collection: {normalized_name}\")\n        return collection\n\n    except WeaviateBaseError as e:\n        self.logger.error(f\"Failed to create collection {name}: {str(e)}\")\n        raise\n</code></pre>"},{"location":"api-reference/#ragora.core.database_manager.DatabaseManager.delete_collection","title":"<code>delete_collection(name)</code>","text":"<p>Delete a collection by name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the collection to delete</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if deletion was successful</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If collection name is empty</p> <code>WeaviateBaseError</code> <p>If collection deletion fails</p> Source code in <code>ragora/ragora/core/database_manager.py</code> <pre><code>def delete_collection(self, name: str) -&gt; bool:\n    \"\"\"Delete a collection by name.\n\n    Args:\n        name: Name of the collection to delete\n\n    Returns:\n        bool: True if deletion was successful\n\n    Raises:\n        ValueError: If collection name is empty\n        WeaviateBaseError: If collection deletion fails\n    \"\"\"\n    if not name or not name.strip():\n        raise ValueError(\"Collection name cannot be empty\")\n\n    try:\n        # Normalize name to Weaviate's naming convention\n        normalized_name = self._normalize_collection_name(name)\n        self.logger.info(f\"Deleting collection: {normalized_name}\")\n        self.client.collections.delete(normalized_name)\n        self.logger.info(f\"Successfully deleted collection: {normalized_name}\")\n        return True\n\n    except WeaviateBaseError as e:\n        self.logger.error(f\"Failed to delete collection {name}: {str(e)}\")\n        raise\n</code></pre>"},{"location":"api-reference/#ragora.core.database_manager.DatabaseManager.get_client","title":"<code>get_client()</code>","text":"<p>Get the underlying Weaviate client.</p> <p>Returns:</p> Name Type Description <code>WeaviateClient</code> <code>WeaviateClient</code> <p>The underlying client instance</p> Source code in <code>ragora/ragora/core/database_manager.py</code> <pre><code>def get_client(self) -&gt; WeaviateClient:\n    \"\"\"Get the underlying Weaviate client.\n\n    Returns:\n        WeaviateClient: The underlying client instance\n    \"\"\"\n    return self.client\n</code></pre>"},{"location":"api-reference/#ragora.core.database_manager.DatabaseManager.get_collection","title":"<code>get_collection(name)</code>","text":"<p>Get a collection reference by name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the collection to retrieve</p> required <p>Returns:</p> Type Description <p>Collection object for the specified name</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If collection name is empty</p> <code>WeaviateBaseError</code> <p>If collection access fails</p> Source code in <code>ragora/ragora/core/database_manager.py</code> <pre><code>def get_collection(self, name: str):\n    \"\"\"Get a collection reference by name.\n\n    Args:\n        name: Name of the collection to retrieve\n\n    Returns:\n        Collection object for the specified name\n\n    Raises:\n        ValueError: If collection name is empty\n        WeaviateBaseError: If collection access fails\n    \"\"\"\n    if not name or not name.strip():\n        raise ValueError(\"Collection name cannot be empty\")\n\n    try:\n        # Normalize name to Weaviate's naming convention\n        normalized_name = self._normalize_collection_name(name)\n        collection = self.client.collections.get(normalized_name)\n        self.logger.debug(f\"Retrieved collection: {normalized_name}\")\n        return collection\n    except WeaviateBaseError as e:\n        self.logger.error(f\"Failed to get collection {name}: {str(e)}\")\n        raise\n</code></pre>"},{"location":"api-reference/#ragora.core.database_manager.DatabaseManager.is_ready","title":"<code>is_ready()</code>","text":"<p>Check if the database is ready for operations.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if database is ready</p> Source code in <code>ragora/ragora/core/database_manager.py</code> <pre><code>def is_ready(self) -&gt; bool:\n    \"\"\"Check if the database is ready for operations.\n\n    Returns:\n        bool: True if database is ready\n    \"\"\"\n    try:\n        return self.client.is_ready()\n    except Exception as e:\n        self.logger.error(f\"Database readiness check failed: {str(e)}\")\n        return False\n</code></pre>"},{"location":"api-reference/#ragora.core.database_manager.DatabaseManager.list_collections","title":"<code>list_collections()</code>","text":"<p>List all available collections.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: List of collection names</p> <p>Raises:</p> Type Description <code>WeaviateBaseError</code> <p>If listing collections fails</p> Source code in <code>ragora/ragora/core/database_manager.py</code> <pre><code>def list_collections(self) -&gt; List[str]:\n    \"\"\"List all available collections.\n\n    Returns:\n        List[str]: List of collection names\n\n    Raises:\n        WeaviateBaseError: If listing collections fails\n    \"\"\"\n    try:\n        collections = self.client.collections.list_all()\n        collection_names = list(collections.keys())\n        self.logger.debug(f\"Found {len(collection_names)} collections\")\n        return collection_names\n    except WeaviateBaseError as e:\n        self.logger.error(f\"Failed to list collections: {str(e)}\")\n        raise\n</code></pre>"},{"location":"api-reference/#chunking","title":"Chunking","text":"<p>Chunking system for Ragora.</p> <p>This module provides the core chunking functionality for the Ragora system, including data structures, context management, and the main chunker interface.</p>"},{"location":"api-reference/#ragora.core.chunking--architecture-overview","title":"Architecture Overview","text":"<p>The chunking system uses a Strategy Pattern to support different types of content chunking (text, documents, emails) with a clean, extensible API. The main components are:</p> <ul> <li>DataChunker: Main interface for chunking operations</li> <li>ChunkingContext: Contains metadata and configuration for chunking</li> <li>ChunkingContextBuilder: Fluent API for creating contexts</li> <li>ChunkingStrategy: Abstract base for different chunking implementations</li> <li>DataChunk: Result object containing chunked text and metadata</li> </ul>"},{"location":"api-reference/#ragora.core.chunking--quick-start","title":"Quick Start","text":"<pre><code>from ragora import DataChunker, ChunkingContextBuilder\n\n# Create a chunker\nchunker = DataChunker()\n\n# Basic text chunking\ncontext = ChunkingContextBuilder().for_text().build()\nchunks = chunker.chunk(\"Your text here\", context)\n\n# Document chunking with metadata\ncontext = (ChunkingContextBuilder()\n          .for_document()\n          .with_source(\"paper.pdf\")\n          .with_page(1)\n          .with_section(\"Introduction\")\n          .build())\nchunks = chunker.chunk(document_text, context)\n\n# Email chunking\ncontext = (ChunkingContextBuilder()\n          .for_email()\n          .with_email_info(\"Meeting Notes\", \"john@example.com\", \"team@example.com\")\n          .build())\nchunks = chunker.chunk(email_text, context)\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking--detailed-usage-guide","title":"Detailed Usage Guide","text":""},{"location":"api-reference/#ragora.core.chunking--1-basic-text-chunking","title":"1. Basic Text Chunking","text":"<p>For simple text chunking without special metadata:</p> <pre><code>from ragora import DataChunker, ChunkingContextBuilder\n\nchunker = DataChunker()\ncontext = ChunkingContextBuilder().for_text().build()\nchunks = chunker.chunk(\"This is a long text that will be chunked...\", context)\n\n# Access chunk data\nfor chunk in chunks:\n    print(f\"Chunk {chunk.metadata.chunk_id}: {chunk.text}\")\n    print(f\"Size: {chunk.metadata.chunk_size} characters\")\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking--2-document-chunking","title":"2. Document Chunking","text":"<p>For academic papers, reports, or structured documents:</p> <pre><code>context = (ChunkingContextBuilder()\n          .for_document()\n          .with_source(\"research_paper.pdf\")\n          .with_page(5)\n          .with_section(\"Methodology\")\n          .with_created_at(\"2024-01-15\")\n          .build())\n\nchunks = chunker.chunk(document_content, context)\n\n# Document chunks include page and section information\nfor chunk in chunks:\n    print(f\"Page {chunk.metadata.page_number}, Section: {chunk.metadata.section_title}\")\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking--3-email-chunking","title":"3. Email Chunking","text":"<p>For email content with sender/recipient metadata:</p> <pre><code>context = (ChunkingContextBuilder()\n          .for_email()\n          .with_email_info(\n              subject=\"Project Update\",\n              sender=\"manager@company.com\",\n              recipient=\"team@company.com\",\n              email_id=\"msg_12345\",\n              email_date=\"2024-01-15T14:30:00Z\"\n          )\n          .build())\n\nchunks = chunker.chunk(email_body, context)\n\n# Email chunks preserve sender/recipient information\nfor chunk in chunks:\n    print(f\"From: {chunk.metadata.email_sender}\")\n    print(f\"Subject: {chunk.metadata.email_subject}\")\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking--4-custom-chunking-strategies","title":"4. Custom Chunking Strategies","text":"<p>Create your own chunking logic for specialized content:</p> <pre><code>from ragora import ChunkingStrategy, ChunkingContext, DataChunk, ChunkMetadata\n\nclass CodeChunkingStrategy(ChunkingStrategy):\n    def __init__(self):\n        super().__init__(chunk_size=1000, overlap_size=100)\n\n    def chunk(self, text: str, context: ChunkingContext) -&gt; List[DataChunk]:\n        # Custom logic for code chunking (e.g., preserve function boundaries)\n        # Implementation here...\n        pass\n\n# Register and use custom strategy\nchunker = DataChunker()\nchunker.register_strategy(\"code\", CodeChunkingStrategy())\n\ncontext = ChunkingContextBuilder().for_text().build()\ncontext.chunk_type = \"code\"  # Use custom strategy\nchunks = chunker.chunk(code_text, context)\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking--5-stateless-chunk-id-management","title":"5. Stateless Chunk ID Management","text":"<p>Control chunk ID generation for consistent results:</p> <pre><code># Start chunking from sequence index 100\ncontext = (ChunkingContextBuilder()\n          .for_document()\n          .with_start_sequence_idx(100)\n          .build())\n\nchunks = chunker.chunk(text, context)\n# First chunk will have sequence number 100, second chunk 101, etc.\n\n# Continue chunking from where you left off\nnext_context = (ChunkingContextBuilder()\n               .for_document()\n               .with_start_sequence_idx(100 + len(chunks))\n               .build())\nmore_chunks = chunker.chunk(more_text, next_context)\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking--6-batch-processing-multiple-documents","title":"6. Batch Processing Multiple Documents","text":"<p>Process multiple documents while maintaining unique chunk IDs:</p> <pre><code>def process_documents(documents):\n    chunker = DataChunker()\n    all_chunks = []\n    sequence_idx_counter = 0\n\n    for doc in documents:\n        context = (ChunkingContextBuilder()\n                  .for_document()\n                  .with_source(doc.filename)\n                  .with_start_sequence_idx(sequence_idx_counter)\n                  .build())\n\n        chunks = chunker.chunk(doc.content, context)\n        all_chunks.extend(chunks)\n        sequence_idx_counter += len(chunks)\n\n    return all_chunks\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking--strategy-types-and-defaults","title":"Strategy Types and Defaults","text":"Strategy Chunk Size Overlap Use Case TextChunkingStrategy 768 100 General text content DocumentChunkingStrategy 768 100 Academic papers, reports EmailChunkingStrategy 512 50 Email messages"},{"location":"api-reference/#ragora.core.chunking--advanced-features","title":"Advanced Features","text":""},{"location":"api-reference/#ragora.core.chunking--custom-metadata","title":"Custom Metadata","text":"<p>Add custom fields for future extensions:</p> <pre><code>context = (ChunkingContextBuilder()\n          .for_text()\n          .with_custom_metadata({\n              \"language\": \"en\",\n              \"domain\": \"scientific\",\n              \"confidence\": 0.95\n          })\n          .build())\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking--strategy-selection","title":"Strategy Selection","text":"<p>The chunker automatically selects strategies based on <code>context.chunk_type</code>:</p> <pre><code># These will use different strategies:\ntext_context = ChunkingContextBuilder().for_text().build()      # TextChunkingStrategy\ndoc_context = ChunkingContextBuilder().for_document().build()  # DocumentChunkingStrategy\nemail_context = ChunkingContextBuilder().for_email().build()  # EmailChunkingStrategy\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking--performance-considerations","title":"Performance Considerations","text":"<ul> <li>Chunk Size: Larger chunks (768+) work well for documents, smaller (512) for emails</li> <li>Overlap: Higher overlap (100) preserves context, lower (50) reduces redundancy</li> <li>Memory: Chunking is memory-efficient, processing text in streams</li> <li>Threading: Strategies are stateless and thread-safe</li> </ul>"},{"location":"api-reference/#ragora.core.chunking--error-handling","title":"Error Handling","text":"<p>The chunking system handles edge cases gracefully:</p> <pre><code># Empty text returns empty list\nchunks = chunker.chunk(\"\", context)  # Returns []\n\n# Whitespace-only text returns empty list\nchunks = chunker.chunk(\"   \n           \", context)  # Returns []\n\n# Invalid context falls back to default strategy\ncontext.chunk_type = \"unknown\"\nchunks = chunker.chunk(text, context)  # Uses default_strategy\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.ChunkIdGenerator","title":"<code>ChunkIdGenerator</code>","text":"<p>Centralized, deterministic chunk ID generator for all chunking strategies.</p> <p>This class provides a unified way to generate human-readable, deterministic chunk IDs across all content types and chunking strategies. The IDs follow a composite format that includes content type, source identification, location information, and sequence numbering.</p> <p>ID Format: {content_type}:{source_id}:{location_id}:{sequence_id}</p> <p>Examples: - text:doc_001:0:0001 - document:paper_2024_01:page_5:0003 - email:msg_abc123:thread_001:0001 - custom:user_data:batch_001:0002</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>class ChunkIdGenerator:\n    \"\"\"Centralized, deterministic chunk ID generator for all chunking strategies.\n\n    This class provides a unified way to generate human-readable, deterministic\n    chunk IDs across all content types and chunking strategies. The IDs follow\n    a composite format that includes content type, source identification,\n    location information, and sequence numbering.\n\n    ID Format: {content_type}:{source_id}:{location_id}:{sequence_id}\n\n    Examples:\n    - text:doc_001:0:0001\n    - document:paper_2024_01:page_5:0003\n    - email:msg_abc123:thread_001:0001\n    - custom:user_data:batch_001:0002\n    \"\"\"\n\n    @staticmethod\n    def generate_chunk_id(\n        content_type: str,\n        source_id: str,\n        location_id: str = \"0\",\n        sequence_id: int = 0,\n        chunk_idx: int = 0,\n    ) -&gt; str:\n        \"\"\"Generate a deterministic, human-readable chunk ID.\n\n        Args:\n            content_type: Type of content (text, document, email, custom)\n            source_id: Unique identifier for the source document/content\n            location_id: Location within source (page, section, etc.)\n            sequence_id: Starting sequence number for this chunking session\n            chunk_idx: Index of this chunk within the sequence\n\n        Returns:\n            str: Deterministic chunk ID in format\n                 content_type:source_id:location_id:sequence_num\n        \"\"\"\n        # Normalize inputs\n        content_type = ChunkIdGenerator._normalize_content_type(content_type)\n        source_id = ChunkIdGenerator._normalize_source_id(source_id)\n        location_id = ChunkIdGenerator._normalize_location_id(location_id)\n\n        # Generate sequence number\n        sequence_num = sequence_id + chunk_idx\n\n        return f\"{content_type}:{source_id}:{location_id}:{sequence_num:04d}\"\n\n    @staticmethod\n    def _normalize_content_type(content_type: str) -&gt; str:\n        \"\"\"Normalize content type for consistent formatting.\"\"\"\n        if not content_type:\n            return \"text\"\n\n        # Convert to lowercase and validate\n        normalized = content_type.lower().strip()\n\n        # Map common variations to standard types\n        type_mapping = {\n            \"doc\": \"document\",\n            \"docs\": \"document\",\n            \"msg\": \"email\",\n            \"mail\": \"email\",\n            \"txt\": \"text\",\n            \"plain\": \"text\",\n        }\n\n        return type_mapping.get(normalized, normalized)\n\n    @staticmethod\n    def _normalize_source_id(source_id: str) -&gt; str:\n        \"\"\"Normalize source ID for consistent formatting.\"\"\"\n        if not source_id:\n            return \"unknown\"\n\n        # Remove special characters, convert to lowercase, limit length\n        normalized = re.sub(r\"[^a-zA-Z0-9_-]\", \"_\", source_id.lower())\n        normalized = re.sub(r\"_+\", \"_\", normalized)  # Collapse multiple underscores\n        normalized = normalized.strip(\"_\")  # Remove leading/trailing underscores\n\n        return normalized[:20] if normalized else \"unknown\"  # Limit to 20 chars\n\n    @staticmethod\n    def _normalize_location_id(location_id: str) -&gt; str:\n        \"\"\"Normalize location ID for consistent formatting.\"\"\"\n        if not location_id:\n            return \"0\"\n\n        # Convert to string and normalize\n        location_str = str(location_id).lower().strip()\n\n        # Handle common location patterns\n        if location_str == \"0\":\n            return \"0\"  # Keep \"0\" as is for default case\n        elif location_str.isdigit():\n            return f\"pos_{location_str}\"\n        elif location_str.startswith(\"page_\"):\n            return location_str\n        elif location_str.startswith(\"sec_\"):\n            return location_str\n        elif location_str.startswith(\"msg_\"):\n            return location_str\n        else:\n            # General normalization\n            normalized = re.sub(r\"[^a-zA-Z0-9_-]\", \"_\", location_str)\n            normalized = re.sub(r\"_+\", \"_\", normalized)\n            normalized = normalized.strip(\"_\")\n            return normalized[:15] if normalized else \"0\"  # Limit to 15 chars\n\n    @staticmethod\n    def parse_chunk_id(chunk_id: str) -&gt; Dict[str, str]:\n        \"\"\"Parse a chunk ID back into its components.\n\n        Args:\n            chunk_id: The chunk ID to parse\n\n        Returns:\n            Dict containing parsed components: content_type, source_id, location_id, sequence_num\n\n        Raises:\n            ValueError: If chunk ID format is invalid\n        \"\"\"\n        parts = chunk_id.split(\":\")\n        if len(parts) != 4:\n            raise ValueError(\n                f\"Invalid chunk ID format: {chunk_id}. Expected format: content_type:source_id:location_id:sequence_num\"\n            )\n\n        return {\n            \"content_type\": parts[0],\n            \"source_id\": parts[1],\n            \"location_id\": parts[2],\n            \"sequence_num\": parts[3],\n        }\n\n    @staticmethod\n    def get_source_hash(source_id: str, max_length: int = 8) -&gt; str:\n        \"\"\"Generate a short hash for source ID when it's too long.\n\n        Args:\n            source_id: The source ID to hash\n            max_length: Maximum length of the hash\n\n        Returns:\n            str: Short hash of the source ID\n        \"\"\"\n        if not source_id:\n            return \"unknown\"\n\n        # Create a deterministic hash\n        hash_obj = hashlib.md5(source_id.encode(\"utf-8\"))\n        hash_hex = hash_obj.hexdigest()\n\n        return hash_hex[:max_length]\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.ChunkIdGenerator._normalize_content_type","title":"<code>_normalize_content_type(content_type)</code>  <code>staticmethod</code>","text":"<p>Normalize content type for consistent formatting.</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>@staticmethod\ndef _normalize_content_type(content_type: str) -&gt; str:\n    \"\"\"Normalize content type for consistent formatting.\"\"\"\n    if not content_type:\n        return \"text\"\n\n    # Convert to lowercase and validate\n    normalized = content_type.lower().strip()\n\n    # Map common variations to standard types\n    type_mapping = {\n        \"doc\": \"document\",\n        \"docs\": \"document\",\n        \"msg\": \"email\",\n        \"mail\": \"email\",\n        \"txt\": \"text\",\n        \"plain\": \"text\",\n    }\n\n    return type_mapping.get(normalized, normalized)\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.ChunkIdGenerator._normalize_location_id","title":"<code>_normalize_location_id(location_id)</code>  <code>staticmethod</code>","text":"<p>Normalize location ID for consistent formatting.</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>@staticmethod\ndef _normalize_location_id(location_id: str) -&gt; str:\n    \"\"\"Normalize location ID for consistent formatting.\"\"\"\n    if not location_id:\n        return \"0\"\n\n    # Convert to string and normalize\n    location_str = str(location_id).lower().strip()\n\n    # Handle common location patterns\n    if location_str == \"0\":\n        return \"0\"  # Keep \"0\" as is for default case\n    elif location_str.isdigit():\n        return f\"pos_{location_str}\"\n    elif location_str.startswith(\"page_\"):\n        return location_str\n    elif location_str.startswith(\"sec_\"):\n        return location_str\n    elif location_str.startswith(\"msg_\"):\n        return location_str\n    else:\n        # General normalization\n        normalized = re.sub(r\"[^a-zA-Z0-9_-]\", \"_\", location_str)\n        normalized = re.sub(r\"_+\", \"_\", normalized)\n        normalized = normalized.strip(\"_\")\n        return normalized[:15] if normalized else \"0\"  # Limit to 15 chars\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.ChunkIdGenerator._normalize_source_id","title":"<code>_normalize_source_id(source_id)</code>  <code>staticmethod</code>","text":"<p>Normalize source ID for consistent formatting.</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>@staticmethod\ndef _normalize_source_id(source_id: str) -&gt; str:\n    \"\"\"Normalize source ID for consistent formatting.\"\"\"\n    if not source_id:\n        return \"unknown\"\n\n    # Remove special characters, convert to lowercase, limit length\n    normalized = re.sub(r\"[^a-zA-Z0-9_-]\", \"_\", source_id.lower())\n    normalized = re.sub(r\"_+\", \"_\", normalized)  # Collapse multiple underscores\n    normalized = normalized.strip(\"_\")  # Remove leading/trailing underscores\n\n    return normalized[:20] if normalized else \"unknown\"  # Limit to 20 chars\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.ChunkIdGenerator.generate_chunk_id","title":"<code>generate_chunk_id(content_type, source_id, location_id='0', sequence_id=0, chunk_idx=0)</code>  <code>staticmethod</code>","text":"<p>Generate a deterministic, human-readable chunk ID.</p> <p>Parameters:</p> Name Type Description Default <code>content_type</code> <code>str</code> <p>Type of content (text, document, email, custom)</p> required <code>source_id</code> <code>str</code> <p>Unique identifier for the source document/content</p> required <code>location_id</code> <code>str</code> <p>Location within source (page, section, etc.)</p> <code>'0'</code> <code>sequence_id</code> <code>int</code> <p>Starting sequence number for this chunking session</p> <code>0</code> <code>chunk_idx</code> <code>int</code> <p>Index of this chunk within the sequence</p> <code>0</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Deterministic chunk ID in format  content_type:source_id:location_id:sequence_num</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>@staticmethod\ndef generate_chunk_id(\n    content_type: str,\n    source_id: str,\n    location_id: str = \"0\",\n    sequence_id: int = 0,\n    chunk_idx: int = 0,\n) -&gt; str:\n    \"\"\"Generate a deterministic, human-readable chunk ID.\n\n    Args:\n        content_type: Type of content (text, document, email, custom)\n        source_id: Unique identifier for the source document/content\n        location_id: Location within source (page, section, etc.)\n        sequence_id: Starting sequence number for this chunking session\n        chunk_idx: Index of this chunk within the sequence\n\n    Returns:\n        str: Deterministic chunk ID in format\n             content_type:source_id:location_id:sequence_num\n    \"\"\"\n    # Normalize inputs\n    content_type = ChunkIdGenerator._normalize_content_type(content_type)\n    source_id = ChunkIdGenerator._normalize_source_id(source_id)\n    location_id = ChunkIdGenerator._normalize_location_id(location_id)\n\n    # Generate sequence number\n    sequence_num = sequence_id + chunk_idx\n\n    return f\"{content_type}:{source_id}:{location_id}:{sequence_num:04d}\"\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.ChunkIdGenerator.get_source_hash","title":"<code>get_source_hash(source_id, max_length=8)</code>  <code>staticmethod</code>","text":"<p>Generate a short hash for source ID when it's too long.</p> <p>Parameters:</p> Name Type Description Default <code>source_id</code> <code>str</code> <p>The source ID to hash</p> required <code>max_length</code> <code>int</code> <p>Maximum length of the hash</p> <code>8</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Short hash of the source ID</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>@staticmethod\ndef get_source_hash(source_id: str, max_length: int = 8) -&gt; str:\n    \"\"\"Generate a short hash for source ID when it's too long.\n\n    Args:\n        source_id: The source ID to hash\n        max_length: Maximum length of the hash\n\n    Returns:\n        str: Short hash of the source ID\n    \"\"\"\n    if not source_id:\n        return \"unknown\"\n\n    # Create a deterministic hash\n    hash_obj = hashlib.md5(source_id.encode(\"utf-8\"))\n    hash_hex = hash_obj.hexdigest()\n\n    return hash_hex[:max_length]\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.ChunkIdGenerator.parse_chunk_id","title":"<code>parse_chunk_id(chunk_id)</code>  <code>staticmethod</code>","text":"<p>Parse a chunk ID back into its components.</p> <p>Parameters:</p> Name Type Description Default <code>chunk_id</code> <code>str</code> <p>The chunk ID to parse</p> required <p>Returns:</p> Type Description <code>Dict[str, str]</code> <p>Dict containing parsed components: content_type, source_id, location_id, sequence_num</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If chunk ID format is invalid</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>@staticmethod\ndef parse_chunk_id(chunk_id: str) -&gt; Dict[str, str]:\n    \"\"\"Parse a chunk ID back into its components.\n\n    Args:\n        chunk_id: The chunk ID to parse\n\n    Returns:\n        Dict containing parsed components: content_type, source_id, location_id, sequence_num\n\n    Raises:\n        ValueError: If chunk ID format is invalid\n    \"\"\"\n    parts = chunk_id.split(\":\")\n    if len(parts) != 4:\n        raise ValueError(\n            f\"Invalid chunk ID format: {chunk_id}. Expected format: content_type:source_id:location_id:sequence_num\"\n        )\n\n    return {\n        \"content_type\": parts[0],\n        \"source_id\": parts[1],\n        \"location_id\": parts[2],\n        \"sequence_num\": parts[3],\n    }\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.ChunkMetadata","title":"<code>ChunkMetadata</code>  <code>dataclass</code>","text":"<p>Metadata for a data chunk in Ragora.</p> <p>This dataclass provides structured metadata for document chunks, ensuring type safety and clear field definitions.</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>@dataclass\nclass ChunkMetadata:\n    \"\"\"Metadata for a data chunk in Ragora.\n\n    This dataclass provides structured metadata for document chunks,\n    ensuring type safety and clear field definitions.\n    \"\"\"\n\n    chunk_idx: int  # Index of the chunk in the document\n    chunk_size: int  # Size of the chunk in tokens\n    total_chunks: int  # Total number of chunks in the document\n    source_document: Optional[str] = None  # Source document filename\n    page_number: Optional[int] = None  # Page number of the chunk\n    section_title: Optional[str] = None  # Section title of the chunk\n    chunk_type: Optional[str] = None  # Type of chunk (text, citation, equation, etc.)\n    created_at: Optional[str] = None  # Creation date of the chunk\n    email_subject: Optional[str] = None  # Email subject of the chunk\n    email_sender: Optional[str] = None  # Email sender of the chunk\n    email_recipient: Optional[str] = None  # Email recipient of the chunk\n    email_date: Optional[str] = None  # Email date of the chunk\n    email_id: Optional[str] = None  # Email id of the chunk\n    email_folder: Optional[str] = None  # Email folder of the chunk\n    custom_metadata: Optional[Dict[str, Any]] = None  # Custom metadata dictionary\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.ChunkingContext","title":"<code>ChunkingContext</code>  <code>dataclass</code>","text":"<p>Context object containing all chunking metadata and configuration.</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>@dataclass\nclass ChunkingContext:\n    \"\"\"Context object containing all chunking metadata and configuration.\"\"\"\n\n    chunk_type: str = \"text\"\n    source_document: Optional[str] = None\n    page_number: Optional[int] = None\n    section_title: Optional[str] = None\n    created_at: Optional[str] = None\n    # Email-specific fields\n    email_subject: Optional[str] = None\n    email_sender: Optional[str] = None\n    email_recipient: Optional[str] = None\n    email_date: Optional[str] = None\n    email_id: Optional[str] = None\n    email_folder: Optional[str] = None\n    # ID generation parameters\n    source_id: Optional[str] = None  # Unique source identifier for ID generation\n    location_id: Optional[str] = None  # Location within source (page, section, etc.)\n    start_sequence_idx: int = 0  # Starting sequence index for deterministic IDs\n    # Future extensions\n    custom_metadata: Optional[Dict[str, Any]] = None\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.ChunkingContextBuilder","title":"<code>ChunkingContextBuilder</code>","text":"<p>Builder for creating ChunkingContext objects with fluent API.</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>class ChunkingContextBuilder:\n    \"\"\"Builder for creating ChunkingContext objects with fluent API.\"\"\"\n\n    def __init__(self):\n        self._context = ChunkingContext()\n\n    def for_text(self) -&gt; \"ChunkingContextBuilder\":\n        \"\"\"Set chunk type to text.\"\"\"\n        self._context.chunk_type = \"text\"\n        return self\n\n    def for_document(self) -&gt; \"ChunkingContextBuilder\":\n        \"\"\"Set chunk type to document.\"\"\"\n        self._context.chunk_type = \"document\"\n        return self\n\n    def for_email(self) -&gt; \"ChunkingContextBuilder\":\n        \"\"\"Set chunk type to email.\"\"\"\n        self._context.chunk_type = \"email\"\n        return self\n\n    def with_source(self, source: str) -&gt; \"ChunkingContextBuilder\":\n        \"\"\"Set source document.\"\"\"\n        self._context.source_document = source\n        return self\n\n    def with_page(self, page: int) -&gt; \"ChunkingContextBuilder\":\n        \"\"\"Set page number.\"\"\"\n        self._context.page_number = page\n        return self\n\n    def with_section(self, section: str) -&gt; \"ChunkingContextBuilder\":\n        \"\"\"Set section title.\"\"\"\n        self._context.section_title = section\n        return self\n\n    def with_created_at(self, created_at: str) -&gt; \"ChunkingContextBuilder\":\n        \"\"\"Set creation date.\"\"\"\n        self._context.created_at = created_at\n        return self\n\n    def with_email_info(\n        self,\n        subject: str,\n        sender: str,\n        recipient: str = None,\n        email_id: str = None,\n        email_date: str = None,\n        email_folder: str = None,\n    ) -&gt; \"ChunkingContextBuilder\":\n        \"\"\"Set email-specific information.\"\"\"\n        self._context.email_subject = subject\n        self._context.email_sender = sender\n        self._context.email_recipient = recipient\n        self._context.email_id = email_id\n        self._context.email_date = email_date\n        self._context.email_folder = email_folder\n        return self\n\n    def with_source_id(self, source_id: str) -&gt; \"ChunkingContextBuilder\":\n        \"\"\"Set unique source identifier for deterministic ID generation.\"\"\"\n        self._context.source_id = source_id\n        return self\n\n    def with_location_id(self, location_id: str) -&gt; \"ChunkingContextBuilder\":\n        \"\"\"Set location within source for deterministic ID generation.\"\"\"\n        self._context.location_id = location_id\n        return self\n\n    def with_start_sequence_idx(self, sequence_idx: int) -&gt; \"ChunkingContextBuilder\":\n        \"\"\"Set starting sequence index for deterministic ID generation.\"\"\"\n        self._context.start_sequence_idx = sequence_idx\n        return self\n\n    def with_custom_metadata(\n        self, metadata: Dict[str, Any]\n    ) -&gt; \"ChunkingContextBuilder\":\n        \"\"\"Set custom metadata.\"\"\"\n        self._context.custom_metadata = metadata\n        return self\n\n    def build(self) -&gt; ChunkingContext:\n        \"\"\"Build the ChunkingContext object.\"\"\"\n        return self._context\n\n    # Convenience methods for common patterns\n    def for_document_with_page(\n        self, source_id: str, page: int\n    ) -&gt; \"ChunkingContextBuilder\":\n        \"\"\"Set up for document chunking with page number and source ID.\"\"\"\n        return (\n            self.for_document()\n            .with_source_id(source_id)\n            .with_page(page)\n            .with_location_id(f\"page_{page}\")\n        )\n\n    def for_email_with_id(\n        self, email_id: str, subject: str, sender: str\n    ) -&gt; \"ChunkingContextBuilder\":\n        \"\"\"Set up for email chunking with email ID and metadata.\"\"\"\n        return (\n            self.for_email()\n            .with_source_id(f\"email_{email_id}\")\n            .with_email_info(subject, sender)\n            .with_location_id(f\"msg_{email_id}\")\n        )\n\n    def for_text_with_source(self, source_id: str) -&gt; \"ChunkingContextBuilder\":\n        \"\"\"Set up for text chunking with source ID.\"\"\"\n        return self.for_text().with_source_id(source_id)\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.ChunkingContextBuilder.build","title":"<code>build()</code>","text":"<p>Build the ChunkingContext object.</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>def build(self) -&gt; ChunkingContext:\n    \"\"\"Build the ChunkingContext object.\"\"\"\n    return self._context\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.ChunkingContextBuilder.for_document","title":"<code>for_document()</code>","text":"<p>Set chunk type to document.</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>def for_document(self) -&gt; \"ChunkingContextBuilder\":\n    \"\"\"Set chunk type to document.\"\"\"\n    self._context.chunk_type = \"document\"\n    return self\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.ChunkingContextBuilder.for_document_with_page","title":"<code>for_document_with_page(source_id, page)</code>","text":"<p>Set up for document chunking with page number and source ID.</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>def for_document_with_page(\n    self, source_id: str, page: int\n) -&gt; \"ChunkingContextBuilder\":\n    \"\"\"Set up for document chunking with page number and source ID.\"\"\"\n    return (\n        self.for_document()\n        .with_source_id(source_id)\n        .with_page(page)\n        .with_location_id(f\"page_{page}\")\n    )\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.ChunkingContextBuilder.for_email","title":"<code>for_email()</code>","text":"<p>Set chunk type to email.</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>def for_email(self) -&gt; \"ChunkingContextBuilder\":\n    \"\"\"Set chunk type to email.\"\"\"\n    self._context.chunk_type = \"email\"\n    return self\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.ChunkingContextBuilder.for_email_with_id","title":"<code>for_email_with_id(email_id, subject, sender)</code>","text":"<p>Set up for email chunking with email ID and metadata.</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>def for_email_with_id(\n    self, email_id: str, subject: str, sender: str\n) -&gt; \"ChunkingContextBuilder\":\n    \"\"\"Set up for email chunking with email ID and metadata.\"\"\"\n    return (\n        self.for_email()\n        .with_source_id(f\"email_{email_id}\")\n        .with_email_info(subject, sender)\n        .with_location_id(f\"msg_{email_id}\")\n    )\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.ChunkingContextBuilder.for_text","title":"<code>for_text()</code>","text":"<p>Set chunk type to text.</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>def for_text(self) -&gt; \"ChunkingContextBuilder\":\n    \"\"\"Set chunk type to text.\"\"\"\n    self._context.chunk_type = \"text\"\n    return self\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.ChunkingContextBuilder.for_text_with_source","title":"<code>for_text_with_source(source_id)</code>","text":"<p>Set up for text chunking with source ID.</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>def for_text_with_source(self, source_id: str) -&gt; \"ChunkingContextBuilder\":\n    \"\"\"Set up for text chunking with source ID.\"\"\"\n    return self.for_text().with_source_id(source_id)\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.ChunkingContextBuilder.with_created_at","title":"<code>with_created_at(created_at)</code>","text":"<p>Set creation date.</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>def with_created_at(self, created_at: str) -&gt; \"ChunkingContextBuilder\":\n    \"\"\"Set creation date.\"\"\"\n    self._context.created_at = created_at\n    return self\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.ChunkingContextBuilder.with_custom_metadata","title":"<code>with_custom_metadata(metadata)</code>","text":"<p>Set custom metadata.</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>def with_custom_metadata(\n    self, metadata: Dict[str, Any]\n) -&gt; \"ChunkingContextBuilder\":\n    \"\"\"Set custom metadata.\"\"\"\n    self._context.custom_metadata = metadata\n    return self\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.ChunkingContextBuilder.with_email_info","title":"<code>with_email_info(subject, sender, recipient=None, email_id=None, email_date=None, email_folder=None)</code>","text":"<p>Set email-specific information.</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>def with_email_info(\n    self,\n    subject: str,\n    sender: str,\n    recipient: str = None,\n    email_id: str = None,\n    email_date: str = None,\n    email_folder: str = None,\n) -&gt; \"ChunkingContextBuilder\":\n    \"\"\"Set email-specific information.\"\"\"\n    self._context.email_subject = subject\n    self._context.email_sender = sender\n    self._context.email_recipient = recipient\n    self._context.email_id = email_id\n    self._context.email_date = email_date\n    self._context.email_folder = email_folder\n    return self\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.ChunkingContextBuilder.with_location_id","title":"<code>with_location_id(location_id)</code>","text":"<p>Set location within source for deterministic ID generation.</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>def with_location_id(self, location_id: str) -&gt; \"ChunkingContextBuilder\":\n    \"\"\"Set location within source for deterministic ID generation.\"\"\"\n    self._context.location_id = location_id\n    return self\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.ChunkingContextBuilder.with_page","title":"<code>with_page(page)</code>","text":"<p>Set page number.</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>def with_page(self, page: int) -&gt; \"ChunkingContextBuilder\":\n    \"\"\"Set page number.\"\"\"\n    self._context.page_number = page\n    return self\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.ChunkingContextBuilder.with_section","title":"<code>with_section(section)</code>","text":"<p>Set section title.</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>def with_section(self, section: str) -&gt; \"ChunkingContextBuilder\":\n    \"\"\"Set section title.\"\"\"\n    self._context.section_title = section\n    return self\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.ChunkingContextBuilder.with_source","title":"<code>with_source(source)</code>","text":"<p>Set source document.</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>def with_source(self, source: str) -&gt; \"ChunkingContextBuilder\":\n    \"\"\"Set source document.\"\"\"\n    self._context.source_document = source\n    return self\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.ChunkingContextBuilder.with_source_id","title":"<code>with_source_id(source_id)</code>","text":"<p>Set unique source identifier for deterministic ID generation.</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>def with_source_id(self, source_id: str) -&gt; \"ChunkingContextBuilder\":\n    \"\"\"Set unique source identifier for deterministic ID generation.\"\"\"\n    self._context.source_id = source_id\n    return self\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.ChunkingContextBuilder.with_start_sequence_idx","title":"<code>with_start_sequence_idx(sequence_idx)</code>","text":"<p>Set starting sequence index for deterministic ID generation.</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>def with_start_sequence_idx(self, sequence_idx: int) -&gt; \"ChunkingContextBuilder\":\n    \"\"\"Set starting sequence index for deterministic ID generation.\"\"\"\n    self._context.start_sequence_idx = sequence_idx\n    return self\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.ChunkingStrategy","title":"<code>ChunkingStrategy</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for different chunking strategies.</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>class ChunkingStrategy(ABC):\n    \"\"\"Abstract base class for different chunking strategies.\"\"\"\n\n    def __init__(self, chunk_size: int = 768, overlap_size: int = 100):\n        self.chunk_size = chunk_size\n        self.overlap_size = overlap_size\n\n    @abstractmethod\n    def chunk(self, text: str, context: ChunkingContext) -&gt; List[DataChunk]:\n        \"\"\"Chunk text using the specific strategy.\"\"\"\n        pass\n\n    def _create_chunk_with_id(\n        self,\n        text: str,\n        start_idx: int,\n        end_idx: int,\n        chunk_idx: int,\n        context: ChunkingContext,\n    ) -&gt; DataChunk:\n        \"\"\"Create a DataChunk with deterministic ID generation.\n\n        Args:\n            text: The chunk text content\n            start_idx: Start index in original text\n            end_idx: End index in original text\n            chunk_idx: Index of this chunk in the sequence\n            context: Chunking context with metadata\n\n        Returns:\n            DataChunk with deterministic chunk_id\n        \"\"\"\n        # Generate deterministic chunk ID\n        chunk_id = ChunkIdGenerator.generate_chunk_id(\n            content_type=context.chunk_type,\n            source_id=self._get_source_id(context),\n            location_id=self._get_location_id(context),\n            sequence_id=context.start_sequence_idx,\n            chunk_idx=chunk_idx,\n        )\n\n        return DataChunk(\n            text=text,\n            start_idx=start_idx,\n            end_idx=end_idx,\n            chunk_id=chunk_id,\n            metadata=ChunkMetadata(\n                chunk_idx=chunk_idx,\n                chunk_size=len(text),\n                total_chunks=0,  # Will be updated after all chunks\n                source_document=context.source_document,\n                page_number=context.page_number,\n                section_title=context.section_title,\n                chunk_type=context.chunk_type,\n                created_at=context.created_at,\n                email_subject=context.email_subject,\n                email_sender=context.email_sender,\n                email_recipient=context.email_recipient,\n                email_date=context.email_date,\n                email_id=context.email_id,\n                email_folder=context.email_folder,\n                custom_metadata=context.custom_metadata,\n            ),\n            chunk_type=context.chunk_type,\n            source_document=context.source_document,\n        )\n\n    def _get_source_id(self, context: ChunkingContext) -&gt; str:\n        \"\"\"Get source ID for chunk ID generation.\"\"\"\n        if context.source_id:\n            return context.source_id\n        elif context.source_document:\n            return context.source_document\n        elif context.email_id:\n            return f\"email_{context.email_id}\"\n        else:\n            return \"unknown\"\n\n    def _get_location_id(self, context: ChunkingContext) -&gt; str:\n        \"\"\"Get location ID for chunk ID generation.\"\"\"\n        if context.location_id:\n            return context.location_id\n        elif context.chunk_type == \"document\" and context.page_number:\n            return f\"page_{context.page_number}\"\n        elif context.chunk_type == \"email\" and context.email_id:\n            return f\"msg_{context.email_id}\"\n        elif context.section_title:\n            return f\"sec_{context.section_title[:10]}\"\n        else:\n            return \"0\"\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.ChunkingStrategy._create_chunk_with_id","title":"<code>_create_chunk_with_id(text, start_idx, end_idx, chunk_idx, context)</code>","text":"<p>Create a DataChunk with deterministic ID generation.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The chunk text content</p> required <code>start_idx</code> <code>int</code> <p>Start index in original text</p> required <code>end_idx</code> <code>int</code> <p>End index in original text</p> required <code>chunk_idx</code> <code>int</code> <p>Index of this chunk in the sequence</p> required <code>context</code> <code>ChunkingContext</code> <p>Chunking context with metadata</p> required <p>Returns:</p> Type Description <code>DataChunk</code> <p>DataChunk with deterministic chunk_id</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>def _create_chunk_with_id(\n    self,\n    text: str,\n    start_idx: int,\n    end_idx: int,\n    chunk_idx: int,\n    context: ChunkingContext,\n) -&gt; DataChunk:\n    \"\"\"Create a DataChunk with deterministic ID generation.\n\n    Args:\n        text: The chunk text content\n        start_idx: Start index in original text\n        end_idx: End index in original text\n        chunk_idx: Index of this chunk in the sequence\n        context: Chunking context with metadata\n\n    Returns:\n        DataChunk with deterministic chunk_id\n    \"\"\"\n    # Generate deterministic chunk ID\n    chunk_id = ChunkIdGenerator.generate_chunk_id(\n        content_type=context.chunk_type,\n        source_id=self._get_source_id(context),\n        location_id=self._get_location_id(context),\n        sequence_id=context.start_sequence_idx,\n        chunk_idx=chunk_idx,\n    )\n\n    return DataChunk(\n        text=text,\n        start_idx=start_idx,\n        end_idx=end_idx,\n        chunk_id=chunk_id,\n        metadata=ChunkMetadata(\n            chunk_idx=chunk_idx,\n            chunk_size=len(text),\n            total_chunks=0,  # Will be updated after all chunks\n            source_document=context.source_document,\n            page_number=context.page_number,\n            section_title=context.section_title,\n            chunk_type=context.chunk_type,\n            created_at=context.created_at,\n            email_subject=context.email_subject,\n            email_sender=context.email_sender,\n            email_recipient=context.email_recipient,\n            email_date=context.email_date,\n            email_id=context.email_id,\n            email_folder=context.email_folder,\n            custom_metadata=context.custom_metadata,\n        ),\n        chunk_type=context.chunk_type,\n        source_document=context.source_document,\n    )\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.ChunkingStrategy._get_location_id","title":"<code>_get_location_id(context)</code>","text":"<p>Get location ID for chunk ID generation.</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>def _get_location_id(self, context: ChunkingContext) -&gt; str:\n    \"\"\"Get location ID for chunk ID generation.\"\"\"\n    if context.location_id:\n        return context.location_id\n    elif context.chunk_type == \"document\" and context.page_number:\n        return f\"page_{context.page_number}\"\n    elif context.chunk_type == \"email\" and context.email_id:\n        return f\"msg_{context.email_id}\"\n    elif context.section_title:\n        return f\"sec_{context.section_title[:10]}\"\n    else:\n        return \"0\"\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.ChunkingStrategy._get_source_id","title":"<code>_get_source_id(context)</code>","text":"<p>Get source ID for chunk ID generation.</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>def _get_source_id(self, context: ChunkingContext) -&gt; str:\n    \"\"\"Get source ID for chunk ID generation.\"\"\"\n    if context.source_id:\n        return context.source_id\n    elif context.source_document:\n        return context.source_document\n    elif context.email_id:\n        return f\"email_{context.email_id}\"\n    else:\n        return \"unknown\"\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.ChunkingStrategy.chunk","title":"<code>chunk(text, context)</code>  <code>abstractmethod</code>","text":"<p>Chunk text using the specific strategy.</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>@abstractmethod\ndef chunk(self, text: str, context: ChunkingContext) -&gt; List[DataChunk]:\n    \"\"\"Chunk text using the specific strategy.\"\"\"\n    pass\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.DataChunk","title":"<code>DataChunk</code>  <code>dataclass</code>","text":"<p>Data chunk for Ragora.</p> <p>This class represents a chunk of data from a document.</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>@dataclass\nclass DataChunk:\n    \"\"\"Data chunk for Ragora.\n\n    This class represents a chunk of data from a document.\n    \"\"\"\n\n    text: str  # The text of the chunk\n    start_idx: int  # The start index of the chunk\n    end_idx: int  # The end index of the chunk\n    chunk_id: str  # The deterministic human-readable chunk ID\n    metadata: ChunkMetadata  # The metadata of the chunk\n    source_document: Optional[str] = None  # Source document filename\n    chunk_type: Optional[str] = None  # Type of chunk (text, citation, equation, etc.)\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.DataChunker","title":"<code>DataChunker</code>","text":"<p>Data chunker for RAG system using strategy pattern.</p> <p>This class delegates chunking to appropriate strategies based on context.</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>class DataChunker:\n    \"\"\"Data chunker for RAG system using strategy pattern.\n\n    This class delegates chunking to appropriate strategies based on context.\n    \"\"\"\n\n    def __init__(self, default_strategy: ChunkingStrategy = None):\n        \"\"\"Initialize the DataChunker with default strategies.\n\n        Args:\n            default_strategy: Default strategy to use when no specific strategy is registered\n        \"\"\"\n        self.default_strategy = default_strategy or TextChunkingStrategy()\n        self.strategies: Dict[str, ChunkingStrategy] = {\n            \"text\": TextChunkingStrategy(),\n            \"document\": DocumentChunkingStrategy(),\n            \"email\": EmailChunkingStrategy(),\n        }\n\n    def chunk(self, text: str, context: ChunkingContext) -&gt; List[DataChunk]:\n        \"\"\"Chunk text using the appropriate strategy based on context.\n\n        Args:\n            text: Text to chunk\n            context: ChunkingContext containing metadata and configuration\n\n        Returns:\n            List[DataChunk]: List of DataChunks\n        \"\"\"\n        strategy = self.strategies.get(context.chunk_type, self.default_strategy)\n        return strategy.chunk(text, context)\n\n    def register_strategy(self, chunk_type: str, strategy: ChunkingStrategy):\n        \"\"\"Register a new chunking strategy.\n\n        Args:\n            chunk_type: Type identifier for the strategy\n            strategy: ChunkingStrategy implementation\n        \"\"\"\n        self.strategies[chunk_type] = strategy\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.DataChunker.chunk","title":"<code>chunk(text, context)</code>","text":"<p>Chunk text using the appropriate strategy based on context.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Text to chunk</p> required <code>context</code> <code>ChunkingContext</code> <p>ChunkingContext containing metadata and configuration</p> required <p>Returns:</p> Type Description <code>List[DataChunk]</code> <p>List[DataChunk]: List of DataChunks</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>def chunk(self, text: str, context: ChunkingContext) -&gt; List[DataChunk]:\n    \"\"\"Chunk text using the appropriate strategy based on context.\n\n    Args:\n        text: Text to chunk\n        context: ChunkingContext containing metadata and configuration\n\n    Returns:\n        List[DataChunk]: List of DataChunks\n    \"\"\"\n    strategy = self.strategies.get(context.chunk_type, self.default_strategy)\n    return strategy.chunk(text, context)\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.DataChunker.register_strategy","title":"<code>register_strategy(chunk_type, strategy)</code>","text":"<p>Register a new chunking strategy.</p> <p>Parameters:</p> Name Type Description Default <code>chunk_type</code> <code>str</code> <p>Type identifier for the strategy</p> required <code>strategy</code> <code>ChunkingStrategy</code> <p>ChunkingStrategy implementation</p> required Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>def register_strategy(self, chunk_type: str, strategy: ChunkingStrategy):\n    \"\"\"Register a new chunking strategy.\n\n    Args:\n        chunk_type: Type identifier for the strategy\n        strategy: ChunkingStrategy implementation\n    \"\"\"\n    self.strategies[chunk_type] = strategy\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.DocumentChunkingStrategy","title":"<code>DocumentChunkingStrategy</code>","text":"<p>               Bases: <code>ChunkingStrategy</code></p> <p>Document-specific chunking strategy.</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>class DocumentChunkingStrategy(ChunkingStrategy):\n    \"\"\"Document-specific chunking strategy.\"\"\"\n\n    def __init__(self, chunk_size: int = 768, overlap_size: int = 100):\n        super().__init__(chunk_size, overlap_size)\n\n    def chunk(self, text: str, context: ChunkingContext) -&gt; List[DataChunk]:\n        \"\"\"Chunk text using document-aware chunking.\"\"\"\n        # For now, use the same logic as text chunking\n        # Future: could implement section-aware chunking, citation preservation, etc.\n        return self._chunk_text(text, context)\n\n    def _chunk_text(self, text: str, context: ChunkingContext) -&gt; List[DataChunk]:\n        \"\"\"Core chunking logic (same as TextChunkingStrategy for now).\"\"\"\n        if not text or not text.strip():\n            return []\n\n        chunks = []\n        start_idx = 0\n        chunk_idx = 0  # Start at 0, sequence_id is handled in ID generation\n\n        while start_idx &lt; len(text):\n            # Calculate end index for this chunk\n            end_idx = min(start_idx + self.chunk_size, len(text))\n\n            # Extract chunk text\n            chunk_text = text[start_idx:end_idx]\n\n            # Create chunk with deterministic ID\n            chunk = self._create_chunk_with_id(\n                text=chunk_text,\n                start_idx=start_idx,\n                end_idx=end_idx,\n                chunk_idx=chunk_idx,\n                context=context,\n            )\n\n            chunks.append(chunk)\n            chunk_idx += 1\n\n            # Move start index for next chunk with overlap\n            # Ensure we make progress to avoid infinite loop\n            if end_idx &gt;= len(text):\n                break\n            start_idx = max(start_idx + 1, end_idx - self.overlap_size)\n\n        # Update total_chunks in metadata\n        for chunk in chunks:\n            chunk.metadata.total_chunks = len(chunks)\n\n        return chunks\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.DocumentChunkingStrategy._chunk_text","title":"<code>_chunk_text(text, context)</code>","text":"<p>Core chunking logic (same as TextChunkingStrategy for now).</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>def _chunk_text(self, text: str, context: ChunkingContext) -&gt; List[DataChunk]:\n    \"\"\"Core chunking logic (same as TextChunkingStrategy for now).\"\"\"\n    if not text or not text.strip():\n        return []\n\n    chunks = []\n    start_idx = 0\n    chunk_idx = 0  # Start at 0, sequence_id is handled in ID generation\n\n    while start_idx &lt; len(text):\n        # Calculate end index for this chunk\n        end_idx = min(start_idx + self.chunk_size, len(text))\n\n        # Extract chunk text\n        chunk_text = text[start_idx:end_idx]\n\n        # Create chunk with deterministic ID\n        chunk = self._create_chunk_with_id(\n            text=chunk_text,\n            start_idx=start_idx,\n            end_idx=end_idx,\n            chunk_idx=chunk_idx,\n            context=context,\n        )\n\n        chunks.append(chunk)\n        chunk_idx += 1\n\n        # Move start index for next chunk with overlap\n        # Ensure we make progress to avoid infinite loop\n        if end_idx &gt;= len(text):\n            break\n        start_idx = max(start_idx + 1, end_idx - self.overlap_size)\n\n    # Update total_chunks in metadata\n    for chunk in chunks:\n        chunk.metadata.total_chunks = len(chunks)\n\n    return chunks\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.DocumentChunkingStrategy._create_chunk_with_id","title":"<code>_create_chunk_with_id(text, start_idx, end_idx, chunk_idx, context)</code>","text":"<p>Create a DataChunk with deterministic ID generation.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The chunk text content</p> required <code>start_idx</code> <code>int</code> <p>Start index in original text</p> required <code>end_idx</code> <code>int</code> <p>End index in original text</p> required <code>chunk_idx</code> <code>int</code> <p>Index of this chunk in the sequence</p> required <code>context</code> <code>ChunkingContext</code> <p>Chunking context with metadata</p> required <p>Returns:</p> Type Description <code>DataChunk</code> <p>DataChunk with deterministic chunk_id</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>def _create_chunk_with_id(\n    self,\n    text: str,\n    start_idx: int,\n    end_idx: int,\n    chunk_idx: int,\n    context: ChunkingContext,\n) -&gt; DataChunk:\n    \"\"\"Create a DataChunk with deterministic ID generation.\n\n    Args:\n        text: The chunk text content\n        start_idx: Start index in original text\n        end_idx: End index in original text\n        chunk_idx: Index of this chunk in the sequence\n        context: Chunking context with metadata\n\n    Returns:\n        DataChunk with deterministic chunk_id\n    \"\"\"\n    # Generate deterministic chunk ID\n    chunk_id = ChunkIdGenerator.generate_chunk_id(\n        content_type=context.chunk_type,\n        source_id=self._get_source_id(context),\n        location_id=self._get_location_id(context),\n        sequence_id=context.start_sequence_idx,\n        chunk_idx=chunk_idx,\n    )\n\n    return DataChunk(\n        text=text,\n        start_idx=start_idx,\n        end_idx=end_idx,\n        chunk_id=chunk_id,\n        metadata=ChunkMetadata(\n            chunk_idx=chunk_idx,\n            chunk_size=len(text),\n            total_chunks=0,  # Will be updated after all chunks\n            source_document=context.source_document,\n            page_number=context.page_number,\n            section_title=context.section_title,\n            chunk_type=context.chunk_type,\n            created_at=context.created_at,\n            email_subject=context.email_subject,\n            email_sender=context.email_sender,\n            email_recipient=context.email_recipient,\n            email_date=context.email_date,\n            email_id=context.email_id,\n            email_folder=context.email_folder,\n            custom_metadata=context.custom_metadata,\n        ),\n        chunk_type=context.chunk_type,\n        source_document=context.source_document,\n    )\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.DocumentChunkingStrategy._get_location_id","title":"<code>_get_location_id(context)</code>","text":"<p>Get location ID for chunk ID generation.</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>def _get_location_id(self, context: ChunkingContext) -&gt; str:\n    \"\"\"Get location ID for chunk ID generation.\"\"\"\n    if context.location_id:\n        return context.location_id\n    elif context.chunk_type == \"document\" and context.page_number:\n        return f\"page_{context.page_number}\"\n    elif context.chunk_type == \"email\" and context.email_id:\n        return f\"msg_{context.email_id}\"\n    elif context.section_title:\n        return f\"sec_{context.section_title[:10]}\"\n    else:\n        return \"0\"\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.DocumentChunkingStrategy._get_source_id","title":"<code>_get_source_id(context)</code>","text":"<p>Get source ID for chunk ID generation.</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>def _get_source_id(self, context: ChunkingContext) -&gt; str:\n    \"\"\"Get source ID for chunk ID generation.\"\"\"\n    if context.source_id:\n        return context.source_id\n    elif context.source_document:\n        return context.source_document\n    elif context.email_id:\n        return f\"email_{context.email_id}\"\n    else:\n        return \"unknown\"\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.DocumentChunkingStrategy.chunk","title":"<code>chunk(text, context)</code>","text":"<p>Chunk text using document-aware chunking.</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>def chunk(self, text: str, context: ChunkingContext) -&gt; List[DataChunk]:\n    \"\"\"Chunk text using document-aware chunking.\"\"\"\n    # For now, use the same logic as text chunking\n    # Future: could implement section-aware chunking, citation preservation, etc.\n    return self._chunk_text(text, context)\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.EmailChunkingStrategy","title":"<code>EmailChunkingStrategy</code>","text":"<p>               Bases: <code>ChunkingStrategy</code></p> <p>Email-specific chunking strategy.</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>class EmailChunkingStrategy(ChunkingStrategy):\n    \"\"\"Email-specific chunking strategy.\"\"\"\n\n    def __init__(self, chunk_size: int = 512, overlap_size: int = 50):\n        super().__init__(chunk_size, overlap_size)\n\n    def chunk(self, text: str, context: ChunkingContext) -&gt; List[DataChunk]:\n        \"\"\"Chunk text using email-aware chunking.\"\"\"\n        # For now, use the same logic as text chunking\n        # Future: could implement thread-aware chunking, attachment handling, etc.\n        return self._chunk_text(text, context)\n\n    def _chunk_text(self, text: str, context: ChunkingContext) -&gt; List[DataChunk]:\n        \"\"\"Core chunking logic (same as TextChunkingStrategy for now).\"\"\"\n        if not text or not text.strip():\n            return []\n\n        chunks = []\n        start_idx = 0\n        chunk_idx = 0  # Start at 0, sequence_id is handled in ID generation\n\n        while start_idx &lt; len(text):\n            # Calculate end index for this chunk\n            end_idx = min(start_idx + self.chunk_size, len(text))\n\n            # Extract chunk text\n            chunk_text = text[start_idx:end_idx]\n\n            # Create chunk with deterministic ID\n            chunk = self._create_chunk_with_id(\n                text=chunk_text,\n                start_idx=start_idx,\n                end_idx=end_idx,\n                chunk_idx=chunk_idx,\n                context=context,\n            )\n\n            chunks.append(chunk)\n            chunk_idx += 1\n\n            # Move start index for next chunk with overlap\n            # Ensure we make progress to avoid infinite loop\n            if end_idx &gt;= len(text):\n                break\n            start_idx = max(start_idx + 1, end_idx - self.overlap_size)\n\n        # Update total_chunks in metadata\n        for chunk in chunks:\n            chunk.metadata.total_chunks = len(chunks)\n\n        return chunks\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.EmailChunkingStrategy._chunk_text","title":"<code>_chunk_text(text, context)</code>","text":"<p>Core chunking logic (same as TextChunkingStrategy for now).</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>def _chunk_text(self, text: str, context: ChunkingContext) -&gt; List[DataChunk]:\n    \"\"\"Core chunking logic (same as TextChunkingStrategy for now).\"\"\"\n    if not text or not text.strip():\n        return []\n\n    chunks = []\n    start_idx = 0\n    chunk_idx = 0  # Start at 0, sequence_id is handled in ID generation\n\n    while start_idx &lt; len(text):\n        # Calculate end index for this chunk\n        end_idx = min(start_idx + self.chunk_size, len(text))\n\n        # Extract chunk text\n        chunk_text = text[start_idx:end_idx]\n\n        # Create chunk with deterministic ID\n        chunk = self._create_chunk_with_id(\n            text=chunk_text,\n            start_idx=start_idx,\n            end_idx=end_idx,\n            chunk_idx=chunk_idx,\n            context=context,\n        )\n\n        chunks.append(chunk)\n        chunk_idx += 1\n\n        # Move start index for next chunk with overlap\n        # Ensure we make progress to avoid infinite loop\n        if end_idx &gt;= len(text):\n            break\n        start_idx = max(start_idx + 1, end_idx - self.overlap_size)\n\n    # Update total_chunks in metadata\n    for chunk in chunks:\n        chunk.metadata.total_chunks = len(chunks)\n\n    return chunks\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.EmailChunkingStrategy._create_chunk_with_id","title":"<code>_create_chunk_with_id(text, start_idx, end_idx, chunk_idx, context)</code>","text":"<p>Create a DataChunk with deterministic ID generation.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The chunk text content</p> required <code>start_idx</code> <code>int</code> <p>Start index in original text</p> required <code>end_idx</code> <code>int</code> <p>End index in original text</p> required <code>chunk_idx</code> <code>int</code> <p>Index of this chunk in the sequence</p> required <code>context</code> <code>ChunkingContext</code> <p>Chunking context with metadata</p> required <p>Returns:</p> Type Description <code>DataChunk</code> <p>DataChunk with deterministic chunk_id</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>def _create_chunk_with_id(\n    self,\n    text: str,\n    start_idx: int,\n    end_idx: int,\n    chunk_idx: int,\n    context: ChunkingContext,\n) -&gt; DataChunk:\n    \"\"\"Create a DataChunk with deterministic ID generation.\n\n    Args:\n        text: The chunk text content\n        start_idx: Start index in original text\n        end_idx: End index in original text\n        chunk_idx: Index of this chunk in the sequence\n        context: Chunking context with metadata\n\n    Returns:\n        DataChunk with deterministic chunk_id\n    \"\"\"\n    # Generate deterministic chunk ID\n    chunk_id = ChunkIdGenerator.generate_chunk_id(\n        content_type=context.chunk_type,\n        source_id=self._get_source_id(context),\n        location_id=self._get_location_id(context),\n        sequence_id=context.start_sequence_idx,\n        chunk_idx=chunk_idx,\n    )\n\n    return DataChunk(\n        text=text,\n        start_idx=start_idx,\n        end_idx=end_idx,\n        chunk_id=chunk_id,\n        metadata=ChunkMetadata(\n            chunk_idx=chunk_idx,\n            chunk_size=len(text),\n            total_chunks=0,  # Will be updated after all chunks\n            source_document=context.source_document,\n            page_number=context.page_number,\n            section_title=context.section_title,\n            chunk_type=context.chunk_type,\n            created_at=context.created_at,\n            email_subject=context.email_subject,\n            email_sender=context.email_sender,\n            email_recipient=context.email_recipient,\n            email_date=context.email_date,\n            email_id=context.email_id,\n            email_folder=context.email_folder,\n            custom_metadata=context.custom_metadata,\n        ),\n        chunk_type=context.chunk_type,\n        source_document=context.source_document,\n    )\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.EmailChunkingStrategy._get_location_id","title":"<code>_get_location_id(context)</code>","text":"<p>Get location ID for chunk ID generation.</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>def _get_location_id(self, context: ChunkingContext) -&gt; str:\n    \"\"\"Get location ID for chunk ID generation.\"\"\"\n    if context.location_id:\n        return context.location_id\n    elif context.chunk_type == \"document\" and context.page_number:\n        return f\"page_{context.page_number}\"\n    elif context.chunk_type == \"email\" and context.email_id:\n        return f\"msg_{context.email_id}\"\n    elif context.section_title:\n        return f\"sec_{context.section_title[:10]}\"\n    else:\n        return \"0\"\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.EmailChunkingStrategy._get_source_id","title":"<code>_get_source_id(context)</code>","text":"<p>Get source ID for chunk ID generation.</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>def _get_source_id(self, context: ChunkingContext) -&gt; str:\n    \"\"\"Get source ID for chunk ID generation.\"\"\"\n    if context.source_id:\n        return context.source_id\n    elif context.source_document:\n        return context.source_document\n    elif context.email_id:\n        return f\"email_{context.email_id}\"\n    else:\n        return \"unknown\"\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.EmailChunkingStrategy.chunk","title":"<code>chunk(text, context)</code>","text":"<p>Chunk text using email-aware chunking.</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>def chunk(self, text: str, context: ChunkingContext) -&gt; List[DataChunk]:\n    \"\"\"Chunk text using email-aware chunking.\"\"\"\n    # For now, use the same logic as text chunking\n    # Future: could implement thread-aware chunking, attachment handling, etc.\n    return self._chunk_text(text, context)\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.TextChunkingStrategy","title":"<code>TextChunkingStrategy</code>","text":"<p>               Bases: <code>ChunkingStrategy</code></p> <p>Standard text chunking strategy.</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>class TextChunkingStrategy(ChunkingStrategy):\n    \"\"\"Standard text chunking strategy.\"\"\"\n\n    def __init__(self, chunk_size: int = 768, overlap_size: int = 100):\n        super().__init__(chunk_size, overlap_size)\n\n    def chunk(self, text: str, context: ChunkingContext) -&gt; List[DataChunk]:\n        \"\"\"Chunk text using standard character-based chunking.\"\"\"\n        return self._chunk_text(text, context)\n\n    def _chunk_text(self, text: str, context: ChunkingContext) -&gt; List[DataChunk]:\n        \"\"\"Core chunking logic.\"\"\"\n        if not text or not text.strip():\n            return []\n\n        chunks = []\n        start_idx = 0\n        chunk_idx = 0  # Start at 0, sequence_id is handled in ID generation\n\n        while start_idx &lt; len(text):\n            # Calculate end index for this chunk\n            end_idx = min(start_idx + self.chunk_size, len(text))\n\n            # Extract chunk text\n            chunk_text = text[start_idx:end_idx]\n\n            # Create chunk with deterministic ID\n            chunk = self._create_chunk_with_id(\n                text=chunk_text,\n                start_idx=start_idx,\n                end_idx=end_idx,\n                chunk_idx=chunk_idx,\n                context=context,\n            )\n\n            chunks.append(chunk)\n            chunk_idx += 1\n\n            # Move start index for next chunk with overlap\n            # Ensure we make progress to avoid infinite loop\n            if end_idx &gt;= len(text):\n                break\n            start_idx = max(start_idx + 1, end_idx - self.overlap_size)\n\n        # Update total_chunks in metadata\n        for chunk in chunks:\n            chunk.metadata.total_chunks = len(chunks)\n\n        return chunks\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.TextChunkingStrategy._chunk_text","title":"<code>_chunk_text(text, context)</code>","text":"<p>Core chunking logic.</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>def _chunk_text(self, text: str, context: ChunkingContext) -&gt; List[DataChunk]:\n    \"\"\"Core chunking logic.\"\"\"\n    if not text or not text.strip():\n        return []\n\n    chunks = []\n    start_idx = 0\n    chunk_idx = 0  # Start at 0, sequence_id is handled in ID generation\n\n    while start_idx &lt; len(text):\n        # Calculate end index for this chunk\n        end_idx = min(start_idx + self.chunk_size, len(text))\n\n        # Extract chunk text\n        chunk_text = text[start_idx:end_idx]\n\n        # Create chunk with deterministic ID\n        chunk = self._create_chunk_with_id(\n            text=chunk_text,\n            start_idx=start_idx,\n            end_idx=end_idx,\n            chunk_idx=chunk_idx,\n            context=context,\n        )\n\n        chunks.append(chunk)\n        chunk_idx += 1\n\n        # Move start index for next chunk with overlap\n        # Ensure we make progress to avoid infinite loop\n        if end_idx &gt;= len(text):\n            break\n        start_idx = max(start_idx + 1, end_idx - self.overlap_size)\n\n    # Update total_chunks in metadata\n    for chunk in chunks:\n        chunk.metadata.total_chunks = len(chunks)\n\n    return chunks\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.TextChunkingStrategy._create_chunk_with_id","title":"<code>_create_chunk_with_id(text, start_idx, end_idx, chunk_idx, context)</code>","text":"<p>Create a DataChunk with deterministic ID generation.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The chunk text content</p> required <code>start_idx</code> <code>int</code> <p>Start index in original text</p> required <code>end_idx</code> <code>int</code> <p>End index in original text</p> required <code>chunk_idx</code> <code>int</code> <p>Index of this chunk in the sequence</p> required <code>context</code> <code>ChunkingContext</code> <p>Chunking context with metadata</p> required <p>Returns:</p> Type Description <code>DataChunk</code> <p>DataChunk with deterministic chunk_id</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>def _create_chunk_with_id(\n    self,\n    text: str,\n    start_idx: int,\n    end_idx: int,\n    chunk_idx: int,\n    context: ChunkingContext,\n) -&gt; DataChunk:\n    \"\"\"Create a DataChunk with deterministic ID generation.\n\n    Args:\n        text: The chunk text content\n        start_idx: Start index in original text\n        end_idx: End index in original text\n        chunk_idx: Index of this chunk in the sequence\n        context: Chunking context with metadata\n\n    Returns:\n        DataChunk with deterministic chunk_id\n    \"\"\"\n    # Generate deterministic chunk ID\n    chunk_id = ChunkIdGenerator.generate_chunk_id(\n        content_type=context.chunk_type,\n        source_id=self._get_source_id(context),\n        location_id=self._get_location_id(context),\n        sequence_id=context.start_sequence_idx,\n        chunk_idx=chunk_idx,\n    )\n\n    return DataChunk(\n        text=text,\n        start_idx=start_idx,\n        end_idx=end_idx,\n        chunk_id=chunk_id,\n        metadata=ChunkMetadata(\n            chunk_idx=chunk_idx,\n            chunk_size=len(text),\n            total_chunks=0,  # Will be updated after all chunks\n            source_document=context.source_document,\n            page_number=context.page_number,\n            section_title=context.section_title,\n            chunk_type=context.chunk_type,\n            created_at=context.created_at,\n            email_subject=context.email_subject,\n            email_sender=context.email_sender,\n            email_recipient=context.email_recipient,\n            email_date=context.email_date,\n            email_id=context.email_id,\n            email_folder=context.email_folder,\n            custom_metadata=context.custom_metadata,\n        ),\n        chunk_type=context.chunk_type,\n        source_document=context.source_document,\n    )\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.TextChunkingStrategy._get_location_id","title":"<code>_get_location_id(context)</code>","text":"<p>Get location ID for chunk ID generation.</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>def _get_location_id(self, context: ChunkingContext) -&gt; str:\n    \"\"\"Get location ID for chunk ID generation.\"\"\"\n    if context.location_id:\n        return context.location_id\n    elif context.chunk_type == \"document\" and context.page_number:\n        return f\"page_{context.page_number}\"\n    elif context.chunk_type == \"email\" and context.email_id:\n        return f\"msg_{context.email_id}\"\n    elif context.section_title:\n        return f\"sec_{context.section_title[:10]}\"\n    else:\n        return \"0\"\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.TextChunkingStrategy._get_source_id","title":"<code>_get_source_id(context)</code>","text":"<p>Get source ID for chunk ID generation.</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>def _get_source_id(self, context: ChunkingContext) -&gt; str:\n    \"\"\"Get source ID for chunk ID generation.\"\"\"\n    if context.source_id:\n        return context.source_id\n    elif context.source_document:\n        return context.source_document\n    elif context.email_id:\n        return f\"email_{context.email_id}\"\n    else:\n        return \"unknown\"\n</code></pre>"},{"location":"api-reference/#ragora.core.chunking.TextChunkingStrategy.chunk","title":"<code>chunk(text, context)</code>","text":"<p>Chunk text using standard character-based chunking.</p> Source code in <code>ragora/ragora/core/chunking.py</code> <pre><code>def chunk(self, text: str, context: ChunkingContext) -&gt; List[DataChunk]:\n    \"\"\"Chunk text using standard character-based chunking.\"\"\"\n    return self._chunk_text(text, context)\n</code></pre>"},{"location":"api-reference/#document-preprocessor","title":"Document Preprocessor","text":"<p>Utilities for parsing and chunking raw documents prior to ingestion.</p> <p>The module centralizes the logic for turning LaTeX, Markdown, and text files into <code>DataChunk</code> objects that the rest of the Ragora pipeline can embed and store.</p>"},{"location":"api-reference/#ragora.core.document_preprocessor.DocumentPreprocessor","title":"<code>DocumentPreprocessor</code>","text":"<p>Parse supported file formats into chunkable intermediate data.</p> <p>The preprocessor delegates parsing to format-specific helpers and then feeds the resulting representation through a :class:<code>DataChunker</code>.</p> <p>Attributes:</p> Name Type Description <code>chunker</code> <p>Chunking strategy that controls chunk size and overlap.</p> <p>Examples:</p> <pre><code>from ragora.core.document_preprocessor import DocumentPreprocessor\n\npreprocessor = DocumentPreprocessor()\nchunks = preprocessor.preprocess_document(\"docs/intro.md\", format=\"markdown\")\n</code></pre> Source code in <code>ragora/ragora/core/document_preprocessor.py</code> <pre><code>class DocumentPreprocessor:\n    \"\"\"Parse supported file formats into chunkable intermediate data.\n\n    The preprocessor delegates parsing to format-specific helpers and then feeds\n    the resulting representation through a :class:`DataChunker`.\n\n    Attributes:\n        chunker: Chunking strategy that controls chunk size and overlap.\n\n    Examples:\n        ```python\n        from ragora.core.document_preprocessor import DocumentPreprocessor\n\n        preprocessor = DocumentPreprocessor()\n        chunks = preprocessor.preprocess_document(\"docs/intro.md\", format=\"markdown\")\n        ```\n    \"\"\"\n\n    def __init__(self, chunker: DataChunker = None):\n        \"\"\"Initialize the DocumentPreprocessor.\n\n        Args:\n            chunker: DataChunker instance (optional)\n        \"\"\"\n        if chunker is not None:\n            self.chunker = chunker\n        else:\n            # Create a default document strategy with specified parameters\n            self.chunker = DataChunker()\n        self.file_extension_map = {\n            \"latex\": [\".tex\", \".latex\", \".bib\"],\n            \"pdf\": [\".pdf\"],\n            \"docx\": [\".docx\"],\n            \"doc\": [\".doc\"],\n            \"markdown\": [\".md\", \".markdown\"],\n            \"text\": [\".txt\"],\n            \"txt\": [\".txt\"],\n        }\n\n        self.latex_parser = LatexParser()\n        self.markdown_parser = MarkdownParser()\n\n    def preprocess_document(\n        self, file_path: str, format: str = \"latex\"\n    ) -&gt; list[DataChunk]:\n        \"\"\"Preprocess a single document into :class:`DataChunk` objects.\n\n        Args:\n            file_path: Path to the document file.\n            format: Document format (``\"latex\"``, ``\"markdown\"``, or ``\"text\"``).\n\n        Returns:\n            list[DataChunk]: Chunked content ready for embedding downstream.\n\n        Raises:\n            ValueError: If an unsupported format is requested.\n\n        Examples:\n            ```python\n            chunks = preprocessor.preprocess_document(\"paper.tex\", format=\"latex\")\n            ```\n        \"\"\"\n        normalized_format = format.lower()\n\n        if normalized_format == \"latex\":\n            if file_path.endswith(\".bib\"):\n                self.latex_parser.parse_bibliography(file_path)\n                return []\n            document = self.latex_parser.parse_document(file_path)\n            return self._chunk_documents([document])\n\n        if normalized_format in {\"markdown\", \"md\", \"text\", \"txt\"}:\n            document = self.markdown_parser.parse_document(file_path)\n            return self._chunk_markdown_documents([document])\n\n        raise ValueError(f\"Unsupported document format: {format}\")\n\n    def preprocess_documents(\n        self, file_paths: list[str], format: str = \"latex\"\n    ) -&gt; list[DataChunk]:\n        \"\"\"Preprocess multiple documents at once.\n\n        Args:\n            file_paths: Collection of paths to document files.\n            format: Document format (``\"latex\"``, ``\"markdown\"``, or ``\"text\"``).\n\n        Returns:\n            list[DataChunk]: Combined chunks from all input documents.\n\n        Raises:\n            ValueError: If an unsupported format is requested.\n\n        Examples:\n            ```python\n            chunks = preprocessor.preprocess_documents(\n                [\"chapter1.tex\", \"chapter2.tex\", \"references.bib\"],\n                format=\"latex\",\n            )\n            ```\n        \"\"\"\n        normalized_format = format.lower()\n\n        if normalized_format == \"latex\":\n            # Find the bibliography file\n            bibliography_path = None\n            for file_path in file_paths:\n                if file_path.endswith(\".bib\"):\n                    bibliography_path = file_path\n                    break\n            if bibliography_path:\n                self.latex_parser.parse_bibliography(bibliography_path)\n            documents = [\n                self.latex_parser.parse_document(file_path)\n                for file_path in file_paths\n                if file_path != bibliography_path\n            ]\n            return self._chunk_documents(documents)\n\n        if normalized_format in {\"markdown\", \"md\", \"text\", \"txt\"}:\n            documents = [\n                self.markdown_parser.parse_document(path) for path in file_paths\n            ]\n            return self._chunk_markdown_documents(documents)\n\n        raise ValueError(f\"Unsupported document format: {format}\")\n\n    def preprocess_document_folder(\n        self, folder_path: str, format: str = \"latex\"\n    ) -&gt; list[DataChunk]:\n        \"\"\"Preprocess every supported file in a folder.\n\n        Args:\n            folder_path: Directory containing documents that should be ingested.\n            format: Document format used to interpret files within the folder.\n\n        Returns:\n            list[DataChunk]: Aggregated chunk list for the entire folder.\n\n        Raises:\n            ValueError: If ``format`` is not in the supported extension map.\n        \"\"\"\n        normalized_format = format.lower()\n        if normalized_format not in self.file_extension_map:\n            raise ValueError(f\"Unsupported document format: {format}\")\n\n        file_paths = [\n            os.path.join(folder_path, file)\n            for file in os.listdir(folder_path)\n            if any(\n                file.endswith(ext) for ext in self.file_extension_map[normalized_format]\n            )\n        ]\n        return self.preprocess_documents(file_paths, normalized_format)\n\n    def _extract_document_text(self, documentList: list[LatexDocument]) -&gt; str:\n        \"\"\"Merge one or more parsed LaTeX documents into plain text.\n\n        Args:\n            documentList: Collection of parsed LaTeX documents to flatten.\n\n        Returns:\n            str: Combined Markdown-like text used for chunking.\n        \"\"\"\n        content_parts = []\n\n        for document in documentList:\n            # Extract from chapters\n            if document.chapters:\n                for chapter in document.chapters:\n                    content_parts.append(f\"# {chapter.title}\")\n                    if chapter.paragraphs:\n                        for para in chapter.paragraphs:\n                            content_parts.append(para.content)\n                    if chapter.sections:\n                        for section in chapter.sections:\n                            content_parts.append(f\"## {section.title}\")\n                            if section.paragraphs:\n                                for para in section.paragraphs:\n                                    content_parts.append(para.content)\n\n            # Extract from standalone sections\n            if document.sections:\n                for section in document.sections:\n                    content_parts.append(f\"## {section.title}\")\n                    if section.paragraphs:\n                        for para in section.paragraphs:\n                            content_parts.append(para.content)\n\n            # Extract from standalone paragraphs\n            if document.paragraphs:\n                for para in document.paragraphs:\n                    content_parts.append(para.content)\n\n            # Extract from tables\n            if document.tables:\n                for table in document.tables:\n                    content_parts.append(table.to_plain_text())\n\n        return \"\\n\\n\".join(content_parts)\n\n    def _chunk_documents(self, documentList: list[LatexDocument]) -&gt; list[DataChunk]:\n        \"\"\"Chunk multiple LaTeX documents.\n\n        Args:\n            documentList: Parsed LaTeX documents.\n\n        Returns:\n            list[DataChunk]: Chunked output.\n        \"\"\"\n        chunks = []\n        if not documentList:\n            return chunks\n        for document in documentList:\n            chunks.extend(self._chunk_document(document))\n        return chunks\n\n    def _chunk_markdown_documents(\n        self, document_list: list[MarkdownDocument]\n    ) -&gt; list[DataChunk]:\n        \"\"\"Chunk Markdown or plain text documents.\n\n        Args:\n            document_list: Parsed Markdown documents.\n\n        Returns:\n            list[DataChunk]: Chunked output.\n        \"\"\"\n\n        chunks: list[DataChunk] = []\n        if not document_list:\n            return chunks\n\n        for document in document_list:\n            chunks.extend(self._chunk_markdown_document(document))\n\n        return chunks\n\n    def _chunk_markdown_document(self, document: MarkdownDocument) -&gt; list[DataChunk]:\n        \"\"\"Chunk a single Markdown document respecting the original hierarchy.\n\n        Args:\n            document: Parsed Markdown document.\n\n        Returns:\n            list[DataChunk]: Chunked output.\n\n        Raises:\n            ValueError: If ``document`` is ``None``.\n        \"\"\"\n        if document is None:\n            raise ValueError(\"Document cannot be None\")\n\n        chunk_id_counter = 0\n        chunks: list[DataChunk] = []\n\n        if document.paragraphs:\n            paragraph_content = \"\\n\\n\".join(\n                paragraph.content\n                for paragraph in document.paragraphs\n                if paragraph.content\n            )\n            if paragraph_content:\n                section_label = document.title or document.source_document\n                context = (\n                    ChunkingContextBuilder()\n                    .for_document()\n                    .with_source(document.source_document)\n                    .with_section(section_label)\n                    .with_start_sequence_idx(chunk_id_counter)\n                    .build()\n                )\n                doc_chunks = self.chunker.chunk(paragraph_content, context)\n                chunks.extend(doc_chunks)\n                chunk_id_counter += len(doc_chunks)\n\n        if document.chapters:\n            for chapter in document.chapters:\n                chapter_content_parts = [f\"# {chapter.title}\" if chapter.title else \"\"]\n                chapter_content_parts.extend(\n                    paragraph.content\n                    for paragraph in chapter.paragraphs\n                    if paragraph.content\n                )\n                chapter_content = \"\\n\\n\".join(\n                    part for part in chapter_content_parts if part.strip()\n                )\n                if chapter_content:\n                    section_label = (\n                        chapter.title or document.title or document.source_document\n                    )\n                    context = (\n                        ChunkingContextBuilder()\n                        .for_document()\n                        .with_source(document.source_document)\n                        .with_section(section_label)\n                        .with_start_sequence_idx(chunk_id_counter)\n                        .build()\n                    )\n                    doc_chunks = self.chunker.chunk(chapter_content, context)\n                    chunks.extend(doc_chunks)\n                    chunk_id_counter += len(doc_chunks)\n\n                if chapter.sections:\n                    for section in chapter.sections:\n                        section_content_parts = [\n                            f\"## {section.title}\" if section.title else \"\",\n                            *[\n                                paragraph.content\n                                for paragraph in section.paragraphs\n                                if paragraph.content\n                            ],\n                        ]\n                        section_content = \"\\n\\n\".join(\n                            part for part in section_content_parts if part.strip()\n                        )\n                        if section_content:\n                            section_label = (\n                                section.title\n                                or chapter.title\n                                or document.title\n                                or document.source_document\n                            )\n                            context = (\n                                ChunkingContextBuilder()\n                                .for_document()\n                                .with_source(document.source_document)\n                                .with_section(section_label)\n                                .with_start_sequence_idx(chunk_id_counter)\n                                .build()\n                            )\n                            doc_chunks = self.chunker.chunk(section_content, context)\n                            chunks.extend(doc_chunks)\n                            chunk_id_counter += len(doc_chunks)\n\n        if document.sections:\n            for section in document.sections:\n                section_content_parts = [\n                    f\"## {section.title}\" if section.title else \"\",\n                    *[\n                        paragraph.content\n                        for paragraph in section.paragraphs\n                        if paragraph.content\n                    ],\n                ]\n                section_content = \"\\n\\n\".join(\n                    part for part in section_content_parts if part.strip()\n                )\n                if section_content:\n                    section_label = (\n                        section.title or document.title or document.source_document\n                    )\n                    context = (\n                        ChunkingContextBuilder()\n                        .for_document()\n                        .with_source(document.source_document)\n                        .with_section(section_label)\n                        .with_start_sequence_idx(chunk_id_counter)\n                        .build()\n                    )\n                    doc_chunks = self.chunker.chunk(section_content, context)\n                    chunks.extend(doc_chunks)\n                    chunk_id_counter += len(doc_chunks)\n\n        return chunks\n\n    def _chunk_document(self, document: LatexDocument) -&gt; list[DataChunk]:\n        \"\"\"Chunk the document into a list of DataChunks.\"\"\"\n        if document is None:\n            raise ValueError(\"Document cannot be None\")\n        chunks = []\n        chunk_id_counter = 0\n\n        if document.paragraphs:\n            paragraph_content = \"\"\n            for paragraph in document.paragraphs:\n                paragraph_content += paragraph.content\n            context = (\n                ChunkingContextBuilder()\n                .for_document()\n                .with_source(document.source_document)\n                .with_section(document.title)\n                .with_start_sequence_idx(chunk_id_counter)\n                .build()\n            )\n            doc_chunks = self.chunker.chunk(paragraph_content, context)\n            chunks.extend(doc_chunks)\n            chunk_id_counter += len(doc_chunks)\n\n        if document.chapters:\n            for chapter in document.chapters:\n                chapter_content = f\"# {chapter.title}\"\n                if chapter.paragraphs:\n                    for paragraph in chapter.paragraphs:\n                        chapter_content += paragraph.content\n                    context = (\n                        ChunkingContextBuilder()\n                        .for_document()\n                        .with_source(document.source_document)\n                        .with_section(chapter.title)\n                        .with_start_sequence_idx(chunk_id_counter)\n                        .build()\n                    )\n                    doc_chunks = self.chunker.chunk(chapter_content, context)\n                    chunks.extend(doc_chunks)\n                    chunk_id_counter += len(doc_chunks)\n\n                if chapter.sections:\n                    for section in chapter.sections:\n                        section_content = f\"## {section.title}\"\n                        if section.paragraphs:\n                            for paragraph in section.paragraphs:\n                                section_content += paragraph.content\n                            context = (\n                                ChunkingContextBuilder()\n                                .for_document()\n                                .with_source(document.source_document)\n                                .with_section(section.title)\n                                .with_start_sequence_idx(chunk_id_counter)\n                                .build()\n                            )\n                            doc_chunks = self.chunker.chunk(section_content, context)\n                            chunks.extend(doc_chunks)\n                            chunk_id_counter += len(doc_chunks)\n\n        if document.sections:\n            for section in document.sections:\n                section_content = f\"## {section.title}\"\n                if section.paragraphs:\n                    for paragraph in section.paragraphs:\n                        section_content += paragraph.content\n                    context = (\n                        ChunkingContextBuilder()\n                        .for_document()\n                        .with_source(document.source_document)\n                        .with_section(section.title)\n                        .with_start_sequence_idx(chunk_id_counter)\n                        .build()\n                    )\n                    doc_chunks = self.chunker.chunk(section_content, context)\n                    chunks.extend(doc_chunks)\n                    chunk_id_counter += len(doc_chunks)\n\n        if document.tables:\n            for table in document.tables:\n                table_content = table.to_plain_text()\n                context = (\n                    ChunkingContextBuilder()\n                    .for_document()\n                    .with_source(document.source_document)\n                    .with_section(document.title)\n                    .with_start_sequence_idx(chunk_id_counter)\n                    .build()\n                )\n                doc_chunks = self.chunker.chunk(table_content, context)\n                chunks.extend(doc_chunks)\n                chunk_id_counter += len(doc_chunks)\n\n        return chunks\n</code></pre>"},{"location":"api-reference/#ragora.core.document_preprocessor.DocumentPreprocessor._chunk_document","title":"<code>_chunk_document(document)</code>","text":"<p>Chunk the document into a list of DataChunks.</p> Source code in <code>ragora/ragora/core/document_preprocessor.py</code> <pre><code>def _chunk_document(self, document: LatexDocument) -&gt; list[DataChunk]:\n    \"\"\"Chunk the document into a list of DataChunks.\"\"\"\n    if document is None:\n        raise ValueError(\"Document cannot be None\")\n    chunks = []\n    chunk_id_counter = 0\n\n    if document.paragraphs:\n        paragraph_content = \"\"\n        for paragraph in document.paragraphs:\n            paragraph_content += paragraph.content\n        context = (\n            ChunkingContextBuilder()\n            .for_document()\n            .with_source(document.source_document)\n            .with_section(document.title)\n            .with_start_sequence_idx(chunk_id_counter)\n            .build()\n        )\n        doc_chunks = self.chunker.chunk(paragraph_content, context)\n        chunks.extend(doc_chunks)\n        chunk_id_counter += len(doc_chunks)\n\n    if document.chapters:\n        for chapter in document.chapters:\n            chapter_content = f\"# {chapter.title}\"\n            if chapter.paragraphs:\n                for paragraph in chapter.paragraphs:\n                    chapter_content += paragraph.content\n                context = (\n                    ChunkingContextBuilder()\n                    .for_document()\n                    .with_source(document.source_document)\n                    .with_section(chapter.title)\n                    .with_start_sequence_idx(chunk_id_counter)\n                    .build()\n                )\n                doc_chunks = self.chunker.chunk(chapter_content, context)\n                chunks.extend(doc_chunks)\n                chunk_id_counter += len(doc_chunks)\n\n            if chapter.sections:\n                for section in chapter.sections:\n                    section_content = f\"## {section.title}\"\n                    if section.paragraphs:\n                        for paragraph in section.paragraphs:\n                            section_content += paragraph.content\n                        context = (\n                            ChunkingContextBuilder()\n                            .for_document()\n                            .with_source(document.source_document)\n                            .with_section(section.title)\n                            .with_start_sequence_idx(chunk_id_counter)\n                            .build()\n                        )\n                        doc_chunks = self.chunker.chunk(section_content, context)\n                        chunks.extend(doc_chunks)\n                        chunk_id_counter += len(doc_chunks)\n\n    if document.sections:\n        for section in document.sections:\n            section_content = f\"## {section.title}\"\n            if section.paragraphs:\n                for paragraph in section.paragraphs:\n                    section_content += paragraph.content\n                context = (\n                    ChunkingContextBuilder()\n                    .for_document()\n                    .with_source(document.source_document)\n                    .with_section(section.title)\n                    .with_start_sequence_idx(chunk_id_counter)\n                    .build()\n                )\n                doc_chunks = self.chunker.chunk(section_content, context)\n                chunks.extend(doc_chunks)\n                chunk_id_counter += len(doc_chunks)\n\n    if document.tables:\n        for table in document.tables:\n            table_content = table.to_plain_text()\n            context = (\n                ChunkingContextBuilder()\n                .for_document()\n                .with_source(document.source_document)\n                .with_section(document.title)\n                .with_start_sequence_idx(chunk_id_counter)\n                .build()\n            )\n            doc_chunks = self.chunker.chunk(table_content, context)\n            chunks.extend(doc_chunks)\n            chunk_id_counter += len(doc_chunks)\n\n    return chunks\n</code></pre>"},{"location":"api-reference/#ragora.core.document_preprocessor.DocumentPreprocessor._chunk_documents","title":"<code>_chunk_documents(documentList)</code>","text":"<p>Chunk multiple LaTeX documents.</p> <p>Parameters:</p> Name Type Description Default <code>documentList</code> <code>list[LatexDocument]</code> <p>Parsed LaTeX documents.</p> required <p>Returns:</p> Type Description <code>list[DataChunk]</code> <p>list[DataChunk]: Chunked output.</p> Source code in <code>ragora/ragora/core/document_preprocessor.py</code> <pre><code>def _chunk_documents(self, documentList: list[LatexDocument]) -&gt; list[DataChunk]:\n    \"\"\"Chunk multiple LaTeX documents.\n\n    Args:\n        documentList: Parsed LaTeX documents.\n\n    Returns:\n        list[DataChunk]: Chunked output.\n    \"\"\"\n    chunks = []\n    if not documentList:\n        return chunks\n    for document in documentList:\n        chunks.extend(self._chunk_document(document))\n    return chunks\n</code></pre>"},{"location":"api-reference/#ragora.core.document_preprocessor.DocumentPreprocessor._chunk_markdown_document","title":"<code>_chunk_markdown_document(document)</code>","text":"<p>Chunk a single Markdown document respecting the original hierarchy.</p> <p>Parameters:</p> Name Type Description Default <code>document</code> <code>MarkdownDocument</code> <p>Parsed Markdown document.</p> required <p>Returns:</p> Type Description <code>list[DataChunk]</code> <p>list[DataChunk]: Chunked output.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>document</code> is <code>None</code>.</p> Source code in <code>ragora/ragora/core/document_preprocessor.py</code> <pre><code>def _chunk_markdown_document(self, document: MarkdownDocument) -&gt; list[DataChunk]:\n    \"\"\"Chunk a single Markdown document respecting the original hierarchy.\n\n    Args:\n        document: Parsed Markdown document.\n\n    Returns:\n        list[DataChunk]: Chunked output.\n\n    Raises:\n        ValueError: If ``document`` is ``None``.\n    \"\"\"\n    if document is None:\n        raise ValueError(\"Document cannot be None\")\n\n    chunk_id_counter = 0\n    chunks: list[DataChunk] = []\n\n    if document.paragraphs:\n        paragraph_content = \"\\n\\n\".join(\n            paragraph.content\n            for paragraph in document.paragraphs\n            if paragraph.content\n        )\n        if paragraph_content:\n            section_label = document.title or document.source_document\n            context = (\n                ChunkingContextBuilder()\n                .for_document()\n                .with_source(document.source_document)\n                .with_section(section_label)\n                .with_start_sequence_idx(chunk_id_counter)\n                .build()\n            )\n            doc_chunks = self.chunker.chunk(paragraph_content, context)\n            chunks.extend(doc_chunks)\n            chunk_id_counter += len(doc_chunks)\n\n    if document.chapters:\n        for chapter in document.chapters:\n            chapter_content_parts = [f\"# {chapter.title}\" if chapter.title else \"\"]\n            chapter_content_parts.extend(\n                paragraph.content\n                for paragraph in chapter.paragraphs\n                if paragraph.content\n            )\n            chapter_content = \"\\n\\n\".join(\n                part for part in chapter_content_parts if part.strip()\n            )\n            if chapter_content:\n                section_label = (\n                    chapter.title or document.title or document.source_document\n                )\n                context = (\n                    ChunkingContextBuilder()\n                    .for_document()\n                    .with_source(document.source_document)\n                    .with_section(section_label)\n                    .with_start_sequence_idx(chunk_id_counter)\n                    .build()\n                )\n                doc_chunks = self.chunker.chunk(chapter_content, context)\n                chunks.extend(doc_chunks)\n                chunk_id_counter += len(doc_chunks)\n\n            if chapter.sections:\n                for section in chapter.sections:\n                    section_content_parts = [\n                        f\"## {section.title}\" if section.title else \"\",\n                        *[\n                            paragraph.content\n                            for paragraph in section.paragraphs\n                            if paragraph.content\n                        ],\n                    ]\n                    section_content = \"\\n\\n\".join(\n                        part for part in section_content_parts if part.strip()\n                    )\n                    if section_content:\n                        section_label = (\n                            section.title\n                            or chapter.title\n                            or document.title\n                            or document.source_document\n                        )\n                        context = (\n                            ChunkingContextBuilder()\n                            .for_document()\n                            .with_source(document.source_document)\n                            .with_section(section_label)\n                            .with_start_sequence_idx(chunk_id_counter)\n                            .build()\n                        )\n                        doc_chunks = self.chunker.chunk(section_content, context)\n                        chunks.extend(doc_chunks)\n                        chunk_id_counter += len(doc_chunks)\n\n    if document.sections:\n        for section in document.sections:\n            section_content_parts = [\n                f\"## {section.title}\" if section.title else \"\",\n                *[\n                    paragraph.content\n                    for paragraph in section.paragraphs\n                    if paragraph.content\n                ],\n            ]\n            section_content = \"\\n\\n\".join(\n                part for part in section_content_parts if part.strip()\n            )\n            if section_content:\n                section_label = (\n                    section.title or document.title or document.source_document\n                )\n                context = (\n                    ChunkingContextBuilder()\n                    .for_document()\n                    .with_source(document.source_document)\n                    .with_section(section_label)\n                    .with_start_sequence_idx(chunk_id_counter)\n                    .build()\n                )\n                doc_chunks = self.chunker.chunk(section_content, context)\n                chunks.extend(doc_chunks)\n                chunk_id_counter += len(doc_chunks)\n\n    return chunks\n</code></pre>"},{"location":"api-reference/#ragora.core.document_preprocessor.DocumentPreprocessor._chunk_markdown_documents","title":"<code>_chunk_markdown_documents(document_list)</code>","text":"<p>Chunk Markdown or plain text documents.</p> <p>Parameters:</p> Name Type Description Default <code>document_list</code> <code>list[MarkdownDocument]</code> <p>Parsed Markdown documents.</p> required <p>Returns:</p> Type Description <code>list[DataChunk]</code> <p>list[DataChunk]: Chunked output.</p> Source code in <code>ragora/ragora/core/document_preprocessor.py</code> <pre><code>def _chunk_markdown_documents(\n    self, document_list: list[MarkdownDocument]\n) -&gt; list[DataChunk]:\n    \"\"\"Chunk Markdown or plain text documents.\n\n    Args:\n        document_list: Parsed Markdown documents.\n\n    Returns:\n        list[DataChunk]: Chunked output.\n    \"\"\"\n\n    chunks: list[DataChunk] = []\n    if not document_list:\n        return chunks\n\n    for document in document_list:\n        chunks.extend(self._chunk_markdown_document(document))\n\n    return chunks\n</code></pre>"},{"location":"api-reference/#ragora.core.document_preprocessor.DocumentPreprocessor._extract_document_text","title":"<code>_extract_document_text(documentList)</code>","text":"<p>Merge one or more parsed LaTeX documents into plain text.</p> <p>Parameters:</p> Name Type Description Default <code>documentList</code> <code>list[LatexDocument]</code> <p>Collection of parsed LaTeX documents to flatten.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Combined Markdown-like text used for chunking.</p> Source code in <code>ragora/ragora/core/document_preprocessor.py</code> <pre><code>def _extract_document_text(self, documentList: list[LatexDocument]) -&gt; str:\n    \"\"\"Merge one or more parsed LaTeX documents into plain text.\n\n    Args:\n        documentList: Collection of parsed LaTeX documents to flatten.\n\n    Returns:\n        str: Combined Markdown-like text used for chunking.\n    \"\"\"\n    content_parts = []\n\n    for document in documentList:\n        # Extract from chapters\n        if document.chapters:\n            for chapter in document.chapters:\n                content_parts.append(f\"# {chapter.title}\")\n                if chapter.paragraphs:\n                    for para in chapter.paragraphs:\n                        content_parts.append(para.content)\n                if chapter.sections:\n                    for section in chapter.sections:\n                        content_parts.append(f\"## {section.title}\")\n                        if section.paragraphs:\n                            for para in section.paragraphs:\n                                content_parts.append(para.content)\n\n        # Extract from standalone sections\n        if document.sections:\n            for section in document.sections:\n                content_parts.append(f\"## {section.title}\")\n                if section.paragraphs:\n                    for para in section.paragraphs:\n                        content_parts.append(para.content)\n\n        # Extract from standalone paragraphs\n        if document.paragraphs:\n            for para in document.paragraphs:\n                content_parts.append(para.content)\n\n        # Extract from tables\n        if document.tables:\n            for table in document.tables:\n                content_parts.append(table.to_plain_text())\n\n    return \"\\n\\n\".join(content_parts)\n</code></pre>"},{"location":"api-reference/#ragora.core.document_preprocessor.DocumentPreprocessor.preprocess_document","title":"<code>preprocess_document(file_path, format='latex')</code>","text":"<p>Preprocess a single document into :class:<code>DataChunk</code> objects.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>Path to the document file.</p> required <code>format</code> <code>str</code> <p>Document format (<code>\"latex\"</code>, <code>\"markdown\"</code>, or <code>\"text\"</code>).</p> <code>'latex'</code> <p>Returns:</p> Type Description <code>list[DataChunk]</code> <p>list[DataChunk]: Chunked content ready for embedding downstream.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an unsupported format is requested.</p> <p>Examples:</p> <pre><code>chunks = preprocessor.preprocess_document(\"paper.tex\", format=\"latex\")\n</code></pre> Source code in <code>ragora/ragora/core/document_preprocessor.py</code> <pre><code>def preprocess_document(\n    self, file_path: str, format: str = \"latex\"\n) -&gt; list[DataChunk]:\n    \"\"\"Preprocess a single document into :class:`DataChunk` objects.\n\n    Args:\n        file_path: Path to the document file.\n        format: Document format (``\"latex\"``, ``\"markdown\"``, or ``\"text\"``).\n\n    Returns:\n        list[DataChunk]: Chunked content ready for embedding downstream.\n\n    Raises:\n        ValueError: If an unsupported format is requested.\n\n    Examples:\n        ```python\n        chunks = preprocessor.preprocess_document(\"paper.tex\", format=\"latex\")\n        ```\n    \"\"\"\n    normalized_format = format.lower()\n\n    if normalized_format == \"latex\":\n        if file_path.endswith(\".bib\"):\n            self.latex_parser.parse_bibliography(file_path)\n            return []\n        document = self.latex_parser.parse_document(file_path)\n        return self._chunk_documents([document])\n\n    if normalized_format in {\"markdown\", \"md\", \"text\", \"txt\"}:\n        document = self.markdown_parser.parse_document(file_path)\n        return self._chunk_markdown_documents([document])\n\n    raise ValueError(f\"Unsupported document format: {format}\")\n</code></pre>"},{"location":"api-reference/#ragora.core.document_preprocessor.DocumentPreprocessor.preprocess_document_folder","title":"<code>preprocess_document_folder(folder_path, format='latex')</code>","text":"<p>Preprocess every supported file in a folder.</p> <p>Parameters:</p> Name Type Description Default <code>folder_path</code> <code>str</code> <p>Directory containing documents that should be ingested.</p> required <code>format</code> <code>str</code> <p>Document format used to interpret files within the folder.</p> <code>'latex'</code> <p>Returns:</p> Type Description <code>list[DataChunk]</code> <p>list[DataChunk]: Aggregated chunk list for the entire folder.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>format</code> is not in the supported extension map.</p> Source code in <code>ragora/ragora/core/document_preprocessor.py</code> <pre><code>def preprocess_document_folder(\n    self, folder_path: str, format: str = \"latex\"\n) -&gt; list[DataChunk]:\n    \"\"\"Preprocess every supported file in a folder.\n\n    Args:\n        folder_path: Directory containing documents that should be ingested.\n        format: Document format used to interpret files within the folder.\n\n    Returns:\n        list[DataChunk]: Aggregated chunk list for the entire folder.\n\n    Raises:\n        ValueError: If ``format`` is not in the supported extension map.\n    \"\"\"\n    normalized_format = format.lower()\n    if normalized_format not in self.file_extension_map:\n        raise ValueError(f\"Unsupported document format: {format}\")\n\n    file_paths = [\n        os.path.join(folder_path, file)\n        for file in os.listdir(folder_path)\n        if any(\n            file.endswith(ext) for ext in self.file_extension_map[normalized_format]\n        )\n    ]\n    return self.preprocess_documents(file_paths, normalized_format)\n</code></pre>"},{"location":"api-reference/#ragora.core.document_preprocessor.DocumentPreprocessor.preprocess_documents","title":"<code>preprocess_documents(file_paths, format='latex')</code>","text":"<p>Preprocess multiple documents at once.</p> <p>Parameters:</p> Name Type Description Default <code>file_paths</code> <code>list[str]</code> <p>Collection of paths to document files.</p> required <code>format</code> <code>str</code> <p>Document format (<code>\"latex\"</code>, <code>\"markdown\"</code>, or <code>\"text\"</code>).</p> <code>'latex'</code> <p>Returns:</p> Type Description <code>list[DataChunk]</code> <p>list[DataChunk]: Combined chunks from all input documents.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an unsupported format is requested.</p> <p>Examples:</p> <pre><code>chunks = preprocessor.preprocess_documents(\n    [\"chapter1.tex\", \"chapter2.tex\", \"references.bib\"],\n    format=\"latex\",\n)\n</code></pre> Source code in <code>ragora/ragora/core/document_preprocessor.py</code> <pre><code>def preprocess_documents(\n    self, file_paths: list[str], format: str = \"latex\"\n) -&gt; list[DataChunk]:\n    \"\"\"Preprocess multiple documents at once.\n\n    Args:\n        file_paths: Collection of paths to document files.\n        format: Document format (``\"latex\"``, ``\"markdown\"``, or ``\"text\"``).\n\n    Returns:\n        list[DataChunk]: Combined chunks from all input documents.\n\n    Raises:\n        ValueError: If an unsupported format is requested.\n\n    Examples:\n        ```python\n        chunks = preprocessor.preprocess_documents(\n            [\"chapter1.tex\", \"chapter2.tex\", \"references.bib\"],\n            format=\"latex\",\n        )\n        ```\n    \"\"\"\n    normalized_format = format.lower()\n\n    if normalized_format == \"latex\":\n        # Find the bibliography file\n        bibliography_path = None\n        for file_path in file_paths:\n            if file_path.endswith(\".bib\"):\n                bibliography_path = file_path\n                break\n        if bibliography_path:\n            self.latex_parser.parse_bibliography(bibliography_path)\n        documents = [\n            self.latex_parser.parse_document(file_path)\n            for file_path in file_paths\n            if file_path != bibliography_path\n        ]\n        return self._chunk_documents(documents)\n\n    if normalized_format in {\"markdown\", \"md\", \"text\", \"txt\"}:\n        documents = [\n            self.markdown_parser.parse_document(path) for path in file_paths\n        ]\n        return self._chunk_markdown_documents(documents)\n\n    raise ValueError(f\"Unsupported document format: {format}\")\n</code></pre>"},{"location":"api-reference/#email-preprocessor","title":"Email Preprocessor","text":"<p>Email preprocessor for the RAG system.</p> <p>This module handles the preprocessing of email messages for the RAG system. It converts email messages into data chunks for the RAG system.</p> <p>Key responsibilities: - Convert email messages into data chunks - Provide a unified interface for preprocessing email messages - Prepare clean text content for the embedding engine - Maintain email message structure and metadata - Clean HTML content and strip quoted replies and signatures</p> <p>The preprocessor returns structured chunks with metadata that can be directly fed to the embedding engine for vector database storage.</p>"},{"location":"api-reference/#ragora.core.email_preprocessor.EmailPreprocessor","title":"<code>EmailPreprocessor</code>","text":"<p>Email preprocessor for the RAG system.</p> <p>This class handles the conversion of EmailMessage objects into DataChunks suitable for vector storage. It follows the same pattern as DocumentPreprocessor for consistency in the codebase.</p> <p>Attributes:</p> Name Type Description <code>chunker</code> <p>DataChunker instance for chunking email content</p> Source code in <code>ragora/ragora/core/email_preprocessor.py</code> <pre><code>class EmailPreprocessor:\n    \"\"\"Email preprocessor for the RAG system.\n\n    This class handles the conversion of EmailMessage objects into DataChunks\n    suitable for vector storage. It follows the same pattern as\n    DocumentPreprocessor for consistency in the codebase.\n\n    Attributes:\n        chunker: DataChunker instance for chunking email content\n    \"\"\"\n\n    # Email TLDs for signature detection (class-level constant)\n    _EMAIL_TLDS = (\n        r\"com|org|net|edu|gov|de|uk|fr|it|es|nl|be|ch|at|se|no|\"\n        r\"dk|fi|pl|cz|hu|ro|gr|pt|ie|lu|mt|cy|sk|si|ee|lv|lt|bg|hr\"\n    )\n\n    # Patterns that indicate signature start (class-level constant)\n    _SIGNATURE_INDICATORS = [\n        r\"^--\\s*$\",  # Two dashes on their own line\n        r\"^\\\\--\\s*$\",  # Escaped two dashes (from HTML/text conversion)\n        r\"^---\\s*$\",  # Three dashes\n        r\"^\\\\---\\s*$\",  # Escaped three dashes (from HTML/text conversion)\n        r\"^_{3,}$\",  # Underscores\n        r\"^={3,}$\",  # Equals signs\n        r\"^Best regards\",\n        r\"^Regards,\",\n        r\"^Sincerely,\",\n        r\"^Cheers,\",\n        r\"^Thanks,\",\n        r\"^Thank you,\",\n        r\"^Sent from my\",\n        r\"^Get Outlook\",\n    ]\n\n    # Compiled regex patterns for signature indicators (pre-compiled for\n    # performance)\n    _SIGNATURE_INDICATOR_PATTERNS = [\n        re.compile(pattern, re.IGNORECASE) for pattern in _SIGNATURE_INDICATORS\n    ]\n\n    # Patterns that indicate signature content (class-level constant)\n    _SIGNATURE_CONTENT_PATTERNS = [\n        # Email addresses\n        re.compile(r\"@.*\\.\" + f\"({_EMAIL_TLDS})\", re.IGNORECASE),\n        # Phone numbers (international format)\n        re.compile(\n            r\"\\+?\\d{1,4}[-.\\s]?\\d{1,4}[-.\\s]?\\d{1,4}[-.\\s]?\\d{1,4}\" r\"[-.\\s]?\\d{0,4}\",\n            re.IGNORECASE,\n        ),\n        re.compile(r\"^www\\.\", re.IGNORECASE),\n        re.compile(r\"^http://\", re.IGNORECASE),\n        re.compile(r\"^https://\", re.IGNORECASE),\n        re.compile(r\"linkedin\\.com\", re.IGNORECASE),\n        re.compile(r\"facebook\\.com\", re.IGNORECASE),\n        re.compile(r\"twitter\\.com\", re.IGNORECASE),\n        re.compile(r\"xing\\.com\", re.IGNORECASE),\n        re.compile(r\"^\\d{5}[\\s-]?\\w+\", re.IGNORECASE),  # Postal codes\n        # Lines ending with comma and country/state (e.g., \"Germany\", \"USA\")\n        re.compile(r\",\\s*\\w+\\s*$\", re.IGNORECASE),\n        re.compile(r\"\\(cellphone\\)\", re.IGNORECASE),\n        re.compile(r\"\\(mobile\\)\", re.IGNORECASE),\n        re.compile(r\"\\(phone\\)\", re.IGNORECASE),\n        re.compile(r\"Dr\\.-?Ing\\.\", re.IGNORECASE),  # German academic titles\n        re.compile(r\"Prof\\.\", re.IGNORECASE),  # Professor\n        re.compile(r\"PhD\", re.IGNORECASE),\n    ]\n\n    def __init__(self, chunker: DataChunker = None):\n        \"\"\"Initialize the EmailPreprocessor.\n\n        Args:\n            chunker: DataChunker instance (optional)\n        \"\"\"\n        if chunker is not None:\n            self.chunker = chunker\n        else:\n            # Create a default chunker\n            self.chunker = DataChunker()\n\n    def preprocess_emails(\n        self, emails: List[EmailMessage], start_sequence_idx: int = 0\n    ) -&gt; List[DataChunk]:\n        \"\"\"Preprocess multiple emails into data chunks.\n\n        This method converts a list of EmailMessage objects into DataChunks\n        for storage in the vector database.\n\n        Args:\n            emails: List of EmailMessage objects to preprocess\n            start_sequence_idx: Starting sequence index for the emails\n\n        Returns:\n            List of DataChunks containing the email messages\n        \"\"\"\n        all_chunks = []\n        chunk_idx_counter = start_sequence_idx\n\n        for email in emails:\n            chunks = self._email_to_chunks(email, chunk_idx_counter)\n            all_chunks.extend(chunks)\n            chunk_idx_counter += len(chunks)\n\n        return all_chunks\n\n    def preprocess_email(\n        self, email: EmailMessage, start_sequence_idx: int = 0\n    ) -&gt; List[DataChunk]:\n        \"\"\"Preprocess a single email into data chunks.\n\n        This method converts a single EmailMessage object into DataChunks\n        for storage in the vector database.\n\n        Args:\n            email: EmailMessage object to preprocess\n            start_sequence_idx: Starting sequence index for this email\n\n        Returns:\n            List of DataChunks containing the email message\n        \"\"\"\n        return self._email_to_chunks(email, start_sequence_idx)\n\n    def clean_email_body(self, email: Union[EmailMessage, EmailMessageModel]) -&gt; str:\n        \"\"\"Clean email body by converting HTML, stripping replies,\n        and removing signatures.\n\n        This method orchestrates all cleaning steps:\n        1. Extract body (HTML preferred, fallback to text)\n        2. Convert HTML to text (if HTML exists)\n        3. Strip quoted replies\n        4. Strip signatures\n        5. Normalize whitespace\n\n        This method can be used independently to get clean email text\n        for processing with LLMs or other text analysis tools without\n        chunking the content.\n\n        Args:\n            email: EmailMessage or EmailMessageModel object to clean (both have\n                the same interface: get_body(), body_html, body_text)\n\n        Returns:\n            Cleaned plain text content. Returns empty string if email\n            has no body content.\n\n        Example:\n            &gt;&gt;&gt; from ragora import EmailPreprocessor\n            &gt;&gt;&gt; from ragora.utils.email_utils.models import EmailMessage\n            &gt;&gt;&gt; from ragora.core.models import EmailMessageModel\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; preprocessor = EmailPreprocessor()\n            &gt;&gt;&gt; # Works with EmailMessage\n            &gt;&gt;&gt; clean_text = preprocessor.clean_email_body(email_message)\n            &gt;&gt;&gt; # Also works with EmailMessageModel\n            &gt;&gt;&gt; clean_text = preprocessor.clean_email_body(email_item)\n            &gt;&gt;&gt; # Use clean_text with LLM or other processing\n        \"\"\"\n        # Step 1: Extract body (HTML preferred, fallback to text)\n        body = email.get_body()\n        if not body or not body.strip():\n            return \"\"\n\n        # Step 2: Convert HTML to text if it's HTML\n        # Check if body is HTML by looking at email.body_html\n        # or by checking if body contains HTML tags\n        is_html = email.body_html is not None and email.body_html.strip()\n        if not is_html:\n            # Also check if body_text itself contains HTML tags\n            is_html = bool(re.search(r\"&lt;[^&gt;]+&gt;\", body))\n\n        if is_html:\n            text = self._html_to_text(body)\n        else:\n            text = body\n\n        # Step 3: Strip quoted replies\n        text = self._strip_quoted_replies(text)\n\n        # Step 4: Strip signatures\n        text = self._strip_signatures(text)\n\n        # Step 5: Normalize whitespace\n        text = self._normalize_whitespace(text)\n\n        return text\n\n    def _email_to_chunks(\n        self, email: EmailMessage, start_sequence_idx: int\n    ) -&gt; List[DataChunk]:\n        \"\"\"Convert an EmailMessage to data chunks.\n\n        Args:\n            email: EmailMessage object to convert\n            start_sequence_idx: Starting sequence index for this email\n\n        Returns:\n            List of DataChunks for this email\n        \"\"\"\n        # Clean and extract text content from email\n        email_text = self.clean_email_body(email)\n\n        # Create context with email metadata\n        context = (\n            ChunkingContextBuilder()\n            .for_email()\n            .with_email_info(\n                subject=email.subject or \"\",\n                sender=str(email.sender) if email.sender else \"\",\n                recipient=(\n                    \", \".join([str(addr) for addr in email.recipients])\n                    if email.recipients\n                    else \"\"\n                ),\n                email_id=email.message_id or \"\",\n                email_date=(email.date_sent.isoformat() if email.date_sent else \"\"),\n            )\n            .with_start_sequence_idx(start_sequence_idx)\n            .build()\n        )\n\n        return self.chunker.chunk(email_text, context)\n\n    def _html_to_text_html2text(self, html_content: str) -&gt; str:\n        \"\"\"Convert HTML content to plain text using html2text library.\n\n        Args:\n            html_content: HTML string to convert\n\n        Returns:\n            Plain text representation of the HTML\n\n        Raises:\n            ImportError: If html2text library is not available\n            Exception: If conversion fails\n        \"\"\"\n        if html2text is None:\n            raise ImportError(\"html2text library is not available\")\n\n        h = html2text.HTML2Text()\n        h.ignore_links = True\n        h.ignore_images = True\n        h.body_width = 0  # Don't wrap lines\n        h.unicode_snob = True  # Use unicode\n        text = h.handle(html_content)\n        return text.strip()\n\n    def _html_to_text_beautifulsoup(self, html_content: str) -&gt; str:\n        \"\"\"Convert HTML content to plain text using BeautifulSoup4.\n\n        Args:\n            html_content: HTML string to convert\n\n        Returns:\n            Plain text representation of the HTML\n\n        Raises:\n            ImportError: If BeautifulSoup4 library is not available\n            Exception: If conversion fails\n        \"\"\"\n        if BeautifulSoup is None:\n            raise ImportError(\"BeautifulSoup4 library is not available\")\n\n        soup = BeautifulSoup(html_content, \"html.parser\")\n        # Remove script and style elements\n        for script in soup([\"script\", \"style\"]):\n            script.decompose()\n        text = soup.get_text()\n        # Clean up whitespace\n        lines = (line.strip() for line in text.splitlines())\n        chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n        text = \"\\n\".join(chunk for chunk in chunks if chunk)\n        return text.strip()\n\n    def _html_to_text_regex(self, html_content: str) -&gt; str:\n        \"\"\"Convert HTML content to plain text using basic regex cleanup.\n\n        This is a last-resort fallback method that uses regex to remove\n        HTML tags and decode common HTML entities.\n\n        Args:\n            html_content: HTML string to convert\n\n        Returns:\n            Plain text representation of the HTML\n        \"\"\"\n        # Remove HTML tags\n        text = re.sub(r\"&lt;[^&gt;]+&gt;\", \"\", html_content)\n        # Decode common HTML entities\n        text = text.replace(\"&amp;nbsp;\", \" \")\n        text = text.replace(\"&amp;amp;\", \"&amp;\")\n        text = text.replace(\"&amp;lt;\", \"&lt;\")\n        text = text.replace(\"&amp;gt;\", \"&gt;\")\n        text = text.replace(\"&amp;quot;\", '\"')\n        text = text.replace(\"&amp;#39;\", \"'\")\n        return text.strip()\n\n    def _html_to_text(self, html_content: str) -&gt; str:\n        \"\"\"Convert HTML content to plain text.\n\n        Tries multiple approaches in order: html2text, BeautifulSoup4, regex.\n\n        Args:\n            html_content: HTML string to convert\n\n        Returns:\n            Plain text representation of the HTML\n        \"\"\"\n        if not html_content or not html_content.strip():\n            return \"\"\n\n        # Try html2text first (better for email HTML)\n        if html2text is not None:\n            try:\n                return self._html_to_text_html2text(html_content)\n            except Exception:\n                # Fall through to BeautifulSoup if html2text fails\n                pass\n\n        # Fallback to BeautifulSoup4\n        if BeautifulSoup is not None:\n            try:\n                return self._html_to_text_beautifulsoup(html_content)\n            except Exception:\n                pass\n\n        # Last resort: basic regex cleanup\n        return self._html_to_text_regex(html_content)\n\n    def _strip_quoted_replies_library(self, text: str) -&gt; str:\n        \"\"\"Strip quoted reply sections using email_reply_parser library.\n\n        Args:\n            text: Email text that may contain quoted replies\n\n        Returns:\n            Text with quoted replies removed\n\n        Raises:\n            ImportError: If email_reply_parser library is not available\n            Exception: If parsing fails\n        \"\"\"\n        if EmailReplyParser is None:\n            raise ImportError(\"email_reply_parser library is not available\")\n\n        # Parse the email to get the actual reply\n        parsed = EmailReplyParser.read(text)\n        # Extract only the visible (non-quoted) text\n        # Use parsed.reply which contains the reply text without quotes\n        reply = parsed.reply\n        if reply:\n            return reply.strip()\n        return \"\"\n\n    def _strip_quoted_replies_regex(self, text: str) -&gt; str:\n        \"\"\"Strip quoted reply sections using regex-based approach.\n\n        This is a fallback method that uses regex patterns to identify\n        and remove common quoted reply formats.\n\n        Args:\n            text: Email text that may contain quoted replies\n\n        Returns:\n            Text with quoted replies removed\n        \"\"\"\n        lines = text.split(\"\\n\")\n        cleaned_lines = []\n        in_quoted_section = False\n        in_header_block = False\n\n        # Patterns that indicate start of quoted section\n        quote_start_patterns = [\n            r\"^On .+ wrote:\",\n            r\"^From:\",\n            r\"^-----Original Message-----\",\n            r\"^&gt;+\",\n            r\"^--- .+ ---\",\n            r\"^_{5,}\",\n            r\"^={5,}\",\n        ]\n\n        # Patterns for email headers (usually follow \"From:\" in quotes)\n        email_header_pattern = r\"^[A-Z][a-zA-Z-]+:\"\n\n        for line in lines:\n            # Check if this line starts a quoted section\n            is_quote_start = any(\n                re.match(pattern, line, re.IGNORECASE)\n                for pattern in quote_start_patterns\n            )\n\n            if is_quote_start:\n                in_quoted_section = True\n                in_header_block = True\n                continue\n\n            # If we hit a blank line after being in quoted section,\n            # we might be transitioning, but continue checking\n            if in_quoted_section:\n                # Check if line is an email header (part of quote metadata)\n                is_email_header = bool(re.match(email_header_pattern, line))\n                if is_email_header:\n                    in_header_block = True\n                    continue\n\n                # After email headers, if we see a blank line,\n                # mark that we're past the header block\n                if line.strip() == \"\":\n                    if in_header_block:\n                        in_header_block = False\n                    continue\n\n                # After headers, everything until we see clear break\n                # is quoted content\n                if not in_header_block:\n                    # This is content after headers - should be quoted\n                    continue\n\n                # If we get here, might be actual content again\n                # Exit quoted section if we have content before\n                if len(cleaned_lines) &gt; 0:\n                    in_quoted_section = False\n                    in_header_block = False\n                    cleaned_lines.append(line)\n                else:\n                    # No content yet, might still be in quote\n                    in_header_block = False\n                continue\n\n            in_header_block = False\n            cleaned_lines.append(line)\n\n        return \"\\n\".join(cleaned_lines).strip()\n\n    def _strip_quoted_replies(self, text: str) -&gt; str:\n        \"\"\"Strip quoted reply sections from email text.\n\n        Tries email_reply_parser library first, falls back to regex approach.\n\n        Args:\n            text: Email text that may contain quoted replies\n\n        Returns:\n            Text with quoted replies removed\n        \"\"\"\n        if not text or not text.strip():\n            return \"\"\n\n        if EmailReplyParser is not None:\n            try:\n                return self._strip_quoted_replies_library(text)\n            except Exception:\n                # Fall through to regex-based approach if library fails\n                pass\n\n        # Fallback regex-based approach for common reply patterns\n        return self._strip_quoted_replies_regex(text)\n\n    def _strip_signatures(self, text: str) -&gt; str:\n        \"\"\"Strip email signatures from text.\n\n        Uses regex patterns to identify and remove common signature formats.\n\n        Args:\n            text: Email text that may contain signatures\n\n        Returns:\n            Text with signatures removed\n        \"\"\"\n        if not text or not text.strip():\n            return \"\"\n\n        lines = text.split(\"\\n\")\n        cleaned_lines = []\n        signature_started = False\n        consecutive_blank_lines = 0\n\n        for i, line in enumerate(lines):\n            # Check if this line starts a signature\n            is_signature_start = any(\n                pattern.match(line) for pattern in self._SIGNATURE_INDICATOR_PATTERNS\n            )\n\n            if is_signature_start:\n                signature_started = True\n                consecutive_blank_lines = 0\n                # Don't include this line\n                continue\n\n            if signature_started:\n                # Track consecutive blank lines - multiple blank lines might\n                # indicate end of signature, but we need to be careful\n                if line.strip() == \"\":\n                    consecutive_blank_lines += 1\n                    # If we have 2+ consecutive blank lines, check if we're\n                    # past signature\n                    if consecutive_blank_lines &gt;= 2:\n                        # Look ahead to see if there's actual content\n                        next_non_blank_idx = i + 1\n                        while (\n                            next_non_blank_idx &lt; len(lines)\n                            and lines[next_non_blank_idx].strip() == \"\"\n                        ):\n                            next_non_blank_idx += 1\n\n                        if next_non_blank_idx &lt; len(lines):\n                            next_line = lines[next_non_blank_idx]\n                            # Check if next line looks like signature content\n                            is_signature_content = any(\n                                pattern.search(next_line)\n                                for pattern in self._SIGNATURE_CONTENT_PATTERNS\n                            ) or any(\n                                pattern.match(next_line)\n                                for pattern in self._SIGNATURE_INDICATOR_PATTERNS\n                            )\n\n                            if not is_signature_content:\n                                # We've hit multiple blank lines followed by\n                                # non-signature content. This likely means\n                                # we're past the signature\n                                signature_started = False\n                                consecutive_blank_lines = 0\n                                # Include the blank lines as they're part of\n                                # the break\n                                cleaned_lines.append(line)\n                                continue\n\n                    # Still in signature, skip blank lines\n                    continue\n                else:\n                    # Reset blank line counter for non-blank lines\n                    consecutive_blank_lines = 0\n\n                    # Check if line looks like signature content\n                    is_signature_content = any(\n                        pattern.search(line)\n                        for pattern in self._SIGNATURE_CONTENT_PATTERNS\n                    )\n\n                    if is_signature_content:\n                        # Definitely signature content, skip it\n                        continue\n\n                    # Line doesn't match signature patterns, but we're after\n                    # a signature delimiter. Continue skipping unless we see\n                    # a clear break (handled by blank line logic above).\n                    # This handles names, titles, and other signature\n                    # elements that don't match patterns\n                    continue\n            else:\n                consecutive_blank_lines = 0\n                cleaned_lines.append(line)\n\n        return \"\\n\".join(cleaned_lines).strip()\n\n    def _normalize_whitespace(self, text: str) -&gt; str:\n        \"\"\"Normalize whitespace in text.\n\n        Args:\n            text: Text to normalize\n\n        Returns:\n            Text with normalized whitespace\n        \"\"\"\n        if not text:\n            return \"\"\n\n        # Replace multiple spaces with single space\n        text = re.sub(r\" +\", \" \", text)\n        # Replace multiple newlines with maximum of two\n        text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text)\n        # Remove trailing whitespace from each line\n        lines = [line.rstrip() for line in text.split(\"\\n\")]\n        return \"\\n\".join(lines).strip()\n</code></pre>"},{"location":"api-reference/#ragora.core.email_preprocessor.EmailPreprocessor._email_to_chunks","title":"<code>_email_to_chunks(email, start_sequence_idx)</code>","text":"<p>Convert an EmailMessage to data chunks.</p> <p>Parameters:</p> Name Type Description Default <code>email</code> <code>EmailMessage</code> <p>EmailMessage object to convert</p> required <code>start_sequence_idx</code> <code>int</code> <p>Starting sequence index for this email</p> required <p>Returns:</p> Type Description <code>List[DataChunk]</code> <p>List of DataChunks for this email</p> Source code in <code>ragora/ragora/core/email_preprocessor.py</code> <pre><code>def _email_to_chunks(\n    self, email: EmailMessage, start_sequence_idx: int\n) -&gt; List[DataChunk]:\n    \"\"\"Convert an EmailMessage to data chunks.\n\n    Args:\n        email: EmailMessage object to convert\n        start_sequence_idx: Starting sequence index for this email\n\n    Returns:\n        List of DataChunks for this email\n    \"\"\"\n    # Clean and extract text content from email\n    email_text = self.clean_email_body(email)\n\n    # Create context with email metadata\n    context = (\n        ChunkingContextBuilder()\n        .for_email()\n        .with_email_info(\n            subject=email.subject or \"\",\n            sender=str(email.sender) if email.sender else \"\",\n            recipient=(\n                \", \".join([str(addr) for addr in email.recipients])\n                if email.recipients\n                else \"\"\n            ),\n            email_id=email.message_id or \"\",\n            email_date=(email.date_sent.isoformat() if email.date_sent else \"\"),\n        )\n        .with_start_sequence_idx(start_sequence_idx)\n        .build()\n    )\n\n    return self.chunker.chunk(email_text, context)\n</code></pre>"},{"location":"api-reference/#ragora.core.email_preprocessor.EmailPreprocessor._html_to_text","title":"<code>_html_to_text(html_content)</code>","text":"<p>Convert HTML content to plain text.</p> <p>Tries multiple approaches in order: html2text, BeautifulSoup4, regex.</p> <p>Parameters:</p> Name Type Description Default <code>html_content</code> <code>str</code> <p>HTML string to convert</p> required <p>Returns:</p> Type Description <code>str</code> <p>Plain text representation of the HTML</p> Source code in <code>ragora/ragora/core/email_preprocessor.py</code> <pre><code>def _html_to_text(self, html_content: str) -&gt; str:\n    \"\"\"Convert HTML content to plain text.\n\n    Tries multiple approaches in order: html2text, BeautifulSoup4, regex.\n\n    Args:\n        html_content: HTML string to convert\n\n    Returns:\n        Plain text representation of the HTML\n    \"\"\"\n    if not html_content or not html_content.strip():\n        return \"\"\n\n    # Try html2text first (better for email HTML)\n    if html2text is not None:\n        try:\n            return self._html_to_text_html2text(html_content)\n        except Exception:\n            # Fall through to BeautifulSoup if html2text fails\n            pass\n\n    # Fallback to BeautifulSoup4\n    if BeautifulSoup is not None:\n        try:\n            return self._html_to_text_beautifulsoup(html_content)\n        except Exception:\n            pass\n\n    # Last resort: basic regex cleanup\n    return self._html_to_text_regex(html_content)\n</code></pre>"},{"location":"api-reference/#ragora.core.email_preprocessor.EmailPreprocessor._html_to_text_beautifulsoup","title":"<code>_html_to_text_beautifulsoup(html_content)</code>","text":"<p>Convert HTML content to plain text using BeautifulSoup4.</p> <p>Parameters:</p> Name Type Description Default <code>html_content</code> <code>str</code> <p>HTML string to convert</p> required <p>Returns:</p> Type Description <code>str</code> <p>Plain text representation of the HTML</p> <p>Raises:</p> Type Description <code>ImportError</code> <p>If BeautifulSoup4 library is not available</p> <code>Exception</code> <p>If conversion fails</p> Source code in <code>ragora/ragora/core/email_preprocessor.py</code> <pre><code>def _html_to_text_beautifulsoup(self, html_content: str) -&gt; str:\n    \"\"\"Convert HTML content to plain text using BeautifulSoup4.\n\n    Args:\n        html_content: HTML string to convert\n\n    Returns:\n        Plain text representation of the HTML\n\n    Raises:\n        ImportError: If BeautifulSoup4 library is not available\n        Exception: If conversion fails\n    \"\"\"\n    if BeautifulSoup is None:\n        raise ImportError(\"BeautifulSoup4 library is not available\")\n\n    soup = BeautifulSoup(html_content, \"html.parser\")\n    # Remove script and style elements\n    for script in soup([\"script\", \"style\"]):\n        script.decompose()\n    text = soup.get_text()\n    # Clean up whitespace\n    lines = (line.strip() for line in text.splitlines())\n    chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n    text = \"\\n\".join(chunk for chunk in chunks if chunk)\n    return text.strip()\n</code></pre>"},{"location":"api-reference/#ragora.core.email_preprocessor.EmailPreprocessor._html_to_text_html2text","title":"<code>_html_to_text_html2text(html_content)</code>","text":"<p>Convert HTML content to plain text using html2text library.</p> <p>Parameters:</p> Name Type Description Default <code>html_content</code> <code>str</code> <p>HTML string to convert</p> required <p>Returns:</p> Type Description <code>str</code> <p>Plain text representation of the HTML</p> <p>Raises:</p> Type Description <code>ImportError</code> <p>If html2text library is not available</p> <code>Exception</code> <p>If conversion fails</p> Source code in <code>ragora/ragora/core/email_preprocessor.py</code> <pre><code>def _html_to_text_html2text(self, html_content: str) -&gt; str:\n    \"\"\"Convert HTML content to plain text using html2text library.\n\n    Args:\n        html_content: HTML string to convert\n\n    Returns:\n        Plain text representation of the HTML\n\n    Raises:\n        ImportError: If html2text library is not available\n        Exception: If conversion fails\n    \"\"\"\n    if html2text is None:\n        raise ImportError(\"html2text library is not available\")\n\n    h = html2text.HTML2Text()\n    h.ignore_links = True\n    h.ignore_images = True\n    h.body_width = 0  # Don't wrap lines\n    h.unicode_snob = True  # Use unicode\n    text = h.handle(html_content)\n    return text.strip()\n</code></pre>"},{"location":"api-reference/#ragora.core.email_preprocessor.EmailPreprocessor._html_to_text_regex","title":"<code>_html_to_text_regex(html_content)</code>","text":"<p>Convert HTML content to plain text using basic regex cleanup.</p> <p>This is a last-resort fallback method that uses regex to remove HTML tags and decode common HTML entities.</p> <p>Parameters:</p> Name Type Description Default <code>html_content</code> <code>str</code> <p>HTML string to convert</p> required <p>Returns:</p> Type Description <code>str</code> <p>Plain text representation of the HTML</p> Source code in <code>ragora/ragora/core/email_preprocessor.py</code> <pre><code>def _html_to_text_regex(self, html_content: str) -&gt; str:\n    \"\"\"Convert HTML content to plain text using basic regex cleanup.\n\n    This is a last-resort fallback method that uses regex to remove\n    HTML tags and decode common HTML entities.\n\n    Args:\n        html_content: HTML string to convert\n\n    Returns:\n        Plain text representation of the HTML\n    \"\"\"\n    # Remove HTML tags\n    text = re.sub(r\"&lt;[^&gt;]+&gt;\", \"\", html_content)\n    # Decode common HTML entities\n    text = text.replace(\"&amp;nbsp;\", \" \")\n    text = text.replace(\"&amp;amp;\", \"&amp;\")\n    text = text.replace(\"&amp;lt;\", \"&lt;\")\n    text = text.replace(\"&amp;gt;\", \"&gt;\")\n    text = text.replace(\"&amp;quot;\", '\"')\n    text = text.replace(\"&amp;#39;\", \"'\")\n    return text.strip()\n</code></pre>"},{"location":"api-reference/#ragora.core.email_preprocessor.EmailPreprocessor._normalize_whitespace","title":"<code>_normalize_whitespace(text)</code>","text":"<p>Normalize whitespace in text.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Text to normalize</p> required <p>Returns:</p> Type Description <code>str</code> <p>Text with normalized whitespace</p> Source code in <code>ragora/ragora/core/email_preprocessor.py</code> <pre><code>def _normalize_whitespace(self, text: str) -&gt; str:\n    \"\"\"Normalize whitespace in text.\n\n    Args:\n        text: Text to normalize\n\n    Returns:\n        Text with normalized whitespace\n    \"\"\"\n    if not text:\n        return \"\"\n\n    # Replace multiple spaces with single space\n    text = re.sub(r\" +\", \" \", text)\n    # Replace multiple newlines with maximum of two\n    text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text)\n    # Remove trailing whitespace from each line\n    lines = [line.rstrip() for line in text.split(\"\\n\")]\n    return \"\\n\".join(lines).strip()\n</code></pre>"},{"location":"api-reference/#ragora.core.email_preprocessor.EmailPreprocessor._strip_quoted_replies","title":"<code>_strip_quoted_replies(text)</code>","text":"<p>Strip quoted reply sections from email text.</p> <p>Tries email_reply_parser library first, falls back to regex approach.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Email text that may contain quoted replies</p> required <p>Returns:</p> Type Description <code>str</code> <p>Text with quoted replies removed</p> Source code in <code>ragora/ragora/core/email_preprocessor.py</code> <pre><code>def _strip_quoted_replies(self, text: str) -&gt; str:\n    \"\"\"Strip quoted reply sections from email text.\n\n    Tries email_reply_parser library first, falls back to regex approach.\n\n    Args:\n        text: Email text that may contain quoted replies\n\n    Returns:\n        Text with quoted replies removed\n    \"\"\"\n    if not text or not text.strip():\n        return \"\"\n\n    if EmailReplyParser is not None:\n        try:\n            return self._strip_quoted_replies_library(text)\n        except Exception:\n            # Fall through to regex-based approach if library fails\n            pass\n\n    # Fallback regex-based approach for common reply patterns\n    return self._strip_quoted_replies_regex(text)\n</code></pre>"},{"location":"api-reference/#ragora.core.email_preprocessor.EmailPreprocessor._strip_quoted_replies_library","title":"<code>_strip_quoted_replies_library(text)</code>","text":"<p>Strip quoted reply sections using email_reply_parser library.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Email text that may contain quoted replies</p> required <p>Returns:</p> Type Description <code>str</code> <p>Text with quoted replies removed</p> <p>Raises:</p> Type Description <code>ImportError</code> <p>If email_reply_parser library is not available</p> <code>Exception</code> <p>If parsing fails</p> Source code in <code>ragora/ragora/core/email_preprocessor.py</code> <pre><code>def _strip_quoted_replies_library(self, text: str) -&gt; str:\n    \"\"\"Strip quoted reply sections using email_reply_parser library.\n\n    Args:\n        text: Email text that may contain quoted replies\n\n    Returns:\n        Text with quoted replies removed\n\n    Raises:\n        ImportError: If email_reply_parser library is not available\n        Exception: If parsing fails\n    \"\"\"\n    if EmailReplyParser is None:\n        raise ImportError(\"email_reply_parser library is not available\")\n\n    # Parse the email to get the actual reply\n    parsed = EmailReplyParser.read(text)\n    # Extract only the visible (non-quoted) text\n    # Use parsed.reply which contains the reply text without quotes\n    reply = parsed.reply\n    if reply:\n        return reply.strip()\n    return \"\"\n</code></pre>"},{"location":"api-reference/#ragora.core.email_preprocessor.EmailPreprocessor._strip_quoted_replies_regex","title":"<code>_strip_quoted_replies_regex(text)</code>","text":"<p>Strip quoted reply sections using regex-based approach.</p> <p>This is a fallback method that uses regex patterns to identify and remove common quoted reply formats.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Email text that may contain quoted replies</p> required <p>Returns:</p> Type Description <code>str</code> <p>Text with quoted replies removed</p> Source code in <code>ragora/ragora/core/email_preprocessor.py</code> <pre><code>def _strip_quoted_replies_regex(self, text: str) -&gt; str:\n    \"\"\"Strip quoted reply sections using regex-based approach.\n\n    This is a fallback method that uses regex patterns to identify\n    and remove common quoted reply formats.\n\n    Args:\n        text: Email text that may contain quoted replies\n\n    Returns:\n        Text with quoted replies removed\n    \"\"\"\n    lines = text.split(\"\\n\")\n    cleaned_lines = []\n    in_quoted_section = False\n    in_header_block = False\n\n    # Patterns that indicate start of quoted section\n    quote_start_patterns = [\n        r\"^On .+ wrote:\",\n        r\"^From:\",\n        r\"^-----Original Message-----\",\n        r\"^&gt;+\",\n        r\"^--- .+ ---\",\n        r\"^_{5,}\",\n        r\"^={5,}\",\n    ]\n\n    # Patterns for email headers (usually follow \"From:\" in quotes)\n    email_header_pattern = r\"^[A-Z][a-zA-Z-]+:\"\n\n    for line in lines:\n        # Check if this line starts a quoted section\n        is_quote_start = any(\n            re.match(pattern, line, re.IGNORECASE)\n            for pattern in quote_start_patterns\n        )\n\n        if is_quote_start:\n            in_quoted_section = True\n            in_header_block = True\n            continue\n\n        # If we hit a blank line after being in quoted section,\n        # we might be transitioning, but continue checking\n        if in_quoted_section:\n            # Check if line is an email header (part of quote metadata)\n            is_email_header = bool(re.match(email_header_pattern, line))\n            if is_email_header:\n                in_header_block = True\n                continue\n\n            # After email headers, if we see a blank line,\n            # mark that we're past the header block\n            if line.strip() == \"\":\n                if in_header_block:\n                    in_header_block = False\n                continue\n\n            # After headers, everything until we see clear break\n            # is quoted content\n            if not in_header_block:\n                # This is content after headers - should be quoted\n                continue\n\n            # If we get here, might be actual content again\n            # Exit quoted section if we have content before\n            if len(cleaned_lines) &gt; 0:\n                in_quoted_section = False\n                in_header_block = False\n                cleaned_lines.append(line)\n            else:\n                # No content yet, might still be in quote\n                in_header_block = False\n            continue\n\n        in_header_block = False\n        cleaned_lines.append(line)\n\n    return \"\\n\".join(cleaned_lines).strip()\n</code></pre>"},{"location":"api-reference/#ragora.core.email_preprocessor.EmailPreprocessor._strip_signatures","title":"<code>_strip_signatures(text)</code>","text":"<p>Strip email signatures from text.</p> <p>Uses regex patterns to identify and remove common signature formats.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Email text that may contain signatures</p> required <p>Returns:</p> Type Description <code>str</code> <p>Text with signatures removed</p> Source code in <code>ragora/ragora/core/email_preprocessor.py</code> <pre><code>def _strip_signatures(self, text: str) -&gt; str:\n    \"\"\"Strip email signatures from text.\n\n    Uses regex patterns to identify and remove common signature formats.\n\n    Args:\n        text: Email text that may contain signatures\n\n    Returns:\n        Text with signatures removed\n    \"\"\"\n    if not text or not text.strip():\n        return \"\"\n\n    lines = text.split(\"\\n\")\n    cleaned_lines = []\n    signature_started = False\n    consecutive_blank_lines = 0\n\n    for i, line in enumerate(lines):\n        # Check if this line starts a signature\n        is_signature_start = any(\n            pattern.match(line) for pattern in self._SIGNATURE_INDICATOR_PATTERNS\n        )\n\n        if is_signature_start:\n            signature_started = True\n            consecutive_blank_lines = 0\n            # Don't include this line\n            continue\n\n        if signature_started:\n            # Track consecutive blank lines - multiple blank lines might\n            # indicate end of signature, but we need to be careful\n            if line.strip() == \"\":\n                consecutive_blank_lines += 1\n                # If we have 2+ consecutive blank lines, check if we're\n                # past signature\n                if consecutive_blank_lines &gt;= 2:\n                    # Look ahead to see if there's actual content\n                    next_non_blank_idx = i + 1\n                    while (\n                        next_non_blank_idx &lt; len(lines)\n                        and lines[next_non_blank_idx].strip() == \"\"\n                    ):\n                        next_non_blank_idx += 1\n\n                    if next_non_blank_idx &lt; len(lines):\n                        next_line = lines[next_non_blank_idx]\n                        # Check if next line looks like signature content\n                        is_signature_content = any(\n                            pattern.search(next_line)\n                            for pattern in self._SIGNATURE_CONTENT_PATTERNS\n                        ) or any(\n                            pattern.match(next_line)\n                            for pattern in self._SIGNATURE_INDICATOR_PATTERNS\n                        )\n\n                        if not is_signature_content:\n                            # We've hit multiple blank lines followed by\n                            # non-signature content. This likely means\n                            # we're past the signature\n                            signature_started = False\n                            consecutive_blank_lines = 0\n                            # Include the blank lines as they're part of\n                            # the break\n                            cleaned_lines.append(line)\n                            continue\n\n                # Still in signature, skip blank lines\n                continue\n            else:\n                # Reset blank line counter for non-blank lines\n                consecutive_blank_lines = 0\n\n                # Check if line looks like signature content\n                is_signature_content = any(\n                    pattern.search(line)\n                    for pattern in self._SIGNATURE_CONTENT_PATTERNS\n                )\n\n                if is_signature_content:\n                    # Definitely signature content, skip it\n                    continue\n\n                # Line doesn't match signature patterns, but we're after\n                # a signature delimiter. Continue skipping unless we see\n                # a clear break (handled by blank line logic above).\n                # This handles names, titles, and other signature\n                # elements that don't match patterns\n                continue\n        else:\n            consecutive_blank_lines = 0\n            cleaned_lines.append(line)\n\n    return \"\\n\".join(cleaned_lines).strip()\n</code></pre>"},{"location":"api-reference/#ragora.core.email_preprocessor.EmailPreprocessor.clean_email_body","title":"<code>clean_email_body(email)</code>","text":"<p>Clean email body by converting HTML, stripping replies, and removing signatures.</p> <p>This method orchestrates all cleaning steps: 1. Extract body (HTML preferred, fallback to text) 2. Convert HTML to text (if HTML exists) 3. Strip quoted replies 4. Strip signatures 5. Normalize whitespace</p> <p>This method can be used independently to get clean email text for processing with LLMs or other text analysis tools without chunking the content.</p> <p>Parameters:</p> Name Type Description Default <code>email</code> <code>Union[EmailMessage, EmailMessageModel]</code> <p>EmailMessage or EmailMessageModel object to clean (both have the same interface: get_body(), body_html, body_text)</p> required <p>Returns:</p> Type Description <code>str</code> <p>Cleaned plain text content. Returns empty string if email</p> <code>str</code> <p>has no body content.</p> Example <p>from ragora import EmailPreprocessor from ragora.utils.email_utils.models import EmailMessage from ragora.core.models import EmailMessageModel</p> <p>preprocessor = EmailPreprocessor()</p> Source code in <code>ragora/ragora/core/email_preprocessor.py</code> <pre><code>def clean_email_body(self, email: Union[EmailMessage, EmailMessageModel]) -&gt; str:\n    \"\"\"Clean email body by converting HTML, stripping replies,\n    and removing signatures.\n\n    This method orchestrates all cleaning steps:\n    1. Extract body (HTML preferred, fallback to text)\n    2. Convert HTML to text (if HTML exists)\n    3. Strip quoted replies\n    4. Strip signatures\n    5. Normalize whitespace\n\n    This method can be used independently to get clean email text\n    for processing with LLMs or other text analysis tools without\n    chunking the content.\n\n    Args:\n        email: EmailMessage or EmailMessageModel object to clean (both have\n            the same interface: get_body(), body_html, body_text)\n\n    Returns:\n        Cleaned plain text content. Returns empty string if email\n        has no body content.\n\n    Example:\n        &gt;&gt;&gt; from ragora import EmailPreprocessor\n        &gt;&gt;&gt; from ragora.utils.email_utils.models import EmailMessage\n        &gt;&gt;&gt; from ragora.core.models import EmailMessageModel\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; preprocessor = EmailPreprocessor()\n        &gt;&gt;&gt; # Works with EmailMessage\n        &gt;&gt;&gt; clean_text = preprocessor.clean_email_body(email_message)\n        &gt;&gt;&gt; # Also works with EmailMessageModel\n        &gt;&gt;&gt; clean_text = preprocessor.clean_email_body(email_item)\n        &gt;&gt;&gt; # Use clean_text with LLM or other processing\n    \"\"\"\n    # Step 1: Extract body (HTML preferred, fallback to text)\n    body = email.get_body()\n    if not body or not body.strip():\n        return \"\"\n\n    # Step 2: Convert HTML to text if it's HTML\n    # Check if body is HTML by looking at email.body_html\n    # or by checking if body contains HTML tags\n    is_html = email.body_html is not None and email.body_html.strip()\n    if not is_html:\n        # Also check if body_text itself contains HTML tags\n        is_html = bool(re.search(r\"&lt;[^&gt;]+&gt;\", body))\n\n    if is_html:\n        text = self._html_to_text(body)\n    else:\n        text = body\n\n    # Step 3: Strip quoted replies\n    text = self._strip_quoted_replies(text)\n\n    # Step 4: Strip signatures\n    text = self._strip_signatures(text)\n\n    # Step 5: Normalize whitespace\n    text = self._normalize_whitespace(text)\n\n    return text\n</code></pre>"},{"location":"api-reference/#ragora.core.email_preprocessor.EmailPreprocessor.clean_email_body--works-with-emailmessage","title":"Works with EmailMessage","text":"<p>clean_text = preprocessor.clean_email_body(email_message)</p>"},{"location":"api-reference/#ragora.core.email_preprocessor.EmailPreprocessor.clean_email_body--also-works-with-emailmessagemodel","title":"Also works with EmailMessageModel","text":"<p>clean_text = preprocessor.clean_email_body(email_item)</p>"},{"location":"api-reference/#ragora.core.email_preprocessor.EmailPreprocessor.clean_email_body--use-clean_text-with-llm-or-other-processing","title":"Use clean_text with LLM or other processing","text":""},{"location":"api-reference/#ragora.core.email_preprocessor.EmailPreprocessor.preprocess_email","title":"<code>preprocess_email(email, start_sequence_idx=0)</code>","text":"<p>Preprocess a single email into data chunks.</p> <p>This method converts a single EmailMessage object into DataChunks for storage in the vector database.</p> <p>Parameters:</p> Name Type Description Default <code>email</code> <code>EmailMessage</code> <p>EmailMessage object to preprocess</p> required <code>start_sequence_idx</code> <code>int</code> <p>Starting sequence index for this email</p> <code>0</code> <p>Returns:</p> Type Description <code>List[DataChunk]</code> <p>List of DataChunks containing the email message</p> Source code in <code>ragora/ragora/core/email_preprocessor.py</code> <pre><code>def preprocess_email(\n    self, email: EmailMessage, start_sequence_idx: int = 0\n) -&gt; List[DataChunk]:\n    \"\"\"Preprocess a single email into data chunks.\n\n    This method converts a single EmailMessage object into DataChunks\n    for storage in the vector database.\n\n    Args:\n        email: EmailMessage object to preprocess\n        start_sequence_idx: Starting sequence index for this email\n\n    Returns:\n        List of DataChunks containing the email message\n    \"\"\"\n    return self._email_to_chunks(email, start_sequence_idx)\n</code></pre>"},{"location":"api-reference/#ragora.core.email_preprocessor.EmailPreprocessor.preprocess_emails","title":"<code>preprocess_emails(emails, start_sequence_idx=0)</code>","text":"<p>Preprocess multiple emails into data chunks.</p> <p>This method converts a list of EmailMessage objects into DataChunks for storage in the vector database.</p> <p>Parameters:</p> Name Type Description Default <code>emails</code> <code>List[EmailMessage]</code> <p>List of EmailMessage objects to preprocess</p> required <code>start_sequence_idx</code> <code>int</code> <p>Starting sequence index for the emails</p> <code>0</code> <p>Returns:</p> Type Description <code>List[DataChunk]</code> <p>List of DataChunks containing the email messages</p> Source code in <code>ragora/ragora/core/email_preprocessor.py</code> <pre><code>def preprocess_emails(\n    self, emails: List[EmailMessage], start_sequence_idx: int = 0\n) -&gt; List[DataChunk]:\n    \"\"\"Preprocess multiple emails into data chunks.\n\n    This method converts a list of EmailMessage objects into DataChunks\n    for storage in the vector database.\n\n    Args:\n        emails: List of EmailMessage objects to preprocess\n        start_sequence_idx: Starting sequence index for the emails\n\n    Returns:\n        List of DataChunks containing the email messages\n    \"\"\"\n    all_chunks = []\n    chunk_idx_counter = start_sequence_idx\n\n    for email in emails:\n        chunks = self._email_to_chunks(email, chunk_idx_counter)\n        all_chunks.extend(chunks)\n        chunk_idx_counter += len(chunks)\n\n    return all_chunks\n</code></pre>"},{"location":"api-reference/#embedding-engine","title":"Embedding Engine","text":"<p>Client-side embedding helpers built on top of Sentence Transformers.</p>"},{"location":"api-reference/#ragora.core.embedding_engine.EmbeddingEngine","title":"<code>EmbeddingEngine</code>","text":"<p>Convert raw text into dense vector embeddings.</p> <p>Attributes:</p> Name Type Description <code>model</code> <p>Loaded <code>SentenceTransformer</code> instance.</p> <code>model_name</code> <p>Name used to initialize the model.</p> <code>embedding_dimension</code> <p>Dimensionality of the produced vectors.</p> <code>logger</code> <p>Module logger.</p> <p>Examples:</p> <pre><code>from ragora.core.embedding_engine import EmbeddingEngine\n\nengine = EmbeddingEngine(model_name=\"all-mpnet-base-v2\")\nvector = engine.embed_text(\"Ragora makes RAG pipelines easier.\")\n</code></pre> Source code in <code>ragora/ragora/core/embedding_engine.py</code> <pre><code>class EmbeddingEngine:\n    \"\"\"Convert raw text into dense vector embeddings.\n\n    Attributes:\n        model: Loaded `SentenceTransformer` instance.\n        model_name: Name used to initialize the model.\n        embedding_dimension: Dimensionality of the produced vectors.\n        logger: Module logger.\n\n    Examples:\n        ```python\n        from ragora.core.embedding_engine import EmbeddingEngine\n\n        engine = EmbeddingEngine(model_name=\"all-mpnet-base-v2\")\n        vector = engine.embed_text(\"Ragora makes RAG pipelines easier.\")\n        ```\n    \"\"\"\n\n    # Supported models with their specifications\n    SUPPORTED_MODELS = {\n        \"all-mpnet-base-v2\": {\n            \"dimension\": 768,\n            \"description\": \"High-quality embeddings for technical content\",\n            \"pooling_strategy\": \"masked_mean\",\n        },\n        \"multi-qa-MiniLM-L6-v2\": {\n            \"dimension\": 384,\n            \"description\": \"Optimized for Q&amp;A tasks, faster inference\",\n            \"pooling_strategy\": \"mean\",\n        },\n    }\n\n    def __init__(\n        self,\n        model_name: str = \"all-mpnet-base-v2\",\n        device: Optional[str] = None,\n        cache_folder: Optional[str] = None,\n    ):\n        \"\"\"Initialize the EmbeddingEngine.\n\n        Args:\n            model_name: Name of the Sentence Transformer model to use\n            device: Device to run the model on ('cpu', 'cuda', 'mps', or None\n                for auto). If None, will automatically select the optimal device\n                for the current platform.\n            cache_folder: Folder to cache the model files\n\n        Raises:\n            ValueError: If model_name is not supported\n            ImportError: If sentence-transformers is not installed\n        \"\"\"\n        if model_name not in self.SUPPORTED_MODELS:\n            raise ValueError(\n                f\"Model '{model_name}' not supported. \"\n                f\"Supported models: {list(self.SUPPORTED_MODELS.keys())}\"\n            )\n\n        self.model_name = model_name\n        self.embedding_dimension = self.SUPPORTED_MODELS[model_name][\"dimension\"]\n\n        # Set up logging\n        self.logger = logging.getLogger(__name__)\n\n        # Auto-select device if not provided\n        if device is None:\n            device = get_sentence_transformer_device()\n            self.logger.info(f\"Auto-selected device: {device}\")\n\n        try:\n            # Initialize the Sentence Transformer model\n            self.logger.info(\n                f\"Loading Sentence Transformer model: {model_name} on device: {device}\"\n            )\n            self.model = SentenceTransformer(\n                model_name, device=device, cache_folder=cache_folder\n            )\n            self.logger.info(\n                f\"Successfully loaded model: {model_name} on device: {device}\"\n            )\n\n        except Exception as e:\n            self.logger.error(f\"Failed to load model {model_name}: {str(e)}\")\n            raise ImportError(f\"Could not load Sentence Transformer model: {str(e)}\")\n\n    def embed_text(self, text: str) -&gt; np.ndarray:\n        \"\"\"Generate embedding for a single text string.\n\n        Args:\n            text: Text to embed\n\n        Returns:\n            np.ndarray: Vector embedding of the text\n\n        Raises:\n            ValueError: If text is empty or None\n        \"\"\"\n        if not text or not text.strip():\n            raise ValueError(\"Text cannot be empty or None\")\n\n        try:\n            embedding = self.model.encode(text, convert_to_numpy=True)\n            return embedding\n        except Exception as e:\n            self.logger.error(f\"Failed to generate embedding for text: {str(e)}\")\n            raise\n\n    def embed_chunk(self, chunk: DataChunk) -&gt; np.ndarray:\n        \"\"\"Generate embedding for a DataChunk object.\n\n        Args:\n            chunk: DataChunk object containing text and metadata\n\n        Returns:\n            np.ndarray: Vector embedding of the chunk text\n\n        Raises:\n            ValueError: If chunk is None or has empty text\n        \"\"\"\n        if chunk is None:\n            raise ValueError(\"Chunk cannot be None\")\n\n        return self.embed_text(chunk.text)\n\n    def embed_chunks(self, chunks: List[DataChunk]) -&gt; List[np.ndarray]:\n        \"\"\"Generate embeddings for multiple DataChunk objects.\n\n        Args:\n            chunks: List of DataChunk objects\n\n        Returns:\n            List[np.ndarray]: List of vector embeddings\n\n        Raises:\n            ValueError: If chunks list is empty or contains invalid chunks\n        \"\"\"\n        if not chunks:\n            raise ValueError(\"Chunks list cannot be empty\")\n\n        # Extract text from chunks\n        texts = []\n        for i, chunk in enumerate(chunks):\n            if chunk is None or not chunk.text or not chunk.text.strip():\n                self.logger.warning(f\"Skipping invalid chunk at index {i}\")\n                continue\n            texts.append(chunk.text)\n\n        if not texts:\n            raise ValueError(\"No valid text found in chunks\")\n\n        try:\n            self.logger.info(f\"Generating embeddings for {len(texts)} chunks\")\n            embeddings = self.model.encode(\n                texts, convert_to_numpy=True, show_progress_bar=True\n            )\n\n            # Convert to list of numpy arrays\n            embedding_list = [embeddings[i] for i in range(len(embeddings))]\n\n            self.logger.info(f\"Successfully generated {len(embedding_list)} embeddings\")\n            return embedding_list\n\n        except Exception as e:\n            self.logger.error(f\"Failed to generate embeddings for chunks: {str(e)}\")\n            raise\n\n    def embed_texts(self, texts: List[str]) -&gt; List[np.ndarray]:\n        \"\"\"Generate embeddings for a list of text strings.\n\n        Args:\n            texts: List of text strings to embed\n\n        Returns:\n            List[np.ndarray]: List of vector embeddings\n\n        Raises:\n            ValueError: If texts list is empty or contains invalid strings\n        \"\"\"\n        if not texts:\n            raise ValueError(\"Texts list cannot be empty\")\n\n        # Filter out empty texts\n        valid_texts = [text for text in texts if text and text.strip()]\n\n        if not valid_texts:\n            raise ValueError(\"No valid text found in texts list\")\n\n        try:\n            self.logger.info(f\"Generating embeddings for {len(valid_texts)} texts\")\n            embeddings = self.model.encode(\n                valid_texts, convert_to_numpy=True, show_progress_bar=True\n            )\n\n            # Convert to list of numpy arrays\n            embedding_list = [embeddings[i] for i in range(len(embeddings))]\n\n            self.logger.info(f\"Successfully generated {len(embedding_list)} embeddings\")\n            return embedding_list\n\n        except Exception as e:\n            self.logger.error(f\"Failed to generate embeddings for texts: {str(e)}\")\n            raise\n\n    def get_embedding_dimension(self) -&gt; int:\n        \"\"\"Get the dimension of embeddings produced by this engine.\n\n        Returns:\n            int: Dimension of the embeddings\n        \"\"\"\n        return self.embedding_dimension\n\n    def get_model_info(self) -&gt; dict:\n        \"\"\"Get information about the current model.\n\n        Returns:\n            dict: Model information including name, dimension, and\n                description\n        \"\"\"\n        return {\n            \"model_name\": self.model_name,\n            \"dimension\": self.embedding_dimension,\n            \"description\": self.SUPPORTED_MODELS[self.model_name][\"description\"],\n            \"pooling_strategy\": self.SUPPORTED_MODELS[self.model_name][\n                \"pooling_strategy\"\n            ],\n        }\n\n    def similarity(\n        self, embedding1: np.ndarray, embedding2: np.ndarray, method: str = \"cosine\"\n    ) -&gt; float:\n        \"\"\"Calculate similarity between two embeddings using specified method.\n\n        This function provides a unified interface for different similarity\n        measures, allowing you to choose the most appropriate method for your\n        use case.\n\n        Method Comparison:\n        - \"cosine\": Measures angular similarity (direction-based)\n          * Range: [-1, 1] where higher values = more similar\n          * Best for: Semantic similarity, normalized vectors\n          * Interpretation: 1.0=identical, 0.0=unrelated, -1.0=opposite\n\n        - \"euclidean\": Measures geometric distance (magnitude-based)\n          * Range: [0, \u221e) where lower values = more similar\n          * Best for: Absolute differences, magnitude-sensitive comparisons\n          * Interpretation: 0.0=identical, higher values=more different\n\n        Args:\n            embedding1: First embedding vector\n            embedding2: Second embedding vector\n            method: Similarity method to use (\"cosine\" or \"euclidean\")\n\n        Returns:\n            float: Similarity score\n            - For cosine: score between -1 and 1 (higher = more similar)\n            - For euclidean: distance between 0 and \u221e (lower = more similar)\n\n        Raises:\n            ValueError: If embeddings have different dimensions or invalid\n                method\n\n        Examples:\n            &gt;&gt;&gt; engine = EmbeddingEngine()\n            &gt;&gt;&gt; vec1 = np.array([1.0, 0.0, 0.0])\n            &gt;&gt;&gt; vec2 = np.array([0.0, 1.0, 0.0])\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Cosine similarity (default)\n            &gt;&gt;&gt; engine.similarity(vec1, vec2)  # Returns 0.0 (orthogonal)\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Euclidean distance\n            &gt;&gt;&gt; engine.similarity(vec1, vec2, method=\"euclidean\")\n            &gt;&gt;&gt; # Returns 1.414\n        \"\"\"\n        if embedding1.shape != embedding2.shape:\n            raise ValueError(\"Embeddings must have the same dimension\")\n\n        if method.lower() == \"cosine\":\n            return self._cosine_similarity(embedding1, embedding2)\n        elif method.lower() == \"euclidean\":\n            return self._euclidean_distance(embedding1, embedding2)\n        else:\n            raise ValueError(\n                f\"Invalid similarity method '{method}'. \"\n                \"Supported methods: 'cosine', 'euclidean'\"\n            )\n\n    def _cosine_similarity(\n        self, embedding1: np.ndarray, embedding2: np.ndarray\n    ) -&gt; float:\n        \"\"\"Calculate cosine similarity between two embeddings.\n\n        Cosine similarity measures the cosine of the angle between two vectors,\n        providing a measure of semantic similarity regardless of vector\n        magnitude.\n\n        Value Interpretation:\n        - +1.0: Identical vectors (0\u00b0 angle) - maximally similar\n        -  0.0: Orthogonal vectors (90\u00b0 angle) - completely unrelated\n        - -1.0: Opposite vectors (180\u00b0 angle) - maximally dissimilar/\n          contradictory\n\n        Examples:\n        - [1,0,0] vs [1,0,0] \u2192 1.0 (identical)\n        - [1,0,0] vs [0,1,0] \u2192 0.0 (orthogonal/unrelated)\n        - [1,0,0] vs [-1,0,0] \u2192 -1.0 (opposite/contradictory)\n\n        Args:\n            embedding1: First embedding vector\n            embedding2: Second embedding vector\n\n        Returns:\n            float: Cosine similarity score between -1 and 1\n                (higher values = more similar)\n        \"\"\"\n        # Calculate cosine similarity\n        dot_product = np.dot(embedding1, embedding2)\n        norm1 = np.linalg.norm(embedding1)\n        norm2 = np.linalg.norm(embedding2)\n\n        if norm1 == 0 or norm2 == 0:\n            return 0.0\n\n        similarity = dot_product / (norm1 * norm2)\n        return float(similarity)\n\n    def _euclidean_distance(\n        self, embedding1: np.ndarray, embedding2: np.ndarray\n    ) -&gt; float:\n        \"\"\"Calculate Euclidean distance between two embeddings.\n\n        Euclidean distance measures the straight-line distance between two\n        points in the embedding space, providing a measure of absolute\n        difference.\n\n        Value Interpretation:\n        - 0.0: Identical vectors - maximally similar\n        - &gt;0.0: Distance between vectors - lower values = more similar\n        - Higher values indicate greater dissimilarity\n\n        Examples:\n        - [1,0,0] vs [1,0,0] \u2192 0.0 (identical)\n        - [1,0,0] vs [0,1,0] \u2192 1.414 (orthogonal)\n        - [1,0,0] vs [-1,0,0] \u2192 2.0 (opposite)\n\n        Note: Unlike cosine similarity, euclidean distance is sensitive to\n        vector magnitude and measures absolute differences rather than\n        directional similarity.\n\n        Args:\n            embedding1: First embedding vector\n            embedding2: Second embedding vector\n\n        Returns:\n            float: Euclidean distance (lower values = more similar)\n        \"\"\"\n        distance = np.linalg.norm(embedding1 - embedding2)\n        return float(distance)\n</code></pre>"},{"location":"api-reference/#ragora.core.embedding_engine.EmbeddingEngine._cosine_similarity","title":"<code>_cosine_similarity(embedding1, embedding2)</code>","text":"<p>Calculate cosine similarity between two embeddings.</p> <p>Cosine similarity measures the cosine of the angle between two vectors, providing a measure of semantic similarity regardless of vector magnitude.</p> <p>Value Interpretation: - +1.0: Identical vectors (0\u00b0 angle) - maximally similar -  0.0: Orthogonal vectors (90\u00b0 angle) - completely unrelated - -1.0: Opposite vectors (180\u00b0 angle) - maximally dissimilar/   contradictory</p> <p>Examples: - [1,0,0] vs [1,0,0] \u2192 1.0 (identical) - [1,0,0] vs [0,1,0] \u2192 0.0 (orthogonal/unrelated) - [1,0,0] vs [-1,0,0] \u2192 -1.0 (opposite/contradictory)</p> <p>Parameters:</p> Name Type Description Default <code>embedding1</code> <code>ndarray</code> <p>First embedding vector</p> required <code>embedding2</code> <code>ndarray</code> <p>Second embedding vector</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>Cosine similarity score between -1 and 1 (higher values = more similar)</p> Source code in <code>ragora/ragora/core/embedding_engine.py</code> <pre><code>def _cosine_similarity(\n    self, embedding1: np.ndarray, embedding2: np.ndarray\n) -&gt; float:\n    \"\"\"Calculate cosine similarity between two embeddings.\n\n    Cosine similarity measures the cosine of the angle between two vectors,\n    providing a measure of semantic similarity regardless of vector\n    magnitude.\n\n    Value Interpretation:\n    - +1.0: Identical vectors (0\u00b0 angle) - maximally similar\n    -  0.0: Orthogonal vectors (90\u00b0 angle) - completely unrelated\n    - -1.0: Opposite vectors (180\u00b0 angle) - maximally dissimilar/\n      contradictory\n\n    Examples:\n    - [1,0,0] vs [1,0,0] \u2192 1.0 (identical)\n    - [1,0,0] vs [0,1,0] \u2192 0.0 (orthogonal/unrelated)\n    - [1,0,0] vs [-1,0,0] \u2192 -1.0 (opposite/contradictory)\n\n    Args:\n        embedding1: First embedding vector\n        embedding2: Second embedding vector\n\n    Returns:\n        float: Cosine similarity score between -1 and 1\n            (higher values = more similar)\n    \"\"\"\n    # Calculate cosine similarity\n    dot_product = np.dot(embedding1, embedding2)\n    norm1 = np.linalg.norm(embedding1)\n    norm2 = np.linalg.norm(embedding2)\n\n    if norm1 == 0 or norm2 == 0:\n        return 0.0\n\n    similarity = dot_product / (norm1 * norm2)\n    return float(similarity)\n</code></pre>"},{"location":"api-reference/#ragora.core.embedding_engine.EmbeddingEngine._euclidean_distance","title":"<code>_euclidean_distance(embedding1, embedding2)</code>","text":"<p>Calculate Euclidean distance between two embeddings.</p> <p>Euclidean distance measures the straight-line distance between two points in the embedding space, providing a measure of absolute difference.</p> <p>Value Interpretation: - 0.0: Identical vectors - maximally similar - &gt;0.0: Distance between vectors - lower values = more similar - Higher values indicate greater dissimilarity</p> <p>Examples: - [1,0,0] vs [1,0,0] \u2192 0.0 (identical) - [1,0,0] vs [0,1,0] \u2192 1.414 (orthogonal) - [1,0,0] vs [-1,0,0] \u2192 2.0 (opposite)</p> <p>Note: Unlike cosine similarity, euclidean distance is sensitive to vector magnitude and measures absolute differences rather than directional similarity.</p> <p>Parameters:</p> Name Type Description Default <code>embedding1</code> <code>ndarray</code> <p>First embedding vector</p> required <code>embedding2</code> <code>ndarray</code> <p>Second embedding vector</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>Euclidean distance (lower values = more similar)</p> Source code in <code>ragora/ragora/core/embedding_engine.py</code> <pre><code>def _euclidean_distance(\n    self, embedding1: np.ndarray, embedding2: np.ndarray\n) -&gt; float:\n    \"\"\"Calculate Euclidean distance between two embeddings.\n\n    Euclidean distance measures the straight-line distance between two\n    points in the embedding space, providing a measure of absolute\n    difference.\n\n    Value Interpretation:\n    - 0.0: Identical vectors - maximally similar\n    - &gt;0.0: Distance between vectors - lower values = more similar\n    - Higher values indicate greater dissimilarity\n\n    Examples:\n    - [1,0,0] vs [1,0,0] \u2192 0.0 (identical)\n    - [1,0,0] vs [0,1,0] \u2192 1.414 (orthogonal)\n    - [1,0,0] vs [-1,0,0] \u2192 2.0 (opposite)\n\n    Note: Unlike cosine similarity, euclidean distance is sensitive to\n    vector magnitude and measures absolute differences rather than\n    directional similarity.\n\n    Args:\n        embedding1: First embedding vector\n        embedding2: Second embedding vector\n\n    Returns:\n        float: Euclidean distance (lower values = more similar)\n    \"\"\"\n    distance = np.linalg.norm(embedding1 - embedding2)\n    return float(distance)\n</code></pre>"},{"location":"api-reference/#ragora.core.embedding_engine.EmbeddingEngine.embed_chunk","title":"<code>embed_chunk(chunk)</code>","text":"<p>Generate embedding for a DataChunk object.</p> <p>Parameters:</p> Name Type Description Default <code>chunk</code> <code>DataChunk</code> <p>DataChunk object containing text and metadata</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Vector embedding of the chunk text</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If chunk is None or has empty text</p> Source code in <code>ragora/ragora/core/embedding_engine.py</code> <pre><code>def embed_chunk(self, chunk: DataChunk) -&gt; np.ndarray:\n    \"\"\"Generate embedding for a DataChunk object.\n\n    Args:\n        chunk: DataChunk object containing text and metadata\n\n    Returns:\n        np.ndarray: Vector embedding of the chunk text\n\n    Raises:\n        ValueError: If chunk is None or has empty text\n    \"\"\"\n    if chunk is None:\n        raise ValueError(\"Chunk cannot be None\")\n\n    return self.embed_text(chunk.text)\n</code></pre>"},{"location":"api-reference/#ragora.core.embedding_engine.EmbeddingEngine.embed_chunks","title":"<code>embed_chunks(chunks)</code>","text":"<p>Generate embeddings for multiple DataChunk objects.</p> <p>Parameters:</p> Name Type Description Default <code>chunks</code> <code>List[DataChunk]</code> <p>List of DataChunk objects</p> required <p>Returns:</p> Type Description <code>List[ndarray]</code> <p>List[np.ndarray]: List of vector embeddings</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If chunks list is empty or contains invalid chunks</p> Source code in <code>ragora/ragora/core/embedding_engine.py</code> <pre><code>def embed_chunks(self, chunks: List[DataChunk]) -&gt; List[np.ndarray]:\n    \"\"\"Generate embeddings for multiple DataChunk objects.\n\n    Args:\n        chunks: List of DataChunk objects\n\n    Returns:\n        List[np.ndarray]: List of vector embeddings\n\n    Raises:\n        ValueError: If chunks list is empty or contains invalid chunks\n    \"\"\"\n    if not chunks:\n        raise ValueError(\"Chunks list cannot be empty\")\n\n    # Extract text from chunks\n    texts = []\n    for i, chunk in enumerate(chunks):\n        if chunk is None or not chunk.text or not chunk.text.strip():\n            self.logger.warning(f\"Skipping invalid chunk at index {i}\")\n            continue\n        texts.append(chunk.text)\n\n    if not texts:\n        raise ValueError(\"No valid text found in chunks\")\n\n    try:\n        self.logger.info(f\"Generating embeddings for {len(texts)} chunks\")\n        embeddings = self.model.encode(\n            texts, convert_to_numpy=True, show_progress_bar=True\n        )\n\n        # Convert to list of numpy arrays\n        embedding_list = [embeddings[i] for i in range(len(embeddings))]\n\n        self.logger.info(f\"Successfully generated {len(embedding_list)} embeddings\")\n        return embedding_list\n\n    except Exception as e:\n        self.logger.error(f\"Failed to generate embeddings for chunks: {str(e)}\")\n        raise\n</code></pre>"},{"location":"api-reference/#ragora.core.embedding_engine.EmbeddingEngine.embed_text","title":"<code>embed_text(text)</code>","text":"<p>Generate embedding for a single text string.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Text to embed</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Vector embedding of the text</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If text is empty or None</p> Source code in <code>ragora/ragora/core/embedding_engine.py</code> <pre><code>def embed_text(self, text: str) -&gt; np.ndarray:\n    \"\"\"Generate embedding for a single text string.\n\n    Args:\n        text: Text to embed\n\n    Returns:\n        np.ndarray: Vector embedding of the text\n\n    Raises:\n        ValueError: If text is empty or None\n    \"\"\"\n    if not text or not text.strip():\n        raise ValueError(\"Text cannot be empty or None\")\n\n    try:\n        embedding = self.model.encode(text, convert_to_numpy=True)\n        return embedding\n    except Exception as e:\n        self.logger.error(f\"Failed to generate embedding for text: {str(e)}\")\n        raise\n</code></pre>"},{"location":"api-reference/#ragora.core.embedding_engine.EmbeddingEngine.embed_texts","title":"<code>embed_texts(texts)</code>","text":"<p>Generate embeddings for a list of text strings.</p> <p>Parameters:</p> Name Type Description Default <code>texts</code> <code>List[str]</code> <p>List of text strings to embed</p> required <p>Returns:</p> Type Description <code>List[ndarray]</code> <p>List[np.ndarray]: List of vector embeddings</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If texts list is empty or contains invalid strings</p> Source code in <code>ragora/ragora/core/embedding_engine.py</code> <pre><code>def embed_texts(self, texts: List[str]) -&gt; List[np.ndarray]:\n    \"\"\"Generate embeddings for a list of text strings.\n\n    Args:\n        texts: List of text strings to embed\n\n    Returns:\n        List[np.ndarray]: List of vector embeddings\n\n    Raises:\n        ValueError: If texts list is empty or contains invalid strings\n    \"\"\"\n    if not texts:\n        raise ValueError(\"Texts list cannot be empty\")\n\n    # Filter out empty texts\n    valid_texts = [text for text in texts if text and text.strip()]\n\n    if not valid_texts:\n        raise ValueError(\"No valid text found in texts list\")\n\n    try:\n        self.logger.info(f\"Generating embeddings for {len(valid_texts)} texts\")\n        embeddings = self.model.encode(\n            valid_texts, convert_to_numpy=True, show_progress_bar=True\n        )\n\n        # Convert to list of numpy arrays\n        embedding_list = [embeddings[i] for i in range(len(embeddings))]\n\n        self.logger.info(f\"Successfully generated {len(embedding_list)} embeddings\")\n        return embedding_list\n\n    except Exception as e:\n        self.logger.error(f\"Failed to generate embeddings for texts: {str(e)}\")\n        raise\n</code></pre>"},{"location":"api-reference/#ragora.core.embedding_engine.EmbeddingEngine.get_embedding_dimension","title":"<code>get_embedding_dimension()</code>","text":"<p>Get the dimension of embeddings produced by this engine.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Dimension of the embeddings</p> Source code in <code>ragora/ragora/core/embedding_engine.py</code> <pre><code>def get_embedding_dimension(self) -&gt; int:\n    \"\"\"Get the dimension of embeddings produced by this engine.\n\n    Returns:\n        int: Dimension of the embeddings\n    \"\"\"\n    return self.embedding_dimension\n</code></pre>"},{"location":"api-reference/#ragora.core.embedding_engine.EmbeddingEngine.get_model_info","title":"<code>get_model_info()</code>","text":"<p>Get information about the current model.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Model information including name, dimension, and description</p> Source code in <code>ragora/ragora/core/embedding_engine.py</code> <pre><code>def get_model_info(self) -&gt; dict:\n    \"\"\"Get information about the current model.\n\n    Returns:\n        dict: Model information including name, dimension, and\n            description\n    \"\"\"\n    return {\n        \"model_name\": self.model_name,\n        \"dimension\": self.embedding_dimension,\n        \"description\": self.SUPPORTED_MODELS[self.model_name][\"description\"],\n        \"pooling_strategy\": self.SUPPORTED_MODELS[self.model_name][\n            \"pooling_strategy\"\n        ],\n    }\n</code></pre>"},{"location":"api-reference/#ragora.core.embedding_engine.EmbeddingEngine.similarity","title":"<code>similarity(embedding1, embedding2, method='cosine')</code>","text":"<p>Calculate similarity between two embeddings using specified method.</p> <p>This function provides a unified interface for different similarity measures, allowing you to choose the most appropriate method for your use case.</p> <p>Method Comparison: - \"cosine\": Measures angular similarity (direction-based)   * Range: [-1, 1] where higher values = more similar   * Best for: Semantic similarity, normalized vectors   * Interpretation: 1.0=identical, 0.0=unrelated, -1.0=opposite</p> <ul> <li>\"euclidean\": Measures geometric distance (magnitude-based)</li> <li>Range: [0, \u221e) where lower values = more similar</li> <li>Best for: Absolute differences, magnitude-sensitive comparisons</li> <li>Interpretation: 0.0=identical, higher values=more different</li> </ul> <p>Parameters:</p> Name Type Description Default <code>embedding1</code> <code>ndarray</code> <p>First embedding vector</p> required <code>embedding2</code> <code>ndarray</code> <p>Second embedding vector</p> required <code>method</code> <code>str</code> <p>Similarity method to use (\"cosine\" or \"euclidean\")</p> <code>'cosine'</code> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>Similarity score</p> <code>float</code> <ul> <li>For cosine: score between -1 and 1 (higher = more similar)</li> </ul> <code>float</code> <ul> <li>For euclidean: distance between 0 and \u221e (lower = more similar)</li> </ul> <p>Raises:</p> Type Description <code>ValueError</code> <p>If embeddings have different dimensions or invalid method</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; engine = EmbeddingEngine()\n&gt;&gt;&gt; vec1 = np.array([1.0, 0.0, 0.0])\n&gt;&gt;&gt; vec2 = np.array([0.0, 1.0, 0.0])\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Cosine similarity (default)\n&gt;&gt;&gt; engine.similarity(vec1, vec2)  # Returns 0.0 (orthogonal)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Euclidean distance\n&gt;&gt;&gt; engine.similarity(vec1, vec2, method=\"euclidean\")\n&gt;&gt;&gt; # Returns 1.414\n</code></pre> Source code in <code>ragora/ragora/core/embedding_engine.py</code> <pre><code>def similarity(\n    self, embedding1: np.ndarray, embedding2: np.ndarray, method: str = \"cosine\"\n) -&gt; float:\n    \"\"\"Calculate similarity between two embeddings using specified method.\n\n    This function provides a unified interface for different similarity\n    measures, allowing you to choose the most appropriate method for your\n    use case.\n\n    Method Comparison:\n    - \"cosine\": Measures angular similarity (direction-based)\n      * Range: [-1, 1] where higher values = more similar\n      * Best for: Semantic similarity, normalized vectors\n      * Interpretation: 1.0=identical, 0.0=unrelated, -1.0=opposite\n\n    - \"euclidean\": Measures geometric distance (magnitude-based)\n      * Range: [0, \u221e) where lower values = more similar\n      * Best for: Absolute differences, magnitude-sensitive comparisons\n      * Interpretation: 0.0=identical, higher values=more different\n\n    Args:\n        embedding1: First embedding vector\n        embedding2: Second embedding vector\n        method: Similarity method to use (\"cosine\" or \"euclidean\")\n\n    Returns:\n        float: Similarity score\n        - For cosine: score between -1 and 1 (higher = more similar)\n        - For euclidean: distance between 0 and \u221e (lower = more similar)\n\n    Raises:\n        ValueError: If embeddings have different dimensions or invalid\n            method\n\n    Examples:\n        &gt;&gt;&gt; engine = EmbeddingEngine()\n        &gt;&gt;&gt; vec1 = np.array([1.0, 0.0, 0.0])\n        &gt;&gt;&gt; vec2 = np.array([0.0, 1.0, 0.0])\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Cosine similarity (default)\n        &gt;&gt;&gt; engine.similarity(vec1, vec2)  # Returns 0.0 (orthogonal)\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Euclidean distance\n        &gt;&gt;&gt; engine.similarity(vec1, vec2, method=\"euclidean\")\n        &gt;&gt;&gt; # Returns 1.414\n    \"\"\"\n    if embedding1.shape != embedding2.shape:\n        raise ValueError(\"Embeddings must have the same dimension\")\n\n    if method.lower() == \"cosine\":\n        return self._cosine_similarity(embedding1, embedding2)\n    elif method.lower() == \"euclidean\":\n        return self._euclidean_distance(embedding1, embedding2)\n    else:\n        raise ValueError(\n            f\"Invalid similarity method '{method}'. \"\n            \"Supported methods: 'cosine', 'euclidean'\"\n        )\n</code></pre>"},{"location":"api-reference/#filters","title":"Filters","text":"<p>Filter utilities for Weaviate queries.</p> <p>This module provides helper functions and builders for constructing Weaviate Filter objects using domain model semantics, making it easier to filter search results without needing to know exact Weaviate property names.</p> <p>The FilterBuilder class maps domain model field names to Weaviate property names, providing a consistent interface aligned with RetrievalMetadata and DataChunk models.</p>"},{"location":"api-reference/#ragora.core.filters.FilterBuilder","title":"<code>FilterBuilder</code>","text":"<p>Helper for building Weaviate filters using domain model semantics.</p> <p>This class provides convenience methods for constructing Weaviate Filter objects using domain model field names, abstracting away the underlying Weaviate property names. This makes filtering more intuitive and reduces the chance of errors from using incorrect property names.</p> <p>Examples:</p> <pre><code>FilterBuilder.by_chunk_type(\"text\")\nFilterBuilder.by_date_range(start=\"2024-01-01\", end=\"2024-12-31\")\nFilterBuilder.combine_and(\n    FilterBuilder.by_chunk_type(\"text\"),\n    FilterBuilder.by_source_document(\"document.pdf\"),\n)\n</code></pre> Source code in <code>ragora/ragora/core/filters.py</code> <pre><code>class FilterBuilder:\n    \"\"\"Helper for building Weaviate filters using domain model semantics.\n\n    This class provides convenience methods for constructing Weaviate Filter\n    objects using domain model field names, abstracting away the underlying\n    Weaviate property names. This makes filtering more intuitive and reduces\n    the chance of errors from using incorrect property names.\n\n    Examples:\n        ```python\n        FilterBuilder.by_chunk_type(\"text\")\n        FilterBuilder.by_date_range(start=\"2024-01-01\", end=\"2024-12-31\")\n        FilterBuilder.combine_and(\n            FilterBuilder.by_chunk_type(\"text\"),\n            FilterBuilder.by_source_document(\"document.pdf\"),\n        )\n        ```\n    \"\"\"\n\n    @staticmethod\n    def by_chunk_type(value: str) -&gt; Filter:\n        \"\"\"Filter by chunk type (e.g., \"text\", \"equation\", \"citation\").\n\n        Args:\n            value: Chunk type value to filter by\n\n        Returns:\n            Filter: Weaviate Filter object for chunk type\n        \"\"\"\n        return Filter.by_property(\"chunk_type\").equal(value)\n\n    @staticmethod\n    def by_source_document(value: str) -&gt; Filter:\n        \"\"\"Filter by source document filename.\n\n        Args:\n            value: Source document filename to filter by\n\n        Returns:\n            Filter: Weaviate Filter object for source document\n        \"\"\"\n        return Filter.by_property(\"source_document\").equal(value)\n\n    @staticmethod\n    def by_email_sender(value: str) -&gt; Filter:\n        \"\"\"Filter by email sender address.\n\n        Args:\n            value: Email sender address to filter by\n\n        Returns:\n            Filter: Weaviate Filter object for email sender\n        \"\"\"\n        return Filter.by_property(\"email_sender\").equal(value)\n\n    @staticmethod\n    def by_email_subject(value: str) -&gt; Filter:\n        \"\"\"Filter by email subject line.\n\n        Args:\n            value: Email subject line to filter by (supports partial matches)\n\n        Returns:\n            Filter: Weaviate Filter object for email subject\n        \"\"\"\n        return Filter.by_property(\"email_subject\").equal(value)\n\n    @staticmethod\n    def by_email_folder(value: str) -&gt; Filter:\n        \"\"\"Filter by email folder/path.\n\n        Args:\n            value: Email folder path to filter by\n\n        Returns:\n            Filter: Weaviate Filter object for email folder\n        \"\"\"\n        return Filter.by_property(\"email_folder\").equal(value)\n\n    @staticmethod\n    def by_email_recipient(value: str) -&gt; Filter:\n        \"\"\"Filter by email recipient address.\n\n        Args:\n            value: Email recipient address to filter by\n\n        Returns:\n            Filter: Weaviate Filter object for email recipient\n        \"\"\"\n        return Filter.by_property(\"email_recipient\").equal(value)\n\n    @staticmethod\n    def by_date_range(\n        start: Optional[str] = None, end: Optional[str] = None\n    ) -&gt; Optional[Filter]:\n        \"\"\"Filter by date range using created_at timestamp.\n\n        Args:\n            start: Start date (ISO format string, e.g., \"2024-01-01\")\n            end: End date (ISO format string, e.g., \"2024-12-31\")\n\n        Returns:\n            Filter: Weaviate Filter object for date range, or None if both\n                start and end are None\n        \"\"\"\n        if start is None and end is None:\n            return None\n\n        filters = []\n        if start:\n            filters.append(Filter.by_property(\"created_at\").greater_or_equal(start))\n        if end:\n            filters.append(Filter.by_property(\"created_at\").less_or_equal(end))\n\n        if len(filters) == 1:\n            return filters[0]\n        return Filter.all_of(filters)\n\n    @staticmethod\n    def by_email_date_range(\n        start: Optional[str] = None, end: Optional[str] = None\n    ) -&gt; Optional[Filter]:\n        \"\"\"Filter by email date range using email_date timestamp.\n\n        Args:\n            start: Start date (ISO format string, e.g., \"2024-01-01\")\n            end: End date (ISO format string, e.g., \"2024-12-31\")\n\n        Returns:\n            Filter: Weaviate Filter object for email date range, or None if\n                both start and end are None\n        \"\"\"\n        if start is None and end is None:\n            return None\n\n        filters = []\n        if start:\n            filters.append(Filter.by_property(\"email_date\").greater_or_equal(start))\n        if end:\n            filters.append(Filter.by_property(\"email_date\").less_or_equal(end))\n\n        if len(filters) == 1:\n            return filters[0]\n        return Filter.all_of(filters)\n\n    @staticmethod\n    def by_page_number(value: int) -&gt; Filter:\n        \"\"\"Filter by page number in source document.\n\n        Args:\n            value: Page number to filter by\n\n        Returns:\n            Filter: Weaviate Filter object for page number\n        \"\"\"\n        return Filter.by_property(\"page_number\").equal(value)\n\n    @staticmethod\n    def by_section_title(value: str) -&gt; Filter:\n        \"\"\"Filter by section or chapter title.\n\n        Args:\n            value: Section title to filter by\n\n        Returns:\n            Filter: Weaviate Filter object for section title\n        \"\"\"\n        return Filter.by_property(\"section_title\").equal(value)\n\n    @staticmethod\n    def by_chunk_idx(value: int) -&gt; Filter:\n        \"\"\"Filter by chunk index.\n\n        Args:\n            value: Chunk index to filter by\n\n        Returns:\n            Filter: Weaviate Filter object for chunk index\n        \"\"\"\n        return Filter.by_property(\"metadata_chunk_idx\").equal(value)\n\n    @staticmethod\n    def combine_and(*filters: Filter) -&gt; Filter:\n        \"\"\"Combine multiple filters with AND logic.\n\n        All filters must match for a result to be included.\n\n        Args:\n            *filters: Variable number of Filter objects to combine\n\n        Returns:\n            Filter: Combined filter using AND logic\n\n        Raises:\n            ValueError: If no filters are provided\n        \"\"\"\n        if not filters:\n            raise ValueError(\"At least one filter must be provided\")\n        if len(filters) == 1:\n            return filters[0]\n        return Filter.all_of(list(filters))\n\n    @staticmethod\n    def combine_or(*filters: Filter) -&gt; Filter:\n        \"\"\"Combine multiple filters with OR logic.\n\n        Any filter matching will include the result.\n\n        Args:\n            *filters: Variable number of Filter objects to combine\n\n        Returns:\n            Filter: Combined filter using OR logic\n\n        Raises:\n            ValueError: If no filters are provided\n        \"\"\"\n        if not filters:\n            raise ValueError(\"At least one filter must be provided\")\n        if len(filters) == 1:\n            return filters[0]\n        return Filter.any_of(list(filters))\n</code></pre>"},{"location":"api-reference/#ragora.core.filters.FilterBuilder.by_chunk_idx","title":"<code>by_chunk_idx(value)</code>  <code>staticmethod</code>","text":"<p>Filter by chunk index.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>int</code> <p>Chunk index to filter by</p> required <p>Returns:</p> Name Type Description <code>Filter</code> <code>Filter</code> <p>Weaviate Filter object for chunk index</p> Source code in <code>ragora/ragora/core/filters.py</code> <pre><code>@staticmethod\ndef by_chunk_idx(value: int) -&gt; Filter:\n    \"\"\"Filter by chunk index.\n\n    Args:\n        value: Chunk index to filter by\n\n    Returns:\n        Filter: Weaviate Filter object for chunk index\n    \"\"\"\n    return Filter.by_property(\"metadata_chunk_idx\").equal(value)\n</code></pre>"},{"location":"api-reference/#ragora.core.filters.FilterBuilder.by_chunk_type","title":"<code>by_chunk_type(value)</code>  <code>staticmethod</code>","text":"<p>Filter by chunk type (e.g., \"text\", \"equation\", \"citation\").</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>str</code> <p>Chunk type value to filter by</p> required <p>Returns:</p> Name Type Description <code>Filter</code> <code>Filter</code> <p>Weaviate Filter object for chunk type</p> Source code in <code>ragora/ragora/core/filters.py</code> <pre><code>@staticmethod\ndef by_chunk_type(value: str) -&gt; Filter:\n    \"\"\"Filter by chunk type (e.g., \"text\", \"equation\", \"citation\").\n\n    Args:\n        value: Chunk type value to filter by\n\n    Returns:\n        Filter: Weaviate Filter object for chunk type\n    \"\"\"\n    return Filter.by_property(\"chunk_type\").equal(value)\n</code></pre>"},{"location":"api-reference/#ragora.core.filters.FilterBuilder.by_date_range","title":"<code>by_date_range(start=None, end=None)</code>  <code>staticmethod</code>","text":"<p>Filter by date range using created_at timestamp.</p> <p>Parameters:</p> Name Type Description Default <code>start</code> <code>Optional[str]</code> <p>Start date (ISO format string, e.g., \"2024-01-01\")</p> <code>None</code> <code>end</code> <code>Optional[str]</code> <p>End date (ISO format string, e.g., \"2024-12-31\")</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Filter</code> <code>Optional[Filter]</code> <p>Weaviate Filter object for date range, or None if both start and end are None</p> Source code in <code>ragora/ragora/core/filters.py</code> <pre><code>@staticmethod\ndef by_date_range(\n    start: Optional[str] = None, end: Optional[str] = None\n) -&gt; Optional[Filter]:\n    \"\"\"Filter by date range using created_at timestamp.\n\n    Args:\n        start: Start date (ISO format string, e.g., \"2024-01-01\")\n        end: End date (ISO format string, e.g., \"2024-12-31\")\n\n    Returns:\n        Filter: Weaviate Filter object for date range, or None if both\n            start and end are None\n    \"\"\"\n    if start is None and end is None:\n        return None\n\n    filters = []\n    if start:\n        filters.append(Filter.by_property(\"created_at\").greater_or_equal(start))\n    if end:\n        filters.append(Filter.by_property(\"created_at\").less_or_equal(end))\n\n    if len(filters) == 1:\n        return filters[0]\n    return Filter.all_of(filters)\n</code></pre>"},{"location":"api-reference/#ragora.core.filters.FilterBuilder.by_email_date_range","title":"<code>by_email_date_range(start=None, end=None)</code>  <code>staticmethod</code>","text":"<p>Filter by email date range using email_date timestamp.</p> <p>Parameters:</p> Name Type Description Default <code>start</code> <code>Optional[str]</code> <p>Start date (ISO format string, e.g., \"2024-01-01\")</p> <code>None</code> <code>end</code> <code>Optional[str]</code> <p>End date (ISO format string, e.g., \"2024-12-31\")</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Filter</code> <code>Optional[Filter]</code> <p>Weaviate Filter object for email date range, or None if both start and end are None</p> Source code in <code>ragora/ragora/core/filters.py</code> <pre><code>@staticmethod\ndef by_email_date_range(\n    start: Optional[str] = None, end: Optional[str] = None\n) -&gt; Optional[Filter]:\n    \"\"\"Filter by email date range using email_date timestamp.\n\n    Args:\n        start: Start date (ISO format string, e.g., \"2024-01-01\")\n        end: End date (ISO format string, e.g., \"2024-12-31\")\n\n    Returns:\n        Filter: Weaviate Filter object for email date range, or None if\n            both start and end are None\n    \"\"\"\n    if start is None and end is None:\n        return None\n\n    filters = []\n    if start:\n        filters.append(Filter.by_property(\"email_date\").greater_or_equal(start))\n    if end:\n        filters.append(Filter.by_property(\"email_date\").less_or_equal(end))\n\n    if len(filters) == 1:\n        return filters[0]\n    return Filter.all_of(filters)\n</code></pre>"},{"location":"api-reference/#ragora.core.filters.FilterBuilder.by_email_folder","title":"<code>by_email_folder(value)</code>  <code>staticmethod</code>","text":"<p>Filter by email folder/path.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>str</code> <p>Email folder path to filter by</p> required <p>Returns:</p> Name Type Description <code>Filter</code> <code>Filter</code> <p>Weaviate Filter object for email folder</p> Source code in <code>ragora/ragora/core/filters.py</code> <pre><code>@staticmethod\ndef by_email_folder(value: str) -&gt; Filter:\n    \"\"\"Filter by email folder/path.\n\n    Args:\n        value: Email folder path to filter by\n\n    Returns:\n        Filter: Weaviate Filter object for email folder\n    \"\"\"\n    return Filter.by_property(\"email_folder\").equal(value)\n</code></pre>"},{"location":"api-reference/#ragora.core.filters.FilterBuilder.by_email_recipient","title":"<code>by_email_recipient(value)</code>  <code>staticmethod</code>","text":"<p>Filter by email recipient address.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>str</code> <p>Email recipient address to filter by</p> required <p>Returns:</p> Name Type Description <code>Filter</code> <code>Filter</code> <p>Weaviate Filter object for email recipient</p> Source code in <code>ragora/ragora/core/filters.py</code> <pre><code>@staticmethod\ndef by_email_recipient(value: str) -&gt; Filter:\n    \"\"\"Filter by email recipient address.\n\n    Args:\n        value: Email recipient address to filter by\n\n    Returns:\n        Filter: Weaviate Filter object for email recipient\n    \"\"\"\n    return Filter.by_property(\"email_recipient\").equal(value)\n</code></pre>"},{"location":"api-reference/#ragora.core.filters.FilterBuilder.by_email_sender","title":"<code>by_email_sender(value)</code>  <code>staticmethod</code>","text":"<p>Filter by email sender address.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>str</code> <p>Email sender address to filter by</p> required <p>Returns:</p> Name Type Description <code>Filter</code> <code>Filter</code> <p>Weaviate Filter object for email sender</p> Source code in <code>ragora/ragora/core/filters.py</code> <pre><code>@staticmethod\ndef by_email_sender(value: str) -&gt; Filter:\n    \"\"\"Filter by email sender address.\n\n    Args:\n        value: Email sender address to filter by\n\n    Returns:\n        Filter: Weaviate Filter object for email sender\n    \"\"\"\n    return Filter.by_property(\"email_sender\").equal(value)\n</code></pre>"},{"location":"api-reference/#ragora.core.filters.FilterBuilder.by_email_subject","title":"<code>by_email_subject(value)</code>  <code>staticmethod</code>","text":"<p>Filter by email subject line.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>str</code> <p>Email subject line to filter by (supports partial matches)</p> required <p>Returns:</p> Name Type Description <code>Filter</code> <code>Filter</code> <p>Weaviate Filter object for email subject</p> Source code in <code>ragora/ragora/core/filters.py</code> <pre><code>@staticmethod\ndef by_email_subject(value: str) -&gt; Filter:\n    \"\"\"Filter by email subject line.\n\n    Args:\n        value: Email subject line to filter by (supports partial matches)\n\n    Returns:\n        Filter: Weaviate Filter object for email subject\n    \"\"\"\n    return Filter.by_property(\"email_subject\").equal(value)\n</code></pre>"},{"location":"api-reference/#ragora.core.filters.FilterBuilder.by_page_number","title":"<code>by_page_number(value)</code>  <code>staticmethod</code>","text":"<p>Filter by page number in source document.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>int</code> <p>Page number to filter by</p> required <p>Returns:</p> Name Type Description <code>Filter</code> <code>Filter</code> <p>Weaviate Filter object for page number</p> Source code in <code>ragora/ragora/core/filters.py</code> <pre><code>@staticmethod\ndef by_page_number(value: int) -&gt; Filter:\n    \"\"\"Filter by page number in source document.\n\n    Args:\n        value: Page number to filter by\n\n    Returns:\n        Filter: Weaviate Filter object for page number\n    \"\"\"\n    return Filter.by_property(\"page_number\").equal(value)\n</code></pre>"},{"location":"api-reference/#ragora.core.filters.FilterBuilder.by_section_title","title":"<code>by_section_title(value)</code>  <code>staticmethod</code>","text":"<p>Filter by section or chapter title.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>str</code> <p>Section title to filter by</p> required <p>Returns:</p> Name Type Description <code>Filter</code> <code>Filter</code> <p>Weaviate Filter object for section title</p> Source code in <code>ragora/ragora/core/filters.py</code> <pre><code>@staticmethod\ndef by_section_title(value: str) -&gt; Filter:\n    \"\"\"Filter by section or chapter title.\n\n    Args:\n        value: Section title to filter by\n\n    Returns:\n        Filter: Weaviate Filter object for section title\n    \"\"\"\n    return Filter.by_property(\"section_title\").equal(value)\n</code></pre>"},{"location":"api-reference/#ragora.core.filters.FilterBuilder.by_source_document","title":"<code>by_source_document(value)</code>  <code>staticmethod</code>","text":"<p>Filter by source document filename.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>str</code> <p>Source document filename to filter by</p> required <p>Returns:</p> Name Type Description <code>Filter</code> <code>Filter</code> <p>Weaviate Filter object for source document</p> Source code in <code>ragora/ragora/core/filters.py</code> <pre><code>@staticmethod\ndef by_source_document(value: str) -&gt; Filter:\n    \"\"\"Filter by source document filename.\n\n    Args:\n        value: Source document filename to filter by\n\n    Returns:\n        Filter: Weaviate Filter object for source document\n    \"\"\"\n    return Filter.by_property(\"source_document\").equal(value)\n</code></pre>"},{"location":"api-reference/#ragora.core.filters.FilterBuilder.combine_and","title":"<code>combine_and(*filters)</code>  <code>staticmethod</code>","text":"<p>Combine multiple filters with AND logic.</p> <p>All filters must match for a result to be included.</p> <p>Parameters:</p> Name Type Description Default <code>*filters</code> <code>Filter</code> <p>Variable number of Filter objects to combine</p> <code>()</code> <p>Returns:</p> Name Type Description <code>Filter</code> <code>Filter</code> <p>Combined filter using AND logic</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If no filters are provided</p> Source code in <code>ragora/ragora/core/filters.py</code> <pre><code>@staticmethod\ndef combine_and(*filters: Filter) -&gt; Filter:\n    \"\"\"Combine multiple filters with AND logic.\n\n    All filters must match for a result to be included.\n\n    Args:\n        *filters: Variable number of Filter objects to combine\n\n    Returns:\n        Filter: Combined filter using AND logic\n\n    Raises:\n        ValueError: If no filters are provided\n    \"\"\"\n    if not filters:\n        raise ValueError(\"At least one filter must be provided\")\n    if len(filters) == 1:\n        return filters[0]\n    return Filter.all_of(list(filters))\n</code></pre>"},{"location":"api-reference/#ragora.core.filters.FilterBuilder.combine_or","title":"<code>combine_or(*filters)</code>  <code>staticmethod</code>","text":"<p>Combine multiple filters with OR logic.</p> <p>Any filter matching will include the result.</p> <p>Parameters:</p> Name Type Description Default <code>*filters</code> <code>Filter</code> <p>Variable number of Filter objects to combine</p> <code>()</code> <p>Returns:</p> Name Type Description <code>Filter</code> <code>Filter</code> <p>Combined filter using OR logic</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If no filters are provided</p> Source code in <code>ragora/ragora/core/filters.py</code> <pre><code>@staticmethod\ndef combine_or(*filters: Filter) -&gt; Filter:\n    \"\"\"Combine multiple filters with OR logic.\n\n    Any filter matching will include the result.\n\n    Args:\n        *filters: Variable number of Filter objects to combine\n\n    Returns:\n        Filter: Combined filter using OR logic\n\n    Raises:\n        ValueError: If no filters are provided\n    \"\"\"\n    if not filters:\n        raise ValueError(\"At least one filter must be provided\")\n    if len(filters) == 1:\n        return filters[0]\n    return Filter.any_of(list(filters))\n</code></pre>"},{"location":"api-reference/#exceptions","title":"Exceptions","text":"<p>Custom exceptions for the knowledge base manager system.</p>"},{"location":"api-reference/#ragora.exceptions.ConfigurationError","title":"<code>ConfigurationError</code>","text":"<p>               Bases: <code>KnowledgeBaseManagerError</code></p> <p>Raised when there's a configuration error.</p> Source code in <code>ragora/ragora/exceptions.py</code> <pre><code>class ConfigurationError(KnowledgeBaseManagerError):\n    \"\"\"Raised when there's a configuration error.\"\"\"\n\n    pass\n</code></pre>"},{"location":"api-reference/#ragora.exceptions.DocumentProcessingError","title":"<code>DocumentProcessingError</code>","text":"<p>               Bases: <code>KnowledgeBaseManagerError</code></p> <p>Raised when document processing fails.</p> Source code in <code>ragora/ragora/exceptions.py</code> <pre><code>class DocumentProcessingError(KnowledgeBaseManagerError):\n    \"\"\"Raised when document processing fails.\"\"\"\n\n    pass\n</code></pre>"},{"location":"api-reference/#ragora.exceptions.EmbeddingError","title":"<code>EmbeddingError</code>","text":"<p>               Bases: <code>KnowledgeBaseManagerError</code></p> <p>Raised when embedding operations fail.</p> Source code in <code>ragora/ragora/exceptions.py</code> <pre><code>class EmbeddingError(KnowledgeBaseManagerError):\n    \"\"\"Raised when embedding operations fail.\"\"\"\n\n    pass\n</code></pre>"},{"location":"api-reference/#ragora.exceptions.KnowledgeBaseManagerError","title":"<code>KnowledgeBaseManagerError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Base exception for knowledge base manager errors.</p> Source code in <code>ragora/ragora/exceptions.py</code> <pre><code>class KnowledgeBaseManagerError(Exception):\n    \"\"\"Base exception for knowledge base manager errors.\"\"\"\n\n    pass\n</code></pre>"},{"location":"api-reference/#ragora.exceptions.RetrievalError","title":"<code>RetrievalError</code>","text":"<p>               Bases: <code>KnowledgeBaseManagerError</code></p> <p>Raised when retrieval operations fail.</p> Source code in <code>ragora/ragora/exceptions.py</code> <pre><code>class RetrievalError(KnowledgeBaseManagerError):\n    \"\"\"Raised when retrieval operations fail.\"\"\"\n\n    pass\n</code></pre>"},{"location":"api-reference/#ragora.exceptions.VectorStoreError","title":"<code>VectorStoreError</code>","text":"<p>               Bases: <code>KnowledgeBaseManagerError</code></p> <p>Raised when vector store operations fail.</p> Source code in <code>ragora/ragora/exceptions.py</code> <pre><code>class VectorStoreError(KnowledgeBaseManagerError):\n    \"\"\"Raised when vector store operations fail.\"\"\"\n\n    pass\n</code></pre>"},{"location":"api-reference/#utilities","title":"Utilities","text":""},{"location":"api-reference/#device-utilities","title":"Device Utilities","text":"<p>Cross-platform device utilities for PyTorch applications.</p> <p>This module provides transparent device selection for PyTorch applications across different platforms, automatically handling: 1. macOS: Forces CPU-only usage 2. Windows/Linux without GPUs: Forces CPU-only usage 3. Windows/Linux with GPUs but without CUDA: Forces CPU-only usage 4. Windows/Linux with GPUs and CUDA: Uses GPU acceleration</p> <p>The module is designed to work seamlessly with pytest and other testing frameworks without requiring any special configuration or user intervention.</p>"},{"location":"api-reference/#ragora.utils.device_utils.DeviceManager","title":"<code>DeviceManager</code>","text":"<p>Manages PyTorch device selection across different platforms.</p> <p>This class automatically detects the platform and available hardware, then selects the appropriate PyTorch device for optimal performance while ensuring compatibility across all supported platforms.</p> Source code in <code>ragora/ragora/utils/device_utils.py</code> <pre><code>class DeviceManager:\n    \"\"\"Manages PyTorch device selection across different platforms.\n\n    This class automatically detects the platform and available hardware,\n    then selects the appropriate PyTorch device for optimal performance\n    while ensuring compatibility across all supported platforms.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"Initialize the device manager and detect platform capabilities.\"\"\"\n        self.platform_info = self._detect_platform()\n        self.gpu_info = self._detect_gpu_capabilities()\n        self.recommended_device = self._select_optimal_device()\n\n        logger.info(\n            f\"Platform: {self.platform_info['system']} {self.platform_info['version']}\"\n        )\n        logger.info(f\"GPU Available: {self.gpu_info['gpu_available']}\")\n        logger.info(f\"CUDA Available: {self.gpu_info['cuda_available']}\")\n        logger.info(f\"Recommended Device: {self.recommended_device}\")\n\n    def _detect_platform(self) -&gt; Dict[str, Any]:\n        \"\"\"Detect the current platform and system information.\n\n        Returns:\n            Dict containing platform information including system, version, and architecture.\n        \"\"\"\n        system = platform.system().lower()\n        version = platform.version()\n        architecture = platform.machine()\n\n        return {\n            \"system\": system,\n            \"version\": version,\n            \"architecture\": architecture,\n            \"is_macos\": system == \"darwin\",\n            \"is_windows\": system == \"windows\",\n            \"is_linux\": system == \"linux\",\n        }\n\n    def _detect_gpu_capabilities(self) -&gt; Dict[str, Any]:\n        \"\"\"Detect GPU and CUDA capabilities on the current system.\n\n        Returns:\n            Dict containing GPU availability and CUDA support information.\n        \"\"\"\n        gpu_available = False\n        cuda_available = False\n        gpu_count = 0\n        gpu_names = []\n\n        try:\n            # Try to import torch to check for GPU availability\n            import torch\n\n            gpu_available = torch.cuda.is_available()\n            if gpu_available:\n                gpu_count = torch.cuda.device_count()\n                gpu_names = [torch.cuda.get_device_name(i) for i in range(gpu_count)]\n                cuda_available = True\n        except ImportError:\n            logger.warning(\"PyTorch not available for GPU detection\")\n        except Exception as e:\n            logger.warning(f\"Error detecting GPU capabilities: {e}\")\n\n        # Additional CUDA detection using nvidia-smi if available\n        if not cuda_available and not self.platform_info[\"is_macos\"]:\n            cuda_available = self._check_cuda_via_nvidia_smi()\n\n        return {\n            \"gpu_available\": gpu_available,\n            \"cuda_available\": cuda_available,\n            \"gpu_count\": gpu_count,\n            \"gpu_names\": gpu_names,\n        }\n\n    def _check_cuda_via_nvidia_smi(self) -&gt; bool:\n        \"\"\"Check for CUDA availability using nvidia-smi command.\n\n        Returns:\n            bool: True if CUDA is available via nvidia-smi, False otherwise.\n        \"\"\"\n        try:\n            result = subprocess.run(\n                [\"nvidia-smi\"], capture_output=True, text=True, timeout=5\n            )\n            return result.returncode == 0\n        except (\n            subprocess.TimeoutExpired,\n            FileNotFoundError,\n            subprocess.SubprocessError,\n        ):\n            return False\n\n    def _select_optimal_device(self) -&gt; str:\n        \"\"\"Select the optimal PyTorch device based on platform and hardware.\n\n        Device selection logic:\n        1. macOS: Always use CPU (MPS support is experimental)\n        2. Windows/Linux without GPUs: Use CPU\n        3. Windows/Linux with GPUs but without CUDA: Use CPU\n        4. Windows/Linux with GPUs and CUDA: Use GPU (cuda:0)\n\n        Returns:\n            str: The recommended PyTorch device string.\n        \"\"\"\n        # Rule 1: macOS always uses CPU\n        if self.platform_info[\"is_macos\"]:\n            return \"cpu\"\n\n        # Rule 2: No GPU available, use CPU\n        if not self.gpu_info[\"gpu_available\"]:\n            return \"cpu\"\n\n        # Rule 3: GPU available but no CUDA, use CPU\n        if not self.gpu_info[\"cuda_available\"]:\n            return \"cpu\"\n\n        # Rule 4: GPU and CUDA available, use GPU\n        return \"cuda:0\"\n\n    def get_recommended_device(self) -&gt; str:\n        \"\"\"Get the recommended PyTorch device for the current platform.\n\n        Returns:\n            str: The recommended device string (e.g., 'cpu', 'cuda:0').\n        \"\"\"\n        return self.recommended_device\n\n    def get_device_info(self) -&gt; Dict[str, Any]:\n        \"\"\"Get comprehensive device information.\n\n        Returns:\n            Dict containing all device and platform information.\n        \"\"\"\n        return {\n            \"platform\": self.platform_info,\n            \"gpu\": self.gpu_info,\n            \"recommended_device\": self.recommended_device,\n        }\n\n    def configure_pytorch_device(\n        self, model=None, force_device: Optional[str] = None\n    ) -&gt; str:\n        \"\"\"Configure PyTorch device and optionally move a model to the device.\n\n        Args:\n            model: Optional PyTorch model to move to the recommended device.\n            force_device: Optional device string to force a specific device.\n\n        Returns:\n            str: The device string that was configured.\n        \"\"\"\n        device = force_device if force_device else self.recommended_device\n\n        if model is not None:\n            try:\n                import torch\n\n                model = model.to(device)\n                logger.info(f\"Model moved to device: {device}\")\n            except Exception as e:\n                logger.error(f\"Failed to move model to device {device}: {e}\")\n                # Fallback to CPU if device move fails\n                if device != \"cpu\":\n                    device = \"cpu\"\n                    model = model.to(device)\n                    logger.info(\"Fallback: Model moved to CPU\")\n\n        return device\n</code></pre>"},{"location":"api-reference/#ragora.utils.device_utils.DeviceManager._check_cuda_via_nvidia_smi","title":"<code>_check_cuda_via_nvidia_smi()</code>","text":"<p>Check for CUDA availability using nvidia-smi command.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if CUDA is available via nvidia-smi, False otherwise.</p> Source code in <code>ragora/ragora/utils/device_utils.py</code> <pre><code>def _check_cuda_via_nvidia_smi(self) -&gt; bool:\n    \"\"\"Check for CUDA availability using nvidia-smi command.\n\n    Returns:\n        bool: True if CUDA is available via nvidia-smi, False otherwise.\n    \"\"\"\n    try:\n        result = subprocess.run(\n            [\"nvidia-smi\"], capture_output=True, text=True, timeout=5\n        )\n        return result.returncode == 0\n    except (\n        subprocess.TimeoutExpired,\n        FileNotFoundError,\n        subprocess.SubprocessError,\n    ):\n        return False\n</code></pre>"},{"location":"api-reference/#ragora.utils.device_utils.DeviceManager._detect_gpu_capabilities","title":"<code>_detect_gpu_capabilities()</code>","text":"<p>Detect GPU and CUDA capabilities on the current system.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict containing GPU availability and CUDA support information.</p> Source code in <code>ragora/ragora/utils/device_utils.py</code> <pre><code>def _detect_gpu_capabilities(self) -&gt; Dict[str, Any]:\n    \"\"\"Detect GPU and CUDA capabilities on the current system.\n\n    Returns:\n        Dict containing GPU availability and CUDA support information.\n    \"\"\"\n    gpu_available = False\n    cuda_available = False\n    gpu_count = 0\n    gpu_names = []\n\n    try:\n        # Try to import torch to check for GPU availability\n        import torch\n\n        gpu_available = torch.cuda.is_available()\n        if gpu_available:\n            gpu_count = torch.cuda.device_count()\n            gpu_names = [torch.cuda.get_device_name(i) for i in range(gpu_count)]\n            cuda_available = True\n    except ImportError:\n        logger.warning(\"PyTorch not available for GPU detection\")\n    except Exception as e:\n        logger.warning(f\"Error detecting GPU capabilities: {e}\")\n\n    # Additional CUDA detection using nvidia-smi if available\n    if not cuda_available and not self.platform_info[\"is_macos\"]:\n        cuda_available = self._check_cuda_via_nvidia_smi()\n\n    return {\n        \"gpu_available\": gpu_available,\n        \"cuda_available\": cuda_available,\n        \"gpu_count\": gpu_count,\n        \"gpu_names\": gpu_names,\n    }\n</code></pre>"},{"location":"api-reference/#ragora.utils.device_utils.DeviceManager._detect_platform","title":"<code>_detect_platform()</code>","text":"<p>Detect the current platform and system information.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict containing platform information including system, version, and architecture.</p> Source code in <code>ragora/ragora/utils/device_utils.py</code> <pre><code>def _detect_platform(self) -&gt; Dict[str, Any]:\n    \"\"\"Detect the current platform and system information.\n\n    Returns:\n        Dict containing platform information including system, version, and architecture.\n    \"\"\"\n    system = platform.system().lower()\n    version = platform.version()\n    architecture = platform.machine()\n\n    return {\n        \"system\": system,\n        \"version\": version,\n        \"architecture\": architecture,\n        \"is_macos\": system == \"darwin\",\n        \"is_windows\": system == \"windows\",\n        \"is_linux\": system == \"linux\",\n    }\n</code></pre>"},{"location":"api-reference/#ragora.utils.device_utils.DeviceManager._select_optimal_device","title":"<code>_select_optimal_device()</code>","text":"<p>Select the optimal PyTorch device based on platform and hardware.</p> <p>Device selection logic: 1. macOS: Always use CPU (MPS support is experimental) 2. Windows/Linux without GPUs: Use CPU 3. Windows/Linux with GPUs but without CUDA: Use CPU 4. Windows/Linux with GPUs and CUDA: Use GPU (cuda:0)</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The recommended PyTorch device string.</p> Source code in <code>ragora/ragora/utils/device_utils.py</code> <pre><code>def _select_optimal_device(self) -&gt; str:\n    \"\"\"Select the optimal PyTorch device based on platform and hardware.\n\n    Device selection logic:\n    1. macOS: Always use CPU (MPS support is experimental)\n    2. Windows/Linux without GPUs: Use CPU\n    3. Windows/Linux with GPUs but without CUDA: Use CPU\n    4. Windows/Linux with GPUs and CUDA: Use GPU (cuda:0)\n\n    Returns:\n        str: The recommended PyTorch device string.\n    \"\"\"\n    # Rule 1: macOS always uses CPU\n    if self.platform_info[\"is_macos\"]:\n        return \"cpu\"\n\n    # Rule 2: No GPU available, use CPU\n    if not self.gpu_info[\"gpu_available\"]:\n        return \"cpu\"\n\n    # Rule 3: GPU available but no CUDA, use CPU\n    if not self.gpu_info[\"cuda_available\"]:\n        return \"cpu\"\n\n    # Rule 4: GPU and CUDA available, use GPU\n    return \"cuda:0\"\n</code></pre>"},{"location":"api-reference/#ragora.utils.device_utils.DeviceManager.configure_pytorch_device","title":"<code>configure_pytorch_device(model=None, force_device=None)</code>","text":"<p>Configure PyTorch device and optionally move a model to the device.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <p>Optional PyTorch model to move to the recommended device.</p> <code>None</code> <code>force_device</code> <code>Optional[str]</code> <p>Optional device string to force a specific device.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The device string that was configured.</p> Source code in <code>ragora/ragora/utils/device_utils.py</code> <pre><code>def configure_pytorch_device(\n    self, model=None, force_device: Optional[str] = None\n) -&gt; str:\n    \"\"\"Configure PyTorch device and optionally move a model to the device.\n\n    Args:\n        model: Optional PyTorch model to move to the recommended device.\n        force_device: Optional device string to force a specific device.\n\n    Returns:\n        str: The device string that was configured.\n    \"\"\"\n    device = force_device if force_device else self.recommended_device\n\n    if model is not None:\n        try:\n            import torch\n\n            model = model.to(device)\n            logger.info(f\"Model moved to device: {device}\")\n        except Exception as e:\n            logger.error(f\"Failed to move model to device {device}: {e}\")\n            # Fallback to CPU if device move fails\n            if device != \"cpu\":\n                device = \"cpu\"\n                model = model.to(device)\n                logger.info(\"Fallback: Model moved to CPU\")\n\n    return device\n</code></pre>"},{"location":"api-reference/#ragora.utils.device_utils.DeviceManager.get_device_info","title":"<code>get_device_info()</code>","text":"<p>Get comprehensive device information.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict containing all device and platform information.</p> Source code in <code>ragora/ragora/utils/device_utils.py</code> <pre><code>def get_device_info(self) -&gt; Dict[str, Any]:\n    \"\"\"Get comprehensive device information.\n\n    Returns:\n        Dict containing all device and platform information.\n    \"\"\"\n    return {\n        \"platform\": self.platform_info,\n        \"gpu\": self.gpu_info,\n        \"recommended_device\": self.recommended_device,\n    }\n</code></pre>"},{"location":"api-reference/#ragora.utils.device_utils.DeviceManager.get_recommended_device","title":"<code>get_recommended_device()</code>","text":"<p>Get the recommended PyTorch device for the current platform.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The recommended device string (e.g., 'cpu', 'cuda:0').</p> Source code in <code>ragora/ragora/utils/device_utils.py</code> <pre><code>def get_recommended_device(self) -&gt; str:\n    \"\"\"Get the recommended PyTorch device for the current platform.\n\n    Returns:\n        str: The recommended device string (e.g., 'cpu', 'cuda:0').\n    \"\"\"\n    return self.recommended_device\n</code></pre>"},{"location":"api-reference/#ragora.utils.device_utils.configure_pytorch_for_platform","title":"<code>configure_pytorch_for_platform(model=None, force_device=None)</code>","text":"<p>Configure PyTorch for the current platform.</p> <p>This function automatically detects the platform and configures PyTorch to use the optimal device. It's designed to be called once at the beginning of your application or test setup.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <p>Optional PyTorch model to move to the recommended device.</p> <code>None</code> <code>force_device</code> <code>Optional[str]</code> <p>Optional device string to force a specific device.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The device string that was configured.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Basic usage - just get the recommended device\n&gt;&gt;&gt; device = configure_pytorch_for_platform()\n&gt;&gt;&gt; print(f\"Using device: {device}\")\n</code></pre> <pre><code>&gt;&gt;&gt; # With a model\n&gt;&gt;&gt; import torch\n&gt;&gt;&gt; model = torch.nn.Linear(10, 1)\n&gt;&gt;&gt; device = configure_pytorch_for_platform(model)\n&gt;&gt;&gt; print(f\"Model is on device: {device}\")\n</code></pre> <pre><code>&gt;&gt;&gt; # Force a specific device (for testing)\n&gt;&gt;&gt; device = configure_pytorch_for_platform(force_device='cpu')\n&gt;&gt;&gt; print(f\"Forced to device: {device}\")\n</code></pre> Source code in <code>ragora/ragora/utils/device_utils.py</code> <pre><code>def configure_pytorch_for_platform(\n    model=None, force_device: Optional[str] = None\n) -&gt; str:\n    \"\"\"Configure PyTorch for the current platform.\n\n    This function automatically detects the platform and configures PyTorch\n    to use the optimal device. It's designed to be called once at the\n    beginning of your application or test setup.\n\n    Args:\n        model: Optional PyTorch model to move to the recommended device.\n        force_device: Optional device string to force a specific device.\n\n    Returns:\n        str: The device string that was configured.\n\n    Examples:\n        &gt;&gt;&gt; # Basic usage - just get the recommended device\n        &gt;&gt;&gt; device = configure_pytorch_for_platform()\n        &gt;&gt;&gt; print(f\"Using device: {device}\")\n\n        &gt;&gt;&gt; # With a model\n        &gt;&gt;&gt; import torch\n        &gt;&gt;&gt; model = torch.nn.Linear(10, 1)\n        &gt;&gt;&gt; device = configure_pytorch_for_platform(model)\n        &gt;&gt;&gt; print(f\"Model is on device: {device}\")\n\n        &gt;&gt;&gt; # Force a specific device (for testing)\n        &gt;&gt;&gt; device = configure_pytorch_for_platform(force_device='cpu')\n        &gt;&gt;&gt; print(f\"Forced to device: {device}\")\n    \"\"\"\n    return get_device_manager().configure_pytorch_device(model, force_device)\n</code></pre>"},{"location":"api-reference/#ragora.utils.device_utils.get_device_info","title":"<code>get_device_info()</code>","text":"<p>Get comprehensive device and platform information.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict containing platform, GPU, and device information.</p> Example <p>info = get_device_info() print(f\"Platform: {info['platform']['system']}\") print(f\"GPU Available: {info['gpu']['gpu_available']}\") print(f\"Recommended Device: {info['recommended_device']}\")</p> Source code in <code>ragora/ragora/utils/device_utils.py</code> <pre><code>def get_device_info() -&gt; Dict[str, Any]:\n    \"\"\"Get comprehensive device and platform information.\n\n    Returns:\n        Dict containing platform, GPU, and device information.\n\n    Example:\n        &gt;&gt;&gt; info = get_device_info()\n        &gt;&gt;&gt; print(f\"Platform: {info['platform']['system']}\")\n        &gt;&gt;&gt; print(f\"GPU Available: {info['gpu']['gpu_available']}\")\n        &gt;&gt;&gt; print(f\"Recommended Device: {info['recommended_device']}\")\n    \"\"\"\n    return get_device_manager().get_device_info()\n</code></pre>"},{"location":"api-reference/#ragora.utils.device_utils.get_device_manager","title":"<code>get_device_manager()</code>","text":"<p>Get the global device manager instance.</p> <p>Returns:</p> Name Type Description <code>DeviceManager</code> <code>DeviceManager</code> <p>The global device manager instance.</p> Source code in <code>ragora/ragora/utils/device_utils.py</code> <pre><code>def get_device_manager() -&gt; DeviceManager:\n    \"\"\"Get the global device manager instance.\n\n    Returns:\n        DeviceManager: The global device manager instance.\n    \"\"\"\n    global _device_manager\n    if _device_manager is None:\n        _device_manager = DeviceManager()\n    return _device_manager\n</code></pre>"},{"location":"api-reference/#ragora.utils.device_utils.get_recommended_device","title":"<code>get_recommended_device()</code>","text":"<p>Get the recommended PyTorch device for the current platform.</p> <p>This is a convenience function that returns the recommended device without needing to instantiate the DeviceManager directly.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The recommended device string.</p> Source code in <code>ragora/ragora/utils/device_utils.py</code> <pre><code>def get_recommended_device() -&gt; str:\n    \"\"\"Get the recommended PyTorch device for the current platform.\n\n    This is a convenience function that returns the recommended device\n    without needing to instantiate the DeviceManager directly.\n\n    Returns:\n        str: The recommended device string.\n    \"\"\"\n    return get_device_manager().get_recommended_device()\n</code></pre>"},{"location":"api-reference/#ragora.utils.device_utils.get_sentence_transformer_device","title":"<code>get_sentence_transformer_device()</code>","text":"<p>Get the recommended device for sentence-transformers models.</p> <p>This function is specifically designed for use with sentence-transformers and handles the device string format expected by that library.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The recommended device string for sentence-transformers.</p> Source code in <code>ragora/ragora/utils/device_utils.py</code> <pre><code>def get_sentence_transformer_device() -&gt; str:\n    \"\"\"Get the recommended device for sentence-transformers models.\n\n    This function is specifically designed for use with sentence-transformers\n    and handles the device string format expected by that library.\n\n    Returns:\n        str: The recommended device string for sentence-transformers.\n    \"\"\"\n    device = get_recommended_device()\n\n    # sentence-transformers uses 'cuda' instead of 'cuda:0'\n    if device.startswith(\"cuda\"):\n        return \"cuda\"\n\n    return device\n</code></pre>"},{"location":"api-reference/#ragora.utils.device_utils.is_cuda_available","title":"<code>is_cuda_available()</code>","text":"<p>Check if CUDA is available on the current system.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if CUDA is available, False otherwise.</p> Source code in <code>ragora/ragora/utils/device_utils.py</code> <pre><code>def is_cuda_available() -&gt; bool:\n    \"\"\"Check if CUDA is available on the current system.\n\n    Returns:\n        bool: True if CUDA is available, False otherwise.\n    \"\"\"\n    return get_device_manager().gpu_info[\"cuda_available\"]\n</code></pre>"},{"location":"api-reference/#ragora.utils.device_utils.is_gpu_available","title":"<code>is_gpu_available()</code>","text":"<p>Check if GPU is available on the current system.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if GPU is available, False otherwise.</p> Source code in <code>ragora/ragora/utils/device_utils.py</code> <pre><code>def is_gpu_available() -&gt; bool:\n    \"\"\"Check if GPU is available on the current system.\n\n    Returns:\n        bool: True if GPU is available, False otherwise.\n    \"\"\"\n    return get_device_manager().gpu_info[\"gpu_available\"]\n</code></pre>"},{"location":"api-reference/#ragora.utils.device_utils.is_linux","title":"<code>is_linux()</code>","text":"<p>Check if the current platform is Linux.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if running on Linux, False otherwise.</p> Source code in <code>ragora/ragora/utils/device_utils.py</code> <pre><code>def is_linux() -&gt; bool:\n    \"\"\"Check if the current platform is Linux.\n\n    Returns:\n        bool: True if running on Linux, False otherwise.\n    \"\"\"\n    return get_device_manager().platform_info[\"is_linux\"]\n</code></pre>"},{"location":"api-reference/#ragora.utils.device_utils.is_macos","title":"<code>is_macos()</code>","text":"<p>Check if the current platform is macOS.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if running on macOS, False otherwise.</p> Source code in <code>ragora/ragora/utils/device_utils.py</code> <pre><code>def is_macos() -&gt; bool:\n    \"\"\"Check if the current platform is macOS.\n\n    Returns:\n        bool: True if running on macOS, False otherwise.\n    \"\"\"\n    return get_device_manager().platform_info[\"is_macos\"]\n</code></pre>"},{"location":"api-reference/#ragora.utils.device_utils.is_windows","title":"<code>is_windows()</code>","text":"<p>Check if the current platform is Windows.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if running on Windows, False otherwise.</p> Source code in <code>ragora/ragora/utils/device_utils.py</code> <pre><code>def is_windows() -&gt; bool:\n    \"\"\"Check if the current platform is Windows.\n\n    Returns:\n        bool: True if running on Windows, False otherwise.\n    \"\"\"\n    return get_device_manager().platform_info[\"is_windows\"]\n</code></pre>"},{"location":"api-reference/#ragora.utils.device_utils.mock_platform_info","title":"<code>mock_platform_info(platform_info, gpu_info)</code>","text":"<p>Mock platform and GPU information for testing.</p> <p>Parameters:</p> Name Type Description Default <code>platform_info</code> <code>Dict[str, Any]</code> <p>Mock platform information.</p> required <code>gpu_info</code> <code>Dict[str, Any]</code> <p>Mock GPU information.</p> required <p>This function is intended for testing scenarios where you need to simulate different platform configurations.</p> Source code in <code>ragora/ragora/utils/device_utils.py</code> <pre><code>def mock_platform_info(platform_info: Dict[str, Any], gpu_info: Dict[str, Any]):\n    \"\"\"Mock platform and GPU information for testing.\n\n    Args:\n        platform_info: Mock platform information.\n        gpu_info: Mock GPU information.\n\n    This function is intended for testing scenarios where you need to\n    simulate different platform configurations.\n    \"\"\"\n    global _device_manager\n    _device_manager = DeviceManager()\n    _device_manager.platform_info = platform_info\n    _device_manager.gpu_info = gpu_info\n    _device_manager.recommended_device = _device_manager._select_optimal_device()\n</code></pre>"},{"location":"api-reference/#ragora.utils.device_utils.reset_device_manager","title":"<code>reset_device_manager()</code>","text":"<p>Reset the global device manager (useful for testing).</p> <p>This function is primarily intended for testing scenarios where you need to reset the device detection state.</p> Source code in <code>ragora/ragora/utils/device_utils.py</code> <pre><code>def reset_device_manager():\n    \"\"\"Reset the global device manager (useful for testing).\n\n    This function is primarily intended for testing scenarios where you\n    need to reset the device detection state.\n    \"\"\"\n    global _device_manager\n    _device_manager = None\n</code></pre>"},{"location":"api-reference/#email-provider-factory","title":"Email Provider Factory","text":"<p>Factory helpers for creating email provider implementations.</p>"},{"location":"api-reference/#ragora.utils.email_provider_factory.EmailProviderFactory","title":"<code>EmailProviderFactory</code>","text":"<p>Factory for constructing concrete email providers.</p> <p>Examples:</p> <pre><code>provider = EmailProviderFactory.create_provider(\n    ProviderType.IMAP,\n    IMAPCredentials(\n        imap_server=\"imap.example.com\",\n        imap_port=993,\n        smtp_server=\"smtp.example.com\",\n        smtp_port=587,\n        username=\"user\",\n        password=\"pass\",\n    ),\n)\nprovider.connect()\n</code></pre> Source code in <code>ragora/ragora/utils/email_provider_factory.py</code> <pre><code>class EmailProviderFactory:\n    \"\"\"Factory for constructing concrete email providers.\n\n    Examples:\n        ```python\n        provider = EmailProviderFactory.create_provider(\n            ProviderType.IMAP,\n            IMAPCredentials(\n                imap_server=\"imap.example.com\",\n                imap_port=993,\n                smtp_server=\"smtp.example.com\",\n                smtp_port=587,\n                username=\"user\",\n                password=\"pass\",\n            ),\n        )\n        provider.connect()\n        ```\n    \"\"\"\n\n    @staticmethod\n    def create_provider(\n        provider_type: Union[ProviderType, str],\n        credentials: Union[IMAPCredentials, GraphCredentials],\n    ) -&gt; EmailProvider:\n        \"\"\"Create an email provider instance.\n\n        Args:\n            provider_type: Type of provider to create (ProviderType enum or string)\n            credentials: Provider-specific credentials\n\n        Returns:\n            EmailProvider: Concrete provider instance.\n\n        Raises:\n            ValueError: If the provider type is unsupported.\n            TypeError: If the provided credentials do not match the provider type.\n\n        Examples:\n            ```python\n            provider = EmailProviderFactory.create_provider(\n                ProviderType.IMAP,\n                IMAPCredentials(\n                    imap_server=\"imap.example.com\",\n                    imap_port=993,\n                    smtp_server=\"smtp.example.com\",\n                    smtp_port=587,\n                    username=\"user\",\n                    password=\"pass\",\n                ),\n            )\n            ```\n        \"\"\"\n        # Normalize provider type\n        if isinstance(provider_type, str):\n            try:\n                provider_type = ProviderType(provider_type.lower())\n            except ValueError:\n                raise ValueError(f\"Unsupported provider type: {provider_type}\")\n\n        # Validate credentials match provider type\n        if provider_type == ProviderType.IMAP:\n            if not isinstance(credentials, IMAPCredentials):\n                raise TypeError(\"IMAP provider requires IMAPCredentials\")\n            return IMAPProvider(credentials)\n\n        elif provider_type == ProviderType.GRAPH:\n            if not isinstance(credentials, GraphCredentials):\n                raise TypeError(\"Graph provider requires GraphCredentials\")\n            return GraphProvider(credentials)\n\n        else:\n            raise ValueError(f\"Unsupported provider type: {provider_type}\")\n\n    @staticmethod\n    def create_imap_provider(\n        imap_server: str,\n        imap_port: int,\n        smtp_server: str,\n        smtp_port: int,\n        username: str,\n        password: str,\n        use_ssl: bool = True,\n        use_tls: bool = False,\n    ) -&gt; IMAPProvider:\n        \"\"\"Create an IMAP provider with the given configuration.\n\n        Args:\n            imap_server: IMAP server hostname\n            imap_port: IMAP server port\n            smtp_server: SMTP server hostname\n            smtp_port: SMTP server port\n            username: Email username\n            password: Email password\n            use_ssl: Whether to use SSL for IMAP connection\n            use_tls: Whether to use TLS for IMAP connection\n\n        Returns:\n            IMAPProvider: Configured provider instance.\n\n        Examples:\n            ```python\n            provider = EmailProviderFactory.create_imap_provider(\n                imap_server=\"imap.example.com\",\n                imap_port=993,\n                smtp_server=\"smtp.example.com\",\n                smtp_port=587,\n                username=\"user\",\n                password=\"pass\",\n            )\n            ```\n        \"\"\"\n        credentials = IMAPCredentials(\n            imap_server=imap_server,\n            imap_port=imap_port,\n            smtp_server=smtp_server,\n            smtp_port=smtp_port,\n            username=username,\n            password=password,\n            use_ssl=use_ssl,\n            use_tls=use_tls,\n        )\n        return IMAPProvider(credentials)\n\n    @staticmethod\n    def create_graph_provider(\n        client_id: str,\n        client_secret: str,\n        tenant_id: str,\n        access_token: str = None,\n        refresh_token: str = None,\n    ) -&gt; GraphProvider:\n        \"\"\"Create a Microsoft Graph provider with the given configuration.\n\n        Args:\n            client_id: Azure application client ID\n            client_secret: Azure application client secret\n            tenant_id: Azure tenant ID\n            access_token: Optional access token (if not provided, will use client credentials)\n            refresh_token: Optional refresh token\n\n        Returns:\n            GraphProvider: Configured provider instance.\n\n        Examples:\n            ```python\n            provider = EmailProviderFactory.create_graph_provider(\n                client_id=\"app-id\",\n                client_secret=\"secret\",\n                tenant_id=\"tenant\",\n            )\n            ```\n        \"\"\"\n        credentials = GraphCredentials(\n            client_id=client_id,\n            client_secret=client_secret,\n            tenant_id=tenant_id,\n            access_token=access_token,\n            refresh_token=refresh_token,\n        )\n        return GraphProvider(credentials)\n\n    @staticmethod\n    def get_supported_providers() -&gt; list[str]:\n        \"\"\"Get list of supported provider types.\n\n        Returns:\n            List of supported provider type names\n        \"\"\"\n        return [provider.value for provider in ProviderType]\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_provider_factory.EmailProviderFactory.create_graph_provider","title":"<code>create_graph_provider(client_id, client_secret, tenant_id, access_token=None, refresh_token=None)</code>  <code>staticmethod</code>","text":"<p>Create a Microsoft Graph provider with the given configuration.</p> <p>Parameters:</p> Name Type Description Default <code>client_id</code> <code>str</code> <p>Azure application client ID</p> required <code>client_secret</code> <code>str</code> <p>Azure application client secret</p> required <code>tenant_id</code> <code>str</code> <p>Azure tenant ID</p> required <code>access_token</code> <code>str</code> <p>Optional access token (if not provided, will use client credentials)</p> <code>None</code> <code>refresh_token</code> <code>str</code> <p>Optional refresh token</p> <code>None</code> <p>Returns:</p> Name Type Description <code>GraphProvider</code> <code>GraphProvider</code> <p>Configured provider instance.</p> <p>Examples:</p> <pre><code>provider = EmailProviderFactory.create_graph_provider(\n    client_id=\"app-id\",\n    client_secret=\"secret\",\n    tenant_id=\"tenant\",\n)\n</code></pre> Source code in <code>ragora/ragora/utils/email_provider_factory.py</code> <pre><code>@staticmethod\ndef create_graph_provider(\n    client_id: str,\n    client_secret: str,\n    tenant_id: str,\n    access_token: str = None,\n    refresh_token: str = None,\n) -&gt; GraphProvider:\n    \"\"\"Create a Microsoft Graph provider with the given configuration.\n\n    Args:\n        client_id: Azure application client ID\n        client_secret: Azure application client secret\n        tenant_id: Azure tenant ID\n        access_token: Optional access token (if not provided, will use client credentials)\n        refresh_token: Optional refresh token\n\n    Returns:\n        GraphProvider: Configured provider instance.\n\n    Examples:\n        ```python\n        provider = EmailProviderFactory.create_graph_provider(\n            client_id=\"app-id\",\n            client_secret=\"secret\",\n            tenant_id=\"tenant\",\n        )\n        ```\n    \"\"\"\n    credentials = GraphCredentials(\n        client_id=client_id,\n        client_secret=client_secret,\n        tenant_id=tenant_id,\n        access_token=access_token,\n        refresh_token=refresh_token,\n    )\n    return GraphProvider(credentials)\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_provider_factory.EmailProviderFactory.create_imap_provider","title":"<code>create_imap_provider(imap_server, imap_port, smtp_server, smtp_port, username, password, use_ssl=True, use_tls=False)</code>  <code>staticmethod</code>","text":"<p>Create an IMAP provider with the given configuration.</p> <p>Parameters:</p> Name Type Description Default <code>imap_server</code> <code>str</code> <p>IMAP server hostname</p> required <code>imap_port</code> <code>int</code> <p>IMAP server port</p> required <code>smtp_server</code> <code>str</code> <p>SMTP server hostname</p> required <code>smtp_port</code> <code>int</code> <p>SMTP server port</p> required <code>username</code> <code>str</code> <p>Email username</p> required <code>password</code> <code>str</code> <p>Email password</p> required <code>use_ssl</code> <code>bool</code> <p>Whether to use SSL for IMAP connection</p> <code>True</code> <code>use_tls</code> <code>bool</code> <p>Whether to use TLS for IMAP connection</p> <code>False</code> <p>Returns:</p> Name Type Description <code>IMAPProvider</code> <code>IMAPProvider</code> <p>Configured provider instance.</p> <p>Examples:</p> <pre><code>provider = EmailProviderFactory.create_imap_provider(\n    imap_server=\"imap.example.com\",\n    imap_port=993,\n    smtp_server=\"smtp.example.com\",\n    smtp_port=587,\n    username=\"user\",\n    password=\"pass\",\n)\n</code></pre> Source code in <code>ragora/ragora/utils/email_provider_factory.py</code> <pre><code>@staticmethod\ndef create_imap_provider(\n    imap_server: str,\n    imap_port: int,\n    smtp_server: str,\n    smtp_port: int,\n    username: str,\n    password: str,\n    use_ssl: bool = True,\n    use_tls: bool = False,\n) -&gt; IMAPProvider:\n    \"\"\"Create an IMAP provider with the given configuration.\n\n    Args:\n        imap_server: IMAP server hostname\n        imap_port: IMAP server port\n        smtp_server: SMTP server hostname\n        smtp_port: SMTP server port\n        username: Email username\n        password: Email password\n        use_ssl: Whether to use SSL for IMAP connection\n        use_tls: Whether to use TLS for IMAP connection\n\n    Returns:\n        IMAPProvider: Configured provider instance.\n\n    Examples:\n        ```python\n        provider = EmailProviderFactory.create_imap_provider(\n            imap_server=\"imap.example.com\",\n            imap_port=993,\n            smtp_server=\"smtp.example.com\",\n            smtp_port=587,\n            username=\"user\",\n            password=\"pass\",\n        )\n        ```\n    \"\"\"\n    credentials = IMAPCredentials(\n        imap_server=imap_server,\n        imap_port=imap_port,\n        smtp_server=smtp_server,\n        smtp_port=smtp_port,\n        username=username,\n        password=password,\n        use_ssl=use_ssl,\n        use_tls=use_tls,\n    )\n    return IMAPProvider(credentials)\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_provider_factory.EmailProviderFactory.create_provider","title":"<code>create_provider(provider_type, credentials)</code>  <code>staticmethod</code>","text":"<p>Create an email provider instance.</p> <p>Parameters:</p> Name Type Description Default <code>provider_type</code> <code>Union[ProviderType, str]</code> <p>Type of provider to create (ProviderType enum or string)</p> required <code>credentials</code> <code>Union[IMAPCredentials, GraphCredentials]</code> <p>Provider-specific credentials</p> required <p>Returns:</p> Name Type Description <code>EmailProvider</code> <code>EmailProvider</code> <p>Concrete provider instance.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the provider type is unsupported.</p> <code>TypeError</code> <p>If the provided credentials do not match the provider type.</p> <p>Examples:</p> <pre><code>provider = EmailProviderFactory.create_provider(\n    ProviderType.IMAP,\n    IMAPCredentials(\n        imap_server=\"imap.example.com\",\n        imap_port=993,\n        smtp_server=\"smtp.example.com\",\n        smtp_port=587,\n        username=\"user\",\n        password=\"pass\",\n    ),\n)\n</code></pre> Source code in <code>ragora/ragora/utils/email_provider_factory.py</code> <pre><code>@staticmethod\ndef create_provider(\n    provider_type: Union[ProviderType, str],\n    credentials: Union[IMAPCredentials, GraphCredentials],\n) -&gt; EmailProvider:\n    \"\"\"Create an email provider instance.\n\n    Args:\n        provider_type: Type of provider to create (ProviderType enum or string)\n        credentials: Provider-specific credentials\n\n    Returns:\n        EmailProvider: Concrete provider instance.\n\n    Raises:\n        ValueError: If the provider type is unsupported.\n        TypeError: If the provided credentials do not match the provider type.\n\n    Examples:\n        ```python\n        provider = EmailProviderFactory.create_provider(\n            ProviderType.IMAP,\n            IMAPCredentials(\n                imap_server=\"imap.example.com\",\n                imap_port=993,\n                smtp_server=\"smtp.example.com\",\n                smtp_port=587,\n                username=\"user\",\n                password=\"pass\",\n            ),\n        )\n        ```\n    \"\"\"\n    # Normalize provider type\n    if isinstance(provider_type, str):\n        try:\n            provider_type = ProviderType(provider_type.lower())\n        except ValueError:\n            raise ValueError(f\"Unsupported provider type: {provider_type}\")\n\n    # Validate credentials match provider type\n    if provider_type == ProviderType.IMAP:\n        if not isinstance(credentials, IMAPCredentials):\n            raise TypeError(\"IMAP provider requires IMAPCredentials\")\n        return IMAPProvider(credentials)\n\n    elif provider_type == ProviderType.GRAPH:\n        if not isinstance(credentials, GraphCredentials):\n            raise TypeError(\"Graph provider requires GraphCredentials\")\n        return GraphProvider(credentials)\n\n    else:\n        raise ValueError(f\"Unsupported provider type: {provider_type}\")\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_provider_factory.EmailProviderFactory.get_supported_providers","title":"<code>get_supported_providers()</code>  <code>staticmethod</code>","text":"<p>Get list of supported provider types.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of supported provider type names</p> Source code in <code>ragora/ragora/utils/email_provider_factory.py</code> <pre><code>@staticmethod\ndef get_supported_providers() -&gt; list[str]:\n    \"\"\"Get list of supported provider types.\n\n    Returns:\n        List of supported provider type names\n    \"\"\"\n    return [provider.value for provider in ProviderType]\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_provider_factory.ProviderType","title":"<code>ProviderType</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Supported email provider types.</p> Source code in <code>ragora/ragora/utils/email_provider_factory.py</code> <pre><code>class ProviderType(Enum):\n    \"\"\"Supported email provider types.\"\"\"\n\n    IMAP = \"imap\"\n    GRAPH = \"graph\"\n</code></pre>"},{"location":"api-reference/#email-utils","title":"Email Utils","text":"<p>Base email provider interface.</p> <p>Microsoft Graph API email provider implementation.</p> <p>IMAP/SMTP email provider implementation.</p> <p>Data models for email functionality.</p>"},{"location":"api-reference/#ragora.utils.email_utils.base.EmailProvider","title":"<code>EmailProvider</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for email providers.</p> <p>This interface defines the contract that all email providers must implement, allowing the RAG system to work with different email backends seamlessly.</p> Source code in <code>ragora/ragora/utils/email_utils/base.py</code> <pre><code>class EmailProvider(ABC):\n    \"\"\"Abstract base class for email providers.\n\n    This interface defines the contract that all email providers must implement,\n    allowing the RAG system to work with different email backends seamlessly.\n    \"\"\"\n\n    def __init__(self, credentials: EmailCredentials):\n        \"\"\"Initialize the email provider with credentials.\n\n        Args:\n            credentials: Provider-specific credentials for authentication\n        \"\"\"\n        self.credentials = credentials\n\n    @abstractmethod\n    def connect(self) -&gt; None:\n        \"\"\"Establish connection to the email service.\n\n        Raises:\n            ConnectionError: If connection fails\n            AuthenticationError: If authentication fails\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def disconnect(self) -&gt; None:\n        \"\"\"Close connection to the email service.\"\"\"\n        pass\n\n    @abstractmethod\n    def fetch_messages(\n        self, limit: int = 50, folder: Optional[str] = None, unread_only: bool = False\n    ) -&gt; List[EmailMessage]:\n        \"\"\"Fetch messages from the email service.\n\n        Args:\n            limit: Maximum number of messages to fetch\n            folder: Specific folder to fetch from (None for inbox)\n            unread_only: If True, only fetch unread messages\n\n        Returns:\n            List of EmailMessage objects\n\n        Raises:\n            ConnectionError: If not connected\n            FetchError: If message fetching fails\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def fetch_message_by_id(self, message_id: str) -&gt; Optional[EmailMessage]:\n        \"\"\"Fetch a specific message by its ID.\n\n        Args:\n            message_id: Unique identifier for the message\n\n        Returns:\n            EmailMessage object or None if not found\n\n        Raises:\n            ConnectionError: If not connected\n            FetchError: If message fetching fails\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def create_draft(\n        self,\n        to: List[str],\n        subject: str,\n        body: str,\n        cc: Optional[List[str]] = None,\n        bcc: Optional[List[str]] = None,\n        attachments: Optional[List[str]] = None,\n        folder: str = \"Drafts\",\n    ) -&gt; EmailDraft:\n        \"\"\"Create a draft message.\n\n        Args:\n            to: List of recipient email addresses\n            subject: Email subject line\n            body: Email body content (HTML or plain text)\n            cc: Optional list of CC recipient email addresses\n            bcc: Optional list of BCC recipient email addresses\n            attachments: Optional list of file paths to attach\n            folder: Folder to store the draft in (default: \"Drafts\")\n\n        Returns:\n            EmailDraft object with the created draft\n\n        Raises:\n            ConnectionError: If not connected\n            DraftError: If draft creation fails\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def send_message(self, draft_id: str, folder: str = \"Drafts\") -&gt; bool:\n        \"\"\"Send a draft message.\n\n        Args:\n            draft_id: ID of the draft to send\n            folder: Folder where the draft is stored (default: \"Drafts\")\n\n        Returns:\n            True if message was sent successfully\n\n        Raises:\n            ConnectionError: If not connected\n            SendError: If message sending fails\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def send_message_direct(\n        self,\n        to: List[str],\n        subject: str,\n        body: str,\n        cc: Optional[List[str]] = None,\n        bcc: Optional[List[str]] = None,\n        attachments: Optional[List[str]] = None,\n    ) -&gt; bool:\n        \"\"\"Send a message directly without creating a draft.\n\n        Args:\n            to: List of recipient email addresses\n            subject: Email subject line\n            body: Email body content (HTML or plain text)\n            cc: Optional list of CC recipient email addresses\n            bcc: Optional list of BCC recipient email addresses\n            attachments: Optional list of file paths to attach\n\n        Returns:\n            True if message was sent successfully\n\n        Raises:\n            ConnectionError: If not connected\n            SendError: If message sending fails\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def mark_as_read(self, message_id: str) -&gt; bool:\n        \"\"\"Mark a message as read.\n\n        Args:\n            message_id: ID of the message to mark as read\n\n        Returns:\n            True if message was marked as read successfully\n\n        Raises:\n            ConnectionError: If not connected\n            UpdateError: If marking fails\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_folders(self) -&gt; List[str]:\n        \"\"\"Get list of available folders.\n\n        Returns:\n            List of folder names\n\n        Raises:\n            ConnectionError: If not connected\n            FetchError: If folder fetching fails\n        \"\"\"\n        pass\n\n    @property\n    @abstractmethod\n    def is_connected(self) -&gt; bool:\n        \"\"\"Check if the provider is connected to the email service.\n\n        Returns:\n            True if connected, False otherwise\n        \"\"\"\n        pass\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.base.EmailProvider.is_connected","title":"<code>is_connected</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Check if the provider is connected to the email service.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if connected, False otherwise</p>"},{"location":"api-reference/#ragora.utils.email_utils.base.EmailProvider.connect","title":"<code>connect()</code>  <code>abstractmethod</code>","text":"<p>Establish connection to the email service.</p> <p>Raises:</p> Type Description <code>ConnectionError</code> <p>If connection fails</p> <code>AuthenticationError</code> <p>If authentication fails</p> Source code in <code>ragora/ragora/utils/email_utils/base.py</code> <pre><code>@abstractmethod\ndef connect(self) -&gt; None:\n    \"\"\"Establish connection to the email service.\n\n    Raises:\n        ConnectionError: If connection fails\n        AuthenticationError: If authentication fails\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.base.EmailProvider.create_draft","title":"<code>create_draft(to, subject, body, cc=None, bcc=None, attachments=None, folder='Drafts')</code>  <code>abstractmethod</code>","text":"<p>Create a draft message.</p> <p>Parameters:</p> Name Type Description Default <code>to</code> <code>List[str]</code> <p>List of recipient email addresses</p> required <code>subject</code> <code>str</code> <p>Email subject line</p> required <code>body</code> <code>str</code> <p>Email body content (HTML or plain text)</p> required <code>cc</code> <code>Optional[List[str]]</code> <p>Optional list of CC recipient email addresses</p> <code>None</code> <code>bcc</code> <code>Optional[List[str]]</code> <p>Optional list of BCC recipient email addresses</p> <code>None</code> <code>attachments</code> <code>Optional[List[str]]</code> <p>Optional list of file paths to attach</p> <code>None</code> <code>folder</code> <code>str</code> <p>Folder to store the draft in (default: \"Drafts\")</p> <code>'Drafts'</code> <p>Returns:</p> Type Description <code>EmailDraft</code> <p>EmailDraft object with the created draft</p> <p>Raises:</p> Type Description <code>ConnectionError</code> <p>If not connected</p> <code>DraftError</code> <p>If draft creation fails</p> Source code in <code>ragora/ragora/utils/email_utils/base.py</code> <pre><code>@abstractmethod\ndef create_draft(\n    self,\n    to: List[str],\n    subject: str,\n    body: str,\n    cc: Optional[List[str]] = None,\n    bcc: Optional[List[str]] = None,\n    attachments: Optional[List[str]] = None,\n    folder: str = \"Drafts\",\n) -&gt; EmailDraft:\n    \"\"\"Create a draft message.\n\n    Args:\n        to: List of recipient email addresses\n        subject: Email subject line\n        body: Email body content (HTML or plain text)\n        cc: Optional list of CC recipient email addresses\n        bcc: Optional list of BCC recipient email addresses\n        attachments: Optional list of file paths to attach\n        folder: Folder to store the draft in (default: \"Drafts\")\n\n    Returns:\n        EmailDraft object with the created draft\n\n    Raises:\n        ConnectionError: If not connected\n        DraftError: If draft creation fails\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.base.EmailProvider.disconnect","title":"<code>disconnect()</code>  <code>abstractmethod</code>","text":"<p>Close connection to the email service.</p> Source code in <code>ragora/ragora/utils/email_utils/base.py</code> <pre><code>@abstractmethod\ndef disconnect(self) -&gt; None:\n    \"\"\"Close connection to the email service.\"\"\"\n    pass\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.base.EmailProvider.fetch_message_by_id","title":"<code>fetch_message_by_id(message_id)</code>  <code>abstractmethod</code>","text":"<p>Fetch a specific message by its ID.</p> <p>Parameters:</p> Name Type Description Default <code>message_id</code> <code>str</code> <p>Unique identifier for the message</p> required <p>Returns:</p> Type Description <code>Optional[EmailMessage]</code> <p>EmailMessage object or None if not found</p> <p>Raises:</p> Type Description <code>ConnectionError</code> <p>If not connected</p> <code>FetchError</code> <p>If message fetching fails</p> Source code in <code>ragora/ragora/utils/email_utils/base.py</code> <pre><code>@abstractmethod\ndef fetch_message_by_id(self, message_id: str) -&gt; Optional[EmailMessage]:\n    \"\"\"Fetch a specific message by its ID.\n\n    Args:\n        message_id: Unique identifier for the message\n\n    Returns:\n        EmailMessage object or None if not found\n\n    Raises:\n        ConnectionError: If not connected\n        FetchError: If message fetching fails\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.base.EmailProvider.fetch_messages","title":"<code>fetch_messages(limit=50, folder=None, unread_only=False)</code>  <code>abstractmethod</code>","text":"<p>Fetch messages from the email service.</p> <p>Parameters:</p> Name Type Description Default <code>limit</code> <code>int</code> <p>Maximum number of messages to fetch</p> <code>50</code> <code>folder</code> <code>Optional[str]</code> <p>Specific folder to fetch from (None for inbox)</p> <code>None</code> <code>unread_only</code> <code>bool</code> <p>If True, only fetch unread messages</p> <code>False</code> <p>Returns:</p> Type Description <code>List[EmailMessage]</code> <p>List of EmailMessage objects</p> <p>Raises:</p> Type Description <code>ConnectionError</code> <p>If not connected</p> <code>FetchError</code> <p>If message fetching fails</p> Source code in <code>ragora/ragora/utils/email_utils/base.py</code> <pre><code>@abstractmethod\ndef fetch_messages(\n    self, limit: int = 50, folder: Optional[str] = None, unread_only: bool = False\n) -&gt; List[EmailMessage]:\n    \"\"\"Fetch messages from the email service.\n\n    Args:\n        limit: Maximum number of messages to fetch\n        folder: Specific folder to fetch from (None for inbox)\n        unread_only: If True, only fetch unread messages\n\n    Returns:\n        List of EmailMessage objects\n\n    Raises:\n        ConnectionError: If not connected\n        FetchError: If message fetching fails\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.base.EmailProvider.get_folders","title":"<code>get_folders()</code>  <code>abstractmethod</code>","text":"<p>Get list of available folders.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of folder names</p> <p>Raises:</p> Type Description <code>ConnectionError</code> <p>If not connected</p> <code>FetchError</code> <p>If folder fetching fails</p> Source code in <code>ragora/ragora/utils/email_utils/base.py</code> <pre><code>@abstractmethod\ndef get_folders(self) -&gt; List[str]:\n    \"\"\"Get list of available folders.\n\n    Returns:\n        List of folder names\n\n    Raises:\n        ConnectionError: If not connected\n        FetchError: If folder fetching fails\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.base.EmailProvider.mark_as_read","title":"<code>mark_as_read(message_id)</code>  <code>abstractmethod</code>","text":"<p>Mark a message as read.</p> <p>Parameters:</p> Name Type Description Default <code>message_id</code> <code>str</code> <p>ID of the message to mark as read</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if message was marked as read successfully</p> <p>Raises:</p> Type Description <code>ConnectionError</code> <p>If not connected</p> <code>UpdateError</code> <p>If marking fails</p> Source code in <code>ragora/ragora/utils/email_utils/base.py</code> <pre><code>@abstractmethod\ndef mark_as_read(self, message_id: str) -&gt; bool:\n    \"\"\"Mark a message as read.\n\n    Args:\n        message_id: ID of the message to mark as read\n\n    Returns:\n        True if message was marked as read successfully\n\n    Raises:\n        ConnectionError: If not connected\n        UpdateError: If marking fails\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.base.EmailProvider.send_message","title":"<code>send_message(draft_id, folder='Drafts')</code>  <code>abstractmethod</code>","text":"<p>Send a draft message.</p> <p>Parameters:</p> Name Type Description Default <code>draft_id</code> <code>str</code> <p>ID of the draft to send</p> required <code>folder</code> <code>str</code> <p>Folder where the draft is stored (default: \"Drafts\")</p> <code>'Drafts'</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if message was sent successfully</p> <p>Raises:</p> Type Description <code>ConnectionError</code> <p>If not connected</p> <code>SendError</code> <p>If message sending fails</p> Source code in <code>ragora/ragora/utils/email_utils/base.py</code> <pre><code>@abstractmethod\ndef send_message(self, draft_id: str, folder: str = \"Drafts\") -&gt; bool:\n    \"\"\"Send a draft message.\n\n    Args:\n        draft_id: ID of the draft to send\n        folder: Folder where the draft is stored (default: \"Drafts\")\n\n    Returns:\n        True if message was sent successfully\n\n    Raises:\n        ConnectionError: If not connected\n        SendError: If message sending fails\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.base.EmailProvider.send_message_direct","title":"<code>send_message_direct(to, subject, body, cc=None, bcc=None, attachments=None)</code>  <code>abstractmethod</code>","text":"<p>Send a message directly without creating a draft.</p> <p>Parameters:</p> Name Type Description Default <code>to</code> <code>List[str]</code> <p>List of recipient email addresses</p> required <code>subject</code> <code>str</code> <p>Email subject line</p> required <code>body</code> <code>str</code> <p>Email body content (HTML or plain text)</p> required <code>cc</code> <code>Optional[List[str]]</code> <p>Optional list of CC recipient email addresses</p> <code>None</code> <code>bcc</code> <code>Optional[List[str]]</code> <p>Optional list of BCC recipient email addresses</p> <code>None</code> <code>attachments</code> <code>Optional[List[str]]</code> <p>Optional list of file paths to attach</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if message was sent successfully</p> <p>Raises:</p> Type Description <code>ConnectionError</code> <p>If not connected</p> <code>SendError</code> <p>If message sending fails</p> Source code in <code>ragora/ragora/utils/email_utils/base.py</code> <pre><code>@abstractmethod\ndef send_message_direct(\n    self,\n    to: List[str],\n    subject: str,\n    body: str,\n    cc: Optional[List[str]] = None,\n    bcc: Optional[List[str]] = None,\n    attachments: Optional[List[str]] = None,\n) -&gt; bool:\n    \"\"\"Send a message directly without creating a draft.\n\n    Args:\n        to: List of recipient email addresses\n        subject: Email subject line\n        body: Email body content (HTML or plain text)\n        cc: Optional list of CC recipient email addresses\n        bcc: Optional list of BCC recipient email addresses\n        attachments: Optional list of file paths to attach\n\n    Returns:\n        True if message was sent successfully\n\n    Raises:\n        ConnectionError: If not connected\n        SendError: If message sending fails\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.graph_provider.AuthenticationError","title":"<code>AuthenticationError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when authentication fails. Args:     message: The error message</p> Source code in <code>ragora/ragora/utils/email_utils/graph_provider.py</code> <pre><code>class AuthenticationError(Exception):\n    \"\"\"Raised when authentication fails.\n    Args:\n        message: The error message\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.graph_provider.GraphProvider","title":"<code>GraphProvider</code>","text":"<p>               Bases: <code>EmailProvider</code></p> <p>Microsoft Graph API email provider for Outlook/Office 365.</p> Source code in <code>ragora/ragora/utils/email_utils/graph_provider.py</code> <pre><code>class GraphProvider(EmailProvider):\n    \"\"\"Microsoft Graph API email provider for Outlook/Office 365.\"\"\"\n\n    BASE_URL = \"https://graph.microsoft.com/v1.0\"\n\n    def __init__(self, credentials: GraphCredentials):\n        \"\"\"Initialize Graph provider with credentials.\n\n        Args:\n            credentials: Microsoft Graph API credentials\n        \"\"\"\n        super().__init__(credentials)\n        self._access_token: Optional[str] = None\n        self._connected = False\n\n    def connect(self) -&gt; None:\n        \"\"\"Establish connection to Microsoft Graph API.\"\"\"\n        try:\n            if self.credentials.access_token:\n                # Use provided access token\n                self._access_token = self.credentials.access_token\n                # Verify token is valid\n                if self._verify_token():\n                    self._connected = True\n                    return\n                else:\n                    raise AuthenticationError(\"Invalid access token\")\n            else:\n                # Get access token using client credentials flow\n                self._get_access_token()\n                self._connected = True\n\n        except Exception as e:\n            self._connected = False\n            raise ConnectionError(f\"Failed to connect to Microsoft Graph: {str(e)}\")\n\n    def disconnect(self) -&gt; None:\n        \"\"\"Close connection to Microsoft Graph API.\"\"\"\n        self._access_token = None\n        self._connected = False\n\n    def _get_access_token(self) -&gt; None:\n        \"\"\"Get access token using client credentials flow.\"\"\"\n        token_url = f\"https://login.microsoftonline.com/{self.credentials.tenant_id}/oauth2/v2.0/token\"\n\n        data = {\n            \"client_id\": self.credentials.client_id,\n            \"client_secret\": self.credentials.client_secret,\n            \"scope\": \"https://graph.microsoft.com/.default\",\n            \"grant_type\": \"client_credentials\",\n        }\n\n        response = requests.post(token_url, data=data)\n        response.raise_for_status()\n\n        token_data = response.json()\n        self._access_token = token_data[\"access_token\"]\n\n    def _verify_token(self) -&gt; bool:\n        \"\"\"Verify if the access token is valid.\"\"\"\n        if not self._access_token:\n            return False\n\n        try:\n            headers = {\"Authorization\": f\"Bearer {self._access_token}\"}\n            response = requests.get(f\"{self.BASE_URL}/me\", headers=headers)\n            return response.status_code == 200\n        except Exception:\n            return False\n\n    def _make_request(\n        self, method: str, endpoint: str, data: Optional[Dict] = None\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Make authenticated request to Microsoft Graph API.\n        Args:\n            method: The HTTP method to use\n            endpoint: The endpoint to request\n            data: The data to send with the request\n        Returns:\n            Dictionary containing the response data\n        \"\"\"\n        if not self.is_connected:\n            raise ConnectionError(\"Not connected to Microsoft Graph\")\n\n        url = urljoin(self.BASE_URL, endpoint)\n        headers = {\n            \"Authorization\": f\"Bearer {self._access_token}\",\n            \"Content-Type\": \"application/json\",\n        }\n\n        try:\n            if method.upper() == \"GET\":\n                response = requests.get(url, headers=headers)\n            elif method.upper() == \"POST\":\n                response = requests.post(url, headers=headers, json=data)\n            elif method.upper() == \"PATCH\":\n                response = requests.patch(url, headers=headers, json=data)\n            elif method.upper() == \"DELETE\":\n                response = requests.delete(url, headers=headers)\n            else:\n                raise ValueError(f\"Unsupported HTTP method: {method}\")\n\n            response.raise_for_status()\n\n            if response.content:\n                return response.json()\n            return {}\n\n        except requests.exceptions.RequestException as e:\n            raise RuntimeError(f\"Graph API request failed: {str(e)}\")\n\n    def fetch_messages(\n        self, limit: int = 50, folder: Optional[str] = None, unread_only: bool = False\n    ) -&gt; List[EmailMessage]:\n        \"\"\"Fetch messages from Microsoft Graph API.\n        Args:\n            limit: The maximum number of messages to fetch\n            folder: The folder to search for messages\n            unread_only: Whether to only fetch unread messages\n        Returns:\n            List of EmailMessage objects\n        \"\"\"\n        try:\n            # Build endpoint\n            if folder:\n                endpoint = f\"/me/mailFolders/{folder}/messages\"\n            else:\n                endpoint = \"/me/messages\"\n\n            # Add query parameters\n            params = []\n            if limit &gt; 0:\n                params.append(f\"$top={limit}\")\n\n            if unread_only:\n                params.append(\"$filter=isRead eq false\")\n\n            # Add ordering\n            params.append(\"$orderby=receivedDateTime desc\")\n\n            if params:\n                endpoint += \"?\" + \"&amp;\".join(params)\n\n            response = self._make_request(\"GET\", endpoint)\n            messages_data = response.get(\"value\", [])\n\n            email_messages = []\n            for msg_data in messages_data:\n                try:\n                    email_msg = self._parse_graph_message(msg_data)\n                    if email_msg:\n                        email_messages.append(email_msg)\n                except Exception:\n                    # Skip problematic messages\n                    continue\n\n            return email_messages\n\n        except Exception as e:\n            raise RuntimeError(f\"Failed to fetch messages: {str(e)}\")\n\n    def fetch_message_by_id(self, message_id: str) -&gt; Optional[EmailMessage]:\n        \"\"\"Fetch a specific message by its ID.\n        Args:\n            message_id: The ID of the message to fetch\n        Returns:\n            EmailMessage object if the message was found, None otherwise\n        \"\"\"\n        try:\n            endpoint = f\"/me/messages/{message_id}\"\n            response = self._make_request(\"GET\", endpoint)\n\n            return self._parse_graph_message(response)\n\n        except Exception as e:\n            if \"404\" in str(e):\n                return None\n            raise RuntimeError(f\"Failed to fetch message {message_id}: {str(e)}\")\n\n    def _parse_graph_message(self, msg_data: Dict[str, Any]) -&gt; Optional[EmailMessage]:\n        \"\"\"Parse Microsoft Graph message data into EmailMessage object.\n        Args:\n            msg_data: The message data to parse\n        Returns:\n            EmailMessage object if the message was found, None otherwise\n        \"\"\"\n        try:\n            # Extract basic fields\n            message_id = msg_data.get(\"id\", \"\")\n            subject = msg_data.get(\"subject\", \"\")\n\n            # Parse sender\n            sender_info = msg_data.get(\"from\", {})\n            sender = EmailAddress(\n                email=sender_info.get(\"emailAddress\", {}).get(\"address\", \"\"),\n                name=sender_info.get(\"emailAddress\", {}).get(\"name\", \"\"),\n            )\n\n            # Parse recipients\n            to_recipients = []\n            for recipient in msg_data.get(\"toRecipients\", []):\n                to_recipients.append(\n                    EmailAddress(\n                        email=recipient.get(\"emailAddress\", {}).get(\"address\", \"\"),\n                        name=recipient.get(\"emailAddress\", {}).get(\"name\", \"\"),\n                    )\n                )\n\n            cc_recipients = []\n            for recipient in msg_data.get(\"ccRecipients\", []):\n                cc_recipients.append(\n                    EmailAddress(\n                        email=recipient.get(\"emailAddress\", {}).get(\"address\", \"\"),\n                        name=recipient.get(\"emailAddress\", {}).get(\"name\", \"\"),\n                    )\n                )\n\n            bcc_recipients = []\n            for recipient in msg_data.get(\"bccRecipients\", []):\n                bcc_recipients.append(\n                    EmailAddress(\n                        email=recipient.get(\"emailAddress\", {}).get(\"address\", \"\"),\n                        name=recipient.get(\"emailAddress\", {}).get(\"name\", \"\"),\n                    )\n                )\n\n            # Parse dates\n            date_sent = self._parse_graph_date(msg_data.get(\"sentDateTime\"))\n            date_received = self._parse_graph_date(msg_data.get(\"receivedDateTime\"))\n\n            # Extract body\n            body = msg_data.get(\"body\", {})\n            body_text = (\n                body.get(\"content\", \"\") if body.get(\"contentType\") == \"text\" else None\n            )\n            body_html = (\n                body.get(\"content\", \"\") if body.get(\"contentType\") == \"html\" else None\n            )\n\n            # Parse status\n            status = (\n                MessageStatus.READ\n                if msg_data.get(\"isRead\", False)\n                else MessageStatus.UNREAD\n            )\n\n            # Parse attachments\n            attachments = self._parse_graph_attachments(msg_data.get(\"attachments\", []))\n\n            # Get folder information\n            parent_folder_id = msg_data.get(\"parentFolderId\", \"\")\n\n            return EmailMessage(\n                message_id=message_id,\n                subject=subject,\n                sender=sender,\n                recipients=to_recipients,\n                cc_recipients=cc_recipients,\n                bcc_recipients=bcc_recipients,\n                body_text=body_text,\n                body_html=body_html,\n                date_sent=date_sent,\n                date_received=date_received,\n                status=status,\n                attachments=attachments,\n                folder=parent_folder_id,\n                metadata=msg_data,\n            )\n\n        except Exception:\n            return None\n\n    def _parse_graph_date(self, date_str: Optional[str]) -&gt; Optional[datetime]:\n        \"\"\"Parse Microsoft Graph date string.\n        Args:\n            date_str: The date string to parse\n        Returns:\n            datetime object if the date was parsed successfully, None otherwise\n        \"\"\"\n        if not date_str:\n            return None\n\n        try:\n            # Graph API returns ISO 8601 format\n            return datetime.fromisoformat(date_str.replace(\"Z\", \"+00:00\"))\n        except Exception:\n            return None\n\n    def _parse_graph_attachments(\n        self, attachments_data: List[Dict[str, Any]]\n    ) -&gt; List[EmailAttachment]:\n        \"\"\"Parse Microsoft Graph attachments.\n        Args:\n            attachments_data: The attachments data to parse\n        Returns:\n            List of EmailAttachment objects\n        \"\"\"\n        attachments = []\n\n        for attachment_data in attachments_data:\n            try:\n                filename = attachment_data.get(\"name\", \"\")\n                content_type = attachment_data.get(\n                    \"contentType\", \"application/octet-stream\"\n                )\n                size = attachment_data.get(\"size\", 0)\n\n                # Get attachment content if available\n                content = None\n                if \"contentBytes\" in attachment_data:\n                    content = base64.b64decode(attachment_data[\"contentBytes\"])\n\n                attachments.append(\n                    EmailAttachment(\n                        filename=filename,\n                        content_type=content_type,\n                        size=size,\n                        content=content,\n                        content_id=attachment_data.get(\"contentId\"),\n                    )\n                )\n\n            except Exception:\n                # Skip problematic attachments\n                continue\n\n        return attachments\n\n    def create_draft(\n        self,\n        to: List[str],\n        subject: str,\n        body: str,\n        cc: Optional[List[str]] = None,\n        bcc: Optional[List[str]] = None,\n        attachments: Optional[List[str]] = None,\n        folder: str = \"Drafts\",\n    ) -&gt; EmailDraft:\n        \"\"\"Create a draft message using Microsoft Graph API.\n        Args:\n            to: List of recipient email addresses\n            subject: Email subject line\n            body: Email body content (HTML or plain text)\n            cc: Optional list of CC recipient email addresses\n            bcc: Optional list of BCC recipient email addresses\n            attachments: Optional list of attachment file paths\n            folder: The folder to save the draft message\n        Returns:\n            EmailDraft object\n        \"\"\"\n        try:\n            # Prepare message data\n            message_data = {\n                \"subject\": subject,\n                \"body\": {\n                    \"contentType\": \"text\" if not body.startswith(\"&lt;\") else \"html\",\n                    \"content\": body,\n                },\n                \"toRecipients\": [{\"emailAddress\": {\"address\": addr}} for addr in to],\n            }\n\n            if cc:\n                message_data[\"ccRecipients\"] = [\n                    {\"emailAddress\": {\"address\": addr}} for addr in cc\n                ]\n\n            if bcc:\n                message_data[\"bccRecipients\"] = [\n                    {\"emailAddress\": {\"address\": addr}} for addr in bcc\n                ]\n\n            # Create draft\n            response = self._make_request(\"POST\", \"/me/messages\", message_data)\n\n            # Save as draft\n            draft_response = self._make_request(\n                \"POST\", f\"/me/messages/{response['id']}/save\", {}\n            )\n\n            draft_id = response[\"id\"]\n\n            # Parse recipients\n            to_addresses = [EmailAddress(addr) for addr in to]\n            cc_addresses = [EmailAddress(addr) for addr in (cc or [])]\n            bcc_addresses = [EmailAddress(addr) for addr in (bcc or [])]\n\n            # Process attachments\n            email_attachments = []\n            if attachments:\n                for file_path in attachments:\n                    try:\n                        with open(file_path, \"rb\") as f:\n                            content = f.read()\n\n                        attachment_data = {\n                            \"@odata.type\": \"#microsoft.graph.fileAttachment\",\n                            \"name\": file_path.split(\"/\")[-1],\n                            \"contentType\": \"application/octet-stream\",\n                            \"contentBytes\": base64.b64encode(content).decode(\"utf-8\"),\n                        }\n\n                        # Add attachment to draft\n                        self._make_request(\n                            \"POST\",\n                            f\"/me/messages/{draft_id}/attachments\",\n                            attachment_data,\n                        )\n\n                        email_attachments.append(\n                            EmailAttachment(\n                                filename=file_path.split(\"/\")[-1],\n                                content_type=\"application/octet-stream\",\n                                size=len(content),\n                                content=content,\n                            )\n                        )\n\n                    except Exception:\n                        # Skip problematic attachments\n                        continue\n\n            return EmailDraft(\n                draft_id=draft_id,\n                subject=subject,\n                recipients=to_addresses,\n                cc_recipients=cc_addresses,\n                bcc_recipients=bcc_addresses,\n                body_text=body,\n                attachments=email_attachments,\n                created_date=datetime.now(),\n                modified_date=datetime.now(),\n                metadata=response,\n            )\n\n        except Exception as e:\n            raise RuntimeError(f\"Failed to create draft: {str(e)}\")\n\n    def send_message(self, draft_id: str, folder: str = \"Drafts\") -&gt; bool:\n        \"\"\"Send a draft message.\n        Args:\n            draft_id: The ID of the draft message to send\n            folder: The folder to search for the draft message\n        Returns:\n            True if the draft message was sent successfully, False otherwise\n        \"\"\"\n        try:\n            self._make_request(\"POST\", f\"/me/messages/{draft_id}/send\")\n            return True\n\n        except Exception as e:\n            raise RuntimeError(f\"Failed to send message: {str(e)}\")\n\n    def send_message_direct(\n        self,\n        to: List[str],\n        subject: str,\n        body: str,\n        cc: Optional[List[str]] = None,\n        bcc: Optional[List[str]] = None,\n        attachments: Optional[List[str]] = None,\n    ) -&gt; bool:\n        \"\"\"Send a message directly via Microsoft Graph API.\n        Args:\n            to: List of recipient email addresses\n            subject: Email subject line\n            body: Email body content (HTML or plain text)\n            cc: Optional list of CC recipient email addresses\n            bcc: Optional list of BCC recipient email addresses\n            attachments: Optional list of attachment file paths\n        Returns:\n            True if the message was sent successfully, False otherwise\n        \"\"\"\n        try:\n            # Create draft first\n            draft = self.create_draft(to, subject, body, cc, bcc, attachments)\n\n            # Send the draft\n            return self.send_message(draft.draft_id)\n\n        except Exception as e:\n            raise RuntimeError(f\"Failed to send message directly: {str(e)}\")\n\n    def mark_as_read(self, message_id: str) -&gt; bool:\n        \"\"\"Mark a message as read.\n        Args:\n            message_id: The ID of the message to mark as read\n        Returns:\n            True if the message was marked as read successfully, False otherwise\n        \"\"\"\n        try:\n            update_data = {\"isRead\": True}\n            self._make_request(\"PATCH\", f\"/me/messages/{message_id}\", update_data)\n            return True\n\n        except Exception as e:\n            if \"404\" in str(e):\n                return False\n            raise RuntimeError(f\"Failed to mark message as read: {str(e)}\")\n\n    def get_folders(self) -&gt; List[str]:\n        \"\"\"Get list of available folders.\n        Returns:\n            List of available folders\n        \"\"\"\n        try:\n            response = self._make_request(\"GET\", \"/me/mailFolders\")\n            folders_data = response.get(\"value\", [])\n\n            folders = []\n            for folder_data in folders_data:\n                folders.append(folder_data.get(\"displayName\", \"\"))\n\n            return folders\n\n        except Exception as e:\n            raise RuntimeError(f\"Failed to get folders: {str(e)}\")\n\n    @property\n    def is_connected(self) -&gt; bool:\n        \"\"\"Check if connected to Microsoft Graph API.\n        Returns:\n            True if connected to Microsoft Graph API, False otherwise\n        \"\"\"\n        return self._connected and self._access_token is not None\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.graph_provider.GraphProvider.is_connected","title":"<code>is_connected</code>  <code>property</code>","text":"<p>Check if connected to Microsoft Graph API. Returns:     True if connected to Microsoft Graph API, False otherwise</p>"},{"location":"api-reference/#ragora.utils.email_utils.graph_provider.GraphProvider._get_access_token","title":"<code>_get_access_token()</code>","text":"<p>Get access token using client credentials flow.</p> Source code in <code>ragora/ragora/utils/email_utils/graph_provider.py</code> <pre><code>def _get_access_token(self) -&gt; None:\n    \"\"\"Get access token using client credentials flow.\"\"\"\n    token_url = f\"https://login.microsoftonline.com/{self.credentials.tenant_id}/oauth2/v2.0/token\"\n\n    data = {\n        \"client_id\": self.credentials.client_id,\n        \"client_secret\": self.credentials.client_secret,\n        \"scope\": \"https://graph.microsoft.com/.default\",\n        \"grant_type\": \"client_credentials\",\n    }\n\n    response = requests.post(token_url, data=data)\n    response.raise_for_status()\n\n    token_data = response.json()\n    self._access_token = token_data[\"access_token\"]\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.graph_provider.GraphProvider._make_request","title":"<code>_make_request(method, endpoint, data=None)</code>","text":"<p>Make authenticated request to Microsoft Graph API. Args:     method: The HTTP method to use     endpoint: The endpoint to request     data: The data to send with the request Returns:     Dictionary containing the response data</p> Source code in <code>ragora/ragora/utils/email_utils/graph_provider.py</code> <pre><code>def _make_request(\n    self, method: str, endpoint: str, data: Optional[Dict] = None\n) -&gt; Dict[str, Any]:\n    \"\"\"Make authenticated request to Microsoft Graph API.\n    Args:\n        method: The HTTP method to use\n        endpoint: The endpoint to request\n        data: The data to send with the request\n    Returns:\n        Dictionary containing the response data\n    \"\"\"\n    if not self.is_connected:\n        raise ConnectionError(\"Not connected to Microsoft Graph\")\n\n    url = urljoin(self.BASE_URL, endpoint)\n    headers = {\n        \"Authorization\": f\"Bearer {self._access_token}\",\n        \"Content-Type\": \"application/json\",\n    }\n\n    try:\n        if method.upper() == \"GET\":\n            response = requests.get(url, headers=headers)\n        elif method.upper() == \"POST\":\n            response = requests.post(url, headers=headers, json=data)\n        elif method.upper() == \"PATCH\":\n            response = requests.patch(url, headers=headers, json=data)\n        elif method.upper() == \"DELETE\":\n            response = requests.delete(url, headers=headers)\n        else:\n            raise ValueError(f\"Unsupported HTTP method: {method}\")\n\n        response.raise_for_status()\n\n        if response.content:\n            return response.json()\n        return {}\n\n    except requests.exceptions.RequestException as e:\n        raise RuntimeError(f\"Graph API request failed: {str(e)}\")\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.graph_provider.GraphProvider._parse_graph_attachments","title":"<code>_parse_graph_attachments(attachments_data)</code>","text":"<p>Parse Microsoft Graph attachments. Args:     attachments_data: The attachments data to parse Returns:     List of EmailAttachment objects</p> Source code in <code>ragora/ragora/utils/email_utils/graph_provider.py</code> <pre><code>def _parse_graph_attachments(\n    self, attachments_data: List[Dict[str, Any]]\n) -&gt; List[EmailAttachment]:\n    \"\"\"Parse Microsoft Graph attachments.\n    Args:\n        attachments_data: The attachments data to parse\n    Returns:\n        List of EmailAttachment objects\n    \"\"\"\n    attachments = []\n\n    for attachment_data in attachments_data:\n        try:\n            filename = attachment_data.get(\"name\", \"\")\n            content_type = attachment_data.get(\n                \"contentType\", \"application/octet-stream\"\n            )\n            size = attachment_data.get(\"size\", 0)\n\n            # Get attachment content if available\n            content = None\n            if \"contentBytes\" in attachment_data:\n                content = base64.b64decode(attachment_data[\"contentBytes\"])\n\n            attachments.append(\n                EmailAttachment(\n                    filename=filename,\n                    content_type=content_type,\n                    size=size,\n                    content=content,\n                    content_id=attachment_data.get(\"contentId\"),\n                )\n            )\n\n        except Exception:\n            # Skip problematic attachments\n            continue\n\n    return attachments\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.graph_provider.GraphProvider._parse_graph_date","title":"<code>_parse_graph_date(date_str)</code>","text":"<p>Parse Microsoft Graph date string. Args:     date_str: The date string to parse Returns:     datetime object if the date was parsed successfully, None otherwise</p> Source code in <code>ragora/ragora/utils/email_utils/graph_provider.py</code> <pre><code>def _parse_graph_date(self, date_str: Optional[str]) -&gt; Optional[datetime]:\n    \"\"\"Parse Microsoft Graph date string.\n    Args:\n        date_str: The date string to parse\n    Returns:\n        datetime object if the date was parsed successfully, None otherwise\n    \"\"\"\n    if not date_str:\n        return None\n\n    try:\n        # Graph API returns ISO 8601 format\n        return datetime.fromisoformat(date_str.replace(\"Z\", \"+00:00\"))\n    except Exception:\n        return None\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.graph_provider.GraphProvider._parse_graph_message","title":"<code>_parse_graph_message(msg_data)</code>","text":"<p>Parse Microsoft Graph message data into EmailMessage object. Args:     msg_data: The message data to parse Returns:     EmailMessage object if the message was found, None otherwise</p> Source code in <code>ragora/ragora/utils/email_utils/graph_provider.py</code> <pre><code>def _parse_graph_message(self, msg_data: Dict[str, Any]) -&gt; Optional[EmailMessage]:\n    \"\"\"Parse Microsoft Graph message data into EmailMessage object.\n    Args:\n        msg_data: The message data to parse\n    Returns:\n        EmailMessage object if the message was found, None otherwise\n    \"\"\"\n    try:\n        # Extract basic fields\n        message_id = msg_data.get(\"id\", \"\")\n        subject = msg_data.get(\"subject\", \"\")\n\n        # Parse sender\n        sender_info = msg_data.get(\"from\", {})\n        sender = EmailAddress(\n            email=sender_info.get(\"emailAddress\", {}).get(\"address\", \"\"),\n            name=sender_info.get(\"emailAddress\", {}).get(\"name\", \"\"),\n        )\n\n        # Parse recipients\n        to_recipients = []\n        for recipient in msg_data.get(\"toRecipients\", []):\n            to_recipients.append(\n                EmailAddress(\n                    email=recipient.get(\"emailAddress\", {}).get(\"address\", \"\"),\n                    name=recipient.get(\"emailAddress\", {}).get(\"name\", \"\"),\n                )\n            )\n\n        cc_recipients = []\n        for recipient in msg_data.get(\"ccRecipients\", []):\n            cc_recipients.append(\n                EmailAddress(\n                    email=recipient.get(\"emailAddress\", {}).get(\"address\", \"\"),\n                    name=recipient.get(\"emailAddress\", {}).get(\"name\", \"\"),\n                )\n            )\n\n        bcc_recipients = []\n        for recipient in msg_data.get(\"bccRecipients\", []):\n            bcc_recipients.append(\n                EmailAddress(\n                    email=recipient.get(\"emailAddress\", {}).get(\"address\", \"\"),\n                    name=recipient.get(\"emailAddress\", {}).get(\"name\", \"\"),\n                )\n            )\n\n        # Parse dates\n        date_sent = self._parse_graph_date(msg_data.get(\"sentDateTime\"))\n        date_received = self._parse_graph_date(msg_data.get(\"receivedDateTime\"))\n\n        # Extract body\n        body = msg_data.get(\"body\", {})\n        body_text = (\n            body.get(\"content\", \"\") if body.get(\"contentType\") == \"text\" else None\n        )\n        body_html = (\n            body.get(\"content\", \"\") if body.get(\"contentType\") == \"html\" else None\n        )\n\n        # Parse status\n        status = (\n            MessageStatus.READ\n            if msg_data.get(\"isRead\", False)\n            else MessageStatus.UNREAD\n        )\n\n        # Parse attachments\n        attachments = self._parse_graph_attachments(msg_data.get(\"attachments\", []))\n\n        # Get folder information\n        parent_folder_id = msg_data.get(\"parentFolderId\", \"\")\n\n        return EmailMessage(\n            message_id=message_id,\n            subject=subject,\n            sender=sender,\n            recipients=to_recipients,\n            cc_recipients=cc_recipients,\n            bcc_recipients=bcc_recipients,\n            body_text=body_text,\n            body_html=body_html,\n            date_sent=date_sent,\n            date_received=date_received,\n            status=status,\n            attachments=attachments,\n            folder=parent_folder_id,\n            metadata=msg_data,\n        )\n\n    except Exception:\n        return None\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.graph_provider.GraphProvider._verify_token","title":"<code>_verify_token()</code>","text":"<p>Verify if the access token is valid.</p> Source code in <code>ragora/ragora/utils/email_utils/graph_provider.py</code> <pre><code>def _verify_token(self) -&gt; bool:\n    \"\"\"Verify if the access token is valid.\"\"\"\n    if not self._access_token:\n        return False\n\n    try:\n        headers = {\"Authorization\": f\"Bearer {self._access_token}\"}\n        response = requests.get(f\"{self.BASE_URL}/me\", headers=headers)\n        return response.status_code == 200\n    except Exception:\n        return False\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.graph_provider.GraphProvider.connect","title":"<code>connect()</code>","text":"<p>Establish connection to Microsoft Graph API.</p> Source code in <code>ragora/ragora/utils/email_utils/graph_provider.py</code> <pre><code>def connect(self) -&gt; None:\n    \"\"\"Establish connection to Microsoft Graph API.\"\"\"\n    try:\n        if self.credentials.access_token:\n            # Use provided access token\n            self._access_token = self.credentials.access_token\n            # Verify token is valid\n            if self._verify_token():\n                self._connected = True\n                return\n            else:\n                raise AuthenticationError(\"Invalid access token\")\n        else:\n            # Get access token using client credentials flow\n            self._get_access_token()\n            self._connected = True\n\n    except Exception as e:\n        self._connected = False\n        raise ConnectionError(f\"Failed to connect to Microsoft Graph: {str(e)}\")\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.graph_provider.GraphProvider.create_draft","title":"<code>create_draft(to, subject, body, cc=None, bcc=None, attachments=None, folder='Drafts')</code>","text":"<p>Create a draft message using Microsoft Graph API. Args:     to: List of recipient email addresses     subject: Email subject line     body: Email body content (HTML or plain text)     cc: Optional list of CC recipient email addresses     bcc: Optional list of BCC recipient email addresses     attachments: Optional list of attachment file paths     folder: The folder to save the draft message Returns:     EmailDraft object</p> Source code in <code>ragora/ragora/utils/email_utils/graph_provider.py</code> <pre><code>def create_draft(\n    self,\n    to: List[str],\n    subject: str,\n    body: str,\n    cc: Optional[List[str]] = None,\n    bcc: Optional[List[str]] = None,\n    attachments: Optional[List[str]] = None,\n    folder: str = \"Drafts\",\n) -&gt; EmailDraft:\n    \"\"\"Create a draft message using Microsoft Graph API.\n    Args:\n        to: List of recipient email addresses\n        subject: Email subject line\n        body: Email body content (HTML or plain text)\n        cc: Optional list of CC recipient email addresses\n        bcc: Optional list of BCC recipient email addresses\n        attachments: Optional list of attachment file paths\n        folder: The folder to save the draft message\n    Returns:\n        EmailDraft object\n    \"\"\"\n    try:\n        # Prepare message data\n        message_data = {\n            \"subject\": subject,\n            \"body\": {\n                \"contentType\": \"text\" if not body.startswith(\"&lt;\") else \"html\",\n                \"content\": body,\n            },\n            \"toRecipients\": [{\"emailAddress\": {\"address\": addr}} for addr in to],\n        }\n\n        if cc:\n            message_data[\"ccRecipients\"] = [\n                {\"emailAddress\": {\"address\": addr}} for addr in cc\n            ]\n\n        if bcc:\n            message_data[\"bccRecipients\"] = [\n                {\"emailAddress\": {\"address\": addr}} for addr in bcc\n            ]\n\n        # Create draft\n        response = self._make_request(\"POST\", \"/me/messages\", message_data)\n\n        # Save as draft\n        draft_response = self._make_request(\n            \"POST\", f\"/me/messages/{response['id']}/save\", {}\n        )\n\n        draft_id = response[\"id\"]\n\n        # Parse recipients\n        to_addresses = [EmailAddress(addr) for addr in to]\n        cc_addresses = [EmailAddress(addr) for addr in (cc or [])]\n        bcc_addresses = [EmailAddress(addr) for addr in (bcc or [])]\n\n        # Process attachments\n        email_attachments = []\n        if attachments:\n            for file_path in attachments:\n                try:\n                    with open(file_path, \"rb\") as f:\n                        content = f.read()\n\n                    attachment_data = {\n                        \"@odata.type\": \"#microsoft.graph.fileAttachment\",\n                        \"name\": file_path.split(\"/\")[-1],\n                        \"contentType\": \"application/octet-stream\",\n                        \"contentBytes\": base64.b64encode(content).decode(\"utf-8\"),\n                    }\n\n                    # Add attachment to draft\n                    self._make_request(\n                        \"POST\",\n                        f\"/me/messages/{draft_id}/attachments\",\n                        attachment_data,\n                    )\n\n                    email_attachments.append(\n                        EmailAttachment(\n                            filename=file_path.split(\"/\")[-1],\n                            content_type=\"application/octet-stream\",\n                            size=len(content),\n                            content=content,\n                        )\n                    )\n\n                except Exception:\n                    # Skip problematic attachments\n                    continue\n\n        return EmailDraft(\n            draft_id=draft_id,\n            subject=subject,\n            recipients=to_addresses,\n            cc_recipients=cc_addresses,\n            bcc_recipients=bcc_addresses,\n            body_text=body,\n            attachments=email_attachments,\n            created_date=datetime.now(),\n            modified_date=datetime.now(),\n            metadata=response,\n        )\n\n    except Exception as e:\n        raise RuntimeError(f\"Failed to create draft: {str(e)}\")\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.graph_provider.GraphProvider.disconnect","title":"<code>disconnect()</code>","text":"<p>Close connection to Microsoft Graph API.</p> Source code in <code>ragora/ragora/utils/email_utils/graph_provider.py</code> <pre><code>def disconnect(self) -&gt; None:\n    \"\"\"Close connection to Microsoft Graph API.\"\"\"\n    self._access_token = None\n    self._connected = False\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.graph_provider.GraphProvider.fetch_message_by_id","title":"<code>fetch_message_by_id(message_id)</code>","text":"<p>Fetch a specific message by its ID. Args:     message_id: The ID of the message to fetch Returns:     EmailMessage object if the message was found, None otherwise</p> Source code in <code>ragora/ragora/utils/email_utils/graph_provider.py</code> <pre><code>def fetch_message_by_id(self, message_id: str) -&gt; Optional[EmailMessage]:\n    \"\"\"Fetch a specific message by its ID.\n    Args:\n        message_id: The ID of the message to fetch\n    Returns:\n        EmailMessage object if the message was found, None otherwise\n    \"\"\"\n    try:\n        endpoint = f\"/me/messages/{message_id}\"\n        response = self._make_request(\"GET\", endpoint)\n\n        return self._parse_graph_message(response)\n\n    except Exception as e:\n        if \"404\" in str(e):\n            return None\n        raise RuntimeError(f\"Failed to fetch message {message_id}: {str(e)}\")\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.graph_provider.GraphProvider.fetch_messages","title":"<code>fetch_messages(limit=50, folder=None, unread_only=False)</code>","text":"<p>Fetch messages from Microsoft Graph API. Args:     limit: The maximum number of messages to fetch     folder: The folder to search for messages     unread_only: Whether to only fetch unread messages Returns:     List of EmailMessage objects</p> Source code in <code>ragora/ragora/utils/email_utils/graph_provider.py</code> <pre><code>def fetch_messages(\n    self, limit: int = 50, folder: Optional[str] = None, unread_only: bool = False\n) -&gt; List[EmailMessage]:\n    \"\"\"Fetch messages from Microsoft Graph API.\n    Args:\n        limit: The maximum number of messages to fetch\n        folder: The folder to search for messages\n        unread_only: Whether to only fetch unread messages\n    Returns:\n        List of EmailMessage objects\n    \"\"\"\n    try:\n        # Build endpoint\n        if folder:\n            endpoint = f\"/me/mailFolders/{folder}/messages\"\n        else:\n            endpoint = \"/me/messages\"\n\n        # Add query parameters\n        params = []\n        if limit &gt; 0:\n            params.append(f\"$top={limit}\")\n\n        if unread_only:\n            params.append(\"$filter=isRead eq false\")\n\n        # Add ordering\n        params.append(\"$orderby=receivedDateTime desc\")\n\n        if params:\n            endpoint += \"?\" + \"&amp;\".join(params)\n\n        response = self._make_request(\"GET\", endpoint)\n        messages_data = response.get(\"value\", [])\n\n        email_messages = []\n        for msg_data in messages_data:\n            try:\n                email_msg = self._parse_graph_message(msg_data)\n                if email_msg:\n                    email_messages.append(email_msg)\n            except Exception:\n                # Skip problematic messages\n                continue\n\n        return email_messages\n\n    except Exception as e:\n        raise RuntimeError(f\"Failed to fetch messages: {str(e)}\")\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.graph_provider.GraphProvider.get_folders","title":"<code>get_folders()</code>","text":"<p>Get list of available folders. Returns:     List of available folders</p> Source code in <code>ragora/ragora/utils/email_utils/graph_provider.py</code> <pre><code>def get_folders(self) -&gt; List[str]:\n    \"\"\"Get list of available folders.\n    Returns:\n        List of available folders\n    \"\"\"\n    try:\n        response = self._make_request(\"GET\", \"/me/mailFolders\")\n        folders_data = response.get(\"value\", [])\n\n        folders = []\n        for folder_data in folders_data:\n            folders.append(folder_data.get(\"displayName\", \"\"))\n\n        return folders\n\n    except Exception as e:\n        raise RuntimeError(f\"Failed to get folders: {str(e)}\")\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.graph_provider.GraphProvider.mark_as_read","title":"<code>mark_as_read(message_id)</code>","text":"<p>Mark a message as read. Args:     message_id: The ID of the message to mark as read Returns:     True if the message was marked as read successfully, False otherwise</p> Source code in <code>ragora/ragora/utils/email_utils/graph_provider.py</code> <pre><code>def mark_as_read(self, message_id: str) -&gt; bool:\n    \"\"\"Mark a message as read.\n    Args:\n        message_id: The ID of the message to mark as read\n    Returns:\n        True if the message was marked as read successfully, False otherwise\n    \"\"\"\n    try:\n        update_data = {\"isRead\": True}\n        self._make_request(\"PATCH\", f\"/me/messages/{message_id}\", update_data)\n        return True\n\n    except Exception as e:\n        if \"404\" in str(e):\n            return False\n        raise RuntimeError(f\"Failed to mark message as read: {str(e)}\")\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.graph_provider.GraphProvider.send_message","title":"<code>send_message(draft_id, folder='Drafts')</code>","text":"<p>Send a draft message. Args:     draft_id: The ID of the draft message to send     folder: The folder to search for the draft message Returns:     True if the draft message was sent successfully, False otherwise</p> Source code in <code>ragora/ragora/utils/email_utils/graph_provider.py</code> <pre><code>def send_message(self, draft_id: str, folder: str = \"Drafts\") -&gt; bool:\n    \"\"\"Send a draft message.\n    Args:\n        draft_id: The ID of the draft message to send\n        folder: The folder to search for the draft message\n    Returns:\n        True if the draft message was sent successfully, False otherwise\n    \"\"\"\n    try:\n        self._make_request(\"POST\", f\"/me/messages/{draft_id}/send\")\n        return True\n\n    except Exception as e:\n        raise RuntimeError(f\"Failed to send message: {str(e)}\")\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.graph_provider.GraphProvider.send_message_direct","title":"<code>send_message_direct(to, subject, body, cc=None, bcc=None, attachments=None)</code>","text":"<p>Send a message directly via Microsoft Graph API. Args:     to: List of recipient email addresses     subject: Email subject line     body: Email body content (HTML or plain text)     cc: Optional list of CC recipient email addresses     bcc: Optional list of BCC recipient email addresses     attachments: Optional list of attachment file paths Returns:     True if the message was sent successfully, False otherwise</p> Source code in <code>ragora/ragora/utils/email_utils/graph_provider.py</code> <pre><code>def send_message_direct(\n    self,\n    to: List[str],\n    subject: str,\n    body: str,\n    cc: Optional[List[str]] = None,\n    bcc: Optional[List[str]] = None,\n    attachments: Optional[List[str]] = None,\n) -&gt; bool:\n    \"\"\"Send a message directly via Microsoft Graph API.\n    Args:\n        to: List of recipient email addresses\n        subject: Email subject line\n        body: Email body content (HTML or plain text)\n        cc: Optional list of CC recipient email addresses\n        bcc: Optional list of BCC recipient email addresses\n        attachments: Optional list of attachment file paths\n    Returns:\n        True if the message was sent successfully, False otherwise\n    \"\"\"\n    try:\n        # Create draft first\n        draft = self.create_draft(to, subject, body, cc, bcc, attachments)\n\n        # Send the draft\n        return self.send_message(draft.draft_id)\n\n    except Exception as e:\n        raise RuntimeError(f\"Failed to send message directly: {str(e)}\")\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.imap_provider.IMAPProvider","title":"<code>IMAPProvider</code>","text":"<p>               Bases: <code>EmailProvider</code></p> <p>IMAP/SMTP email provider for generic email servers.</p> Source code in <code>ragora/ragora/utils/email_utils/imap_provider.py</code> <pre><code>class IMAPProvider(EmailProvider):\n    \"\"\"IMAP/SMTP email provider for generic email servers.\"\"\"\n\n    def __init__(self, credentials: IMAPCredentials):\n        \"\"\"Initialize IMAP provider with credentials.\n\n        Args:\n            credentials: IMAP/SMTP server credentials\n        \"\"\"\n        super().__init__(credentials)\n        self._imap_client: Optional[imaplib.IMAP4_SSL] = None\n        self._smtp_client: Optional[smtplib.SMTP] = None\n        self._connected = False\n\n    def connect(self) -&gt; None:\n        \"\"\"Establish connection to IMAP and SMTP servers.\"\"\"\n        try:\n            # Connect to IMAP server\n            if self.credentials.use_ssl:\n                self._imap_client = imaplib.IMAP4_SSL(\n                    self.credentials.imap_server, self.credentials.imap_port\n                )\n            else:\n                self._imap_client = imaplib.IMAP4(\n                    self.credentials.imap_server, self.credentials.imap_port\n                )\n                if self.credentials.use_tls:\n                    self._imap_client.starttls()\n\n            # Login to IMAP\n            self._imap_client.login(\n                self.credentials.username, self.credentials.password\n            )\n\n            # Connect to SMTP server\n            if self.credentials.use_ssl:\n                self._smtp_client = smtplib.SMTP_SSL(\n                    self.credentials.smtp_server, self.credentials.smtp_port\n                )\n            else:\n                self._smtp_client = smtplib.SMTP(\n                    self.credentials.smtp_server, self.credentials.smtp_port\n                )\n                if self.credentials.use_tls:\n                    self._smtp_client.starttls()\n\n            self._smtp_client.login(\n                self.credentials.username, self.credentials.password\n            )\n\n            self._connected = True\n\n        except Exception as e:\n            self._connected = False\n            raise ConnectionError(f\"Failed to connect to email servers: {str(e)}\")\n\n    def disconnect(self) -&gt; None:\n        \"\"\"Close connections to IMAP and SMTP servers.\"\"\"\n        try:\n            if self._imap_client:\n                self._imap_client.close()\n                self._imap_client.logout()\n                self._imap_client = None\n\n            if self._smtp_client:\n                self._smtp_client.quit()\n                self._smtp_client = None\n\n            self._connected = False\n\n        except Exception:\n            # Ignore errors during disconnect\n            pass\n\n    def fetch_messages(\n        self,\n        limit: Optional[int] = None,\n        folder: Optional[str] = None,\n        unread_only: bool = False,\n    ) -&gt; List[EmailMessage]:\n        \"\"\"Fetch messages from IMAP server.\n        Args:\n            limit: The maximum number of messages to fetch\n            folder: The folder to search for messages\n            unread_only: Whether to only fetch unread messages\n        Returns:\n            List of EmailMessage objects\n        \"\"\"\n        if not self.is_connected:\n            raise ConnectionError(\"Not connected to IMAP server\")\n\n        try:\n            # Select folder (default to INBOX)\n            folder_name = folder or \"INBOX\"\n            self._imap_client.select(folder_name)\n\n            # Build search criteria\n            search_criteria = \"ALL\"\n            if unread_only:\n                search_criteria = \"UNSEEN\"\n\n            # Search for messages\n            status, messages = self._imap_client.search(None, search_criteria)\n            if status != \"OK\":\n                raise RuntimeError(\"Failed to search messages\")\n\n            message_ids = messages[0].split()\n            message_ids = (\n                message_ids[-limit:] if limit is not None and limit &gt; 0 else message_ids\n            )\n\n            email_messages = []\n            for msg_id in message_ids:\n                try:\n                    email_msg = self._fetch_single_message(msg_id)\n                    if email_msg:\n                        email_messages.append(email_msg)\n                except Exception as e:\n                    # Skip problematic messages\n                    continue\n\n            return email_messages\n\n        except Exception as e:\n            raise RuntimeError(f\"Failed to fetch messages: {str(e)}\")\n\n    def fetch_message_by_id(self, message_id: str) -&gt; Optional[EmailMessage]:\n        \"\"\"Fetch a specific message by its ID.\n        Args:\n            message_id: The ID of the message to fetch\n        Returns:\n            EmailMessage object if the message was found, None otherwise\n        \"\"\"\n        if not self.is_connected:\n            raise ConnectionError(\"Not connected to IMAP server\")\n\n        try:\n            # Search for the specific message ID\n            status, messages = self._imap_client.search(\n                None, f'HEADER Message-ID \"{message_id}\"'\n            )\n            if status != \"OK\" or not messages[0]:\n                return None\n\n            msg_ids = messages[0].split()\n            if not msg_ids:\n                return None\n\n            return self._fetch_single_message(msg_ids[0])\n\n        except Exception as e:\n            raise RuntimeError(f\"Failed to fetch message {message_id}: {str(e)}\")\n\n    def _fetch_single_message(self, msg_id: bytes) -&gt; Optional[EmailMessage]:\n        \"\"\"Fetch and parse a single message.\n        Args:\n            msg_id: The ID of the message to fetch\n        Returns:\n            EmailMessage object if the message was found, None otherwise\n        \"\"\"\n        try:\n            status, msg_data = self._imap_client.fetch(msg_id, \"(RFC822)\")\n            if status != \"OK\":\n                return None\n\n            raw_email = msg_data[0][1]\n            email_message = email.message_from_bytes(raw_email)\n\n            return self._parse_email_message(email_message, msg_id.decode())\n\n        except Exception:\n            return None\n\n    def _parse_email_message(\n        self, email_msg: email.message.Message, msg_id: str\n    ) -&gt; EmailMessage:\n        \"\"\"Parse email.message.Message into EmailMessage object.\n        Args:\n            email_msg: The email.message.Message object to parse\n            msg_id: The ID of the message\n        Returns:\n            EmailMessage object\n        \"\"\"\n        # Extract headers\n        subject = self._decode_header(email_msg.get(\"Subject\", \"\"))\n        sender = self._parse_address(email_msg.get(\"From\", \"\"))\n\n        # Parse recipients\n        to_addresses = self._parse_address_list(email_msg.get(\"To\", \"\"))\n        cc_addresses = self._parse_address_list(email_msg.get(\"Cc\", \"\"))\n        bcc_addresses = self._parse_address_list(email_msg.get(\"Bcc\", \"\"))\n\n        # Parse dates\n        date_sent = self._parse_date(email_msg.get(\"Date\"))\n\n        # Extract body\n        body_text, body_html = self._extract_body(email_msg)\n\n        # Extract attachments\n        attachments = self._extract_attachments(email_msg)\n\n        # Determine status\n        status = MessageStatus.READ if email_msg.get(\"X-Seen\") else MessageStatus.UNREAD\n\n        return EmailMessage(\n            message_id=email_msg.get(\"Message-ID\", msg_id),\n            subject=subject,\n            sender=sender,\n            recipients=to_addresses,\n            cc_recipients=cc_addresses,\n            bcc_recipients=bcc_addresses,\n            body_text=body_text,\n            body_html=body_html,\n            date_sent=date_sent,\n            date_received=datetime.now(),\n            status=status,\n            attachments=attachments,\n        )\n\n    def _decode_header(self, header: str) -&gt; str:\n        \"\"\"Decode email header.\n        Args:\n            header: The email header to decode\n        Returns:\n            Decoded email header\n        \"\"\"\n        if not header:\n            return \"\"\n\n        decoded_parts = decode_header(header)\n        decoded_string = \"\"\n\n        for part, encoding in decoded_parts:\n            if isinstance(part, bytes):\n                if encoding:\n                    decoded_string += part.decode(encoding)\n                else:\n                    decoded_string += part.decode(\"utf-8\", errors=\"ignore\")\n            else:\n                decoded_string += part\n\n        return decoded_string\n\n    def _parse_address(self, address_str: str) -&gt; EmailAddress:\n        \"\"\"Parse a single email address.\n        Args:\n            address_str: The email address to parse\n        Returns:\n            EmailAddress object\n        \"\"\"\n        if not address_str:\n            return EmailAddress(\"\")\n\n        decoded = self._decode_header(address_str)\n\n        # Simple parsing - could be improved with proper email parsing library\n        if \"&lt;\" in decoded and \"&gt;\" in decoded:\n            name_part = decoded.split(\"&lt;\")[0].strip()\n            email_part = decoded.split(\"&lt;\")[1].split(\"&gt;\")[0].strip()\n            return EmailAddress(email_part, name_part if name_part else None)\n        else:\n            return EmailAddress(decoded.strip())\n\n    def _parse_address_list(self, address_list: str) -&gt; List[EmailAddress]:\n        \"\"\"Parse a list of email addresses.\n        Args:\n            address_list: The list of email addresses to parse\n        Returns:\n            List of EmailAddress objects\n        \"\"\"\n        if not address_list:\n            return []\n\n        addresses = []\n        for addr in address_list.split(\",\"):\n            addr = addr.strip()\n            if addr:\n                addresses.append(self._parse_address(addr))\n\n        return addresses\n\n    def _parse_date(self, date_str: Optional[str]) -&gt; Optional[datetime]:\n        \"\"\"Parse email date string.\n        Args:\n            date_str: The email date string to parse\n        Returns:\n            datetime object if the date was parsed successfully, None otherwise\n        \"\"\"\n        if not date_str:\n            return None\n\n        try:\n            # Try parsing with email.utils.parsedate_to_datetime\n            return email.utils.parsedate_to_datetime(date_str)\n        except Exception:\n            return None\n\n    def _extract_body(\n        self, email_msg: email.message.Message\n    ) -&gt; tuple[Optional[str], Optional[str]]:\n        \"\"\"Extract text and HTML body from email message.\n        Args:\n            email_msg: The email.message.Message object to extract the body from\n        Returns:\n            Tuple of text and HTML body\n        \"\"\"\n        body_text = None\n        body_html = None\n\n        if email_msg.is_multipart():\n            for part in email_msg.walk():\n                content_type = part.get_content_type()\n                content_disposition = str(part.get(\"Content-Disposition\"))\n\n                # Skip attachments\n                if \"attachment\" in content_disposition:\n                    continue\n\n                if content_type == \"text/plain\" and not body_text:\n                    body_text = part.get_payload(decode=True).decode(\n                        \"utf-8\", errors=\"ignore\"\n                    )\n                elif content_type == \"text/html\" and not body_html:\n                    body_html = part.get_payload(decode=True).decode(\n                        \"utf-8\", errors=\"ignore\"\n                    )\n        else:\n            content_type = email_msg.get_content_type()\n            payload = email_msg.get_payload(decode=True)\n\n            if payload:\n                decoded_payload = payload.decode(\"utf-8\", errors=\"ignore\")\n                if content_type == \"text/plain\":\n                    body_text = decoded_payload\n                elif content_type == \"text/html\":\n                    body_html = decoded_payload\n\n        return body_text, body_html\n\n    def _extract_attachments(\n        self, email_msg: email.message.Message\n    ) -&gt; List[EmailAttachment]:\n        \"\"\"Extract attachments from email message.\"\"\"\n        attachments = []\n\n        if email_msg.is_multipart():\n            for part in email_msg.walk():\n                content_disposition = str(part.get(\"Content-Disposition\"))\n\n                if \"attachment\" in content_disposition:\n                    filename = part.get_filename()\n                    if filename:\n                        filename = self._decode_header(filename)\n\n                        content_type = part.get_content_type()\n                        content = part.get_payload(decode=True)\n\n                        attachments.append(\n                            EmailAttachment(\n                                filename=filename,\n                                content_type=content_type,\n                                size=len(content) if content else 0,\n                                content=content,\n                                content_id=part.get(\"Content-ID\"),\n                            )\n                        )\n\n        return attachments\n\n    def _create_draft_message(\n        self,\n        to: List[str],\n        subject: str,\n        body: str,\n        cc: Optional[List[str]],\n        bcc: Optional[List[str]],\n        attachments: Optional[List[str]],\n        draft_id: str,\n    ) -&gt; str:\n        \"\"\"Create a properly formatted draft message for IMAP APPEND.\n        Args:\n            to: List of recipient email addresses\n            subject: Email subject line\n            body: Email body content (HTML or plain text)\n            cc: Optional list of CC recipient email addresses\n            bcc: Optional list of BCC recipient email addresses\n            attachments: Optional list of attachment file paths\n        Returns:\n            String representation of the draft message\n        \"\"\"\n        # Create the message structure\n        msg = MIMEMultipart()\n\n        # Set headers\n        msg[\"From\"] = self.credentials.username\n        msg[\"To\"] = \", \".join(to)\n        msg[\"Subject\"] = subject\n        msg[\"Message-ID\"] = f\"&lt;{draft_id}@draft&gt;\"\n        msg[\"Date\"] = email.utils.formatdate(localtime=True)\n\n        if cc:\n            msg[\"Cc\"] = \", \".join(cc)\n        if bcc:\n            msg[\"Bcc\"] = \", \".join(bcc)\n\n        # Add body\n        msg.attach(MIMEText(body, \"plain\"))\n\n        # Add attachments\n        if attachments:\n            for file_path in attachments:\n                if os.path.exists(file_path):\n                    with open(file_path, \"rb\") as attachment:\n                        part = MIMEApplication(\n                            attachment.read(), Name=Path(file_path).name\n                        )\n                        part[\"Content-Disposition\"] = (\n                            f'attachment; filename=\"{Path(file_path).name}\"'\n                        )\n                        msg.attach(part)\n\n        return msg.as_string()\n\n    def _create_local_draft(\n        self,\n        to: List[str],\n        subject: str,\n        body: str,\n        cc: Optional[List[str]],\n        bcc: Optional[List[str]],\n        attachments: Optional[List[str]],\n    ) -&gt; EmailDraft:\n        \"\"\"Create a local draft without storing on server.\n        Args:\n            to: List of recipient email addresses\n            subject: Email subject line\n            body: Email body content (HTML or plain text)\n            cc: Optional list of CC recipient email addresses\n            bcc: Optional list of BCC recipient email addresses\n            attachments: Optional list of attachment file paths\n        Returns:\n            EmailDraft object\n        \"\"\"\n        draft_id = f\"draft_{datetime.now().timestamp()}\"\n\n        # Parse recipients\n        to_addresses = [EmailAddress(addr) for addr in to]\n        cc_addresses = [EmailAddress(addr) for addr in (cc or [])]\n        bcc_addresses = [EmailAddress(addr) for addr in (bcc or [])]\n\n        # Process attachments\n        email_attachments = []\n        if attachments:\n            for file_path in attachments:\n                if os.path.exists(file_path):\n                    with open(file_path, \"rb\") as f:\n                        content = f.read()\n\n                    email_attachments.append(\n                        EmailAttachment(\n                            filename=Path(file_path).name,\n                            content_type=\"application/octet-stream\",\n                            size=len(content),\n                            content=content,\n                        )\n                    )\n\n        return EmailDraft(\n            draft_id=draft_id,\n            subject=subject,\n            recipients=to_addresses,\n            cc_recipients=cc_addresses,\n            bcc_recipients=bcc_addresses,\n            body_text=body,\n            attachments=email_attachments,\n            created_date=datetime.now(),\n            modified_date=datetime.now(),\n        )\n\n    def create_draft(\n        self,\n        to: List[str],\n        subject: str,\n        body: str,\n        cc: Optional[List[str]] = None,\n        bcc: Optional[List[str]] = None,\n        attachments: Optional[List[str]] = None,\n        folder: str = \"Drafts\",\n    ) -&gt; EmailDraft:\n        \"\"\"Create and store a draft message on the server using IMAP APPEND.\n        Args:\n            to: List of recipient email addresses\n            subject: Email subject line\n            body: Email body content (HTML or plain text)\n            cc: Optional list of CC recipient email addresses\n            bcc: Optional list of BCC recipient email addresses\n            attachments: Optional list of attachment file paths\n        Returns:\n            EmailDraft object\n        \"\"\"\n        # If not connected, create a local draft only\n        if not self.is_connected:\n            return self._create_local_draft(to, subject, body, cc, bcc, attachments)\n\n        draft_id = f\"draft_{datetime.now().timestamp()}\"\n\n        # Parse recipients\n        to_addresses = [EmailAddress(addr) for addr in to]\n        cc_addresses = [EmailAddress(addr) for addr in (cc or [])]\n        bcc_addresses = [EmailAddress(addr) for addr in (bcc or [])]\n\n        # Process attachments\n        email_attachments = []\n        if attachments:\n            for file_path in attachments:\n                if os.path.exists(file_path):\n                    with open(file_path, \"rb\") as f:\n                        content = f.read()\n\n                    email_attachments.append(\n                        EmailAttachment(\n                            filename=Path(file_path).name,\n                            content_type=\"application/octet-stream\",\n                            size=len(content),\n                            content=content,\n                        )\n                    )\n\n        # Create the draft message\n        draft_msg = self._create_draft_message(\n            to, subject, body, cc, bcc, attachments, draft_id\n        )\n\n        try:\n            # Select the drafts folder\n            self._imap_client.select(folder)\n\n            # Append the draft message to the server\n            status, response = self._imap_client.append(\n                folder,\n                \"(\\\\Draft)\",  # Set the \\Draft flag\n                None,  # Use current date/time\n                draft_msg.encode(\"utf-8\"),\n            )\n\n            if status != \"OK\":\n                raise RuntimeError(f\"Failed to store draft on server: {response}\")\n\n        except Exception as e:\n            raise RuntimeError(f\"Failed to create draft: {str(e)}\")\n\n        return EmailDraft(\n            draft_id=draft_id,\n            subject=subject,\n            recipients=to_addresses,\n            cc_recipients=cc_addresses,\n            bcc_recipients=bcc_addresses,\n            body_text=body,\n            attachments=email_attachments,\n            created_date=datetime.now(),\n            modified_date=datetime.now(),\n        )\n\n    def send_message(self, draft_id: str, folder: str = \"Drafts\") -&gt; bool:\n        \"\"\"Send a draft message by fetching from server and sending via SMTP.\n        Args:\n            draft_id: The ID of the draft message to send\n            folder: The folder to search for the draft message\n        Returns:\n            True if the draft message was sent successfully, False otherwise\n        \"\"\"\n\n        if not self.is_connected:\n            raise ConnectionError(\"Not connected to email servers\")\n        # If draft_id starts with \"draft_\" and contains timestamp,\n        # it's a local draft. In this case, we can't send it since\n        # it wasn't stored on the server\n        if draft_id.startswith(\"draft_\") and \".\" in draft_id:\n            raise RuntimeError(\n                \"Cannot send local draft - draft must be stored on server first\"\n            )\n\n        try:\n            # Select the drafts folder\n            self._imap_client.select(folder)\n\n            # Search for the draft message\n            status, messages = self._imap_client.search(\n                None, f'HEADER Message-ID \"&lt;{draft_id}@draft&gt;\"'\n            )\n            if status != \"OK\" or not messages[0]:\n                raise RuntimeError(f\"Draft with ID {draft_id} not found\")\n\n            msg_ids = messages[0].split()\n            if not msg_ids:\n                raise RuntimeError(f\"Draft with ID {draft_id} not found\")\n\n            # Fetch the draft message\n            status, msg_data = self._imap_client.fetch(msg_ids[0], \"(RFC822)\")\n            if status != \"OK\":\n                raise RuntimeError(\"Failed to fetch draft message\")\n\n            # Send the message via SMTP\n            raw_email = msg_data[0][1]\n            self._smtp_client.send_message(email.message_from_bytes(raw_email))\n\n            # Optionally delete the draft after sending\n            # self._imap_client.store(msg_ids[0], \"+FLAGS\", \"\\\\Deleted\")\n\n            return True\n        except Exception as e:\n            raise RuntimeError(f\"Failed to send draft message: {str(e)}\")\n\n    def send_message_direct(\n        self,\n        to: List[str],\n        subject: str,\n        body: str,\n        cc: Optional[List[str]] = None,\n        bcc: Optional[List[str]] = None,\n        attachments: Optional[List[str]] = None,\n    ) -&gt; bool:\n        \"\"\"Send a message directly via SMTP.\n        Args:\n            to: List of recipient email addresses\n            subject: Email subject line\n            body: Email body content (HTML or plain text)\n            cc: Optional list of CC recipient email addresses\n            bcc: Optional list of BCC recipient email addresses\n            attachments: Optional list of attachment file paths\n        Returns:\n            True if the message was sent successfully, False otherwise\n        \"\"\"\n        if not self.is_connected or not self._smtp_client:\n            raise ConnectionError(\"Not connected to SMTP server\")\n\n        try:\n            # Create message\n            msg = MIMEMultipart()\n            msg[\"From\"] = self.credentials.username\n            msg[\"To\"] = \", \".join(to)\n            msg[\"Subject\"] = subject\n\n            if cc:\n                msg[\"Cc\"] = \", \".join(cc)\n            if bcc:\n                msg[\"Bcc\"] = \", \".join(bcc)\n\n            # Add body\n            msg.attach(MIMEText(body, \"plain\"))\n\n            # Add attachments\n            if attachments:\n                for file_path in attachments:\n                    if os.path.exists(file_path):\n                        with open(file_path, \"rb\") as attachment:\n                            part = MIMEApplication(\n                                attachment.read(), Name=Path(file_path).name\n                            )\n                            part[\"Content-Disposition\"] = (\n                                f'attachment; filename=\"{Path(file_path).name}\"'\n                            )\n                            msg.attach(part)\n\n            # Send message\n            all_recipients = to + (cc or []) + (bcc or [])\n            self._smtp_client.send_message(msg, to_addrs=all_recipients)\n\n            return True\n\n        except Exception as e:\n            raise RuntimeError(f\"Failed to send message: {str(e)}\")\n\n    def mark_as_read(self, message_id: str) -&gt; bool:\n        \"\"\"Mark a message as read.\n        Args:\n            message_id: The ID of the message to mark as read\n        Returns:\n            True if the message was marked as read successfully, False otherwise\n        \"\"\"\n        if not self.is_connected:\n            raise ConnectionError(\"Not connected to IMAP server\")\n\n        try:\n            # Search for the message\n            status, messages = self._imap_client.search(\n                None, f'HEADER Message-ID \"{message_id}\"'\n            )\n            if status != \"OK\" or not messages[0]:\n                return False\n\n            msg_ids = messages[0].split()\n            if not msg_ids:\n                return False\n\n            # Mark as read\n            self._imap_client.store(msg_ids[0], \"+FLAGS\", \"\\\\Seen\")\n            return True\n\n        except Exception:\n            return False\n\n    def get_folders(self) -&gt; List[str]:\n        \"\"\"Get list of available folders.\n        Returns:\n            List of available folders\n        \"\"\"\n        if not self.is_connected:\n            raise ConnectionError(\"Not connected to IMAP server\")\n\n        try:\n            status, folders = self._imap_client.list()\n            if status != \"OK\":\n                return []\n\n            folder_list = []\n            for folder in folders:\n                folder_str = folder.decode()\n                # Extract folder name from IMAP response\n                folder_name = folder_str.split(' \"/\" ')[-1].strip('\"')\n                folder_list.append(folder_name)\n\n            return folder_list\n\n        except Exception:\n            return []\n\n    @property\n    def is_connected(self) -&gt; bool:\n        \"\"\"Check if connected to email servers.\n        Returns:\n            True if connected to email servers, False otherwise\n        \"\"\"\n        return (\n            self._connected\n            and self._imap_client is not None\n            and self._smtp_client is not None\n        )\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.imap_provider.IMAPProvider.is_connected","title":"<code>is_connected</code>  <code>property</code>","text":"<p>Check if connected to email servers. Returns:     True if connected to email servers, False otherwise</p>"},{"location":"api-reference/#ragora.utils.email_utils.imap_provider.IMAPProvider._create_draft_message","title":"<code>_create_draft_message(to, subject, body, cc, bcc, attachments, draft_id)</code>","text":"<p>Create a properly formatted draft message for IMAP APPEND. Args:     to: List of recipient email addresses     subject: Email subject line     body: Email body content (HTML or plain text)     cc: Optional list of CC recipient email addresses     bcc: Optional list of BCC recipient email addresses     attachments: Optional list of attachment file paths Returns:     String representation of the draft message</p> Source code in <code>ragora/ragora/utils/email_utils/imap_provider.py</code> <pre><code>def _create_draft_message(\n    self,\n    to: List[str],\n    subject: str,\n    body: str,\n    cc: Optional[List[str]],\n    bcc: Optional[List[str]],\n    attachments: Optional[List[str]],\n    draft_id: str,\n) -&gt; str:\n    \"\"\"Create a properly formatted draft message for IMAP APPEND.\n    Args:\n        to: List of recipient email addresses\n        subject: Email subject line\n        body: Email body content (HTML or plain text)\n        cc: Optional list of CC recipient email addresses\n        bcc: Optional list of BCC recipient email addresses\n        attachments: Optional list of attachment file paths\n    Returns:\n        String representation of the draft message\n    \"\"\"\n    # Create the message structure\n    msg = MIMEMultipart()\n\n    # Set headers\n    msg[\"From\"] = self.credentials.username\n    msg[\"To\"] = \", \".join(to)\n    msg[\"Subject\"] = subject\n    msg[\"Message-ID\"] = f\"&lt;{draft_id}@draft&gt;\"\n    msg[\"Date\"] = email.utils.formatdate(localtime=True)\n\n    if cc:\n        msg[\"Cc\"] = \", \".join(cc)\n    if bcc:\n        msg[\"Bcc\"] = \", \".join(bcc)\n\n    # Add body\n    msg.attach(MIMEText(body, \"plain\"))\n\n    # Add attachments\n    if attachments:\n        for file_path in attachments:\n            if os.path.exists(file_path):\n                with open(file_path, \"rb\") as attachment:\n                    part = MIMEApplication(\n                        attachment.read(), Name=Path(file_path).name\n                    )\n                    part[\"Content-Disposition\"] = (\n                        f'attachment; filename=\"{Path(file_path).name}\"'\n                    )\n                    msg.attach(part)\n\n    return msg.as_string()\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.imap_provider.IMAPProvider._create_local_draft","title":"<code>_create_local_draft(to, subject, body, cc, bcc, attachments)</code>","text":"<p>Create a local draft without storing on server. Args:     to: List of recipient email addresses     subject: Email subject line     body: Email body content (HTML or plain text)     cc: Optional list of CC recipient email addresses     bcc: Optional list of BCC recipient email addresses     attachments: Optional list of attachment file paths Returns:     EmailDraft object</p> Source code in <code>ragora/ragora/utils/email_utils/imap_provider.py</code> <pre><code>def _create_local_draft(\n    self,\n    to: List[str],\n    subject: str,\n    body: str,\n    cc: Optional[List[str]],\n    bcc: Optional[List[str]],\n    attachments: Optional[List[str]],\n) -&gt; EmailDraft:\n    \"\"\"Create a local draft without storing on server.\n    Args:\n        to: List of recipient email addresses\n        subject: Email subject line\n        body: Email body content (HTML or plain text)\n        cc: Optional list of CC recipient email addresses\n        bcc: Optional list of BCC recipient email addresses\n        attachments: Optional list of attachment file paths\n    Returns:\n        EmailDraft object\n    \"\"\"\n    draft_id = f\"draft_{datetime.now().timestamp()}\"\n\n    # Parse recipients\n    to_addresses = [EmailAddress(addr) for addr in to]\n    cc_addresses = [EmailAddress(addr) for addr in (cc or [])]\n    bcc_addresses = [EmailAddress(addr) for addr in (bcc or [])]\n\n    # Process attachments\n    email_attachments = []\n    if attachments:\n        for file_path in attachments:\n            if os.path.exists(file_path):\n                with open(file_path, \"rb\") as f:\n                    content = f.read()\n\n                email_attachments.append(\n                    EmailAttachment(\n                        filename=Path(file_path).name,\n                        content_type=\"application/octet-stream\",\n                        size=len(content),\n                        content=content,\n                    )\n                )\n\n    return EmailDraft(\n        draft_id=draft_id,\n        subject=subject,\n        recipients=to_addresses,\n        cc_recipients=cc_addresses,\n        bcc_recipients=bcc_addresses,\n        body_text=body,\n        attachments=email_attachments,\n        created_date=datetime.now(),\n        modified_date=datetime.now(),\n    )\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.imap_provider.IMAPProvider._decode_header","title":"<code>_decode_header(header)</code>","text":"<p>Decode email header. Args:     header: The email header to decode Returns:     Decoded email header</p> Source code in <code>ragora/ragora/utils/email_utils/imap_provider.py</code> <pre><code>def _decode_header(self, header: str) -&gt; str:\n    \"\"\"Decode email header.\n    Args:\n        header: The email header to decode\n    Returns:\n        Decoded email header\n    \"\"\"\n    if not header:\n        return \"\"\n\n    decoded_parts = decode_header(header)\n    decoded_string = \"\"\n\n    for part, encoding in decoded_parts:\n        if isinstance(part, bytes):\n            if encoding:\n                decoded_string += part.decode(encoding)\n            else:\n                decoded_string += part.decode(\"utf-8\", errors=\"ignore\")\n        else:\n            decoded_string += part\n\n    return decoded_string\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.imap_provider.IMAPProvider._extract_attachments","title":"<code>_extract_attachments(email_msg)</code>","text":"<p>Extract attachments from email message.</p> Source code in <code>ragora/ragora/utils/email_utils/imap_provider.py</code> <pre><code>def _extract_attachments(\n    self, email_msg: email.message.Message\n) -&gt; List[EmailAttachment]:\n    \"\"\"Extract attachments from email message.\"\"\"\n    attachments = []\n\n    if email_msg.is_multipart():\n        for part in email_msg.walk():\n            content_disposition = str(part.get(\"Content-Disposition\"))\n\n            if \"attachment\" in content_disposition:\n                filename = part.get_filename()\n                if filename:\n                    filename = self._decode_header(filename)\n\n                    content_type = part.get_content_type()\n                    content = part.get_payload(decode=True)\n\n                    attachments.append(\n                        EmailAttachment(\n                            filename=filename,\n                            content_type=content_type,\n                            size=len(content) if content else 0,\n                            content=content,\n                            content_id=part.get(\"Content-ID\"),\n                        )\n                    )\n\n    return attachments\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.imap_provider.IMAPProvider._extract_body","title":"<code>_extract_body(email_msg)</code>","text":"<p>Extract text and HTML body from email message. Args:     email_msg: The email.message.Message object to extract the body from Returns:     Tuple of text and HTML body</p> Source code in <code>ragora/ragora/utils/email_utils/imap_provider.py</code> <pre><code>def _extract_body(\n    self, email_msg: email.message.Message\n) -&gt; tuple[Optional[str], Optional[str]]:\n    \"\"\"Extract text and HTML body from email message.\n    Args:\n        email_msg: The email.message.Message object to extract the body from\n    Returns:\n        Tuple of text and HTML body\n    \"\"\"\n    body_text = None\n    body_html = None\n\n    if email_msg.is_multipart():\n        for part in email_msg.walk():\n            content_type = part.get_content_type()\n            content_disposition = str(part.get(\"Content-Disposition\"))\n\n            # Skip attachments\n            if \"attachment\" in content_disposition:\n                continue\n\n            if content_type == \"text/plain\" and not body_text:\n                body_text = part.get_payload(decode=True).decode(\n                    \"utf-8\", errors=\"ignore\"\n                )\n            elif content_type == \"text/html\" and not body_html:\n                body_html = part.get_payload(decode=True).decode(\n                    \"utf-8\", errors=\"ignore\"\n                )\n    else:\n        content_type = email_msg.get_content_type()\n        payload = email_msg.get_payload(decode=True)\n\n        if payload:\n            decoded_payload = payload.decode(\"utf-8\", errors=\"ignore\")\n            if content_type == \"text/plain\":\n                body_text = decoded_payload\n            elif content_type == \"text/html\":\n                body_html = decoded_payload\n\n    return body_text, body_html\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.imap_provider.IMAPProvider._fetch_single_message","title":"<code>_fetch_single_message(msg_id)</code>","text":"<p>Fetch and parse a single message. Args:     msg_id: The ID of the message to fetch Returns:     EmailMessage object if the message was found, None otherwise</p> Source code in <code>ragora/ragora/utils/email_utils/imap_provider.py</code> <pre><code>def _fetch_single_message(self, msg_id: bytes) -&gt; Optional[EmailMessage]:\n    \"\"\"Fetch and parse a single message.\n    Args:\n        msg_id: The ID of the message to fetch\n    Returns:\n        EmailMessage object if the message was found, None otherwise\n    \"\"\"\n    try:\n        status, msg_data = self._imap_client.fetch(msg_id, \"(RFC822)\")\n        if status != \"OK\":\n            return None\n\n        raw_email = msg_data[0][1]\n        email_message = email.message_from_bytes(raw_email)\n\n        return self._parse_email_message(email_message, msg_id.decode())\n\n    except Exception:\n        return None\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.imap_provider.IMAPProvider._parse_address","title":"<code>_parse_address(address_str)</code>","text":"<p>Parse a single email address. Args:     address_str: The email address to parse Returns:     EmailAddress object</p> Source code in <code>ragora/ragora/utils/email_utils/imap_provider.py</code> <pre><code>def _parse_address(self, address_str: str) -&gt; EmailAddress:\n    \"\"\"Parse a single email address.\n    Args:\n        address_str: The email address to parse\n    Returns:\n        EmailAddress object\n    \"\"\"\n    if not address_str:\n        return EmailAddress(\"\")\n\n    decoded = self._decode_header(address_str)\n\n    # Simple parsing - could be improved with proper email parsing library\n    if \"&lt;\" in decoded and \"&gt;\" in decoded:\n        name_part = decoded.split(\"&lt;\")[0].strip()\n        email_part = decoded.split(\"&lt;\")[1].split(\"&gt;\")[0].strip()\n        return EmailAddress(email_part, name_part if name_part else None)\n    else:\n        return EmailAddress(decoded.strip())\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.imap_provider.IMAPProvider._parse_address_list","title":"<code>_parse_address_list(address_list)</code>","text":"<p>Parse a list of email addresses. Args:     address_list: The list of email addresses to parse Returns:     List of EmailAddress objects</p> Source code in <code>ragora/ragora/utils/email_utils/imap_provider.py</code> <pre><code>def _parse_address_list(self, address_list: str) -&gt; List[EmailAddress]:\n    \"\"\"Parse a list of email addresses.\n    Args:\n        address_list: The list of email addresses to parse\n    Returns:\n        List of EmailAddress objects\n    \"\"\"\n    if not address_list:\n        return []\n\n    addresses = []\n    for addr in address_list.split(\",\"):\n        addr = addr.strip()\n        if addr:\n            addresses.append(self._parse_address(addr))\n\n    return addresses\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.imap_provider.IMAPProvider._parse_date","title":"<code>_parse_date(date_str)</code>","text":"<p>Parse email date string. Args:     date_str: The email date string to parse Returns:     datetime object if the date was parsed successfully, None otherwise</p> Source code in <code>ragora/ragora/utils/email_utils/imap_provider.py</code> <pre><code>def _parse_date(self, date_str: Optional[str]) -&gt; Optional[datetime]:\n    \"\"\"Parse email date string.\n    Args:\n        date_str: The email date string to parse\n    Returns:\n        datetime object if the date was parsed successfully, None otherwise\n    \"\"\"\n    if not date_str:\n        return None\n\n    try:\n        # Try parsing with email.utils.parsedate_to_datetime\n        return email.utils.parsedate_to_datetime(date_str)\n    except Exception:\n        return None\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.imap_provider.IMAPProvider._parse_email_message","title":"<code>_parse_email_message(email_msg, msg_id)</code>","text":"<p>Parse email.message.Message into EmailMessage object. Args:     email_msg: The email.message.Message object to parse     msg_id: The ID of the message Returns:     EmailMessage object</p> Source code in <code>ragora/ragora/utils/email_utils/imap_provider.py</code> <pre><code>def _parse_email_message(\n    self, email_msg: email.message.Message, msg_id: str\n) -&gt; EmailMessage:\n    \"\"\"Parse email.message.Message into EmailMessage object.\n    Args:\n        email_msg: The email.message.Message object to parse\n        msg_id: The ID of the message\n    Returns:\n        EmailMessage object\n    \"\"\"\n    # Extract headers\n    subject = self._decode_header(email_msg.get(\"Subject\", \"\"))\n    sender = self._parse_address(email_msg.get(\"From\", \"\"))\n\n    # Parse recipients\n    to_addresses = self._parse_address_list(email_msg.get(\"To\", \"\"))\n    cc_addresses = self._parse_address_list(email_msg.get(\"Cc\", \"\"))\n    bcc_addresses = self._parse_address_list(email_msg.get(\"Bcc\", \"\"))\n\n    # Parse dates\n    date_sent = self._parse_date(email_msg.get(\"Date\"))\n\n    # Extract body\n    body_text, body_html = self._extract_body(email_msg)\n\n    # Extract attachments\n    attachments = self._extract_attachments(email_msg)\n\n    # Determine status\n    status = MessageStatus.READ if email_msg.get(\"X-Seen\") else MessageStatus.UNREAD\n\n    return EmailMessage(\n        message_id=email_msg.get(\"Message-ID\", msg_id),\n        subject=subject,\n        sender=sender,\n        recipients=to_addresses,\n        cc_recipients=cc_addresses,\n        bcc_recipients=bcc_addresses,\n        body_text=body_text,\n        body_html=body_html,\n        date_sent=date_sent,\n        date_received=datetime.now(),\n        status=status,\n        attachments=attachments,\n    )\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.imap_provider.IMAPProvider.connect","title":"<code>connect()</code>","text":"<p>Establish connection to IMAP and SMTP servers.</p> Source code in <code>ragora/ragora/utils/email_utils/imap_provider.py</code> <pre><code>def connect(self) -&gt; None:\n    \"\"\"Establish connection to IMAP and SMTP servers.\"\"\"\n    try:\n        # Connect to IMAP server\n        if self.credentials.use_ssl:\n            self._imap_client = imaplib.IMAP4_SSL(\n                self.credentials.imap_server, self.credentials.imap_port\n            )\n        else:\n            self._imap_client = imaplib.IMAP4(\n                self.credentials.imap_server, self.credentials.imap_port\n            )\n            if self.credentials.use_tls:\n                self._imap_client.starttls()\n\n        # Login to IMAP\n        self._imap_client.login(\n            self.credentials.username, self.credentials.password\n        )\n\n        # Connect to SMTP server\n        if self.credentials.use_ssl:\n            self._smtp_client = smtplib.SMTP_SSL(\n                self.credentials.smtp_server, self.credentials.smtp_port\n            )\n        else:\n            self._smtp_client = smtplib.SMTP(\n                self.credentials.smtp_server, self.credentials.smtp_port\n            )\n            if self.credentials.use_tls:\n                self._smtp_client.starttls()\n\n        self._smtp_client.login(\n            self.credentials.username, self.credentials.password\n        )\n\n        self._connected = True\n\n    except Exception as e:\n        self._connected = False\n        raise ConnectionError(f\"Failed to connect to email servers: {str(e)}\")\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.imap_provider.IMAPProvider.create_draft","title":"<code>create_draft(to, subject, body, cc=None, bcc=None, attachments=None, folder='Drafts')</code>","text":"<p>Create and store a draft message on the server using IMAP APPEND. Args:     to: List of recipient email addresses     subject: Email subject line     body: Email body content (HTML or plain text)     cc: Optional list of CC recipient email addresses     bcc: Optional list of BCC recipient email addresses     attachments: Optional list of attachment file paths Returns:     EmailDraft object</p> Source code in <code>ragora/ragora/utils/email_utils/imap_provider.py</code> <pre><code>def create_draft(\n    self,\n    to: List[str],\n    subject: str,\n    body: str,\n    cc: Optional[List[str]] = None,\n    bcc: Optional[List[str]] = None,\n    attachments: Optional[List[str]] = None,\n    folder: str = \"Drafts\",\n) -&gt; EmailDraft:\n    \"\"\"Create and store a draft message on the server using IMAP APPEND.\n    Args:\n        to: List of recipient email addresses\n        subject: Email subject line\n        body: Email body content (HTML or plain text)\n        cc: Optional list of CC recipient email addresses\n        bcc: Optional list of BCC recipient email addresses\n        attachments: Optional list of attachment file paths\n    Returns:\n        EmailDraft object\n    \"\"\"\n    # If not connected, create a local draft only\n    if not self.is_connected:\n        return self._create_local_draft(to, subject, body, cc, bcc, attachments)\n\n    draft_id = f\"draft_{datetime.now().timestamp()}\"\n\n    # Parse recipients\n    to_addresses = [EmailAddress(addr) for addr in to]\n    cc_addresses = [EmailAddress(addr) for addr in (cc or [])]\n    bcc_addresses = [EmailAddress(addr) for addr in (bcc or [])]\n\n    # Process attachments\n    email_attachments = []\n    if attachments:\n        for file_path in attachments:\n            if os.path.exists(file_path):\n                with open(file_path, \"rb\") as f:\n                    content = f.read()\n\n                email_attachments.append(\n                    EmailAttachment(\n                        filename=Path(file_path).name,\n                        content_type=\"application/octet-stream\",\n                        size=len(content),\n                        content=content,\n                    )\n                )\n\n    # Create the draft message\n    draft_msg = self._create_draft_message(\n        to, subject, body, cc, bcc, attachments, draft_id\n    )\n\n    try:\n        # Select the drafts folder\n        self._imap_client.select(folder)\n\n        # Append the draft message to the server\n        status, response = self._imap_client.append(\n            folder,\n            \"(\\\\Draft)\",  # Set the \\Draft flag\n            None,  # Use current date/time\n            draft_msg.encode(\"utf-8\"),\n        )\n\n        if status != \"OK\":\n            raise RuntimeError(f\"Failed to store draft on server: {response}\")\n\n    except Exception as e:\n        raise RuntimeError(f\"Failed to create draft: {str(e)}\")\n\n    return EmailDraft(\n        draft_id=draft_id,\n        subject=subject,\n        recipients=to_addresses,\n        cc_recipients=cc_addresses,\n        bcc_recipients=bcc_addresses,\n        body_text=body,\n        attachments=email_attachments,\n        created_date=datetime.now(),\n        modified_date=datetime.now(),\n    )\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.imap_provider.IMAPProvider.disconnect","title":"<code>disconnect()</code>","text":"<p>Close connections to IMAP and SMTP servers.</p> Source code in <code>ragora/ragora/utils/email_utils/imap_provider.py</code> <pre><code>def disconnect(self) -&gt; None:\n    \"\"\"Close connections to IMAP and SMTP servers.\"\"\"\n    try:\n        if self._imap_client:\n            self._imap_client.close()\n            self._imap_client.logout()\n            self._imap_client = None\n\n        if self._smtp_client:\n            self._smtp_client.quit()\n            self._smtp_client = None\n\n        self._connected = False\n\n    except Exception:\n        # Ignore errors during disconnect\n        pass\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.imap_provider.IMAPProvider.fetch_message_by_id","title":"<code>fetch_message_by_id(message_id)</code>","text":"<p>Fetch a specific message by its ID. Args:     message_id: The ID of the message to fetch Returns:     EmailMessage object if the message was found, None otherwise</p> Source code in <code>ragora/ragora/utils/email_utils/imap_provider.py</code> <pre><code>def fetch_message_by_id(self, message_id: str) -&gt; Optional[EmailMessage]:\n    \"\"\"Fetch a specific message by its ID.\n    Args:\n        message_id: The ID of the message to fetch\n    Returns:\n        EmailMessage object if the message was found, None otherwise\n    \"\"\"\n    if not self.is_connected:\n        raise ConnectionError(\"Not connected to IMAP server\")\n\n    try:\n        # Search for the specific message ID\n        status, messages = self._imap_client.search(\n            None, f'HEADER Message-ID \"{message_id}\"'\n        )\n        if status != \"OK\" or not messages[0]:\n            return None\n\n        msg_ids = messages[0].split()\n        if not msg_ids:\n            return None\n\n        return self._fetch_single_message(msg_ids[0])\n\n    except Exception as e:\n        raise RuntimeError(f\"Failed to fetch message {message_id}: {str(e)}\")\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.imap_provider.IMAPProvider.fetch_messages","title":"<code>fetch_messages(limit=None, folder=None, unread_only=False)</code>","text":"<p>Fetch messages from IMAP server. Args:     limit: The maximum number of messages to fetch     folder: The folder to search for messages     unread_only: Whether to only fetch unread messages Returns:     List of EmailMessage objects</p> Source code in <code>ragora/ragora/utils/email_utils/imap_provider.py</code> <pre><code>def fetch_messages(\n    self,\n    limit: Optional[int] = None,\n    folder: Optional[str] = None,\n    unread_only: bool = False,\n) -&gt; List[EmailMessage]:\n    \"\"\"Fetch messages from IMAP server.\n    Args:\n        limit: The maximum number of messages to fetch\n        folder: The folder to search for messages\n        unread_only: Whether to only fetch unread messages\n    Returns:\n        List of EmailMessage objects\n    \"\"\"\n    if not self.is_connected:\n        raise ConnectionError(\"Not connected to IMAP server\")\n\n    try:\n        # Select folder (default to INBOX)\n        folder_name = folder or \"INBOX\"\n        self._imap_client.select(folder_name)\n\n        # Build search criteria\n        search_criteria = \"ALL\"\n        if unread_only:\n            search_criteria = \"UNSEEN\"\n\n        # Search for messages\n        status, messages = self._imap_client.search(None, search_criteria)\n        if status != \"OK\":\n            raise RuntimeError(\"Failed to search messages\")\n\n        message_ids = messages[0].split()\n        message_ids = (\n            message_ids[-limit:] if limit is not None and limit &gt; 0 else message_ids\n        )\n\n        email_messages = []\n        for msg_id in message_ids:\n            try:\n                email_msg = self._fetch_single_message(msg_id)\n                if email_msg:\n                    email_messages.append(email_msg)\n            except Exception as e:\n                # Skip problematic messages\n                continue\n\n        return email_messages\n\n    except Exception as e:\n        raise RuntimeError(f\"Failed to fetch messages: {str(e)}\")\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.imap_provider.IMAPProvider.get_folders","title":"<code>get_folders()</code>","text":"<p>Get list of available folders. Returns:     List of available folders</p> Source code in <code>ragora/ragora/utils/email_utils/imap_provider.py</code> <pre><code>def get_folders(self) -&gt; List[str]:\n    \"\"\"Get list of available folders.\n    Returns:\n        List of available folders\n    \"\"\"\n    if not self.is_connected:\n        raise ConnectionError(\"Not connected to IMAP server\")\n\n    try:\n        status, folders = self._imap_client.list()\n        if status != \"OK\":\n            return []\n\n        folder_list = []\n        for folder in folders:\n            folder_str = folder.decode()\n            # Extract folder name from IMAP response\n            folder_name = folder_str.split(' \"/\" ')[-1].strip('\"')\n            folder_list.append(folder_name)\n\n        return folder_list\n\n    except Exception:\n        return []\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.imap_provider.IMAPProvider.mark_as_read","title":"<code>mark_as_read(message_id)</code>","text":"<p>Mark a message as read. Args:     message_id: The ID of the message to mark as read Returns:     True if the message was marked as read successfully, False otherwise</p> Source code in <code>ragora/ragora/utils/email_utils/imap_provider.py</code> <pre><code>def mark_as_read(self, message_id: str) -&gt; bool:\n    \"\"\"Mark a message as read.\n    Args:\n        message_id: The ID of the message to mark as read\n    Returns:\n        True if the message was marked as read successfully, False otherwise\n    \"\"\"\n    if not self.is_connected:\n        raise ConnectionError(\"Not connected to IMAP server\")\n\n    try:\n        # Search for the message\n        status, messages = self._imap_client.search(\n            None, f'HEADER Message-ID \"{message_id}\"'\n        )\n        if status != \"OK\" or not messages[0]:\n            return False\n\n        msg_ids = messages[0].split()\n        if not msg_ids:\n            return False\n\n        # Mark as read\n        self._imap_client.store(msg_ids[0], \"+FLAGS\", \"\\\\Seen\")\n        return True\n\n    except Exception:\n        return False\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.imap_provider.IMAPProvider.send_message","title":"<code>send_message(draft_id, folder='Drafts')</code>","text":"<p>Send a draft message by fetching from server and sending via SMTP. Args:     draft_id: The ID of the draft message to send     folder: The folder to search for the draft message Returns:     True if the draft message was sent successfully, False otherwise</p> Source code in <code>ragora/ragora/utils/email_utils/imap_provider.py</code> <pre><code>def send_message(self, draft_id: str, folder: str = \"Drafts\") -&gt; bool:\n    \"\"\"Send a draft message by fetching from server and sending via SMTP.\n    Args:\n        draft_id: The ID of the draft message to send\n        folder: The folder to search for the draft message\n    Returns:\n        True if the draft message was sent successfully, False otherwise\n    \"\"\"\n\n    if not self.is_connected:\n        raise ConnectionError(\"Not connected to email servers\")\n    # If draft_id starts with \"draft_\" and contains timestamp,\n    # it's a local draft. In this case, we can't send it since\n    # it wasn't stored on the server\n    if draft_id.startswith(\"draft_\") and \".\" in draft_id:\n        raise RuntimeError(\n            \"Cannot send local draft - draft must be stored on server first\"\n        )\n\n    try:\n        # Select the drafts folder\n        self._imap_client.select(folder)\n\n        # Search for the draft message\n        status, messages = self._imap_client.search(\n            None, f'HEADER Message-ID \"&lt;{draft_id}@draft&gt;\"'\n        )\n        if status != \"OK\" or not messages[0]:\n            raise RuntimeError(f\"Draft with ID {draft_id} not found\")\n\n        msg_ids = messages[0].split()\n        if not msg_ids:\n            raise RuntimeError(f\"Draft with ID {draft_id} not found\")\n\n        # Fetch the draft message\n        status, msg_data = self._imap_client.fetch(msg_ids[0], \"(RFC822)\")\n        if status != \"OK\":\n            raise RuntimeError(\"Failed to fetch draft message\")\n\n        # Send the message via SMTP\n        raw_email = msg_data[0][1]\n        self._smtp_client.send_message(email.message_from_bytes(raw_email))\n\n        # Optionally delete the draft after sending\n        # self._imap_client.store(msg_ids[0], \"+FLAGS\", \"\\\\Deleted\")\n\n        return True\n    except Exception as e:\n        raise RuntimeError(f\"Failed to send draft message: {str(e)}\")\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.imap_provider.IMAPProvider.send_message_direct","title":"<code>send_message_direct(to, subject, body, cc=None, bcc=None, attachments=None)</code>","text":"<p>Send a message directly via SMTP. Args:     to: List of recipient email addresses     subject: Email subject line     body: Email body content (HTML or plain text)     cc: Optional list of CC recipient email addresses     bcc: Optional list of BCC recipient email addresses     attachments: Optional list of attachment file paths Returns:     True if the message was sent successfully, False otherwise</p> Source code in <code>ragora/ragora/utils/email_utils/imap_provider.py</code> <pre><code>def send_message_direct(\n    self,\n    to: List[str],\n    subject: str,\n    body: str,\n    cc: Optional[List[str]] = None,\n    bcc: Optional[List[str]] = None,\n    attachments: Optional[List[str]] = None,\n) -&gt; bool:\n    \"\"\"Send a message directly via SMTP.\n    Args:\n        to: List of recipient email addresses\n        subject: Email subject line\n        body: Email body content (HTML or plain text)\n        cc: Optional list of CC recipient email addresses\n        bcc: Optional list of BCC recipient email addresses\n        attachments: Optional list of attachment file paths\n    Returns:\n        True if the message was sent successfully, False otherwise\n    \"\"\"\n    if not self.is_connected or not self._smtp_client:\n        raise ConnectionError(\"Not connected to SMTP server\")\n\n    try:\n        # Create message\n        msg = MIMEMultipart()\n        msg[\"From\"] = self.credentials.username\n        msg[\"To\"] = \", \".join(to)\n        msg[\"Subject\"] = subject\n\n        if cc:\n            msg[\"Cc\"] = \", \".join(cc)\n        if bcc:\n            msg[\"Bcc\"] = \", \".join(bcc)\n\n        # Add body\n        msg.attach(MIMEText(body, \"plain\"))\n\n        # Add attachments\n        if attachments:\n            for file_path in attachments:\n                if os.path.exists(file_path):\n                    with open(file_path, \"rb\") as attachment:\n                        part = MIMEApplication(\n                            attachment.read(), Name=Path(file_path).name\n                        )\n                        part[\"Content-Disposition\"] = (\n                            f'attachment; filename=\"{Path(file_path).name}\"'\n                        )\n                        msg.attach(part)\n\n        # Send message\n        all_recipients = to + (cc or []) + (bcc or [])\n        self._smtp_client.send_message(msg, to_addrs=all_recipients)\n\n        return True\n\n    except Exception as e:\n        raise RuntimeError(f\"Failed to send message: {str(e)}\")\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.models.EmailAddress","title":"<code>EmailAddress</code>  <code>dataclass</code>","text":"<p>Represents an email address with optional display name.</p> Source code in <code>ragora/ragora/utils/email_utils/models.py</code> <pre><code>@dataclass\nclass EmailAddress:\n    \"\"\"Represents an email address with optional display name.\"\"\"\n\n    email: str\n    name: Optional[str] = None\n\n    def __str__(self) -&gt; str:\n        if self.name:\n            return f\"{self.name} &lt;{self.email}&gt;\"\n        return self.email\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.models.EmailAttachment","title":"<code>EmailAttachment</code>  <code>dataclass</code>","text":"<p>Represents an email attachment.</p> Source code in <code>ragora/ragora/utils/email_utils/models.py</code> <pre><code>@dataclass\nclass EmailAttachment:\n    \"\"\"Represents an email attachment.\"\"\"\n\n    filename: str\n    content_type: str\n    size: int\n    content: Optional[bytes] = None\n    content_id: Optional[str] = None  # For inline attachments\n\n    def __post_init__(self):\n        if self.content and len(self.content) != self.size:\n            self.size = len(self.content)\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.models.EmailCredentials","title":"<code>EmailCredentials</code>  <code>dataclass</code>","text":"<p>Base class for email credentials.</p> Source code in <code>ragora/ragora/utils/email_utils/models.py</code> <pre><code>@dataclass\nclass EmailCredentials:\n    \"\"\"Base class for email credentials.\"\"\"\n\n    pass\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.models.EmailDraft","title":"<code>EmailDraft</code>  <code>dataclass</code>","text":"<p>Represents a draft email message.</p> Source code in <code>ragora/ragora/utils/email_utils/models.py</code> <pre><code>@dataclass\nclass EmailDraft:\n    \"\"\"Represents a draft email message.\"\"\"\n\n    draft_id: str\n    subject: str\n    recipients: List[EmailAddress]\n    cc_recipients: List[EmailAddress] = field(default_factory=list)\n    bcc_recipients: List[EmailAddress] = field(default_factory=list)\n    body_text: Optional[str] = None\n    body_html: Optional[str] = None\n    attachments: List[EmailAttachment] = field(default_factory=list)\n    created_date: Optional[datetime] = None\n    modified_date: Optional[datetime] = None\n    metadata: Dict[str, Any] = field(default_factory=dict)\n\n    def get_body(self) -&gt; str:\n        \"\"\"Get the best available body content (HTML preferred, fallback to text).\"\"\"\n        return self.body_html if self.body_html else (self.body_text or \"\")\n\n    def get_all_recipients(self) -&gt; List[EmailAddress]:\n        \"\"\"Get all recipients including CC and BCC.\"\"\"\n        return self.recipients + self.cc_recipients + self.bcc_recipients\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.models.EmailDraft.get_all_recipients","title":"<code>get_all_recipients()</code>","text":"<p>Get all recipients including CC and BCC.</p> Source code in <code>ragora/ragora/utils/email_utils/models.py</code> <pre><code>def get_all_recipients(self) -&gt; List[EmailAddress]:\n    \"\"\"Get all recipients including CC and BCC.\"\"\"\n    return self.recipients + self.cc_recipients + self.bcc_recipients\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.models.EmailDraft.get_body","title":"<code>get_body()</code>","text":"<p>Get the best available body content (HTML preferred, fallback to text).</p> Source code in <code>ragora/ragora/utils/email_utils/models.py</code> <pre><code>def get_body(self) -&gt; str:\n    \"\"\"Get the best available body content (HTML preferred, fallback to text).\"\"\"\n    return self.body_html if self.body_html else (self.body_text or \"\")\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.models.EmailMessage","title":"<code>EmailMessage</code>  <code>dataclass</code>","text":"<p>Represents an email message.</p> Source code in <code>ragora/ragora/utils/email_utils/models.py</code> <pre><code>@dataclass\nclass EmailMessage:\n    \"\"\"Represents an email message.\"\"\"\n\n    message_id: str\n    subject: str\n    sender: EmailAddress\n    recipients: List[EmailAddress]\n    cc_recipients: List[EmailAddress] = field(default_factory=list)\n    bcc_recipients: List[EmailAddress] = field(default_factory=list)\n    body_text: Optional[str] = None\n    body_html: Optional[str] = None\n    date_sent: Optional[datetime] = None\n    date_received: Optional[datetime] = None\n    status: MessageStatus = MessageStatus.UNREAD\n    attachments: List[EmailAttachment] = field(default_factory=list)\n    thread_id: Optional[str] = None\n    conversation_id: Optional[str] = None\n    folder: Optional[str] = None\n    metadata: Dict[str, Any] = field(default_factory=dict)\n\n    def get_body(self) -&gt; str:\n        \"\"\"Get the best available body content (HTML preferred, fallback to text).\"\"\"\n        return self.body_html if self.body_html else (self.body_text or \"\")\n\n    def get_all_recipients(self) -&gt; List[EmailAddress]:\n        \"\"\"Get all recipients including CC and BCC.\"\"\"\n        return self.recipients + self.cc_recipients + self.bcc_recipients\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.models.EmailMessage.get_all_recipients","title":"<code>get_all_recipients()</code>","text":"<p>Get all recipients including CC and BCC.</p> Source code in <code>ragora/ragora/utils/email_utils/models.py</code> <pre><code>def get_all_recipients(self) -&gt; List[EmailAddress]:\n    \"\"\"Get all recipients including CC and BCC.\"\"\"\n    return self.recipients + self.cc_recipients + self.bcc_recipients\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.models.EmailMessage.get_body","title":"<code>get_body()</code>","text":"<p>Get the best available body content (HTML preferred, fallback to text).</p> Source code in <code>ragora/ragora/utils/email_utils/models.py</code> <pre><code>def get_body(self) -&gt; str:\n    \"\"\"Get the best available body content (HTML preferred, fallback to text).\"\"\"\n    return self.body_html if self.body_html else (self.body_text or \"\")\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.models.GraphCredentials","title":"<code>GraphCredentials</code>  <code>dataclass</code>","text":"<p>               Bases: <code>EmailCredentials</code></p> <p>Credentials for Microsoft Graph API.</p> Source code in <code>ragora/ragora/utils/email_utils/models.py</code> <pre><code>@dataclass\nclass GraphCredentials(EmailCredentials):\n    \"\"\"Credentials for Microsoft Graph API.\"\"\"\n\n    client_id: str\n    client_secret: str\n    tenant_id: str\n    access_token: Optional[str] = None\n    refresh_token: Optional[str] = None\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.models.IMAPCredentials","title":"<code>IMAPCredentials</code>  <code>dataclass</code>","text":"<p>               Bases: <code>EmailCredentials</code></p> <p>Credentials for IMAP/SMTP servers.</p> Source code in <code>ragora/ragora/utils/email_utils/models.py</code> <pre><code>@dataclass\nclass IMAPCredentials(EmailCredentials):\n    \"\"\"Credentials for IMAP/SMTP servers.\"\"\"\n\n    imap_server: str\n    imap_port: int\n    smtp_server: str\n    smtp_port: int\n    username: str\n    password: str\n    use_ssl: bool = True\n    use_tls: bool = False\n</code></pre>"},{"location":"api-reference/#ragora.utils.email_utils.models.MessageStatus","title":"<code>MessageStatus</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Status of an email message.</p> Source code in <code>ragora/ragora/utils/email_utils/models.py</code> <pre><code>class MessageStatus(Enum):\n    \"\"\"Status of an email message.\"\"\"\n\n    UNREAD = \"unread\"\n    READ = \"read\"\n    DRAFT = \"draft\"\n    SENT = \"sent\"\n    TRASH = \"trash\"\n</code></pre>"},{"location":"api-reference/#latex-parser","title":"LaTeX Parser","text":"<p>Parse LaTeX sources into structured Ragora data classes.</p>"},{"location":"api-reference/#ragora.utils.latex_parser.Citation","title":"<code>Citation</code>  <code>dataclass</code>","text":"<p>Citation information for a document.</p> Source code in <code>ragora/ragora/utils/latex_parser.py</code> <pre><code>@dataclass\nclass Citation:\n    \"\"\"Citation information for a document.\"\"\"\n\n    author: str\n    year: str\n    title: str\n    doi: str\n    source_document: str\n    page_reference: str\n    citation_label: str\n    citation_hash: str\n\n    def to_text(self, citation_command: str) -&gt; str:\n        \"\"\"Convert the citation to a text string.\"\"\"\n        if citation_command == \"\\\\cite\":\n            return f\"[{self.author}, {self.year}, {self.citation_label}]\"\n        elif citation_command == \"\\\\citep\":\n            return f\"[{self.author}, {self.year}, {self.citation_label}]\"\n        elif citation_command == \"\\\\citet\":\n            return f\"[{self.author}, {self.year}, {self.citation_label}]\"\n        elif citation_command == \"\\\\citeauthor\":\n            return self.author\n        elif citation_command == \"\\\\citeyear\":\n            return self.year\n        else:\n            return f\"[{self.author}, {self.year}, {self.citation_label}]\"\n</code></pre>"},{"location":"api-reference/#ragora.utils.latex_parser.Citation.to_text","title":"<code>to_text(citation_command)</code>","text":"<p>Convert the citation to a text string.</p> Source code in <code>ragora/ragora/utils/latex_parser.py</code> <pre><code>def to_text(self, citation_command: str) -&gt; str:\n    \"\"\"Convert the citation to a text string.\"\"\"\n    if citation_command == \"\\\\cite\":\n        return f\"[{self.author}, {self.year}, {self.citation_label}]\"\n    elif citation_command == \"\\\\citep\":\n        return f\"[{self.author}, {self.year}, {self.citation_label}]\"\n    elif citation_command == \"\\\\citet\":\n        return f\"[{self.author}, {self.year}, {self.citation_label}]\"\n    elif citation_command == \"\\\\citeauthor\":\n        return self.author\n    elif citation_command == \"\\\\citeyear\":\n        return self.year\n    else:\n        return f\"[{self.author}, {self.year}, {self.citation_label}]\"\n</code></pre>"},{"location":"api-reference/#ragora.utils.latex_parser.LatexChapter","title":"<code>LatexChapter</code>  <code>dataclass</code>","text":"<p>A LaTeX chapter.</p> Source code in <code>ragora/ragora/utils/latex_parser.py</code> <pre><code>@dataclass\nclass LatexChapter:\n    \"\"\"A LaTeX chapter.\"\"\"\n\n    title: str\n    label: str\n    paragraphs: Optional[List[LatexParagraph]] = None\n    sections: Optional[List[LatexSection]] = None\n</code></pre>"},{"location":"api-reference/#ragora.utils.latex_parser.LatexDocument","title":"<code>LatexDocument</code>  <code>dataclass</code>","text":"<p>A LaTeX document.</p> Source code in <code>ragora/ragora/utils/latex_parser.py</code> <pre><code>@dataclass\nclass LatexDocument:\n    \"\"\"A LaTeX document.\"\"\"\n\n    title: str\n    author: str\n    year: str\n    doi: str\n    source_document: str\n    page_reference: str\n    chapters: Optional[List[LatexChapter]] = None\n    sections: Optional[List[LatexSection]] = None\n    subsections: Optional[List[LatexSubsection]] = None\n    subsubsections: Optional[List[LatexSubsubsection]] = None\n    paragraphs: Optional[List[LatexParagraph]] = None\n    tables: Optional[List[LatexTable]] = None\n    figures: Optional[List[LatexFigure]] = None\n</code></pre>"},{"location":"api-reference/#ragora.utils.latex_parser.LatexFigure","title":"<code>LatexFigure</code>  <code>dataclass</code>","text":"<p>A LaTeX figure.</p> Source code in <code>ragora/ragora/utils/latex_parser.py</code> <pre><code>@dataclass\nclass LatexFigure:\n    \"\"\"A LaTeX figure.\"\"\"\n\n    caption: str\n    label: str\n    image_path: str\n</code></pre>"},{"location":"api-reference/#ragora.utils.latex_parser.LatexParagraph","title":"<code>LatexParagraph</code>  <code>dataclass</code>","text":"<p>A LaTeX paragraph.</p> Source code in <code>ragora/ragora/utils/latex_parser.py</code> <pre><code>@dataclass\nclass LatexParagraph:\n    \"\"\"A LaTeX paragraph.\"\"\"\n\n    content: str\n    citations: Optional[List[Citation]] = None\n</code></pre>"},{"location":"api-reference/#ragora.utils.latex_parser.LatexParser","title":"<code>LatexParser</code>","text":"<p>Parse LaTeX sources into structured document objects.</p> <p>The parser extracts citations, tables, figures, and hierarchical document structure (chapters/sections) that downstream components convert into chunks.</p> <p>Examples:</p> <pre><code>parser = LatexParser()\ndoc = parser.parse_document(\"paper.tex\")\nprint(doc.title)\n</code></pre> Source code in <code>ragora/ragora/utils/latex_parser.py</code> <pre><code>class LatexParser:\n    \"\"\"Parse LaTeX sources into structured document objects.\n\n    The parser extracts citations, tables, figures, and hierarchical document\n    structure (chapters/sections) that downstream components convert into\n    chunks.\n\n    Examples:\n        ```python\n        parser = LatexParser()\n        doc = parser.parse_document(\"paper.tex\")\n        print(doc.title)\n        ```\n    \"\"\"\n\n    def __init__(self, document_path: str = None, bibliography_path: str = None):\n        self.document_path = document_path\n        self.bibliography_path = bibliography_path\n        # If bibliography or document path is provided, load bibliography entries\n        # otherwise, set bibliography entries to an empty dictionary\n        self.bibliography_entries = (\n            self._load_bibliography()\n            if (self.bibliography_path or self.document_path)\n            else {}\n        )\n        # If document path is provided, parse the document\n        # otherwise, set document to None\n        self.document = self.parse_document(document_path) if document_path else None\n\n    def parse_bibliography(self, bibliography_path: str):\n        \"\"\"Parse the bibliography.\"\"\"\n        self.bibliography_path = bibliography_path\n        self.bibliography_entries = self._load_bibliography()\n\n    def get_bibliography_entries(self) -&gt; Dict[str, Citation]:\n        \"\"\"Get the bibliography entries.\"\"\"\n        return self.bibliography_entries\n\n    def _load_bibliography(self) -&gt; Dict[str, Citation]:\n        \"\"\"Load bibliography entries from bibliography_path file or document_path file.\"\"\"\n        if not (self.bibliography_path or self.document_path):\n            return {}\n        actual_path = self.bibliography_path or self.document_path\n        try:\n            with open(actual_path, \"r\", encoding=\"utf-8\") as file:\n                bib_content = file.read()\n            return self._parse_bibtex(bib_content)\n        except Exception as e:\n            logger.warning(f\"Could not load bibliography file: {e}\")\n            return {}\n\n    def _parse_bibtex(self, bib_content: str) -&gt; Dict[str, Citation]:\n        \"\"\"Parse BibTeX content into Citation objects.\"\"\"\n        entries = {}\n\n        # Split into individual entries\n        bib_entries = re.split(r\"\\n\\s*\\n\", bib_content)\n\n        for entry in bib_entries:\n            if not entry.strip():\n                continue\n\n            # Extract entry type and key\n            type_match = re.search(r\"@(\\w+)\\{([^,]+),\", entry)\n            if not type_match:\n                continue\n\n            entry_type = type_match.group(1)\n            entry_key = type_match.group(2)\n\n            # Only process article, book, inproceedings, etc.\n            if entry_type.lower() not in [\n                \"article\",\n                \"book\",\n                \"inproceedings\",\n                \"conference\",\n                \"techreport\",\n            ]:\n                continue\n\n            # Extract fields\n            author = self._extract_bib_field(entry, \"author\", \"Unknown\")\n            year = self._extract_bib_field(entry, \"year\", \"Unknown\")\n            title = self._extract_bib_field(entry, \"title\", \"Unknown\")\n            doi = self._extract_bib_field(entry, \"doi\", \"\")\n\n            citation = Citation(\n                author=author,\n                year=year,\n                title=title,\n                doi=doi,\n                source_document=self.bibliography_path or \"unknown\",\n                page_reference=\"\",\n                citation_label=entry_key,\n                citation_hash=hash(entry_key),\n            )\n\n            entries[entry_key] = citation\n\n        return entries\n\n    def _extract_bib_field(self, entry: str, field: str, default: str) -&gt; str:\n        \"\"\"Extract a specific field from a BibTeX entry.\"\"\"\n        pattern = rf\"{field}\\s*=\\s*{{([^}}]+)}}\"\n        match = re.search(pattern, entry, re.IGNORECASE)\n        return match.group(1).strip() if match else default\n\n    def parse_document(self, document_path: str) -&gt; LatexDocument:\n        \"\"\"Parse a LaTeX file into a :class:`LatexDocument`.\n\n        Args:\n            document_path: Path to the `.tex` file.\n\n        Returns:\n            LatexDocument | None: Parsed representation, or ``None`` if parsing fails.\n\n        Examples:\n            ```python\n            parser = LatexParser()\n            document = parser.parse_document(\"thesis.tex\")\n            ```\n        \"\"\"\n        try:\n            if not self.document_path:\n                self.document_path = document_path\n            with open(document_path, \"r\", encoding=\"utf-8\") as file:\n                document_text = file.read()\n            return self.parse_document_text(document_text)\n        except Exception as e:\n            logger.error(f\"Error parsing document: {e}\")\n            return None\n\n    def parse_document_text(self, document_text: str) -&gt; LatexDocument:\n        \"\"\"Parse in-memory LaTeX text into a :class:`LatexDocument`.\n\n        Args:\n            document_text: Raw LaTeX content.\n\n        Returns:\n            LatexDocument: Parsed representation suitable for chunking.\n\n        Examples:\n            ```python\n            parser = LatexParser()\n            doc = parser.parse_document_text(\n                \"\\\\title{Sample}\\\\n\\\\begin{document}Hello\\\\end{document}\"\n            )\n            ```\n        \"\"\"\n        # Extract document metadata\n        title = self._extract_title(document_text)\n        author = self._extract_author(document_text)\n        year = self._extract_year(document_text)\n        doi = self._extract_doi(document_text)\n\n        cleaned_text = self._remove_document_preamble(document_text)\n\n        # Parse tables and figures FIRST (to remove them from text)\n        tables, cleaned_text = self._parse_tables(cleaned_text)\n        figures, cleaned_text = self._parse_figures(cleaned_text)\n\n        # Parse chapters hierarchically from cleaned text\n        chapters, cleaned_text = self._parse_chapters(cleaned_text)\n\n        # Parse sections hierarchically from cleaned text\n        sections, cleaned_text = self._parse_sections(cleaned_text)\n\n        # Parse paragraphs from remaining text\n        paragraphs = self._parse_paragraphs(cleaned_text)\n\n        return LatexDocument(\n            title=title,\n            author=author,\n            year=year,\n            doi=doi,\n            source_document=self.document_path,\n            page_reference=\"1\",\n            chapters=chapters,\n            sections=sections,\n            paragraphs=paragraphs,\n            tables=tables,\n            figures=figures,\n        )\n\n    def _remove_document_preamble(self, text: str) -&gt; str:\n        \"\"\"Remove document preamble from text.\"\"\"\n        return re.sub(r\"\\\\begin\\{document\\}|\\\\end\\{document\\}\", \"\", text)\n\n    def _extract_title(self, text: str) -&gt; str:\n        \"\"\"Extract document title from LaTeX text.\"\"\"\n        title_match = re.search(r\"\\\\title\\{([^}]+)\\}\", text)\n        return title_match.group(1) if title_match else \"\"\n\n    def _extract_author(self, text: str) -&gt; str:\n        \"\"\"Extract document author from LaTeX text.\"\"\"\n        author_match = re.search(r\"\\\\author\\{([^}]+)\\}\", text)\n        return author_match.group(1) if author_match else \"\"\n\n    def _extract_year(self, text: str) -&gt; str:\n        \"\"\"Extract document year from LaTeX text.\"\"\"\n        year_match = re.search(r\"\\\\date\\{([^}]+)\\}\", text)\n        if year_match:\n            year_text = year_match.group(1)\n            year_match = re.search(r\"\\b(\\d{4})\\b\", year_text)\n            return year_match.group(1) if year_match else year_text\n        return \"\"\n\n    def _extract_label(self, text: str) -&gt; str:\n        \"\"\"Extract label from LaTeX text.\"\"\"\n        label_match = re.search(r\"\\\\label\\{([^}]+)\\}\", text)\n        return label_match.group(1) if label_match else \"\"\n\n    def _extract_doi(self, text: str) -&gt; str:\n        \"\"\"Extract DOI from LaTeX text.\"\"\"\n        doi_match = re.search(r\"\\\\doi\\{([^}]+)\\}\", text)\n        return doi_match.group(1) if doi_match else \"\"\n\n    def _parse_chapters(self, text: str) -&gt; tuple[List[LatexChapter], str]:\n        \"\"\"Parse chapters hierarchically from LaTeX text.\"\"\"\n        chapters = []\n        remaining_text = text\n        # Split text into chapter blocks\n        chapter_blocks = self._split_into_chapters(text)\n\n        for block in chapter_blocks:\n            if block.strip():\n                chapter = self._parse_single_chapter(block)\n                if chapter:\n                    chapters.append(chapter)\n                    remaining_text = remaining_text.replace(block, \"\", 1)\n\n        return chapters, remaining_text\n\n    def _split_into_chapters(self, text: str) -&gt; List[str]:\n        \"\"\"Split LaTeX text into chapter blocks.\"\"\"\n        # Use re.finditer to match chapter command and its content together\n        chapter_pattern = r\"(\\\\chapter\\*?\\{[^}]+\\}.*?)(?=(\\\\chapter\\*?\\{[^}]+\\})|$)\"\n        matches = re.finditer(chapter_pattern, text, re.DOTALL)\n        return [m.group(1) for m in matches]\n\n    def _parse_single_chapter(self, chapter_text: str) -&gt; Optional[LatexChapter]:\n        \"\"\"Parse a single chapter block into a LatexChapter object.\"\"\"\n        title_match = re.search(r\"\\\\chapter\\*?\\{([^}]+)\\}\", chapter_text)\n        chapter_text_after_title = re.sub(r\"\\\\chapter\\*?\\{[^}]+\\}\", \"\", chapter_text)\n        if not title_match:\n            return None\n\n        title = title_match.group(1)\n        label = self._extract_label(chapter_text)\n        chapter_text_after_label = re.sub(\n            r\"\\\\label\\{[^}]+\\}\", \"\", chapter_text_after_title, count=1\n        )\n\n        # capture sections\n        sections, remaining_text = self._parse_sections(chapter_text_after_label)\n\n        # capture paragraphs\n        paragraphs = self._parse_paragraphs(remaining_text)\n\n        return LatexChapter(\n            title=title, label=label, paragraphs=paragraphs, sections=sections\n        )\n\n    def _parse_sections(self, text: str) -&gt; tuple[List[LatexSection], str]:\n        \"\"\"Parse sections hierarchically from LaTeX text.\n        Returns:\n            List[LatexSection]: List of sections\n            str: Remaining text after sections are parsed and removed\n        \"\"\"\n        sections = []\n        remaining_text = text\n        # Split text into section blocks\n        section_blocks = self._split_into_sections(text)\n\n        for block in section_blocks:\n            if block.strip():\n                section = self._parse_single_section(block)\n                if section:\n                    remaining_text = remaining_text.replace(block, \"\", 1)\n                    sections.append(section)\n\n        return sections, remaining_text\n\n    def _split_into_sections(self, text: str) -&gt; List[str]:\n        \"\"\"Split LaTeX text into section blocks which start with section, subsection, or subsubsection.\n        Any other text not part of a section command is ignored.\n        Returns:\n            List[str]: List of section blocks\n        \"\"\"\n\n        # Split by section, subsection, or subsubsection commands\n        section_pattern = r\"(\\\\section\\*?\\{[^}]+\\}|\\\\subsection\\*?\\{[^}]+\\}|\\\\subsubsection\\*?\\{[^}]+\\})\"\n        parts = re.split(section_pattern, text)\n\n        # Group section commands with their content\n        sections = []\n        current_section = \"\"\n\n        for i, part in enumerate(parts):\n            if (\n                part.startswith(\"\\\\section\")\n                or part.startswith(\"\\\\subsection\")\n                or part.startswith(\"\\\\subsubsection\")\n            ):\n                if current_section:\n                    sections.append(current_section)\n                current_section = part\n            elif i &gt; 0:\n                current_section += part\n\n        if current_section:\n            sections.append(current_section)\n\n        return sections\n\n    def _parse_single_section(self, section_text: str) -&gt; Optional[LatexSection]:\n        \"\"\"Parse a single section block into a LatexSection object.\"\"\"\n\n        regular_expression = r\"\\\\section\\*?\\{([^}]+)\\}|\\\\subsection\\*?\\{([^}]+)\\}|\\\\subsubsection\\*?\\{([^}]+)\\}\"\n\n        # Extract section title\n        title_match = re.search(\n            regular_expression,\n            section_text,\n        )\n        if not title_match:\n            return None\n\n        title = (\n            title_match.group(1)\n            if title_match.group(1)\n            else title_match.group(2) if title_match.group(2) else title_match.group(3)\n        )\n\n        # Remove the section command\n        section_text = re.sub(regular_expression, \"\", section_text)\n\n        # capture label\n        label = self._extract_label(section_text)\n        section_text_after_label = re.sub(\n            r\"\\\\label\\{[^}]+\\}\", \"\", section_text, count=1\n        )\n\n        # Extract paragraphs\n        paragraphs = self._parse_paragraphs(section_text_after_label)\n\n        return LatexSection(title=title, label=label, paragraphs=paragraphs)\n\n    def _parse_paragraphs(self, text: str) -&gt; List[LatexParagraph]:\n        \"\"\"Parse paragraphs from section text.\"\"\"\n        paragraphs = []\n\n        # Split by paragraph breaks (double newlines or \\par commands)\n        para_blocks = re.split(r\"\\n\\s*\\n|\\s*\\\\par\\s*\", text)\n\n        for block in para_blocks:\n            block = block.strip()\n            if block and not block.startswith(\"\\\\\"):\n                # Extract citations and embed them in text\n                clean_content, citations = self._process_citations_in_text(block)\n\n                if clean_content.strip():\n                    paragraphs.append(\n                        LatexParagraph(content=clean_content, citations=citations)\n                    )\n\n        return paragraphs\n\n    def _process_citations_in_text(self, text: str) -&gt; tuple[str, List[Citation]]:\n        \"\"\"Process citations in text, embedding them and creating Citation objects.\"\"\"\n        citations = []\n        processed_text = text\n\n        # Find all citation commands\n        cite_patterns = [\n            (r\"\\\\cite\\{([^}]+)\\}\", \"\\\\cite\"),\n            (r\"\\\\citep\\{([^}]+)\\}\", \"\\\\citep\"),\n            (r\"\\\\citet\\{([^}]+)\\}\", \"\\\\citet\"),\n            (r\"\\\\citeauthor\\{([^}]+)\\}\", \"\\\\citeauthor\"),\n            (r\"\\\\citeyear\\{([^}]+)\\}\", \"\\\\citeyear\"),\n        ]\n\n        for pattern, command in cite_patterns:\n            matches = list(re.finditer(pattern, processed_text))\n\n            for match in reversed(matches):  # Process in reverse to maintain indices\n                citation_key = match.group(1)\n                citation = self._get_or_create_citation(citation_key)\n                citations.append(citation)\n\n                # Replace citation command with embedded text\n                replacement = citation.to_text(command)\n                start, end = match.span()\n                processed_text = (\n                    processed_text[:start] + replacement + processed_text[end:]\n                )\n\n        return processed_text, citations\n\n    def _get_or_create_citation(self, citation_key: str) -&gt; Citation:\n        \"\"\"Get existing citation from bibliography or create a new one.\"\"\"\n        if citation_key in self.bibliography_entries:\n            return self.bibliography_entries[citation_key]\n\n        # Create placeholder citation\n        return Citation(\n            author=\"Unknown\",\n            year=\"Unknown\",\n            title=\"Unknown\",\n            doi=\"\",\n            source_document=self.document_path or \"unknown\",\n            page_reference=\"\",\n            citation_label=citation_key,\n            citation_hash=hash(citation_key),\n        )\n\n    def _parse_tables(self, text: str) -&gt; tuple[List[LatexTable], str]:\n        \"\"\"Parse tables from LaTeX text.\"\"\"\n        tables = []\n        remaining_text = text\n\n        # Find table environments\n        table_pattern = r\"\\\\begin\\{table\\}.*?\\\\end\\{table\\}\"\n        table_matches = re.finditer(table_pattern, text, re.DOTALL)\n\n        for match in table_matches:\n            table_text = match.group(0)\n            table = self._parse_single_table(table_text)\n            if table:\n                tables.append(table)\n                # remove the table text from the text\n                remaining_text = remaining_text.replace(table_text, \"\", 1)\n\n        return tables, remaining_text\n\n    def _parse_single_table(self, table_text: str) -&gt; Optional[LatexTable]:\n        \"\"\"Parse a single table environment.\"\"\"\n        # Extract caption\n        caption_match = re.search(r\"\\\\caption\\{([^}]+)\\}\", table_text)\n        caption = caption_match.group(1) if caption_match else \"\"\n\n        # Extract label\n        label_match = re.search(r\"\\\\label\\{([^}]+)\\}\", table_text)\n        label = label_match.group(1) if label_match else \"\"\n\n        # Parse tabular content\n        headers, rows = self._parse_tabular_content(table_text)\n\n        return (\n            LatexTable(caption=caption, label=label, headers=headers, rows=rows)\n            if headers or rows\n            else None\n        )\n\n    def _parse_tabular_content(\n        self, table_text: str\n    ) -&gt; tuple[List[str], List[List[str]]]:\n        \"\"\"Parse tabular content from table text.\"\"\"\n        # Find tabular environment\n        tabular_match = re.search(\n            r\"\\\\begin\\{tabular\\}.*?\\\\end\\{tabular\\}\", table_text, re.DOTALL\n        )\n        if not tabular_match:\n            return [], []\n\n        tabular_text = tabular_match.group(0)\n\n        # Remove the tabular commands and only keep the content\n        tabular_text = re.sub(r\"\\\\begin\\{tabular\\}\", \"\", tabular_text)\n        tabular_text = re.sub(r\"\\\\end\\{tabular\\}\", \"\", tabular_text)\n        tabular_text = tabular_text.strip()\n\n        # Remove column formatting like {|c|c|} at the start of tabular\n        tabular_text = re.sub(r\"^\\s*\\{[^\\}]*\\}\\s*\", \"\", tabular_text)\n        tabular_text = tabular_text.strip()\n        # Split into rows\n        rows = []\n        for line in tabular_text.split(\"\\\\\\\\\"):\n            if \"&amp;\" in line:\n                # Split by &amp; and clean up\n                cells = [\n                    cell.strip().replace(\"\\\\hline\", \"\").strip()\n                    for cell in line.split(\"&amp;\")\n                ]\n                cells = [cell for cell in cells if cell]\n                if cells:\n                    rows.append(cells)\n\n        # First row is headers\n        headers = rows[0] if rows else []\n        data_rows = rows[1:] if len(rows) &gt; 1 else []\n\n        return headers, data_rows\n\n    def _parse_figures(self, text: str) -&gt; tuple[List[LatexFigure], str]:\n        \"\"\"Parse figures from LaTeX text.\"\"\"\n        figures = []\n        remaining_text = text\n        # Find figure environments\n        figure_pattern = r\"\\\\begin\\{figure\\}.*?\\\\end\\{figure\\}\"\n        figure_matches = re.finditer(figure_pattern, text, re.DOTALL)\n\n        for match in figure_matches:\n            figure_text = match.group(0)\n            figure = self._parse_single_figure(figure_text)\n            if figure:\n                figures.append(figure)\n                # remove the figure text from the text\n                remaining_text = remaining_text.replace(figure_text, \"\", 1)\n\n        return figures, remaining_text\n\n    def _parse_single_figure(self, figure_text: str) -&gt; Optional[LatexFigure]:\n        \"\"\"Parse a single figure environment.\"\"\"\n        # Extract caption\n        caption_match = re.search(r\"\\\\caption\\{([^}]+)\\}\", figure_text)\n        caption = caption_match.group(1) if caption_match else \"\"\n\n        # Extract label\n        label_match = re.search(r\"\\\\label\\{([^}]+)\\}\", figure_text)\n        label = label_match.group(1) if label_match else \"\"\n\n        # Extract image path\n        includegraphics_match = re.search(r\"\\\\includegraphics\\{([^}]+)\\}\", figure_text)\n        image_path = includegraphics_match.group(1) if includegraphics_match else \"\"\n\n        return LatexFigure(caption=caption, label=label, image_path=image_path)\n</code></pre>"},{"location":"api-reference/#ragora.utils.latex_parser.LatexParser._extract_author","title":"<code>_extract_author(text)</code>","text":"<p>Extract document author from LaTeX text.</p> Source code in <code>ragora/ragora/utils/latex_parser.py</code> <pre><code>def _extract_author(self, text: str) -&gt; str:\n    \"\"\"Extract document author from LaTeX text.\"\"\"\n    author_match = re.search(r\"\\\\author\\{([^}]+)\\}\", text)\n    return author_match.group(1) if author_match else \"\"\n</code></pre>"},{"location":"api-reference/#ragora.utils.latex_parser.LatexParser._extract_bib_field","title":"<code>_extract_bib_field(entry, field, default)</code>","text":"<p>Extract a specific field from a BibTeX entry.</p> Source code in <code>ragora/ragora/utils/latex_parser.py</code> <pre><code>def _extract_bib_field(self, entry: str, field: str, default: str) -&gt; str:\n    \"\"\"Extract a specific field from a BibTeX entry.\"\"\"\n    pattern = rf\"{field}\\s*=\\s*{{([^}}]+)}}\"\n    match = re.search(pattern, entry, re.IGNORECASE)\n    return match.group(1).strip() if match else default\n</code></pre>"},{"location":"api-reference/#ragora.utils.latex_parser.LatexParser._extract_doi","title":"<code>_extract_doi(text)</code>","text":"<p>Extract DOI from LaTeX text.</p> Source code in <code>ragora/ragora/utils/latex_parser.py</code> <pre><code>def _extract_doi(self, text: str) -&gt; str:\n    \"\"\"Extract DOI from LaTeX text.\"\"\"\n    doi_match = re.search(r\"\\\\doi\\{([^}]+)\\}\", text)\n    return doi_match.group(1) if doi_match else \"\"\n</code></pre>"},{"location":"api-reference/#ragora.utils.latex_parser.LatexParser._extract_label","title":"<code>_extract_label(text)</code>","text":"<p>Extract label from LaTeX text.</p> Source code in <code>ragora/ragora/utils/latex_parser.py</code> <pre><code>def _extract_label(self, text: str) -&gt; str:\n    \"\"\"Extract label from LaTeX text.\"\"\"\n    label_match = re.search(r\"\\\\label\\{([^}]+)\\}\", text)\n    return label_match.group(1) if label_match else \"\"\n</code></pre>"},{"location":"api-reference/#ragora.utils.latex_parser.LatexParser._extract_title","title":"<code>_extract_title(text)</code>","text":"<p>Extract document title from LaTeX text.</p> Source code in <code>ragora/ragora/utils/latex_parser.py</code> <pre><code>def _extract_title(self, text: str) -&gt; str:\n    \"\"\"Extract document title from LaTeX text.\"\"\"\n    title_match = re.search(r\"\\\\title\\{([^}]+)\\}\", text)\n    return title_match.group(1) if title_match else \"\"\n</code></pre>"},{"location":"api-reference/#ragora.utils.latex_parser.LatexParser._extract_year","title":"<code>_extract_year(text)</code>","text":"<p>Extract document year from LaTeX text.</p> Source code in <code>ragora/ragora/utils/latex_parser.py</code> <pre><code>def _extract_year(self, text: str) -&gt; str:\n    \"\"\"Extract document year from LaTeX text.\"\"\"\n    year_match = re.search(r\"\\\\date\\{([^}]+)\\}\", text)\n    if year_match:\n        year_text = year_match.group(1)\n        year_match = re.search(r\"\\b(\\d{4})\\b\", year_text)\n        return year_match.group(1) if year_match else year_text\n    return \"\"\n</code></pre>"},{"location":"api-reference/#ragora.utils.latex_parser.LatexParser._get_or_create_citation","title":"<code>_get_or_create_citation(citation_key)</code>","text":"<p>Get existing citation from bibliography or create a new one.</p> Source code in <code>ragora/ragora/utils/latex_parser.py</code> <pre><code>def _get_or_create_citation(self, citation_key: str) -&gt; Citation:\n    \"\"\"Get existing citation from bibliography or create a new one.\"\"\"\n    if citation_key in self.bibliography_entries:\n        return self.bibliography_entries[citation_key]\n\n    # Create placeholder citation\n    return Citation(\n        author=\"Unknown\",\n        year=\"Unknown\",\n        title=\"Unknown\",\n        doi=\"\",\n        source_document=self.document_path or \"unknown\",\n        page_reference=\"\",\n        citation_label=citation_key,\n        citation_hash=hash(citation_key),\n    )\n</code></pre>"},{"location":"api-reference/#ragora.utils.latex_parser.LatexParser._load_bibliography","title":"<code>_load_bibliography()</code>","text":"<p>Load bibliography entries from bibliography_path file or document_path file.</p> Source code in <code>ragora/ragora/utils/latex_parser.py</code> <pre><code>def _load_bibliography(self) -&gt; Dict[str, Citation]:\n    \"\"\"Load bibliography entries from bibliography_path file or document_path file.\"\"\"\n    if not (self.bibliography_path or self.document_path):\n        return {}\n    actual_path = self.bibliography_path or self.document_path\n    try:\n        with open(actual_path, \"r\", encoding=\"utf-8\") as file:\n            bib_content = file.read()\n        return self._parse_bibtex(bib_content)\n    except Exception as e:\n        logger.warning(f\"Could not load bibliography file: {e}\")\n        return {}\n</code></pre>"},{"location":"api-reference/#ragora.utils.latex_parser.LatexParser._parse_bibtex","title":"<code>_parse_bibtex(bib_content)</code>","text":"<p>Parse BibTeX content into Citation objects.</p> Source code in <code>ragora/ragora/utils/latex_parser.py</code> <pre><code>def _parse_bibtex(self, bib_content: str) -&gt; Dict[str, Citation]:\n    \"\"\"Parse BibTeX content into Citation objects.\"\"\"\n    entries = {}\n\n    # Split into individual entries\n    bib_entries = re.split(r\"\\n\\s*\\n\", bib_content)\n\n    for entry in bib_entries:\n        if not entry.strip():\n            continue\n\n        # Extract entry type and key\n        type_match = re.search(r\"@(\\w+)\\{([^,]+),\", entry)\n        if not type_match:\n            continue\n\n        entry_type = type_match.group(1)\n        entry_key = type_match.group(2)\n\n        # Only process article, book, inproceedings, etc.\n        if entry_type.lower() not in [\n            \"article\",\n            \"book\",\n            \"inproceedings\",\n            \"conference\",\n            \"techreport\",\n        ]:\n            continue\n\n        # Extract fields\n        author = self._extract_bib_field(entry, \"author\", \"Unknown\")\n        year = self._extract_bib_field(entry, \"year\", \"Unknown\")\n        title = self._extract_bib_field(entry, \"title\", \"Unknown\")\n        doi = self._extract_bib_field(entry, \"doi\", \"\")\n\n        citation = Citation(\n            author=author,\n            year=year,\n            title=title,\n            doi=doi,\n            source_document=self.bibliography_path or \"unknown\",\n            page_reference=\"\",\n            citation_label=entry_key,\n            citation_hash=hash(entry_key),\n        )\n\n        entries[entry_key] = citation\n\n    return entries\n</code></pre>"},{"location":"api-reference/#ragora.utils.latex_parser.LatexParser._parse_chapters","title":"<code>_parse_chapters(text)</code>","text":"<p>Parse chapters hierarchically from LaTeX text.</p> Source code in <code>ragora/ragora/utils/latex_parser.py</code> <pre><code>def _parse_chapters(self, text: str) -&gt; tuple[List[LatexChapter], str]:\n    \"\"\"Parse chapters hierarchically from LaTeX text.\"\"\"\n    chapters = []\n    remaining_text = text\n    # Split text into chapter blocks\n    chapter_blocks = self._split_into_chapters(text)\n\n    for block in chapter_blocks:\n        if block.strip():\n            chapter = self._parse_single_chapter(block)\n            if chapter:\n                chapters.append(chapter)\n                remaining_text = remaining_text.replace(block, \"\", 1)\n\n    return chapters, remaining_text\n</code></pre>"},{"location":"api-reference/#ragora.utils.latex_parser.LatexParser._parse_figures","title":"<code>_parse_figures(text)</code>","text":"<p>Parse figures from LaTeX text.</p> Source code in <code>ragora/ragora/utils/latex_parser.py</code> <pre><code>def _parse_figures(self, text: str) -&gt; tuple[List[LatexFigure], str]:\n    \"\"\"Parse figures from LaTeX text.\"\"\"\n    figures = []\n    remaining_text = text\n    # Find figure environments\n    figure_pattern = r\"\\\\begin\\{figure\\}.*?\\\\end\\{figure\\}\"\n    figure_matches = re.finditer(figure_pattern, text, re.DOTALL)\n\n    for match in figure_matches:\n        figure_text = match.group(0)\n        figure = self._parse_single_figure(figure_text)\n        if figure:\n            figures.append(figure)\n            # remove the figure text from the text\n            remaining_text = remaining_text.replace(figure_text, \"\", 1)\n\n    return figures, remaining_text\n</code></pre>"},{"location":"api-reference/#ragora.utils.latex_parser.LatexParser._parse_paragraphs","title":"<code>_parse_paragraphs(text)</code>","text":"<p>Parse paragraphs from section text.</p> Source code in <code>ragora/ragora/utils/latex_parser.py</code> <pre><code>def _parse_paragraphs(self, text: str) -&gt; List[LatexParagraph]:\n    \"\"\"Parse paragraphs from section text.\"\"\"\n    paragraphs = []\n\n    # Split by paragraph breaks (double newlines or \\par commands)\n    para_blocks = re.split(r\"\\n\\s*\\n|\\s*\\\\par\\s*\", text)\n\n    for block in para_blocks:\n        block = block.strip()\n        if block and not block.startswith(\"\\\\\"):\n            # Extract citations and embed them in text\n            clean_content, citations = self._process_citations_in_text(block)\n\n            if clean_content.strip():\n                paragraphs.append(\n                    LatexParagraph(content=clean_content, citations=citations)\n                )\n\n    return paragraphs\n</code></pre>"},{"location":"api-reference/#ragora.utils.latex_parser.LatexParser._parse_sections","title":"<code>_parse_sections(text)</code>","text":"<p>Parse sections hierarchically from LaTeX text. Returns:     List[LatexSection]: List of sections     str: Remaining text after sections are parsed and removed</p> Source code in <code>ragora/ragora/utils/latex_parser.py</code> <pre><code>def _parse_sections(self, text: str) -&gt; tuple[List[LatexSection], str]:\n    \"\"\"Parse sections hierarchically from LaTeX text.\n    Returns:\n        List[LatexSection]: List of sections\n        str: Remaining text after sections are parsed and removed\n    \"\"\"\n    sections = []\n    remaining_text = text\n    # Split text into section blocks\n    section_blocks = self._split_into_sections(text)\n\n    for block in section_blocks:\n        if block.strip():\n            section = self._parse_single_section(block)\n            if section:\n                remaining_text = remaining_text.replace(block, \"\", 1)\n                sections.append(section)\n\n    return sections, remaining_text\n</code></pre>"},{"location":"api-reference/#ragora.utils.latex_parser.LatexParser._parse_single_chapter","title":"<code>_parse_single_chapter(chapter_text)</code>","text":"<p>Parse a single chapter block into a LatexChapter object.</p> Source code in <code>ragora/ragora/utils/latex_parser.py</code> <pre><code>def _parse_single_chapter(self, chapter_text: str) -&gt; Optional[LatexChapter]:\n    \"\"\"Parse a single chapter block into a LatexChapter object.\"\"\"\n    title_match = re.search(r\"\\\\chapter\\*?\\{([^}]+)\\}\", chapter_text)\n    chapter_text_after_title = re.sub(r\"\\\\chapter\\*?\\{[^}]+\\}\", \"\", chapter_text)\n    if not title_match:\n        return None\n\n    title = title_match.group(1)\n    label = self._extract_label(chapter_text)\n    chapter_text_after_label = re.sub(\n        r\"\\\\label\\{[^}]+\\}\", \"\", chapter_text_after_title, count=1\n    )\n\n    # capture sections\n    sections, remaining_text = self._parse_sections(chapter_text_after_label)\n\n    # capture paragraphs\n    paragraphs = self._parse_paragraphs(remaining_text)\n\n    return LatexChapter(\n        title=title, label=label, paragraphs=paragraphs, sections=sections\n    )\n</code></pre>"},{"location":"api-reference/#ragora.utils.latex_parser.LatexParser._parse_single_figure","title":"<code>_parse_single_figure(figure_text)</code>","text":"<p>Parse a single figure environment.</p> Source code in <code>ragora/ragora/utils/latex_parser.py</code> <pre><code>def _parse_single_figure(self, figure_text: str) -&gt; Optional[LatexFigure]:\n    \"\"\"Parse a single figure environment.\"\"\"\n    # Extract caption\n    caption_match = re.search(r\"\\\\caption\\{([^}]+)\\}\", figure_text)\n    caption = caption_match.group(1) if caption_match else \"\"\n\n    # Extract label\n    label_match = re.search(r\"\\\\label\\{([^}]+)\\}\", figure_text)\n    label = label_match.group(1) if label_match else \"\"\n\n    # Extract image path\n    includegraphics_match = re.search(r\"\\\\includegraphics\\{([^}]+)\\}\", figure_text)\n    image_path = includegraphics_match.group(1) if includegraphics_match else \"\"\n\n    return LatexFigure(caption=caption, label=label, image_path=image_path)\n</code></pre>"},{"location":"api-reference/#ragora.utils.latex_parser.LatexParser._parse_single_section","title":"<code>_parse_single_section(section_text)</code>","text":"<p>Parse a single section block into a LatexSection object.</p> Source code in <code>ragora/ragora/utils/latex_parser.py</code> <pre><code>def _parse_single_section(self, section_text: str) -&gt; Optional[LatexSection]:\n    \"\"\"Parse a single section block into a LatexSection object.\"\"\"\n\n    regular_expression = r\"\\\\section\\*?\\{([^}]+)\\}|\\\\subsection\\*?\\{([^}]+)\\}|\\\\subsubsection\\*?\\{([^}]+)\\}\"\n\n    # Extract section title\n    title_match = re.search(\n        regular_expression,\n        section_text,\n    )\n    if not title_match:\n        return None\n\n    title = (\n        title_match.group(1)\n        if title_match.group(1)\n        else title_match.group(2) if title_match.group(2) else title_match.group(3)\n    )\n\n    # Remove the section command\n    section_text = re.sub(regular_expression, \"\", section_text)\n\n    # capture label\n    label = self._extract_label(section_text)\n    section_text_after_label = re.sub(\n        r\"\\\\label\\{[^}]+\\}\", \"\", section_text, count=1\n    )\n\n    # Extract paragraphs\n    paragraphs = self._parse_paragraphs(section_text_after_label)\n\n    return LatexSection(title=title, label=label, paragraphs=paragraphs)\n</code></pre>"},{"location":"api-reference/#ragora.utils.latex_parser.LatexParser._parse_single_table","title":"<code>_parse_single_table(table_text)</code>","text":"<p>Parse a single table environment.</p> Source code in <code>ragora/ragora/utils/latex_parser.py</code> <pre><code>def _parse_single_table(self, table_text: str) -&gt; Optional[LatexTable]:\n    \"\"\"Parse a single table environment.\"\"\"\n    # Extract caption\n    caption_match = re.search(r\"\\\\caption\\{([^}]+)\\}\", table_text)\n    caption = caption_match.group(1) if caption_match else \"\"\n\n    # Extract label\n    label_match = re.search(r\"\\\\label\\{([^}]+)\\}\", table_text)\n    label = label_match.group(1) if label_match else \"\"\n\n    # Parse tabular content\n    headers, rows = self._parse_tabular_content(table_text)\n\n    return (\n        LatexTable(caption=caption, label=label, headers=headers, rows=rows)\n        if headers or rows\n        else None\n    )\n</code></pre>"},{"location":"api-reference/#ragora.utils.latex_parser.LatexParser._parse_tables","title":"<code>_parse_tables(text)</code>","text":"<p>Parse tables from LaTeX text.</p> Source code in <code>ragora/ragora/utils/latex_parser.py</code> <pre><code>def _parse_tables(self, text: str) -&gt; tuple[List[LatexTable], str]:\n    \"\"\"Parse tables from LaTeX text.\"\"\"\n    tables = []\n    remaining_text = text\n\n    # Find table environments\n    table_pattern = r\"\\\\begin\\{table\\}.*?\\\\end\\{table\\}\"\n    table_matches = re.finditer(table_pattern, text, re.DOTALL)\n\n    for match in table_matches:\n        table_text = match.group(0)\n        table = self._parse_single_table(table_text)\n        if table:\n            tables.append(table)\n            # remove the table text from the text\n            remaining_text = remaining_text.replace(table_text, \"\", 1)\n\n    return tables, remaining_text\n</code></pre>"},{"location":"api-reference/#ragora.utils.latex_parser.LatexParser._parse_tabular_content","title":"<code>_parse_tabular_content(table_text)</code>","text":"<p>Parse tabular content from table text.</p> Source code in <code>ragora/ragora/utils/latex_parser.py</code> <pre><code>def _parse_tabular_content(\n    self, table_text: str\n) -&gt; tuple[List[str], List[List[str]]]:\n    \"\"\"Parse tabular content from table text.\"\"\"\n    # Find tabular environment\n    tabular_match = re.search(\n        r\"\\\\begin\\{tabular\\}.*?\\\\end\\{tabular\\}\", table_text, re.DOTALL\n    )\n    if not tabular_match:\n        return [], []\n\n    tabular_text = tabular_match.group(0)\n\n    # Remove the tabular commands and only keep the content\n    tabular_text = re.sub(r\"\\\\begin\\{tabular\\}\", \"\", tabular_text)\n    tabular_text = re.sub(r\"\\\\end\\{tabular\\}\", \"\", tabular_text)\n    tabular_text = tabular_text.strip()\n\n    # Remove column formatting like {|c|c|} at the start of tabular\n    tabular_text = re.sub(r\"^\\s*\\{[^\\}]*\\}\\s*\", \"\", tabular_text)\n    tabular_text = tabular_text.strip()\n    # Split into rows\n    rows = []\n    for line in tabular_text.split(\"\\\\\\\\\"):\n        if \"&amp;\" in line:\n            # Split by &amp; and clean up\n            cells = [\n                cell.strip().replace(\"\\\\hline\", \"\").strip()\n                for cell in line.split(\"&amp;\")\n            ]\n            cells = [cell for cell in cells if cell]\n            if cells:\n                rows.append(cells)\n\n    # First row is headers\n    headers = rows[0] if rows else []\n    data_rows = rows[1:] if len(rows) &gt; 1 else []\n\n    return headers, data_rows\n</code></pre>"},{"location":"api-reference/#ragora.utils.latex_parser.LatexParser._process_citations_in_text","title":"<code>_process_citations_in_text(text)</code>","text":"<p>Process citations in text, embedding them and creating Citation objects.</p> Source code in <code>ragora/ragora/utils/latex_parser.py</code> <pre><code>def _process_citations_in_text(self, text: str) -&gt; tuple[str, List[Citation]]:\n    \"\"\"Process citations in text, embedding them and creating Citation objects.\"\"\"\n    citations = []\n    processed_text = text\n\n    # Find all citation commands\n    cite_patterns = [\n        (r\"\\\\cite\\{([^}]+)\\}\", \"\\\\cite\"),\n        (r\"\\\\citep\\{([^}]+)\\}\", \"\\\\citep\"),\n        (r\"\\\\citet\\{([^}]+)\\}\", \"\\\\citet\"),\n        (r\"\\\\citeauthor\\{([^}]+)\\}\", \"\\\\citeauthor\"),\n        (r\"\\\\citeyear\\{([^}]+)\\}\", \"\\\\citeyear\"),\n    ]\n\n    for pattern, command in cite_patterns:\n        matches = list(re.finditer(pattern, processed_text))\n\n        for match in reversed(matches):  # Process in reverse to maintain indices\n            citation_key = match.group(1)\n            citation = self._get_or_create_citation(citation_key)\n            citations.append(citation)\n\n            # Replace citation command with embedded text\n            replacement = citation.to_text(command)\n            start, end = match.span()\n            processed_text = (\n                processed_text[:start] + replacement + processed_text[end:]\n            )\n\n    return processed_text, citations\n</code></pre>"},{"location":"api-reference/#ragora.utils.latex_parser.LatexParser._remove_document_preamble","title":"<code>_remove_document_preamble(text)</code>","text":"<p>Remove document preamble from text.</p> Source code in <code>ragora/ragora/utils/latex_parser.py</code> <pre><code>def _remove_document_preamble(self, text: str) -&gt; str:\n    \"\"\"Remove document preamble from text.\"\"\"\n    return re.sub(r\"\\\\begin\\{document\\}|\\\\end\\{document\\}\", \"\", text)\n</code></pre>"},{"location":"api-reference/#ragora.utils.latex_parser.LatexParser._split_into_chapters","title":"<code>_split_into_chapters(text)</code>","text":"<p>Split LaTeX text into chapter blocks.</p> Source code in <code>ragora/ragora/utils/latex_parser.py</code> <pre><code>def _split_into_chapters(self, text: str) -&gt; List[str]:\n    \"\"\"Split LaTeX text into chapter blocks.\"\"\"\n    # Use re.finditer to match chapter command and its content together\n    chapter_pattern = r\"(\\\\chapter\\*?\\{[^}]+\\}.*?)(?=(\\\\chapter\\*?\\{[^}]+\\})|$)\"\n    matches = re.finditer(chapter_pattern, text, re.DOTALL)\n    return [m.group(1) for m in matches]\n</code></pre>"},{"location":"api-reference/#ragora.utils.latex_parser.LatexParser._split_into_sections","title":"<code>_split_into_sections(text)</code>","text":"<p>Split LaTeX text into section blocks which start with section, subsection, or subsubsection. Any other text not part of a section command is ignored. Returns:     List[str]: List of section blocks</p> Source code in <code>ragora/ragora/utils/latex_parser.py</code> <pre><code>def _split_into_sections(self, text: str) -&gt; List[str]:\n    \"\"\"Split LaTeX text into section blocks which start with section, subsection, or subsubsection.\n    Any other text not part of a section command is ignored.\n    Returns:\n        List[str]: List of section blocks\n    \"\"\"\n\n    # Split by section, subsection, or subsubsection commands\n    section_pattern = r\"(\\\\section\\*?\\{[^}]+\\}|\\\\subsection\\*?\\{[^}]+\\}|\\\\subsubsection\\*?\\{[^}]+\\})\"\n    parts = re.split(section_pattern, text)\n\n    # Group section commands with their content\n    sections = []\n    current_section = \"\"\n\n    for i, part in enumerate(parts):\n        if (\n            part.startswith(\"\\\\section\")\n            or part.startswith(\"\\\\subsection\")\n            or part.startswith(\"\\\\subsubsection\")\n        ):\n            if current_section:\n                sections.append(current_section)\n            current_section = part\n        elif i &gt; 0:\n            current_section += part\n\n    if current_section:\n        sections.append(current_section)\n\n    return sections\n</code></pre>"},{"location":"api-reference/#ragora.utils.latex_parser.LatexParser.get_bibliography_entries","title":"<code>get_bibliography_entries()</code>","text":"<p>Get the bibliography entries.</p> Source code in <code>ragora/ragora/utils/latex_parser.py</code> <pre><code>def get_bibliography_entries(self) -&gt; Dict[str, Citation]:\n    \"\"\"Get the bibliography entries.\"\"\"\n    return self.bibliography_entries\n</code></pre>"},{"location":"api-reference/#ragora.utils.latex_parser.LatexParser.parse_bibliography","title":"<code>parse_bibliography(bibliography_path)</code>","text":"<p>Parse the bibliography.</p> Source code in <code>ragora/ragora/utils/latex_parser.py</code> <pre><code>def parse_bibliography(self, bibliography_path: str):\n    \"\"\"Parse the bibliography.\"\"\"\n    self.bibliography_path = bibliography_path\n    self.bibliography_entries = self._load_bibliography()\n</code></pre>"},{"location":"api-reference/#ragora.utils.latex_parser.LatexParser.parse_document","title":"<code>parse_document(document_path)</code>","text":"<p>Parse a LaTeX file into a :class:<code>LatexDocument</code>.</p> <p>Parameters:</p> Name Type Description Default <code>document_path</code> <code>str</code> <p>Path to the <code>.tex</code> file.</p> required <p>Returns:</p> Type Description <code>LatexDocument</code> <p>LatexDocument | None: Parsed representation, or <code>None</code> if parsing fails.</p> <p>Examples:</p> <pre><code>parser = LatexParser()\ndocument = parser.parse_document(\"thesis.tex\")\n</code></pre> Source code in <code>ragora/ragora/utils/latex_parser.py</code> <pre><code>def parse_document(self, document_path: str) -&gt; LatexDocument:\n    \"\"\"Parse a LaTeX file into a :class:`LatexDocument`.\n\n    Args:\n        document_path: Path to the `.tex` file.\n\n    Returns:\n        LatexDocument | None: Parsed representation, or ``None`` if parsing fails.\n\n    Examples:\n        ```python\n        parser = LatexParser()\n        document = parser.parse_document(\"thesis.tex\")\n        ```\n    \"\"\"\n    try:\n        if not self.document_path:\n            self.document_path = document_path\n        with open(document_path, \"r\", encoding=\"utf-8\") as file:\n            document_text = file.read()\n        return self.parse_document_text(document_text)\n    except Exception as e:\n        logger.error(f\"Error parsing document: {e}\")\n        return None\n</code></pre>"},{"location":"api-reference/#ragora.utils.latex_parser.LatexParser.parse_document_text","title":"<code>parse_document_text(document_text)</code>","text":"<p>Parse in-memory LaTeX text into a :class:<code>LatexDocument</code>.</p> <p>Parameters:</p> Name Type Description Default <code>document_text</code> <code>str</code> <p>Raw LaTeX content.</p> required <p>Returns:</p> Name Type Description <code>LatexDocument</code> <code>LatexDocument</code> <p>Parsed representation suitable for chunking.</p> <p>Examples:</p> <pre><code>parser = LatexParser()\ndoc = parser.parse_document_text(\n    \"\\title{Sample}\\n\\begin{document}Hello\\end{document}\"\n)\n</code></pre> Source code in <code>ragora/ragora/utils/latex_parser.py</code> <pre><code>def parse_document_text(self, document_text: str) -&gt; LatexDocument:\n    \"\"\"Parse in-memory LaTeX text into a :class:`LatexDocument`.\n\n    Args:\n        document_text: Raw LaTeX content.\n\n    Returns:\n        LatexDocument: Parsed representation suitable for chunking.\n\n    Examples:\n        ```python\n        parser = LatexParser()\n        doc = parser.parse_document_text(\n            \"\\\\title{Sample}\\\\n\\\\begin{document}Hello\\\\end{document}\"\n        )\n        ```\n    \"\"\"\n    # Extract document metadata\n    title = self._extract_title(document_text)\n    author = self._extract_author(document_text)\n    year = self._extract_year(document_text)\n    doi = self._extract_doi(document_text)\n\n    cleaned_text = self._remove_document_preamble(document_text)\n\n    # Parse tables and figures FIRST (to remove them from text)\n    tables, cleaned_text = self._parse_tables(cleaned_text)\n    figures, cleaned_text = self._parse_figures(cleaned_text)\n\n    # Parse chapters hierarchically from cleaned text\n    chapters, cleaned_text = self._parse_chapters(cleaned_text)\n\n    # Parse sections hierarchically from cleaned text\n    sections, cleaned_text = self._parse_sections(cleaned_text)\n\n    # Parse paragraphs from remaining text\n    paragraphs = self._parse_paragraphs(cleaned_text)\n\n    return LatexDocument(\n        title=title,\n        author=author,\n        year=year,\n        doi=doi,\n        source_document=self.document_path,\n        page_reference=\"1\",\n        chapters=chapters,\n        sections=sections,\n        paragraphs=paragraphs,\n        tables=tables,\n        figures=figures,\n    )\n</code></pre>"},{"location":"api-reference/#ragora.utils.latex_parser.LatexSection","title":"<code>LatexSection</code>  <code>dataclass</code>","text":"<p>A LaTeX section.</p> Source code in <code>ragora/ragora/utils/latex_parser.py</code> <pre><code>@dataclass\nclass LatexSection:\n    \"\"\"A LaTeX section.\"\"\"\n\n    title: str\n    label: str\n    paragraphs: Optional[List[LatexParagraph]] = None\n</code></pre>"},{"location":"api-reference/#ragora.utils.latex_parser.LatexSubsection","title":"<code>LatexSubsection</code>  <code>dataclass</code>","text":"<p>A LaTeX subsection.</p> Source code in <code>ragora/ragora/utils/latex_parser.py</code> <pre><code>@dataclass\nclass LatexSubsection:\n    \"\"\"A LaTeX subsection.\"\"\"\n\n    title: str\n    label: str\n    paragraphs: Optional[List[LatexParagraph]] = None\n    subsubsections: Optional[List[LatexSubsubsection]] = None\n</code></pre>"},{"location":"api-reference/#ragora.utils.latex_parser.LatexSubsubsection","title":"<code>LatexSubsubsection</code>  <code>dataclass</code>","text":"<p>A LaTeX subsubsection.</p> Source code in <code>ragora/ragora/utils/latex_parser.py</code> <pre><code>@dataclass\nclass LatexSubsubsection:\n    \"\"\"A LaTeX subsubsection.\"\"\"\n\n    title: str\n    label: str\n    paragraphs: Optional[List[LatexParagraph]] = None\n</code></pre>"},{"location":"api-reference/#ragora.utils.latex_parser.LatexTable","title":"<code>LatexTable</code>  <code>dataclass</code>","text":"<p>A LaTeX table.</p> Source code in <code>ragora/ragora/utils/latex_parser.py</code> <pre><code>@dataclass\nclass LatexTable:\n    \"\"\"A LaTeX table.\"\"\"\n\n    caption: str\n    label: str\n    headers: List[str]\n    rows: List[List[str]]\n    footnotes: Optional[List[str]] = None\n\n    def to_markdown(self) -&gt; str:\n        \"\"\"Convert the table to a Markdown table.\"\"\"\n        if not self.headers and not self.rows:\n            return f\"**Table: {self.caption}**\\n\\n\"\n\n            # Build markdown table\n        md_lines = []\n        if self.caption:\n            md_lines.append(f\"**Table: {self.caption}**\\n\")\n\n        # Headers\n        if self.headers:\n            md_lines.append(\"| \" + \" | \".join(self.headers) + \" |\")\n            md_lines.append(\"|\" + \"|\".join([\"---\"] * len(self.headers)) + \"|\")\n\n        # Rows\n        for row in self.rows:\n            md_lines.append(\"| \" + \" | \".join(str(cell) for cell in row) + \" |\")\n\n        return \"\\n\".join(md_lines) + \"\\n\"\n\n    def to_plain_text(self) -&gt; str:\n        \"\"\"Convert the table to a plain text table.\"\"\"\n        if not self.headers and not self.rows:\n            return f\"Table: {self.caption}\\n\\n\"\n\n        lines = []\n        if self.caption:\n            lines.append(f\"Table: {self.caption}\")\n\n        # Headers\n        if self.headers:\n            lines.append(\" | \".join(self.headers))\n            lines.append(\" | \".join([\"-\" * len(header) for header in self.headers]))\n\n        # Rows\n        for row in self.rows:\n            lines.append(\" | \".join(str(cell) for cell in row))\n\n        return \"\\n\".join(lines) + \"\\n\"\n</code></pre>"},{"location":"api-reference/#ragora.utils.latex_parser.LatexTable.to_markdown","title":"<code>to_markdown()</code>","text":"<p>Convert the table to a Markdown table.</p> Source code in <code>ragora/ragora/utils/latex_parser.py</code> <pre><code>def to_markdown(self) -&gt; str:\n    \"\"\"Convert the table to a Markdown table.\"\"\"\n    if not self.headers and not self.rows:\n        return f\"**Table: {self.caption}**\\n\\n\"\n\n        # Build markdown table\n    md_lines = []\n    if self.caption:\n        md_lines.append(f\"**Table: {self.caption}**\\n\")\n\n    # Headers\n    if self.headers:\n        md_lines.append(\"| \" + \" | \".join(self.headers) + \" |\")\n        md_lines.append(\"|\" + \"|\".join([\"---\"] * len(self.headers)) + \"|\")\n\n    # Rows\n    for row in self.rows:\n        md_lines.append(\"| \" + \" | \".join(str(cell) for cell in row) + \" |\")\n\n    return \"\\n\".join(md_lines) + \"\\n\"\n</code></pre>"},{"location":"api-reference/#ragora.utils.latex_parser.LatexTable.to_plain_text","title":"<code>to_plain_text()</code>","text":"<p>Convert the table to a plain text table.</p> Source code in <code>ragora/ragora/utils/latex_parser.py</code> <pre><code>def to_plain_text(self) -&gt; str:\n    \"\"\"Convert the table to a plain text table.\"\"\"\n    if not self.headers and not self.rows:\n        return f\"Table: {self.caption}\\n\\n\"\n\n    lines = []\n    if self.caption:\n        lines.append(f\"Table: {self.caption}\")\n\n    # Headers\n    if self.headers:\n        lines.append(\" | \".join(self.headers))\n        lines.append(\" | \".join([\"-\" * len(header) for header in self.headers]))\n\n    # Rows\n    for row in self.rows:\n        lines.append(\" | \".join(str(cell) for cell in row))\n\n    return \"\\n\".join(lines) + \"\\n\"\n</code></pre>"},{"location":"api-reference/#markdown-parser","title":"Markdown Parser","text":"<p>Parse Markdown or plain-text files into structured Ragora models.</p>"},{"location":"api-reference/#ragora.utils.markdown_parser.MarkdownChapter","title":"<code>MarkdownChapter</code>  <code>dataclass</code>","text":"<p>Represents a top-level Markdown heading (level 1).</p> Source code in <code>ragora/ragora/utils/markdown_parser.py</code> <pre><code>@dataclass\nclass MarkdownChapter:\n    \"\"\"Represents a top-level Markdown heading (level 1).\"\"\"\n\n    title: str\n    paragraphs: List[MarkdownParagraph] = field(default_factory=list)\n    sections: List[MarkdownSection] = field(default_factory=list)\n</code></pre>"},{"location":"api-reference/#ragora.utils.markdown_parser.MarkdownDocument","title":"<code>MarkdownDocument</code>  <code>dataclass</code>","text":"<p>Structured representation of a Markdown/plain text document.</p> Source code in <code>ragora/ragora/utils/markdown_parser.py</code> <pre><code>@dataclass\nclass MarkdownDocument:\n    \"\"\"Structured representation of a Markdown/plain text document.\"\"\"\n\n    source_document: str\n    title: Optional[str] = None\n    paragraphs: List[MarkdownParagraph] = field(default_factory=list)\n    chapters: List[MarkdownChapter] = field(default_factory=list)\n    sections: List[MarkdownSection] = field(default_factory=list)\n</code></pre>"},{"location":"api-reference/#ragora.utils.markdown_parser.MarkdownParagraph","title":"<code>MarkdownParagraph</code>  <code>dataclass</code>","text":"<p>Represents a paragraph or block of text within a Markdown document.</p> Source code in <code>ragora/ragora/utils/markdown_parser.py</code> <pre><code>@dataclass\nclass MarkdownParagraph:\n    \"\"\"Represents a paragraph or block of text within a Markdown document.\"\"\"\n\n    content: str\n</code></pre>"},{"location":"api-reference/#ragora.utils.markdown_parser.MarkdownParser","title":"<code>MarkdownParser</code>","text":"<p>Convert Markdown/plain text into the :class:<code>MarkdownDocument</code> model.</p> Source code in <code>ragora/ragora/utils/markdown_parser.py</code> <pre><code>class MarkdownParser:\n    \"\"\"Convert Markdown/plain text into the :class:`MarkdownDocument` model.\"\"\"\n\n    def __init__(self, enable_tables: bool = True, enable_fenced_code: bool = True):\n        \"\"\"Build a parser with optional CommonMark extensions.\n\n        Args:\n            enable_tables: Enable GitHub-style table support.\n            enable_fenced_code: Enable fenced code block parsing.\n        \"\"\"\n        self._markdown = MarkdownIt(\"commonmark\")\n        if enable_tables:\n            self._markdown.enable(\"table\")\n        if enable_fenced_code:\n            self._markdown.enable(\"fence\")\n\n    def parse_document(self, file_path: str) -&gt; MarkdownDocument:\n        \"\"\"Parse a Markdown document from disk.\n\n        Args:\n            file_path: Path to the Markdown/plain text file.\n\n        Returns:\n            MarkdownDocument: Parsed representation.\n\n        Raises:\n            FileNotFoundError: If the file does not exist.\n\n        Examples:\n            ```python\n            parser = MarkdownParser()\n            doc = parser.parse_document(\"notes.md\")\n            ```\n        \"\"\"\n\n        if not os.path.exists(file_path):\n            raise FileNotFoundError(f\"Markdown file not found: {file_path}\")\n\n        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n            content = file.read()\n\n        return self.parse_text(content, source_document=os.path.basename(file_path))\n\n    def parse_text(\n        self, text: str, source_document: Optional[str] = None\n    ) -&gt; MarkdownDocument:\n        \"\"\"Parse provided Markdown/plain text content.\n\n        Args:\n            text: Text blob to parse.\n            source_document: Optional source name for metadata.\n\n        Returns:\n            MarkdownDocument: Parsed representation suitable for chunking.\n\n        Examples:\n            ```python\n            parser = MarkdownParser()\n            doc = parser.parse_text(\"# Title\\\\n\\\\nSome content\")\n            ```\n        \"\"\"\n\n        source_name = source_document or \"\"\n        default_title = (\n            os.path.splitext(os.path.basename(source_name))[0] if source_name else None\n        )\n        document = MarkdownDocument(source_document=source_name, title=default_title)\n\n        tokens = self._markdown.parse(text)\n        current_chapter: Optional[MarkdownChapter] = None\n        current_section: Optional[MarkdownSection] = None\n        block_context: Optional[str] = None\n        blockquote_level = 0\n        list_stack: List[dict] = []\n        in_list_item = False\n\n        def add_paragraph(raw_text: str):\n            text_to_add = raw_text.strip()\n            if not text_to_add:\n                return\n\n            if blockquote_level:\n                prefix = \"&gt; \" * blockquote_level\n                text_to_add = f\"{prefix}{text_to_add}\"\n\n            paragraph = MarkdownParagraph(content=text_to_add)\n\n            if current_section is not None:\n                current_section.paragraphs.append(paragraph)\n            elif current_chapter is not None:\n                current_chapter.paragraphs.append(paragraph)\n            else:\n                document.paragraphs.append(paragraph)\n\n        index = 0\n        while index &lt; len(tokens):\n            token = tokens[index]\n\n            if token.type == \"heading_open\":\n                level = (\n                    int(token.tag[-1]) if token.tag and token.tag[-1].isdigit() else 1\n                )\n                title = \"\"\n                lookahead = index + 1\n                while (\n                    lookahead &lt; len(tokens)\n                    and tokens[lookahead].type != \"heading_close\"\n                ):\n                    if tokens[lookahead].type == \"inline\":\n                        title = tokens[lookahead].content.strip()\n                    lookahead += 1\n\n                if level &lt;= 1:\n                    current_chapter = MarkdownChapter(title=title)\n                    document.chapters.append(current_chapter)\n                    current_section = None\n                    if not document.title:\n                        document.title = title\n                elif level == 2:\n                    section = MarkdownSection(title=title, level=level)\n                    if current_chapter is not None:\n                        current_chapter.sections.append(section)\n                    else:\n                        document.sections.append(section)\n                    current_section = section\n                else:\n                    add_paragraph(f\"{'#' * level} {title}\")\n\n                index = lookahead  # Skip inline tokens handled above\n                block_context = None\n            elif token.type == \"paragraph_open\":\n                block_context = \"paragraph\"\n            elif token.type == \"paragraph_close\":\n                block_context = None\n            elif token.type == \"blockquote_open\":\n                blockquote_level += 1\n            elif token.type == \"blockquote_close\":\n                blockquote_level = max(0, blockquote_level - 1)\n            elif token.type == \"bullet_list_open\":\n                list_stack.append({\"type\": \"bullet\"})\n            elif token.type == \"bullet_list_close\":\n                if list_stack:\n                    list_stack.pop()\n            elif token.type == \"ordered_list_open\":\n                start_attr = token.attrGet(\"start\")\n                start_index = int(start_attr) if start_attr else 1\n                list_stack.append({\"type\": \"ordered\", \"index\": start_index})\n            elif token.type == \"ordered_list_close\":\n                if list_stack:\n                    list_stack.pop()\n            elif token.type == \"list_item_open\":\n                block_context = \"list_item\"\n                in_list_item = True\n            elif token.type == \"list_item_close\":\n                if list_stack and list_stack[-1][\"type\"] == \"ordered\":\n                    list_stack[-1][\"index\"] += 1\n                block_context = None\n                in_list_item = False\n            elif token.type in {\"fence\", \"code_block\"}:\n                code_text = token.content.rstrip(\"\\n\")\n                add_paragraph(f\"```\\n{code_text}\\n```\")\n            elif token.type == \"inline\":\n                inline_text = token.content.strip()\n                if not inline_text:\n                    index += 1\n                    continue\n\n                if in_list_item and list_stack:\n                    current_list = list_stack[-1]\n                    if current_list[\"type\"] == \"bullet\":\n                        formatted_text = f\"- {inline_text}\"\n                    else:\n                        formatted_text = f\"{current_list['index']}. {inline_text}\"\n                    add_paragraph(formatted_text)\n                else:\n                    add_paragraph(inline_text)\n\n            index += 1\n\n        return document\n</code></pre>"},{"location":"api-reference/#ragora.utils.markdown_parser.MarkdownParser.parse_document","title":"<code>parse_document(file_path)</code>","text":"<p>Parse a Markdown document from disk.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>Path to the Markdown/plain text file.</p> required <p>Returns:</p> Name Type Description <code>MarkdownDocument</code> <code>MarkdownDocument</code> <p>Parsed representation.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the file does not exist.</p> <p>Examples:</p> <pre><code>parser = MarkdownParser()\ndoc = parser.parse_document(\"notes.md\")\n</code></pre> Source code in <code>ragora/ragora/utils/markdown_parser.py</code> <pre><code>def parse_document(self, file_path: str) -&gt; MarkdownDocument:\n    \"\"\"Parse a Markdown document from disk.\n\n    Args:\n        file_path: Path to the Markdown/plain text file.\n\n    Returns:\n        MarkdownDocument: Parsed representation.\n\n    Raises:\n        FileNotFoundError: If the file does not exist.\n\n    Examples:\n        ```python\n        parser = MarkdownParser()\n        doc = parser.parse_document(\"notes.md\")\n        ```\n    \"\"\"\n\n    if not os.path.exists(file_path):\n        raise FileNotFoundError(f\"Markdown file not found: {file_path}\")\n\n    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n        content = file.read()\n\n    return self.parse_text(content, source_document=os.path.basename(file_path))\n</code></pre>"},{"location":"api-reference/#ragora.utils.markdown_parser.MarkdownParser.parse_text","title":"<code>parse_text(text, source_document=None)</code>","text":"<p>Parse provided Markdown/plain text content.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Text blob to parse.</p> required <code>source_document</code> <code>Optional[str]</code> <p>Optional source name for metadata.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>MarkdownDocument</code> <code>MarkdownDocument</code> <p>Parsed representation suitable for chunking.</p> <p>Examples:</p> <pre><code>parser = MarkdownParser()\ndoc = parser.parse_text(\"# Title\\n\\nSome content\")\n</code></pre> Source code in <code>ragora/ragora/utils/markdown_parser.py</code> <pre><code>def parse_text(\n    self, text: str, source_document: Optional[str] = None\n) -&gt; MarkdownDocument:\n    \"\"\"Parse provided Markdown/plain text content.\n\n    Args:\n        text: Text blob to parse.\n        source_document: Optional source name for metadata.\n\n    Returns:\n        MarkdownDocument: Parsed representation suitable for chunking.\n\n    Examples:\n        ```python\n        parser = MarkdownParser()\n        doc = parser.parse_text(\"# Title\\\\n\\\\nSome content\")\n        ```\n    \"\"\"\n\n    source_name = source_document or \"\"\n    default_title = (\n        os.path.splitext(os.path.basename(source_name))[0] if source_name else None\n    )\n    document = MarkdownDocument(source_document=source_name, title=default_title)\n\n    tokens = self._markdown.parse(text)\n    current_chapter: Optional[MarkdownChapter] = None\n    current_section: Optional[MarkdownSection] = None\n    block_context: Optional[str] = None\n    blockquote_level = 0\n    list_stack: List[dict] = []\n    in_list_item = False\n\n    def add_paragraph(raw_text: str):\n        text_to_add = raw_text.strip()\n        if not text_to_add:\n            return\n\n        if blockquote_level:\n            prefix = \"&gt; \" * blockquote_level\n            text_to_add = f\"{prefix}{text_to_add}\"\n\n        paragraph = MarkdownParagraph(content=text_to_add)\n\n        if current_section is not None:\n            current_section.paragraphs.append(paragraph)\n        elif current_chapter is not None:\n            current_chapter.paragraphs.append(paragraph)\n        else:\n            document.paragraphs.append(paragraph)\n\n    index = 0\n    while index &lt; len(tokens):\n        token = tokens[index]\n\n        if token.type == \"heading_open\":\n            level = (\n                int(token.tag[-1]) if token.tag and token.tag[-1].isdigit() else 1\n            )\n            title = \"\"\n            lookahead = index + 1\n            while (\n                lookahead &lt; len(tokens)\n                and tokens[lookahead].type != \"heading_close\"\n            ):\n                if tokens[lookahead].type == \"inline\":\n                    title = tokens[lookahead].content.strip()\n                lookahead += 1\n\n            if level &lt;= 1:\n                current_chapter = MarkdownChapter(title=title)\n                document.chapters.append(current_chapter)\n                current_section = None\n                if not document.title:\n                    document.title = title\n            elif level == 2:\n                section = MarkdownSection(title=title, level=level)\n                if current_chapter is not None:\n                    current_chapter.sections.append(section)\n                else:\n                    document.sections.append(section)\n                current_section = section\n            else:\n                add_paragraph(f\"{'#' * level} {title}\")\n\n            index = lookahead  # Skip inline tokens handled above\n            block_context = None\n        elif token.type == \"paragraph_open\":\n            block_context = \"paragraph\"\n        elif token.type == \"paragraph_close\":\n            block_context = None\n        elif token.type == \"blockquote_open\":\n            blockquote_level += 1\n        elif token.type == \"blockquote_close\":\n            blockquote_level = max(0, blockquote_level - 1)\n        elif token.type == \"bullet_list_open\":\n            list_stack.append({\"type\": \"bullet\"})\n        elif token.type == \"bullet_list_close\":\n            if list_stack:\n                list_stack.pop()\n        elif token.type == \"ordered_list_open\":\n            start_attr = token.attrGet(\"start\")\n            start_index = int(start_attr) if start_attr else 1\n            list_stack.append({\"type\": \"ordered\", \"index\": start_index})\n        elif token.type == \"ordered_list_close\":\n            if list_stack:\n                list_stack.pop()\n        elif token.type == \"list_item_open\":\n            block_context = \"list_item\"\n            in_list_item = True\n        elif token.type == \"list_item_close\":\n            if list_stack and list_stack[-1][\"type\"] == \"ordered\":\n                list_stack[-1][\"index\"] += 1\n            block_context = None\n            in_list_item = False\n        elif token.type in {\"fence\", \"code_block\"}:\n            code_text = token.content.rstrip(\"\\n\")\n            add_paragraph(f\"```\\n{code_text}\\n```\")\n        elif token.type == \"inline\":\n            inline_text = token.content.strip()\n            if not inline_text:\n                index += 1\n                continue\n\n            if in_list_item and list_stack:\n                current_list = list_stack[-1]\n                if current_list[\"type\"] == \"bullet\":\n                    formatted_text = f\"- {inline_text}\"\n                else:\n                    formatted_text = f\"{current_list['index']}. {inline_text}\"\n                add_paragraph(formatted_text)\n            else:\n                add_paragraph(inline_text)\n\n        index += 1\n\n    return document\n</code></pre>"},{"location":"api-reference/#ragora.utils.markdown_parser.MarkdownSection","title":"<code>MarkdownSection</code>  <code>dataclass</code>","text":"<p>Represents a Markdown section (heading level &gt;= 2).</p> Source code in <code>ragora/ragora/utils/markdown_parser.py</code> <pre><code>@dataclass\nclass MarkdownSection:\n    \"\"\"Represents a Markdown section (heading level &gt;= 2).\"\"\"\n\n    title: str\n    level: int\n    paragraphs: List[MarkdownParagraph] = field(default_factory=list)\n</code></pre>"},{"location":"api-reference/#configuration","title":"Configuration","text":"<p>Dataclasses that capture Ragora configuration.</p>"},{"location":"api-reference/#ragora.config.settings.ChunkConfig","title":"<code>ChunkConfig</code>  <code>dataclass</code>","text":"<p>Chunking behaviour for document ingestion.</p> <p>Attributes:</p> Name Type Description <code>chunk_size</code> <code>int</code> <p>Target token length per chunk.</p> <code>overlap_size</code> <code>int</code> <p>Token overlap between sequential chunks.</p> <code>chunk_type</code> <code>str</code> <p>Friendly label used downstream for metadata.</p> Source code in <code>ragora/ragora/config/settings.py</code> <pre><code>@dataclass\nclass ChunkConfig:\n    \"\"\"Chunking behaviour for document ingestion.\n\n    Attributes:\n        chunk_size: Target token length per chunk.\n        overlap_size: Token overlap between sequential chunks.\n        chunk_type: Friendly label used downstream for metadata.\n    \"\"\"\n\n    chunk_size: int = 768\n    overlap_size: int = 100\n    chunk_type: str = \"document\"\n</code></pre>"},{"location":"api-reference/#ragora.config.settings.DatabaseManagerConfig","title":"<code>DatabaseManagerConfig</code>  <code>dataclass</code>","text":"<p>Connection properties for the Weaviate backend.</p> <p>Attributes:</p> Name Type Description <code>url</code> <code>str</code> <p>HTTP endpoint for Weaviate.</p> <code>grpc_port</code> <code>int</code> <p>Optional gRPC port.</p> <code>timeout</code> <code>int</code> <p>Request timeout in seconds.</p> <code>retry_attempts</code> <code>int</code> <p>Automatic retry count for transient failures.</p> Source code in <code>ragora/ragora/config/settings.py</code> <pre><code>@dataclass\nclass DatabaseManagerConfig:\n    \"\"\"Connection properties for the Weaviate backend.\n\n    Attributes:\n        url: HTTP endpoint for Weaviate.\n        grpc_port: Optional gRPC port.\n        timeout: Request timeout in seconds.\n        retry_attempts: Automatic retry count for transient failures.\n    \"\"\"\n\n    url: str = \"http://localhost:8080\"\n    grpc_port: int = 50051\n    timeout: int = 30\n    retry_attempts: int = 3\n</code></pre>"},{"location":"api-reference/#ragora.config.settings.EmbeddingConfig","title":"<code>EmbeddingConfig</code>  <code>dataclass</code>","text":"<p>Sentence-transformer settings for semantic retrieval.</p> <p>Attributes:</p> Name Type Description <code>model_name</code> <code>str</code> <p>Hugging Face model identifier.</p> <code>device</code> <code>Optional[str]</code> <p>Explicit torch device string (<code>\"cpu\"</code>, <code>\"cuda\"</code>); <code>None</code> auto-selects.</p> <code>max_length</code> <code>int</code> <p>Maximum tokens per forward pass.</p> Source code in <code>ragora/ragora/config/settings.py</code> <pre><code>@dataclass\nclass EmbeddingConfig:\n    \"\"\"Sentence-transformer settings for semantic retrieval.\n\n    Attributes:\n        model_name: Hugging Face model identifier.\n        device: Explicit torch device string (``\\\"cpu\\\"``, ``\\\"cuda\\\"``); ``None`` auto-selects.\n        max_length: Maximum tokens per forward pass.\n    \"\"\"\n\n    model_name: str = \"all-mpnet-base-v2\"\n    device: Optional[str] = None\n    max_length: int = 512\n</code></pre>"},{"location":"api-reference/#ragora.config.settings.KnowledgeBaseManagerConfig","title":"<code>KnowledgeBaseManagerConfig</code>  <code>dataclass</code>","text":"<p>Aggregates all subsystems used by :class:<code>KnowledgeBaseManager</code>.</p> Source code in <code>ragora/ragora/config/settings.py</code> <pre><code>@dataclass\nclass KnowledgeBaseManagerConfig:\n    \"\"\"Aggregates all subsystems used by :class:`KnowledgeBaseManager`.\"\"\"\n\n    chunk_config: Optional[ChunkConfig] = None\n    embedding_config: Optional[EmbeddingConfig] = None\n    database_manager_config: Optional[DatabaseManagerConfig] = None\n\n    @classmethod\n    def from_dict(cls, config_dict: Dict[str, Any]) -&gt; \"KnowledgeBaseManagerConfig\":\n        \"\"\"Create a configuration from nested dictionaries.\n\n        Args:\n            config_dict: Dictionary matching the dataclass schema\n                (the keys ``chunk``, ``embedding``, ``database_manager`` are recognised).\n\n        Returns:\n            KnowledgeBaseManagerConfig: Parsed configuration instance.\n\n        Examples:\n            ```python\n            cfg = KnowledgeBaseManagerConfig.from_dict(\n                {\n                    \"chunk\": {\"chunk_size\": 512, \"overlap_size\": 64},\n                    \"embedding\": {\"model_name\": \"multi-qa-MiniLM-L6-v2\"},\n                }\n            )\n            ```\n        \"\"\"\n        return cls(\n            chunk_config=(\n                ChunkConfig(**config_dict.get(\"chunk\", {}))\n                if config_dict.get(\"chunk\")\n                else None\n            ),\n            embedding_config=(\n                EmbeddingConfig(**config_dict.get(\"embedding\", {}))\n                if config_dict.get(\"embedding\")\n                else None\n            ),\n            database_manager_config=(\n                DatabaseManagerConfig(**config_dict.get(\"database_manager\", {}))\n                if config_dict.get(\"database_manager\")\n                else None\n            ),\n        )\n\n    @classmethod\n    def default(cls) -&gt; \"KnowledgeBaseManagerConfig\":\n        \"\"\"Create a configuration with Ragora defaults.\n\n        Returns:\n            KnowledgeBaseManagerConfig: Configuration using standard values.\n\n        Examples:\n            ```python\n            cfg = KnowledgeBaseManagerConfig.default()\n            ```\n        \"\"\"\n        return cls(\n            chunk_config=ChunkConfig(),\n            embedding_config=EmbeddingConfig(),\n            database_manager_config=DatabaseManagerConfig(),\n        )\n</code></pre>"},{"location":"api-reference/#ragora.config.settings.KnowledgeBaseManagerConfig.default","title":"<code>default()</code>  <code>classmethod</code>","text":"<p>Create a configuration with Ragora defaults.</p> <p>Returns:</p> Name Type Description <code>KnowledgeBaseManagerConfig</code> <code>KnowledgeBaseManagerConfig</code> <p>Configuration using standard values.</p> <p>Examples:</p> <pre><code>cfg = KnowledgeBaseManagerConfig.default()\n</code></pre> Source code in <code>ragora/ragora/config/settings.py</code> <pre><code>@classmethod\ndef default(cls) -&gt; \"KnowledgeBaseManagerConfig\":\n    \"\"\"Create a configuration with Ragora defaults.\n\n    Returns:\n        KnowledgeBaseManagerConfig: Configuration using standard values.\n\n    Examples:\n        ```python\n        cfg = KnowledgeBaseManagerConfig.default()\n        ```\n    \"\"\"\n    return cls(\n        chunk_config=ChunkConfig(),\n        embedding_config=EmbeddingConfig(),\n        database_manager_config=DatabaseManagerConfig(),\n    )\n</code></pre>"},{"location":"api-reference/#ragora.config.settings.KnowledgeBaseManagerConfig.from_dict","title":"<code>from_dict(config_dict)</code>  <code>classmethod</code>","text":"<p>Create a configuration from nested dictionaries.</p> <p>Parameters:</p> Name Type Description Default <code>config_dict</code> <code>Dict[str, Any]</code> <p>Dictionary matching the dataclass schema (the keys <code>chunk</code>, <code>embedding</code>, <code>database_manager</code> are recognised).</p> required <p>Returns:</p> Name Type Description <code>KnowledgeBaseManagerConfig</code> <code>KnowledgeBaseManagerConfig</code> <p>Parsed configuration instance.</p> <p>Examples:</p> <pre><code>cfg = KnowledgeBaseManagerConfig.from_dict(\n    {\n        \"chunk\": {\"chunk_size\": 512, \"overlap_size\": 64},\n        \"embedding\": {\"model_name\": \"multi-qa-MiniLM-L6-v2\"},\n    }\n)\n</code></pre> Source code in <code>ragora/ragora/config/settings.py</code> <pre><code>@classmethod\ndef from_dict(cls, config_dict: Dict[str, Any]) -&gt; \"KnowledgeBaseManagerConfig\":\n    \"\"\"Create a configuration from nested dictionaries.\n\n    Args:\n        config_dict: Dictionary matching the dataclass schema\n            (the keys ``chunk``, ``embedding``, ``database_manager`` are recognised).\n\n    Returns:\n        KnowledgeBaseManagerConfig: Parsed configuration instance.\n\n    Examples:\n        ```python\n        cfg = KnowledgeBaseManagerConfig.from_dict(\n            {\n                \"chunk\": {\"chunk_size\": 512, \"overlap_size\": 64},\n                \"embedding\": {\"model_name\": \"multi-qa-MiniLM-L6-v2\"},\n            }\n        )\n        ```\n    \"\"\"\n    return cls(\n        chunk_config=(\n            ChunkConfig(**config_dict.get(\"chunk\", {}))\n            if config_dict.get(\"chunk\")\n            else None\n        ),\n        embedding_config=(\n            EmbeddingConfig(**config_dict.get(\"embedding\", {}))\n            if config_dict.get(\"embedding\")\n            else None\n        ),\n        database_manager_config=(\n            DatabaseManagerConfig(**config_dict.get(\"database_manager\", {}))\n            if config_dict.get(\"database_manager\")\n            else None\n        ),\n    )\n</code></pre>"},{"location":"contributing/","title":"Contributing to Ragora","text":"<p>Thank you for your interest in contributing to Ragora! This document provides guidelines and instructions for contributing to the project.</p>"},{"location":"contributing/#how-to-contribute","title":"\ud83e\udd1d How to Contribute","text":""},{"location":"contributing/#ways-to-contribute","title":"Ways to Contribute","text":"<ul> <li>Report Bugs: Submit detailed bug reports</li> <li>Suggest Features: Propose new features or improvements</li> <li>Improve Documentation: Fix typos, clarify instructions, add examples</li> <li>Write Code: Fix bugs, implement features, improve performance</li> <li>Review Pull Requests: Help review and test PRs</li> <li>Answer Questions: Help other users in Issues and Discussions</li> </ul>"},{"location":"contributing/#getting-started","title":"\ud83d\ude80 Getting Started","text":""},{"location":"contributing/#1-set-up-development-environment","title":"1. Set Up Development Environment","text":"<pre><code># Fork and clone the repository\ngit clone https://github.com/vahidlari/aiapps.git\ncd aiapps\n\n# Open in DevContainer (recommended)\ncode .\n# Click \"Reopen in Container\"\n\n# Or set up locally\npip install -e \"ragora[dev]\"\n\n# Start Weaviate database\ncd tools/database_server\n./database-manager.sh start\n</code></pre>"},{"location":"contributing/#2-create-a-branch","title":"2. Create a Branch","text":"<pre><code># Create a new branch for your work\ngit checkout -b feature/your-feature-name\n\n# Or for bug fixes\ngit checkout -b fix/bug-description\n</code></pre>"},{"location":"contributing/#3-make-your-changes","title":"3. Make Your Changes","text":"<p>Follow our coding standards (see below) and make your changes.</p>"},{"location":"contributing/#4-test-your-changes","title":"4. Test Your Changes","text":"<pre><code># Run all tests\ncd ragora\npython -m pytest\n\n# Run specific tests\npython -m pytest tests/unit/test_your_module.py\n\n# Check test coverage\npython -m pytest --cov=ragora --cov-report=html\n</code></pre>"},{"location":"contributing/#5-submit-a-pull-request","title":"5. Submit a Pull Request","text":"<pre><code># Commit your changes\ngit add .\ngit commit -m \"feat: add your feature description\"\n\n# Push to your fork\ngit push origin feature/your-feature-name\n\n# Create a Pull Request on GitHub\n</code></pre>"},{"location":"contributing/#coding-standards","title":"\ud83d\udcdd Coding Standards","text":""},{"location":"contributing/#python-style-guide","title":"Python Style Guide","text":"<p>We follow PEP 8 with the following tools:</p> <p>Black - Code formatting <pre><code>black ragora/\n</code></pre></p> <p>isort - Import sorting <pre><code>isort ragora/\n</code></pre></p> <p>Flake8 - Linting <pre><code>flake8 ragora/\n</code></pre></p>"},{"location":"contributing/#type-hints","title":"Type Hints","text":"<p>Always use type hints for function signatures:</p> <pre><code>from typing import List, Dict, Optional\n\ndef process_documents(\n    documents: List[str],\n    chunk_size: int = 768,\n    overlap: Optional[int] = None\n) -&gt; Dict[str, any]:\n    \"\"\"Process documents and return results.\n\n    Args:\n        documents: List of document paths\n        chunk_size: Size of chunks in tokens\n        overlap: Overlap between chunks\n\n    Returns:\n        Dictionary containing processing results\n    \"\"\"\n    pass\n</code></pre>"},{"location":"contributing/#docstrings","title":"Docstrings","text":"<p>Use Google-style docstrings for all public functions and classes:</p> <pre><code>def search_hybrid(\n    self,\n    query: str,\n    alpha: float = 0.7,\n    top_k: int = 5\n) -&gt; List[Dict]:\n    \"\"\"Perform hybrid search combining vector and keyword search.\n\n    Hybrid search uses both semantic similarity (vector search) and \n    keyword matching (BM25) to find relevant results.\n\n    Args:\n        query: The search query string\n        alpha: Weight for vector vs keyword search (0.0-1.0)\n               1.0 = pure vector, 0.0 = pure keyword\n        top_k: Number of results to return\n\n    Returns:\n        List of dictionaries containing:\n            - content: The chunk content\n            - similarity_score: Relevance score\n            - metadata: Additional metadata\n\n    Raises:\n        ValueError: If query is empty or alpha not in [0.0, 1.0]\n        ConnectionError: If database connection fails\n\n    Example:\n        &gt;&gt;&gt; retriever = Retriever(db_manager, \"Documents\")\n        &gt;&gt;&gt; results = retriever.search_hybrid(\"machine learning\", alpha=0.7)\n        &gt;&gt;&gt; print(f\"Found {len(results)} results\")\n        Found 5 results\n    \"\"\"\n    pass\n</code></pre>"},{"location":"contributing/#code-organization","title":"Code Organization","text":"<pre><code># Standard library imports\nimport os\nimport sys\nfrom typing import List, Dict\n\n# Third-party imports\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer\n\n# Local imports\nfrom ragora.core import DatabaseManager\nfrom ragora.utils import get_device\n</code></pre>"},{"location":"contributing/#testing-guidelines","title":"\ud83e\uddea Testing Guidelines","text":""},{"location":"contributing/#writing-tests","title":"Writing Tests","text":"<p>Place tests in the appropriate directory: - <code>tests/unit/</code> - Unit tests for individual components - <code>tests/integration/</code> - Integration tests for component interactions</p>"},{"location":"contributing/#test-structure","title":"Test Structure","text":"<pre><code>import pytest\nfrom ragora.core import DataChunker\n\nclass TestDataChunker:\n    \"\"\"Tests for the DataChunker class.\"\"\"\n\n    def test_basic_chunking(self):\n        \"\"\"Test basic chunking functionality.\"\"\"\n        chunker = DataChunker()\n        context = ChunkingContextBuilder().for_text().build()\n        text = \"This is a test. \" * 50\n\n        chunks = chunker.chunk(text, context)\n\n        assert len(chunks) &gt; 0\n        assert all(isinstance(chunk, DataChunk) for chunk in chunks)\n\n    def test_chunking_with_overlap(self):\n        \"\"\"Test that overlap is correctly applied.\"\"\"\n        from ragora import TextChunkingStrategy\n        custom_strategy = TextChunkingStrategy(chunk_size=100, overlap_size=20)\n        chunker = DataChunker(default_strategy=custom_strategy)\n        context = ChunkingContextBuilder().for_text().build()\n        text = \"Test content. \" * 100\n\n        chunks = chunker.chunk(text, context)\n\n        # Verify overlap exists\n        for i in range(len(chunks) - 1):\n            assert chunks[i].text[-10:] in chunks[i + 1].text\n\n    def test_empty_text(self):\n        \"\"\"Test handling of empty input.\"\"\"\n        chunker = DataChunker()\n        context = ChunkingContextBuilder().for_text().build()\n\n        chunks = chunker.chunk(\"\", context)\n        assert len(chunks) == 0\n</code></pre>"},{"location":"contributing/#test-coverage","title":"Test Coverage","text":"<p>Aim for: - Unit tests: 80%+ coverage - Integration tests: Cover main workflows - Edge cases: Test boundary conditions and error cases</p>"},{"location":"contributing/#running-tests","title":"Running Tests","text":"<pre><code># Run all tests\npython -m pytest\n\n# Run with coverage\npython -m pytest --cov=ragora --cov-report=html --cov-report=term\n\n# Run specific test file\npython -m pytest tests/unit/test_data_chunker.py\n\n# Run specific test\npython -m pytest tests/unit/test_data_chunker.py::TestDataChunker::test_basic_chunking\n\n# Run tests matching pattern\npython -m pytest -k \"chunker\"\n</code></pre> <p>For more details, see testing.md.</p>"},{"location":"contributing/#commit-message-convention","title":"\ud83d\udccb Commit Message Convention","text":"<p>We use Conventional Commits for automatic versioning.</p>"},{"location":"contributing/#format","title":"Format","text":"<pre><code>type(scope): description\n\n[optional body]\n\n[optional footer]\n</code></pre>"},{"location":"contributing/#types","title":"Types","text":"<ul> <li><code>feat:</code> - New feature (minor version bump)</li> <li><code>fix:</code> - Bug fix (patch version bump)</li> <li><code>docs:</code> - Documentation changes</li> <li><code>test:</code> - Adding or updating tests</li> <li><code>refactor:</code> - Code refactoring</li> <li><code>perf:</code> - Performance improvements</li> <li><code>style:</code> - Code style changes (formatting, etc.)</li> <li><code>chore:</code> - Maintenance tasks</li> <li><code>ci:</code> - CI/CD changes</li> </ul>"},{"location":"contributing/#examples","title":"Examples","text":"<pre><code># Good commit messages\ngit commit -m \"feat: add hybrid search functionality\"\ngit commit -m \"fix: resolve memory leak in embedding engine\"\ngit commit -m \"docs: update installation instructions\"\ngit commit -m \"test: add unit tests for retriever\"\n\n# With scope\ngit commit -m \"feat(retriever): add filtered search capability\"\ngit commit -m \"fix(chunker): handle edge case with empty text\"\n\n# Breaking change (major version bump)\ngit commit -m \"feat!: redesign API interface\n\nBREAKING CHANGE: All search methods now return different format\"\n</code></pre> <p>For more details, see the release documentation in the root folder of the development repository.</p>"},{"location":"contributing/#pull-request-process","title":"\ud83d\udd0d Pull Request Process","text":""},{"location":"contributing/#before-submitting","title":"Before Submitting","text":"<ul> <li>[ ] Code follows style guidelines (Black, isort, Flake8)</li> <li>[ ] All tests pass</li> <li>[ ] New tests added for new features</li> <li>[ ] Documentation updated</li> <li>[ ] Commit messages follow convention</li> <li>[ ] Branch is up to date with main</li> </ul>"},{"location":"contributing/#pr-template","title":"PR Template","text":"<pre><code>## Description\nBrief description of changes\n\n## Motivation\nWhy is this change needed?\n\n## Changes\n- List of specific changes\n- Another change\n\n## Testing\nHow was this tested?\n\n## Related Issues\nCloses #123\n</code></pre>"},{"location":"contributing/#review-process","title":"Review Process","text":"<ol> <li>Automated Checks: CI/CD runs tests and linting</li> <li>Code Review: Maintainers review code</li> <li>Feedback: Address any requested changes</li> <li>Approval: Approved by maintainer(s)</li> <li>Merge: Merged to main branch</li> </ol>"},{"location":"contributing/#reporting-bugs","title":"\ud83d\udc1b Reporting Bugs","text":""},{"location":"contributing/#before-reporting","title":"Before Reporting","text":"<ol> <li>Check existing issues</li> <li>Verify bug in latest version</li> <li>Test in clean environment</li> </ol>"},{"location":"contributing/#bug-report-template","title":"Bug Report Template","text":"<pre><code>## Description\nClear description of the bug\n\n## Steps to Reproduce\n1. Step one\n2. Step two\n3. Step three\n\n## Expected Behavior\nWhat should happen\n\n## Actual Behavior\nWhat actually happens\n\n## Environment\n- Ragora version:\n- Python version:\n- OS:\n- Weaviate version:\n\n## Additional Context\nAny other relevant information\n</code></pre>"},{"location":"contributing/#suggesting-features","title":"\ud83d\udca1 Suggesting Features","text":""},{"location":"contributing/#feature-request-template","title":"Feature Request Template","text":"<pre><code>## Feature Description\nClear description of the feature\n\n## Motivation\nWhy is this feature needed?\n\n## Proposed Solution\nHow should this work?\n\n## Alternatives Considered\nOther approaches considered\n\n## Additional Context\nAny other relevant information\n</code></pre>"},{"location":"contributing/#documentation","title":"\ud83d\udcda Documentation","text":""},{"location":"contributing/#documentation-standards","title":"Documentation Standards","text":"<ul> <li>Clear and Concise: Easy to understand</li> <li>Examples: Include code examples</li> <li>Complete: Cover all use cases</li> <li>Up-to-date: Keep synchronized with code</li> </ul>"},{"location":"contributing/#where-to-add-documentation","title":"Where to Add Documentation","text":"<ul> <li>Code Comments: For complex logic</li> <li>Docstrings: For all public APIs</li> <li>README: For package overview</li> <li>docs/: For detailed guides</li> <li>Examples: For usage demonstrations</li> </ul>"},{"location":"contributing/#documentation-types","title":"Documentation Types","text":"<ul> <li>API Reference: Auto-generated from docstrings</li> <li>Guides: Step-by-step instructions</li> <li>Tutorials: Learning-oriented content</li> <li>How-to: Problem-solving focused</li> </ul>"},{"location":"contributing/#recognition","title":"\ud83c\udfc6 Recognition","text":"<p>Contributors are recognized in: - CONTRIBUTORS.md file - Release notes - GitHub contributors page</p>"},{"location":"contributing/#getting-help","title":"\ud83d\udcde Getting Help","text":"<ul> <li>Documentation: Check docs directory</li> <li>Issues: Ask in GitHub Issues</li> <li>Discussions: GitHub Discussions</li> <li>Email: Contact maintainers directly</li> </ul>"},{"location":"contributing/#code-of-conduct","title":"\ud83d\udcdc Code of Conduct","text":""},{"location":"contributing/#our-standards","title":"Our Standards","text":"<ul> <li>Be Respectful: Treat everyone with respect</li> <li>Be Constructive: Provide helpful feedback</li> <li>Be Collaborative: Work together effectively</li> <li>Be Patient: Help others learn</li> </ul>"},{"location":"contributing/#unacceptable-behavior","title":"Unacceptable Behavior","text":"<ul> <li>Harassment or discrimination</li> <li>Trolling or insulting comments</li> <li>Public or private harassment</li> <li>Publishing private information</li> </ul>"},{"location":"contributing/#related-documentation","title":"\ud83d\udd17 Related Documentation","text":"<ul> <li>Development Guide - Development workflow</li> <li>Testing Guide - Testing standards</li> <li>Design Decisions - System architecture</li> </ul>"},{"location":"contributing/#thank-you","title":"\ud83d\ude4f Thank You","text":"<p>Thank you for contributing to Ragora! Your contributions help make this project better for everyone.</p>"},{"location":"deployment/","title":"Deployment Guide","text":"<p>This guide covers deploying Ragora in various environments, from development to production.</p>"},{"location":"deployment/#deployment-options","title":"\ud83c\udfaf Deployment Options","text":""},{"location":"deployment/#1-development-deployment","title":"1. Development Deployment","text":"<p>For local development and testing.</p>"},{"location":"deployment/#using-devcontainer-recommended","title":"Using DevContainer (Recommended)","text":"<pre><code># Clone repository\ngit clone https://github.com/vahidlari/aiapps.git\ncd aiapps\n\n# Open in VS Code DevContainer\ncode .\n# Click \"Reopen in Container\"\n\n# Download and start database server\nwget https://github.com/vahidlari/aiapps/releases/latest/download/ragora-database-server.tar.gz\ntar -xzf ragora-database-server.tar.gz\ncd ragora-database-server\n./database-manager.sh start\n\n# Install Ragora in dev mode\ncd ../ragora\npip install -e \".[dev]\"\n</code></pre> <p>See devcontainer documentation in the root folder of the development repository.</p>"},{"location":"deployment/#local-installation","title":"Local Installation","text":"<pre><code># Install Ragora\npip install ragora\n\n# Download and start database server\nwget https://github.com/vahidlari/aiapps/releases/latest/download/ragora-database-server.tar.gz\ntar -xzf ragora-database-server.tar.gz\ncd ragora-database-server\n./database-manager.sh start\n</code></pre>"},{"location":"deployment/#2-production-deployment","title":"2. Production Deployment","text":"<p>For production environments with proper security and scalability.</p>"},{"location":"deployment/#using-ragora-database-server-quick-setup","title":"Using Ragora Database Server (Quick Setup)","text":"<p>For smaller production deployments or getting started quickly:</p> <pre><code># Download database server\nwget https://github.com/vahidlari/aiapps/releases/latest/download/ragora-database-server.tar.gz\ntar -xzf ragora-database-server.tar.gz\ncd ragora-database-server\n\n# Configure for production (edit config.yaml)\ncp examples/config-production.yaml config.yaml\nnano config.yaml  # Enable authentication, adjust settings\n\n# Start with production config\n./database-manager.sh start\n\n# Install Ragora\npip install ragora\n\n# Deploy your application\n# ... your application setup ...\n</code></pre> <p>Advantages: - Quick setup with pre-configured Weaviate - Zero dependencies (only Docker) - Includes configuration examples for production - Suitable for single-server deployments</p> <p>Note: For large-scale production with multiple servers, clustering, or cloud-native deployment, see the custom Docker Compose section below.</p>"},{"location":"deployment/#custom-docker-compose-deployment","title":"Custom Docker Compose Deployment","text":"<p>For larger production environments with custom requirements, create <code>docker-compose.yml</code>:</p> <pre><code>version: '3.8'\n\nservices:\n  weaviate:\n    image: semitechnologies/weaviate:1.22.4\n    restart: always\n    ports:\n      - \"8080:8080\"\n    environment:\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_APIKEY_ENABLED: 'true'\n      AUTHENTICATION_APIKEY_ALLOWED_KEYS: '${WEAVIATE_API_KEY}'\n      AUTHENTICATION_APIKEY_USERS: 'admin'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      DEFAULT_VECTORIZER_MODULE: 'text2vec-transformers'\n      ENABLE_MODULES: 'text2vec-transformers'\n      TRANSFORMERS_INFERENCE_API: 'http://t2v-transformers:8080'\n      CLUSTER_HOSTNAME: 'node1'\n    volumes:\n      - weaviate_data:/var/lib/weaviate\n    networks:\n      - ragora_network\n\n  t2v-transformers:\n    image: semitechnologies/transformers-inference:sentence-transformers-multi-qa-MiniLM-L6-cos-v1\n    restart: always\n    environment:\n      ENABLE_CUDA: '0'\n    networks:\n      - ragora_network\n\n  ragora-api:\n    build: .\n    restart: always\n    ports:\n      - \"8000:8000\"\n    environment:\n      WEAVIATE_URL: 'http://weaviate:8080'\n      WEAVIATE_API_KEY: '${WEAVIATE_API_KEY}'\n    depends_on:\n      - weaviate\n    networks:\n      - ragora_network\n\nvolumes:\n  weaviate_data:\n\nnetworks:\n  ragora_network:\n    driver: bridge\n</code></pre> <p>Deploy:</p> <pre><code># Set environment variables\nexport WEAVIATE_API_KEY=\"your-secure-api-key\"\n\n# Start services\ndocker-compose up -d\n\n# Check status\ndocker-compose ps\n\n# View logs\ndocker-compose logs -f\n</code></pre>"},{"location":"deployment/#3-cloud-deployment","title":"3. Cloud Deployment","text":""},{"location":"deployment/#aws-deployment","title":"AWS Deployment","text":"<p>Using ECS (Elastic Container Service):</p> <pre><code># Build and push image\ndocker build -t ragora-app .\ndocker tag ragora-app:latest ${AWS_ACCOUNT}.dkr.ecr.${REGION}.amazonaws.com/ragora:latest\ndocker push ${AWS_ACCOUNT}.dkr.ecr.${REGION}.amazonaws.com/ragora:latest\n\n# Deploy to ECS (using AWS CLI or Console)\naws ecs create-service \\\n  --cluster ragora-cluster \\\n  --service-name ragora-service \\\n  --task-definition ragora-task \\\n  --desired-count 2\n</code></pre> <p>Weaviate on AWS: - Use Weaviate Cloud Services (WCS) - Or deploy on EC2 with proper security groups - Consider using RDS for metadata storage</p>"},{"location":"deployment/#google-cloud-platform","title":"Google Cloud Platform","text":"<p>Using Cloud Run:</p> <pre><code># Build and deploy\ngcloud builds submit --tag gcr.io/${PROJECT_ID}/ragora\ngcloud run deploy ragora \\\n  --image gcr.io/${PROJECT_ID}/ragora \\\n  --platform managed \\\n  --region us-central1 \\\n  --allow-unauthenticated\n</code></pre> <p>Weaviate on GCP: - Use Weaviate Cloud Services - Or deploy on GKE (Google Kubernetes Engine) - Consider using Cloud SQL for metadata</p>"},{"location":"deployment/#azure-deployment","title":"Azure Deployment","text":"<p>Using Azure Container Instances:</p> <pre><code># Create resource group\naz group create --name ragora-rg --location eastus\n\n# Deploy container\naz container create \\\n  --resource-group ragora-rg \\\n  --name ragora-app \\\n  --image youracr.azurecr.io/ragora:latest \\\n  --dns-name-label ragora-app \\\n  --ports 8000\n</code></pre>"},{"location":"deployment/#security-configuration","title":"\ud83d\udd12 Security Configuration","text":""},{"location":"deployment/#authentication","title":"Authentication","text":"<p>Enable API key authentication for Weaviate:</p> <pre><code>from ragora.core import DatabaseManager\n\ndb_manager = DatabaseManager(\n    url=\"http://weaviate:8080\",\n    api_key=\"your-secure-api-key\"\n)\n</code></pre> <p>Environment variables:</p> <pre><code>export WEAVIATE_URL=\"http://weaviate:8080\"\nexport WEAVIATE_API_KEY=\"your-secure-api-key\"\nexport EMBEDDING_MODEL=\"all-mpnet-base-v2\"\n</code></pre>"},{"location":"deployment/#network-security","title":"Network Security","text":"<p>Firewall Rules: - Allow inbound traffic only on necessary ports (8000 for API, 8080 for Weaviate) - Use VPC/private networks for internal communication - Enable HTTPS for external access</p> <p>Example AWS Security Group: <pre><code># Allow API access\naws ec2 authorize-security-group-ingress \\\n  --group-id sg-xxxxx \\\n  --protocol tcp \\\n  --port 8000 \\\n  --cidr 0.0.0.0/0\n\n# Allow Weaviate (internal only)\naws ec2 authorize-security-group-ingress \\\n  --group-id sg-xxxxx \\\n  --protocol tcp \\\n  --port 8080 \\\n  --source-group sg-yyyyy\n</code></pre></p>"},{"location":"deployment/#data-encryption","title":"Data Encryption","text":"<p>At Rest: <pre><code># docker-compose.yml\nservices:\n  weaviate:\n    volumes:\n      - type: volume\n        source: weaviate_data\n        target: /var/lib/weaviate\n        volume:\n          encrypted: true\n</code></pre></p> <p>In Transit: - Use TLS/SSL for all connections - Configure reverse proxy (nginx, traefik) with SSL certificates - Use Let's Encrypt for free SSL certificates</p>"},{"location":"deployment/#performance-optimization","title":"\u26a1 Performance Optimization","text":""},{"location":"deployment/#scaling-strategies","title":"Scaling Strategies","text":""},{"location":"deployment/#vertical-scaling","title":"Vertical Scaling","text":"<p>Increase resources for single instance:</p> <pre><code>services:\n  ragora-api:\n    deploy:\n      resources:\n        limits:\n          cpus: '4.0'\n          memory: 16G\n        reservations:\n          cpus: '2.0'\n          memory: 8G\n</code></pre>"},{"location":"deployment/#horizontal-scaling","title":"Horizontal Scaling","text":"<p>Multiple instances with load balancer:</p> <pre><code>services:\n  ragora-api:\n    deploy:\n      replicas: 3\n\n  nginx:\n    image: nginx:alpine\n    ports:\n      - \"80:80\"\n    volumes:\n      - ./nginx.conf:/etc/nginx/nginx.conf\n</code></pre>"},{"location":"deployment/#weaviate-optimization","title":"Weaviate Optimization","text":"<p>Resource Allocation: <pre><code>services:\n  weaviate:\n    environment:\n      LIMIT_RESOURCES: 'true'\n      DISK_USE_WARNING_PERCENTAGE: 80\n      DISK_USE_READONLY_PERCENTAGE: 90\n    deploy:\n      resources:\n        limits:\n          memory: 8G\n</code></pre></p> <p>Sharding Configuration: <pre><code># For large datasets\nschema = {\n    \"class\": \"Documents\",\n    \"shardingConfig\": {\n        \"desiredCount\": 3,\n        \"actualCount\": 3\n    }\n}\n</code></pre></p>"},{"location":"deployment/#caching","title":"Caching","text":"<p>Implement caching for frequent queries:</p> <pre><code>from functools import lru_cache\n\n@lru_cache(maxsize=1000)\ndef cached_query(query: str, top_k: int):\n    return kbm.query(query, search_type=\"hybrid\", top_k=top_k)\n</code></pre>"},{"location":"deployment/#monitoring","title":"\ud83d\udcca Monitoring","text":""},{"location":"deployment/#application-monitoring","title":"Application Monitoring","text":"<p>Using Prometheus:</p> <pre><code>from prometheus_client import Counter, Histogram\n\nquery_counter = Counter('ragora_queries_total', 'Total queries')\nquery_duration = Histogram('ragora_query_duration_seconds', 'Query duration')\n\n@query_duration.time()\ndef query_with_metrics(query: str):\n    query_counter.inc()\n    return kbm.query(query)\n</code></pre> <p>Using Application Insights (Azure):</p> <pre><code>from applicationinsights import TelemetryClient\n\ntc = TelemetryClient('your-instrumentation-key')\n\ndef query_with_telemetry(query: str):\n    tc.track_event('Query', {'query': query})\n    result = kbm.query(query)\n    tc.flush()\n    return result\n</code></pre>"},{"location":"deployment/#database-monitoring","title":"Database Monitoring","text":"<p>Monitor Weaviate health:</p> <pre><code>import requests\n\ndef check_weaviate_health():\n    response = requests.get('http://weaviate:8080/v1/.well-known/ready')\n    return response.status_code == 200\n</code></pre>"},{"location":"deployment/#logging","title":"Logging","text":"<p>Configure structured logging:</p> <pre><code>import logging\nimport json\n\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\n\nlogger = logging.getLogger('ragora')\n\ndef log_query(query: str, results: int, duration: float):\n    logger.info(json.dumps({\n        'event': 'query',\n        'query': query,\n        'results': results,\n        'duration': duration\n    }))\n</code></pre>"},{"location":"deployment/#backup-and-recovery","title":"\ud83d\udd04 Backup and Recovery","text":""},{"location":"deployment/#data-backup","title":"Data Backup","text":"<p>Weaviate Backup:</p> <pre><code># Backup Weaviate data\ndocker exec weaviate tar czf /tmp/backup.tar.gz /var/lib/weaviate\ndocker cp weaviate:/tmp/backup.tar.gz ./backups/\n\n# Schedule with cron\n0 2 * * * /path/to/backup-script.sh\n</code></pre> <p>Automated Backups:</p> <pre><code>services:\n  backup:\n    image: alpine\n    volumes:\n      - weaviate_data:/data:ro\n      - ./backups:/backups\n    command: |\n      sh -c \"tar czf /backups/backup-$(date +%Y%m%d).tar.gz /data\"\n</code></pre>"},{"location":"deployment/#disaster-recovery","title":"Disaster Recovery","text":"<p>Recovery Steps:</p> <pre><code># Stop Weaviate\ndocker-compose stop weaviate\n\n# Restore data\ndocker run --rm -v weaviate_data:/data -v ./backups:/backups alpine \\\n  tar xzf /backups/backup-20240101.tar.gz -C /data\n\n# Start Weaviate\ndocker-compose start weaviate\n</code></pre>"},{"location":"deployment/#testing-deployment","title":"\ud83e\uddea Testing Deployment","text":""},{"location":"deployment/#health-checks","title":"Health Checks","text":"<pre><code>def health_check():\n    \"\"\"Comprehensive health check.\"\"\"\n    checks = {\n        'weaviate': check_weaviate_health(),\n        'embedding_model': check_embedding_model(),\n        'api': check_api_endpoints()\n    }\n    return all(checks.values()), checks\n</code></pre>"},{"location":"deployment/#load-testing","title":"Load Testing","text":"<pre><code># Using Apache Bench\nab -n 1000 -c 10 http://localhost:8000/api/query\n\n# Using Locust\npip install locust\nlocust -f locustfile.py --host=http://localhost:8000\n</code></pre>"},{"location":"deployment/#related-documentation","title":"\ud83d\udd17 Related Documentation","text":"<ul> <li>Getting Started - Initial setup</li> <li>Design Decisions - System architecture</li> <li>Contributing - Development guidelines</li> <li>Database Server - Database setup</li> </ul>"},{"location":"deployment/#production-checklist","title":"\ud83d\udcdd Production Checklist","text":"<ul> <li>[ ] Enable authentication on Weaviate</li> <li>[ ] Configure SSL/TLS certificates</li> <li>[ ] Set up monitoring and alerting</li> <li>[ ] Configure automated backups</li> <li>[ ] Implement rate limiting</li> <li>[ ] Set up logging aggregation</li> <li>[ ] Configure auto-scaling policies</li> <li>[ ] Document disaster recovery procedures</li> <li>[ ] Set up health checks</li> <li>[ ] Configure security groups/firewall rules</li> <li>[ ] Review and harden security settings</li> <li>[ ] Test backup and recovery procedures</li> </ul>"},{"location":"design_decisions/","title":"Design Decisions","text":"<p>This document explains the key design decisions made in building Ragora and the rationale behind them.</p>"},{"location":"design_decisions/#architecture-decisions","title":"\ud83c\udfaf Architecture Decisions","text":""},{"location":"design_decisions/#three-layer-architecture","title":"Three-Layer Architecture","text":"<p>Decision: Implement a three-layer architecture (DatabaseManager \u2192 VectorStore \u2192 Retriever)</p> <p>Rationale: - Maintainability: Each layer has a single, clear responsibility - Testability: Components can be tested independently with clear mocking boundaries - Flexibility: Easy to swap database backends by changing DatabaseManager - Performance: Direct Weaviate API usage without unnecessary abstractions - Clarity: Clear separation between infrastructure, storage, and search concerns</p> <p>Alternatives Considered: - Two-layer approach: Combining VectorStore and Retriever would have been simpler but less flexible - Single unified class: Would have been easier to use but harder to test and maintain - Four+ layers: Additional abstraction would have added complexity without clear benefits</p>"},{"location":"design_decisions/#direct-weaviate-api-usage","title":"Direct Weaviate API Usage","text":"<p>Decision: Use Weaviate APIs directly in the Retriever layer instead of abstracting them</p> <p>Rationale: - Performance: Direct API access is faster than additional abstraction layers - Features: Full access to Weaviate's rich query capabilities - Simplicity: Less code to maintain - Flexibility: Easy to leverage new Weaviate features as they're released</p> <p>Trade-offs: - Tighter coupling to Weaviate (acceptable for our use case) - Would require more work to support other vector databases (not a current requirement)</p>"},{"location":"design_decisions/#vector-store-schema-design","title":"\ud83d\uddc4\ufe0f Vector Store Schema Design","text":""},{"location":"design_decisions/#hybrid-metadata-approach","title":"Hybrid Metadata Approach","text":"<p>Decision: Implement a hybrid approach combining dedicated fields with JSON blob for custom metadata</p> <p>Rationale: - Query Performance: Dedicated fields enable efficient filtering and indexing - Flexibility: JSON blob supports arbitrary custom metadata without schema changes - Type Safety: Dedicated fields provide compile-time validation for common use cases - Future-Proof: New content types can be added without breaking existing data - Industry Standard: 24 fields is well within production RAG system norms (typically 30-80+ fields)</p> <p>Schema Organization:</p> <p>Core Fields (6): Essential fields present in all chunk types - <code>content</code>, <code>chunk_id</code>, <code>chunk_key</code>, <code>source_document</code>, <code>chunk_type</code>, <code>created_at</code></p> <p>Content-Type Specific Fields (12):  - Document fields (6): <code>metadata_*</code>, <code>page_number</code>, <code>section_title</code> - Email fields (6): <code>email_*</code> fields for sender, recipient, subject, etc.</p> <p>Custom Metadata Fields (7): - JSON blob: <code>custom_metadata</code> for arbitrary data - Common fields: <code>language</code>, <code>domain</code>, <code>confidence</code>, <code>tags</code>, <code>priority</code>, <code>content_category</code></p> <p>Design Benefits: - Sparse Storage: Unused fields don't consume significant space - Efficient Filtering: Common queries use indexed dedicated fields - Extensibility: New chunk types don't require schema changes - Backward Compatibility: Sensible defaults prevent breaking changes</p> <p>Alternatives Considered: - Pure JSON approach: Would lose query performance benefits - Fully normalized: Would require complex joins and lose simplicity - Separate collections: Would complicate cross-type queries</p>"},{"location":"design_decisions/#content-type-agnostic-design","title":"Content-Type Agnostic Design","text":"<p>Decision: Single collection supporting multiple content types rather than separate collections</p> <p>Rationale: - Unified Search: Enable cross-type queries (e.g., search emails and documents together) - Simplified Management: Single schema to maintain and backup - Consistent API: Same methods work for all content types - Resource Efficiency: Shared vectorizer and indexing infrastructure</p> <p>Trade-offs: - Schema Size: 24 fields vs. smaller per-type schemas - Query Complexity: Some fields irrelevant for certain content types - Storage: Sparse fields still consume some space</p> <p>Mitigation Strategies: - Sensible defaults (empty strings, 0, null) minimize storage impact - Weaviate handles sparse fields efficiently - Clear field organization makes schema understandable</p>"},{"location":"design_decisions/#document-processing-strategy","title":"\ud83d\udcc4 Document Processing Strategy","text":""},{"location":"design_decisions/#latex-handling","title":"LaTeX Handling","text":"<p>Decision: Specialized LaTeX processing with equation preservation</p> <p>Rationale: - Target Audience: Primary use case is academic/scientific documents - Mathematical Content: Equations contain critical semantic information - Citation Tracking: Academic documents rely heavily on citations - Format Complexity: LaTeX has specific structures that generic parsers miss</p> <p>Implementation Details:</p> <ol> <li>Equation Preservation</li> <li>Keep mathematical equations intact (e.g., <code>$E = mc^2$</code>)</li> <li>Preserve both inline and display equations</li> <li> <p>Maintain LaTeX math notation in embeddings</p> </li> <li> <p>Citation Strategy</p> </li> <li>Extract citations as separate entities</li> <li>Store with rich metadata (author, year, title, DOI)</li> <li>Link citations to source chunks</li> <li> <p>Enable citation-based search</p> </li> <li> <p>Command Removal</p> </li> <li>Strip formatting commands (<code>\\textbf{}</code>, <code>\\section{}</code>, etc.)</li> <li>Preserve semantic content</li> <li>Maintain document structure in metadata</li> </ol> <p>Citation Metadata Structure: <pre><code>{\n    \"type\": \"citation\",\n    \"author\": \"Einstein, A.\",\n    \"year\": 1905,\n    \"title\": \"On the Electrodynamics of Moving Bodies\",\n    \"doi\": \"10.1002/andp.19053221004\",\n    \"content\": \"The theory of relativity...\",\n    \"source_document\": \"chapter_1.tex\",\n    \"page_reference\": 15,\n    \"chunk_id\": \"chunk_001\"\n}\n</code></pre></p>"},{"location":"design_decisions/#chunking-strategy","title":"Chunking Strategy","text":"<p>Decision: Adaptive fixed-size chunking with configurable overlap</p> <p>Rationale: - Predictability: Fixed size ensures consistent embedding quality - Optimization: Can tune chunk size for specific embedding models - Context: Overlap preserves context across chunk boundaries - Flexibility: Token-based with line boundary respect</p> <p>Parameters: - Default Chunk Size: 768 tokens (matches common embedding model limits) - Default Overlap: 100-150 tokens (provides sufficient context) - Boundary Respect: Respect line boundaries when possible</p> <p>Alternatives Considered: - Semantic chunking: More intelligent but less predictable - Paragraph-based: Simple but variable sizes hurt embedding quality - Sentence-based: Too granular, loses context - Sliding window: More overlap but increased storage</p> <p>Object-Oriented Design: <pre><code>class DataChunker:\n    def __init__(self, chunk_size: int = 768, overlap: int = 100)\n    def chunk_text(self, text: str) -&gt; List[Chunk]\n    def chunk_with_metadata(self, text: str, metadata: Dict) -&gt; List[Chunk]\n</code></pre></p> <p>Benefits: - Format-agnostic (works with any text) - Easily configurable - Reusable across different document types - Testable in isolation</p>"},{"location":"design_decisions/#embedding-storage","title":"\ud83d\udd22 Embedding &amp; Storage","text":""},{"location":"design_decisions/#embedding-model-selection","title":"Embedding Model Selection","text":"<p>Decision: Sentence Transformers with <code>all-mpnet-base-v2</code> as default</p> <p>Rationale: - Local Deployment: No API costs or rate limits - Privacy: Data never leaves your infrastructure - Performance: Good balance of quality and speed - Dimensions: 768 dimensions suitable for most use cases - Technical Content: MPNet models perform well on scientific text</p> <p>Alternative Models: - <code>multi-qa-MiniLM-L6-v2</code>: Smaller, faster, optimized for Q&amp;A - <code>all-MiniLM-L12-v2</code>: Good general-purpose alternative - <code>sentence-transformers/allenai-specter</code>: Specialized for scientific papers</p> <p>Configuration: <pre><code>{\n    \"model\": \"all-mpnet-base-v2\",\n    \"pooling_strategy\": \"mean\",\n    \"normalize_embeddings\": True\n}\n</code></pre></p>"},{"location":"design_decisions/#vector-database-choice","title":"Vector Database Choice","text":"<p>Decision: Weaviate as the vector database</p> <p>Rationale: - Rich Features: Hybrid search, filtering, graphQL API - Modularity: Built-in vectorizer modules - Performance: HNSW index for fast similarity search - Schema Flexibility: Dynamic schema with rich property types - Active Development: Regular updates and improvements - Open Source: Can self-host</p> <p>Weaviate Configuration: <pre><code>{\n    \"vectorizer\": \"text2vec-transformers\",\n    \"moduleConfig\": {\n        \"text2vec-transformers\": {\n            \"model\": \"all-mpnet-base-v2\",\n            \"poolingStrategy\": \"masked_mean\",\n            \"vectorizeClassName\": False\n        }\n    }\n}\n</code></pre></p> <p>Alternatives Considered: - ChromaDB: Simpler but less features - Qdrant: Good alternative but less mature at time of decision - Pinecone: Cloud-only, not suitable for self-hosted requirement - FAISS: Lower-level, would need more custom implementation</p>"},{"location":"design_decisions/#retrieval-strategy","title":"\ud83d\udd0d Retrieval Strategy","text":""},{"location":"design_decisions/#hybrid-search","title":"Hybrid Search","text":"<p>Decision: Support multiple search modes (vector, keyword, hybrid)</p> <p>Rationale: - Flexibility: Different queries benefit from different search strategies - Semantic + Exact: Hybrid combines best of both worlds - Technical Terms: Keyword search catches exact technical terms - Natural Language: Vector search handles conceptual queries</p> <p>Search Modes:</p> <ol> <li>Vector Search (Semantic)</li> <li>Dense embeddings for semantic similarity</li> <li>Best for conceptual queries</li> <li> <p>Example: \"What is quantum entanglement?\"</p> </li> <li> <p>Keyword Search (BM25)</p> </li> <li>Sparse keyword matching</li> <li>Best for exact terms</li> <li> <p>Example: \"Schr\u00f6dinger equation\"</p> </li> <li> <p>Hybrid Search</p> </li> <li>Combines vector and keyword</li> <li>Configurable alpha parameter (0.0-1.0)</li> <li>Best for general use</li> <li>Example: \"explain machine learning algorithms\"</li> </ol> <p>Alpha Parameter: - <code>alpha=1.0</code>: Pure vector search - <code>alpha=0.0</code>: Pure keyword search - <code>alpha=0.5</code>: Balanced hybrid (default) - <code>alpha=0.7</code>: Favor semantic (recommended for most queries)</p>"},{"location":"design_decisions/#query-processing","title":"Query Processing","text":"<p>Decision: Minimal query preprocessing</p> <p>Rationale: - Preserve Intent: Heavy preprocessing can distort query meaning - Technical Terms: Preserve mathematical notation and technical terms - Simplicity: Less processing means faster queries - Let Model Handle: Modern embedding models handle variations well</p> <p>What We Do: - Preserve exact technical terms - Keep mathematical notation - Pass queries through largely unchanged</p> <p>What We Don't Do: - Heavy stemming/lemmatization - Aggressive stopword removal - Query expansion (let the embedding handle it)</p>"},{"location":"design_decisions/#generation-system","title":"\ud83e\udd16 Generation System","text":""},{"location":"design_decisions/#llm-integration","title":"LLM Integration","text":"<p>Decision: Support multiple LLM backends (Ollama, OpenAI, etc.)</p> <p>Rationale: - Flexibility: Users can choose based on their needs - Local Option: Ollama for privacy-sensitive use cases - Cloud Option: OpenAI/Anthropic for best quality - Cost Control: Local models have no per-token costs</p> <p>Default: Ollama with Mistral 7B - Free and local - Good performance on technical content - 4096 token context window - Easy to self-host</p> <p>Prompt Engineering: <pre><code>def create_rag_prompt(query: str, context: List[str]) -&gt; str:\n    return f\"\"\"Based on the following context, answer the question.\n\nContext:\n{format_context(context)}\n\nQuestion: {query}\n\nAnswer: \"\"\"\n</code></pre></p> <p>Design Principles: - Include citation information in responses - Preserve mathematical notation - Indicate confidence level - Cite sources when possible</p>"},{"location":"design_decisions/#performance-considerations","title":"\ud83d\udcca Performance Considerations","text":""},{"location":"design_decisions/#chunk-size-optimization","title":"Chunk Size Optimization","text":"<p>Decision: Default 768 tokens with ability to configure</p> <p>Rationale: - Embedding Models: Most models work best with 512-768 tokens - Context Balance: Large enough for context, small enough for relevance - Retrieval Quality: Empirical testing showed good results - Flexibility: Users can tune for their specific use case</p> <p>Testing Strategy: - Test range: 256, 512, 768, 1024 tokens - Measure retrieval quality (MRR, Precision@K) - Consider domain-specific optimization</p>"},{"location":"design_decisions/#batch-processing","title":"Batch Processing","text":"<p>Decision: Batch embedding and storage operations</p> <p>Rationale: - Performance: 5-10x faster than individual operations - GPU Utilization: Better GPU usage with batched inference - Network Efficiency: Fewer round trips to database - Resource Usage: More efficient memory usage</p> <p>Implementation: <pre><code># Batch size tuned for typical GPU memory\nEMBEDDING_BATCH_SIZE = 32\nSTORAGE_BATCH_SIZE = 100\n</code></pre></p>"},{"location":"design_decisions/#testing-strategy","title":"\ud83e\uddea Testing Strategy","text":"<p>Decision: Comprehensive three-tier testing approach</p> <p>Test Layers: 1. Unit Tests: Individual component testing 2. Integration Tests: Component interaction testing 3. End-to-End Tests: Complete workflow testing</p> <p>Rationale: - Quality Assurance: Catch issues early - Refactoring Safety: Confident code changes - Documentation: Tests serve as usage examples - CI/CD: Automated testing in pipeline</p> <p>For more details, see testing.md.</p>"},{"location":"design_decisions/#future-considerations","title":"\ud83d\udd04 Future Considerations","text":""},{"location":"design_decisions/#planned-improvements","title":"Planned Improvements","text":"<ol> <li>Multi-modal Support: Images, tables, diagrams</li> <li>Advanced Chunking: Semantic chunking options</li> <li>Fine-tuning: Domain-specific embedding models</li> <li>Caching: Query result caching</li> <li>Streaming: Streaming LLM responses</li> </ol>"},{"location":"design_decisions/#extensibility-points","title":"Extensibility Points","text":"<ul> <li>Plugin system for custom document processors</li> <li>Custom embedding model integration</li> <li>Alternative vector database backends</li> <li>Custom retrieval algorithms</li> </ul>"},{"location":"design_decisions/#related-documentation","title":"\ud83d\udd17 Related Documentation","text":"<ul> <li>Design Decisions - System architecture overview</li> <li>Getting Started - Setup and usage guide</li> <li>Testing - Testing guidelines</li> </ul>"},{"location":"devcontainer/","title":"DevContainer Setup Guide","text":"<p>This guide provides detailed information about the DevContainer setup for Ragora development.</p>"},{"location":"devcontainer/#quick-start-with-devcontainer","title":"\ud83d\ude80 Quick Start with DevContainer","text":"<p>The easiest way to get started is using the development container:</p>"},{"location":"devcontainer/#prerequisites","title":"Prerequisites","text":"<ul> <li>Install Docker Desktop</li> <li>Install VS Code</li> <li>Install the Dev Containers extension for VS Code</li> </ul>"},{"location":"devcontainer/#open-in-devcontainer","title":"Open in DevContainer","text":"<ol> <li>Clone this repository</li> <li>Open the repository in VS Code</li> <li>When prompted, click \"Reopen in Container\" or use <code>Ctrl+Shift+P</code> \u2192 \"Dev Containers: Reopen in Container\"</li> </ol>"},{"location":"devcontainer/#docker-image-management","title":"\ud83d\udc33 Docker Image Management","text":"<p>The development environment uses a custom Docker image hosted on GitHub Container Registry. The image includes:</p> <ul> <li>Python 3.11 with all necessary development tools</li> <li>Common AI/ML libraries (numpy, pandas, scikit-learn, etc.)</li> <li>RAG-specific packages (langchain, chromadb, sentence-transformers)</li> <li>Development tools (black, flake8, isort, pytest)</li> <li>Jupyter notebooks support</li> </ul>"},{"location":"devcontainer/#building-the-docker-image-locally","title":"Building the Docker Image Locally","text":"<p>To update the Docker image:</p> <pre><code>cd tools/docker\n./build-docker.sh -u\n</code></pre> <p>Note: The devContainer fetches the image from a GitHub registry, therefore, a local image build is normally not needed. In order to update the image, create a PR with changes in Dockerfile or Pipfile. A GitHub action is invoked to update the image. Once the image is updated, update the image tag in <code>.devcontainer/devcontainer.json</code>.</p> <p>For detailed instructions, see <code>tools/docker/README.md</code>.</p>"},{"location":"devcontainer/#development-environment-features","title":"\ud83d\udd27 Development Environment Features","text":"<p>The devcontainer includes:</p> <ul> <li>Python 3.11 as the default interpreter</li> <li>VS Code extensions for Python development, Jupyter notebooks, and Docker</li> <li>Code formatting with Black and import sorting with isort</li> <li>Linting with flake8</li> <li>Git integration with GitHub CLI</li> <li>Jupyter Lab for interactive development</li> </ul>"},{"location":"devcontainer/#python-dependencies","title":"\ud83d\udce6 Python Dependencies","text":"<p>The environment comes pre-installed with:</p> <ul> <li>Core ML libraries: numpy, pandas, matplotlib, seaborn, scikit-learn</li> <li>Deep Learning: PyTorch, Transformers, Datasets</li> <li>RAG systems: LangChain, ChromaDB, FAISS, Sentence Transformers</li> <li>AI APIs: OpenAI, Anthropic</li> <li>Development tools: Black, flake8, isort, pytest</li> </ul>"},{"location":"devcontainer/#automatic-docker-builds","title":"\ud83d\udd04 Automatic Docker Builds","text":"<p>The repository includes GitHub Actions that automatically build and push the Docker image when changes are made to the Dockerfile. This ensures the devcontainer always uses the latest environment.</p>"},{"location":"devcontainer/#troubleshooting","title":"\ud83d\udc1b Troubleshooting","text":""},{"location":"devcontainer/#devcontainer-issues","title":"DevContainer Issues","text":"<p>Container won't start: <pre><code># Check Docker is running\ndocker info\n\n# Rebuild the container\nCtrl+Shift+P \u2192 \"Dev Containers: Rebuild Container\"\n</code></pre></p> <p>Slow build times: - First-time builds can take 10-15 minutes - Subsequent rebuilds are faster due to caching - Consider using the pre-built image from GitHub Container Registry</p> <p>Permission issues: <pre><code># On Linux/WSL, ensure user is in docker group\nsudo usermod -aG docker $USER\n# Log out and back in for changes to take effect\n</code></pre></p>"},{"location":"devcontainer/#authentication-issues","title":"Authentication Issues","text":"<p>If you encounter authentication errors when pulling the Docker image, see the Authentication Setup section in the onboarding guide.</p>"},{"location":"devcontainer/#configuration","title":"\ud83d\udd27 Configuration","text":""},{"location":"devcontainer/#devcontainer-configuration-location","title":"DevContainer Configuration Location","text":"<p>The devcontainer configuration is located at <code>.devcontainer/devcontainer.json</code>.</p>"},{"location":"devcontainer/#customizing-the-environment","title":"Customizing the Environment","text":"<p>To add VS Code extensions: 1. Edit <code>.devcontainer/devcontainer.json</code> 2. Add extension IDs to the <code>extensions</code> array 3. Rebuild the container</p> <p>To add system packages: 1. Edit <code>tools/docker/Dockerfile</code> 2. Create a PR with your changes 3. GitHub Actions will build and publish the new image</p> <p>To add Python packages: 1. Edit <code>tools/docker/Pipfile</code> 2. Create a PR with your changes 3. GitHub Actions will update the image</p>"},{"location":"devcontainer/#best-practices","title":"\ud83d\udcdd Best Practices","text":"<ul> <li>Keep devcontainer.json minimal: Most configuration should be in the Docker image</li> <li>Version your image tags: Use specific tags in production workflows</li> <li>Test locally first: Build and test Docker image changes locally before pushing</li> <li>Document changes: Update this guide when making significant environment changes</li> </ul>"},{"location":"devcontainer/#related-documentation","title":"\ud83d\udd17 Related Documentation","text":"<ul> <li>Onboarding Guide - Getting started for new team members</li> <li>Development Guide - Development workflow and best practices</li> <li>Docker Tools - Docker image build scripts</li> </ul>"},{"location":"development/","title":"Development Guide","text":"<p>This guide covers development workflows, coding standards, and best practices for contributing to Ragora.</p>"},{"location":"development/#development-workflow","title":"\ud83d\udd27 Development Workflow","text":""},{"location":"development/#setting-up-your-development-environment","title":"Setting Up Your Development Environment","text":"<ol> <li>Clone the repository and open in DevContainer (see devcontainer.md)</li> <li>Install Ragora in development mode: <pre><code>cd ragora\npip install -e .\n</code></pre></li> <li>Verify installation: <pre><code>python -c \"import ragora; print('\u2705 Ragora installed successfully')\"\n</code></pre></li> </ol>"},{"location":"development/#branch-strategy","title":"Branch Strategy","text":"<p>We follow a feature branch workflow:</p> <pre><code># Create a new branch for your work\ngit checkout -b feature/your-feature-name\n\n# Make your changes and commit\ngit add .\ngit commit -m \"feat: add your feature description\"\n\n# Push to GitHub\ngit push origin feature/your-feature-name\n\n# Create a Pull Request on GitHub\n</code></pre>"},{"location":"development/#commit-message-convention","title":"Commit Message Convention","text":"<p>We use Conventional Commits for automatic versioning:</p> <pre><code># Feature (minor version bump)\ngit commit -m \"feat: add user authentication\"\n\n# Bug fix (patch version bump)\ngit commit -m \"fix: resolve login timeout issue\"\n\n# Breaking change (major version bump)\ngit commit -m \"feat!: redesign API endpoints\"\n\n# Other types (patch version bump)\ngit commit -m \"docs: update installation guide\"\ngit commit -m \"test: add unit tests for auth module\"\ngit commit -m \"refactor: simplify API structure\"\n</code></pre> <p>For detailed information, see release.md.</p>"},{"location":"development/#code-quality-standards","title":"\ud83c\udfa8 Code Quality Standards","text":""},{"location":"development/#formatting-and-linting","title":"Formatting and Linting","text":"<p>The project uses automated code quality tools:</p> <ul> <li>Black - Code formatting (runs on save in VS Code)</li> <li>isort - Import sorting</li> <li>Flake8 - Linting</li> </ul> <p>Run manually if needed: <pre><code># Format code with Black\nblack ragora/\n\n# Sort imports\nisort ragora/\n\n# Check linting\nflake8 ragora/\n</code></pre></p>"},{"location":"development/#type-hints","title":"Type Hints","text":"<p>Use type hints for all function signatures:</p> <pre><code>from typing import List, Dict, Optional\n\ndef process_documents(\n    documents: List[str],\n    chunk_size: int = 768,\n    overlap: Optional[int] = None\n) -&gt; Dict[str, any]:\n    \"\"\"Process documents and return results.\"\"\"\n    pass\n</code></pre>"},{"location":"development/#docstrings","title":"Docstrings","text":"<p>Use Google-style docstrings for all public functions and classes:</p> <pre><code>def search_similar(query: str, top_k: int = 5) -&gt; List[Dict]:\n    \"\"\"Search for similar documents using vector similarity.\n\n    Args:\n        query: The search query string\n        top_k: Number of results to return\n\n    Returns:\n        List of dictionaries containing search results with scores\n\n    Raises:\n        ValueError: If query is empty or top_k is negative\n\n    Example:\n        &gt;&gt;&gt; results = search_similar(\"machine learning\", top_k=3)\n        &gt;&gt;&gt; print(len(results))\n        3\n    \"\"\"\n    pass\n</code></pre>"},{"location":"development/#testing","title":"\ud83e\uddea Testing","text":""},{"location":"development/#running-tests","title":"Running Tests","text":"<pre><code># Run all tests\ncd ragora\npython -m pytest\n\n# Run specific test types\npython -m pytest tests/unit/          # Unit tests only\npython -m pytest tests/integration/  # Integration tests only\n\n# Run with coverage\npython -m pytest --cov=ragora --cov-report=html\n</code></pre>"},{"location":"development/#writing-tests","title":"Writing Tests","text":"<p>Place tests in the appropriate directory: - <code>tests/unit/</code> - Unit tests for individual components - <code>tests/integration/</code> - Integration tests for component interactions</p> <p>Example test: <pre><code>import pytest\nfrom ragora.core import DataChunker\n\ndef test_chunker_basic():\n    \"\"\"Test basic chunking functionality.\"\"\"\n    chunker = DataChunker()\n    context = ChunkingContextBuilder().for_text().build()\n    text = \"This is a test document. \" * 50\n    chunks = chunker.chunk(text, context)\n\n    assert len(chunks) &gt; 0\n    assert all(isinstance(chunk, DataChunk) for chunk in chunks)\n</code></pre></p> <p>For more details, see testing.md.</p>"},{"location":"development/#managing-dependencies","title":"\ud83d\udce6 Managing Dependencies","text":""},{"location":"development/#adding-python-dependencies","title":"Adding Python Dependencies","text":""},{"location":"development/#for-ragora-package","title":"For Ragora Package","text":"<p>Add to <code>ragora/requirements.txt</code> for production dependencies: <pre><code>cd ragora\necho \"new-package&gt;=1.0.0\" &gt;&gt; requirements.txt\npip install -r requirements.txt\n</code></pre></p> <p>Add to <code>ragora/requirements-dev.txt</code> for development dependencies: <pre><code>echo \"dev-tool&gt;=2.0.0\" &gt;&gt; requirements-dev.txt\npip install -r requirements-dev.txt\n</code></pre></p>"},{"location":"development/#for-development-environment","title":"For Development Environment","text":"<p>To add packages to the DevContainer image: 1. Edit <code>tools/docker/Pipfile</code> 2. Add the package: <code>new-package = \"&gt;=1.0.0\"</code> 3. Create a PR with your changes 4. GitHub Actions will automatically build and publish the updated image</p>"},{"location":"development/#updating-dependencies","title":"Updating Dependencies","text":"<pre><code># Update specific package\npip install --upgrade package-name\n\n# Regenerate requirements\npip freeze &gt; requirements.txt\n\n# For dev dependencies\npip freeze &gt; requirements-dev.txt\n</code></pre>"},{"location":"development/#project-structure","title":"\ud83c\udfd7\ufe0f Project Structure","text":""},{"location":"development/#package-organization","title":"Package Organization","text":"<pre><code>ragora/\n\u251c\u2500\u2500 core/              # Core RAG components\n\u2502   \u251c\u2500\u2500 database_manager.py\n\u2502   \u251c\u2500\u2500 vector_store.py\n\u2502   \u2514\u2500\u2500 retriever.py\n\u251c\u2500\u2500 utils/             # Utility functions\n\u251c\u2500\u2500 config/            # Configuration management\n\u251c\u2500\u2500 cli/               # Command-line interface\n\u2514\u2500\u2500 examples/          # Usage examples\n</code></pre>"},{"location":"development/#adding-new-modules","title":"Adding New Modules","text":"<ol> <li>Create the module file in the appropriate directory</li> <li>Add comprehensive docstrings and type hints</li> <li>Write unit tests</li> <li>Update relevant documentation</li> <li>Add usage examples if applicable</li> </ol>"},{"location":"development/#code-review-guidelines","title":"\ud83d\udd0d Code Review Guidelines","text":""},{"location":"development/#before-submitting-a-pr","title":"Before Submitting a PR","text":"<ul> <li>[ ] All tests pass locally</li> <li>[ ] Code is formatted with Black</li> <li>[ ] Imports are sorted with isort</li> <li>[ ] No linting errors from Flake8</li> <li>[ ] Type hints are present</li> <li>[ ] Docstrings are complete</li> <li>[ ] Tests are added for new features</li> <li>[ ] Documentation is updated</li> </ul>"},{"location":"development/#pr-template","title":"PR Template","text":"<p>When creating a PR, include: - Description: What does this PR do? - Motivation: Why is this change needed? - Testing: How was this tested? - Related Issues: Links to related issues</p>"},{"location":"development/#debugging","title":"\ud83d\udc1b Debugging","text":""},{"location":"development/#using-vs-code-debugger","title":"Using VS Code Debugger","text":"<p>The devcontainer includes debug configurations. To debug: 1. Set breakpoints in your code 2. Press F5 or use the Debug panel 3. Select the appropriate debug configuration</p>"},{"location":"development/#common-debug-configurations","title":"Common Debug Configurations","text":"<ul> <li>Python: Current File - Debug the currently open file</li> <li>Python: pytest - Debug tests</li> <li>Python: Remote Attach - Attach to running process</li> </ul>"},{"location":"development/#logging","title":"Logging","text":"<p>Use Python's logging module for debugging:</p> <pre><code>import logging\n\nlogger = logging.getLogger(__name__)\n\ndef process_data(data):\n    logger.debug(f\"Processing data: {data}\")\n    logger.info(\"Processing completed\")\n    logger.warning(\"Performance may be slow\")\n    logger.error(\"Failed to process data\")\n</code></pre>"},{"location":"development/#performance-profiling","title":"\ud83d\udcca Performance Profiling","text":""},{"location":"development/#profiling-code","title":"Profiling Code","text":"<pre><code>import cProfile\nimport pstats\n\ndef profile_function():\n    profiler = cProfile.Profile()\n    profiler.enable()\n\n    # Your code here\n\n    profiler.disable()\n    stats = pstats.Stats(profiler)\n    stats.sort_stats('cumulative')\n    stats.print_stats(20)\n</code></pre>"},{"location":"development/#memory-profiling","title":"Memory Profiling","text":"<pre><code># Install memory profiler\npip install memory-profiler\n\n# Run with memory profiling\npython -m memory_profiler your_script.py\n</code></pre>"},{"location":"development/#related-documentation","title":"\ud83d\udd17 Related Documentation","text":"<ul> <li>Onboarding Guide - Getting started for new team members</li> <li>DevContainer Guide - Development environment setup</li> <li>Release Process - How to create releases</li> <li>Contributing Guide - Contribution guidelines</li> </ul>"},{"location":"development/#getting-help","title":"\ud83c\udd98 Getting Help","text":"<ul> <li>Documentation: Check the docs in each directory</li> <li>Issues: Create GitHub issues for bugs or questions</li> <li>Discussions: Use GitHub Discussions for general questions</li> <li>Code Review: Request reviews from team members</li> </ul>"},{"location":"getting_started/","title":"Getting Started with Ragora","text":"<p>This guide will help you get started with Ragora, from installation to building your first RAG system.</p>"},{"location":"getting_started/#prerequisites","title":"\ud83d\udccb Prerequisites","text":""},{"location":"getting_started/#system-requirements","title":"System Requirements","text":"<ul> <li>Python: 3.11 or higher</li> <li>Memory: 8GB RAM minimum (16GB recommended for larger models)</li> <li>Storage: 5GB free space for models and data</li> <li>OS: Linux, macOS, or Windows with WSL</li> </ul>"},{"location":"getting_started/#required-software","title":"Required Software","text":"<ol> <li>Docker (for Weaviate database)</li> <li>Docker Desktop for Windows/macOS</li> <li> <p>Docker Engine for Linux</p> </li> <li> <p>Python Environment</p> </li> <li>Python 3.11+</li> <li>pip or conda for package management</li> </ol>"},{"location":"getting_started/#installation","title":"\ud83d\ude80 Installation","text":""},{"location":"getting_started/#option-1-install-from-pypi-recommended","title":"Option 1: Install from PyPI (Recommended)","text":"<pre><code># Install the latest version\npip install ragora\n\n# Or install a specific version\npip install ragora==1.0.0\n</code></pre>"},{"location":"getting_started/#option-2-install-from-source","title":"Option 2: Install from Source","text":"<pre><code># Clone the repository\ngit clone https://github.com/vahidlari/aiapps.git\ncd aiapps/ragora\n\n# Install in development mode\npip install -e .\n\n# Or install with development dependencies\npip install -e \".[dev]\"\n</code></pre>"},{"location":"getting_started/#verify-installation","title":"Verify Installation","text":"<pre><code>python -c \"import ragora; print(f'Ragora version: {ragora.__version__}')\"\n</code></pre>"},{"location":"getting_started/#database-setup","title":"\ud83d\uddc4\ufe0f Database Setup","text":"<p>Ragora uses Weaviate as its vector database. You need to start a Weaviate instance before using Ragora.</p>"},{"location":"getting_started/#using-the-ragora-database-server-recommended","title":"Using the Ragora Database Server (Recommended)","text":"<p>Download the pre-configured database server from the latest release:</p> <pre><code># Download from GitHub releases\nwget https://github.com/vahidlari/aiapps/releases/latest/download/ragora-database-server.tar.gz\n\n# Extract\ntar -xzf ragora-database-server.tar.gz\ncd ragora-database-server\n\n# Start the server\n./database-manager.sh start\n\n# Check if it's running\n./database-manager.sh status\n</code></pre> <p>The database will be available at <code>http://localhost:8080</code>.</p> <p>Features: - Zero dependencies (only requires Docker) - Pre-configured for Ragora - Includes sentence-transformers inference API - Works on Windows, macOS, and Linux</p> <p>For detailed documentation, see the included README.md in the database server package.</p>"},{"location":"getting_started/#alternative-manual-docker-setup","title":"Alternative: Manual Docker Setup","text":"<p>If you prefer to set up Weaviate manually:</p> <pre><code>docker run -d \\\n  --name weaviate \\\n  -p 8080:8080 \\\n  -e QUERY_DEFAULTS_LIMIT=25 \\\n  -e AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED=true \\\n  -e PERSISTENCE_DATA_PATH='/var/lib/weaviate' \\\n  semitechnologies/weaviate:1.22.4\n</code></pre>"},{"location":"getting_started/#quick-start","title":"\ud83c\udfaf Quick Start","text":""},{"location":"getting_started/#basic-usage","title":"Basic Usage","text":"<p>Here's a simple example to get you started:</p> <pre><code>from ragora import KnowledgeBaseManager\n\n# Initialize the knowledge base manager\nkbm = KnowledgeBaseManager(\n    weaviate_url=\"http://localhost:8080\"\n)\n\n# Process documents\ndocument_paths = [\n    \"path/to/document1.tex\",\n    \"path/to/document2.tex\"\n]\nchunk_ids = kbm.process_documents(document_paths)\nprint(f\"Processed {len(chunk_ids)} chunks\")\n\n# Query the knowledge base\nfrom ragora import SearchStrategy\n\nresults = kbm.search(\n    \"What is quantum entanglement?\",\n    strategy=SearchStrategy.HYBRID,\n    top_k=5\n)\n\n# Display results\nfor i, result in enumerate(results.results, 1):\n    print(f\"\\n{i}. Score: {result.get('similarity_score', 0):.3f}\")\n    print(f\"   Content: {result['content'][:200]}...\")\n</code></pre>"},{"location":"getting_started/#document-processing","title":"Document Processing","text":"<pre><code>from ragora.core import (\n    DocumentPreprocessor,\n    DataChunker,\n    EmbeddingEngine\n)\n\n# Initialize components\npreprocessor = DocumentPreprocessor()\nchunker = DataChunker()\nembedder = EmbeddingEngine(model_name=\"all-mpnet-base-v2\")\n\n# Process a LaTeX document\ndocument = preprocessor.parse_latex(\"document.tex\", \"references.bib\")\n\n# Chunk the content\nchunks = []\nfor section in document.sections:\n    for paragraph in section.paragraphs:\n        paragraph_chunks = chunker.chunk_text(paragraph.content)\n        chunks.extend(paragraph_chunks)\n\n# Generate embeddings\nembeddings = embedder.embed_batch([chunk.content for chunk in chunks])\n\nprint(f\"Created {len(chunks)} chunks with embeddings\")\n</code></pre>"},{"location":"getting_started/#search-and-retrieval","title":"Search and Retrieval","text":"<pre><code>from ragora.core import DatabaseManager, Retriever\n\n# Initialize database connection\ndb_manager = DatabaseManager(url=\"http://localhost:8080\")\n\n# Create retriever\nretriever = Retriever(\n    db_manager=db_manager,\n    collection=\"Document\"\n)\n\n# Semantic search\nresults = retriever.search_similar(\n    query=\"machine learning algorithms\",\n    top_k=5\n)\n\n# Hybrid search (recommended)\nresults = retriever.search_hybrid(\n    query=\"deep learning neural networks\",\n    alpha=0.7,  # 0.0 = pure keyword, 1.0 = pure vector\n    top_k=5\n)\n\n# Keyword search\nresults = retriever.search_keyword(\n    query=\"Schr\u00f6dinger equation\",\n    top_k=5\n)\n\n# Display results\nfor result in results:\n    print(f\"Score: {result['similarity_score']:.3f}\")\n    print(f\"Content: {result['content'][:150]}...\")\n    print(f\"Metadata: {result.get('metadata', {})}\\n\")\n</code></pre>"},{"location":"getting_started/#filtering-search-results","title":"Filtering Search Results","text":"<p>Ragora supports filtering search results by properties using Weaviate filters. The <code>FilterBuilder</code> class provides convenient methods for creating filters aligned with your domain model.</p> <pre><code>from ragora import KnowledgeBaseManager, FilterBuilder, SearchStrategy\n\nkbm = KnowledgeBaseManager()\n\n# Filter by chunk type (only text chunks)\nfilter = FilterBuilder.by_chunk_type(\"text\")\nresults = kbm.search(\n    \"machine learning\",\n    strategy=SearchStrategy.HYBRID,\n    filter=filter\n)\n\n# Filter by source document\nfilter = FilterBuilder.by_source_document(\"research_paper.pdf\")\nresults = kbm.search(\"quantum mechanics\", filter=filter)\n\n# Filter by date range (documents from 2024)\ndate_filter = FilterBuilder.by_date_range(\n    start=\"2024-01-01\",\n    end=\"2024-12-31\"\n)\nresults = kbm.search(\"latest research\", filter=date_filter)\n\n# Combine multiple filters (AND logic)\ntype_filter = FilterBuilder.by_chunk_type(\"text\")\ndoc_filter = FilterBuilder.by_source_document(\"paper.pdf\")\ncombined = FilterBuilder.combine_and(type_filter, doc_filter)\nresults = kbm.search(\"findings\", filter=combined)\n\n# Email-specific filters\nemail_filter = FilterBuilder.by_email_sender(\"colleague@example.com\")\nresults = kbm.search(\n    \"project update\",\n    collection=\"Email\",\n    filter=email_filter\n)\n\n# Filter by page number\npage_filter = FilterBuilder.by_page_number(1)\nresults = kbm.search(\"introduction\", filter=page_filter)\n\n# Advanced: Use raw Weaviate Filter for complex queries\nfrom weaviate.classes.query import Filter\nraw_filter = Filter.by_property(\"chunk_type\").equal(\"text\")\nresults = kbm.search(\"query\", filter=raw_filter)\n</code></pre> <p>Common Filter Patterns:</p> <ul> <li>Filter by content type: <code>FilterBuilder.by_chunk_type(\"text\")</code></li> <li>Filter by document: <code>FilterBuilder.by_source_document(\"filename.pdf\")</code></li> <li>Filter by date range: <code>FilterBuilder.by_date_range(start=\"2024-01-01\", end=\"2024-12-31\")</code></li> <li>Filter by email sender: <code>FilterBuilder.by_email_sender(\"sender@example.com\")</code></li> <li>Combine filters: <code>FilterBuilder.combine_and(filter1, filter2)</code></li> </ul> <p>For more details, see the API Reference - Filters.</p>"},{"location":"getting_started/#configuration","title":"\ud83d\udd27 Configuration","text":""},{"location":"getting_started/#embedding-models","title":"Embedding Models","text":"<p>Ragora supports multiple embedding models. Choose based on your needs:</p> <pre><code># Recommended: Best quality\nkbm = KnowledgeBaseManager(\n    weaviate_url=\"http://localhost:8080\"\n)\n\n# Faster, smaller\nkbm = KnowledgeBaseManager(\n    weaviate_url=\"http://localhost:8080\"\n)\n\n# Optimized for Q&amp;A\nkbm = KnowledgeBaseManager(\n    weaviate_url=\"http://localhost:8080\"\n)\n</code></pre>"},{"location":"getting_started/#chunking-configuration","title":"Chunking Configuration","text":"<pre><code># Default configuration\nkbm = KnowledgeBaseManager(\n    weaviate_url=\"http://localhost:8080\",\n    chunk_size=768,      # Tokens per chunk\n    chunk_overlap=100    # Overlap between chunks\n)\n\n# Smaller chunks (faster, less context)\nkbm = KnowledgeBaseManager(\n    weaviate_url=\"http://localhost:8080\",\n    chunk_size=512,\n    chunk_overlap=50\n)\n\n# Larger chunks (slower, more context)\nkbm = KnowledgeBaseManager(\n    weaviate_url=\"http://localhost:8080\",\n    chunk_size=1024,\n    chunk_overlap=150\n)\n</code></pre>"},{"location":"getting_started/#search-configuration","title":"Search Configuration","text":"<pre><code># Configure search types\nresults = kbm.search(\n    \"your query here\",\n    strategy=SearchStrategy.HYBRID,  # Options: SearchStrategy.SIMILAR, SearchStrategy.KEYWORD, SearchStrategy.HYBRID\n    top_k=10,              # Number of results\n    alpha=0.7              # Hybrid search weight (0.0-1.0)\n)\n</code></pre>"},{"location":"getting_started/#examples","title":"\ud83d\udcda Examples","text":""},{"location":"getting_started/#example-1-latex-document-processing","title":"Example 1: LaTeX Document Processing","text":"<pre><code>from ragora import KnowledgeBaseManager\n\n# Initialize\nkbm = KnowledgeBaseManager(\n    weaviate_url=\"http://localhost:8080\",\n    collection=\"AcademicPapers\"\n)\n\n# Process LaTeX documents\npapers = [\n    \"papers/quantum_mechanics.tex\",\n    \"papers/statistical_physics.tex\"\n]\nkbm.process_documents(papers)\n\n# Query with technical terms\nresults = kbm.search(\n    \"What is the Heisenberg uncertainty principle?\",\n    strategy=SearchStrategy.HYBRID,\n    top_k=5\n)\n</code></pre>"},{"location":"getting_started/#example-2-multi-document-knowledge-base","title":"Example 2: Multi-Document Knowledge Base","text":"<pre><code>import glob\nfrom ragora import KnowledgeBaseManager\n\n# Initialize\nkbm = KnowledgeBaseManager(\n    weaviate_url=\"http://localhost:8080\",\n    collection=\"Document\"\n)\n\n# Process all documents in a directory\ndocuments = glob.glob(\"docs/**/*.tex\", recursive=True)\nchunk_ids = kbm.process_documents(documents)\n\n# Get system statistics\nstats = kbm.get_system_stats()\nprint(f\"Total chunks: {stats['vector_store']['total_objects']}\")\n</code></pre>"},{"location":"getting_started/#example-3-custom-pipeline","title":"Example 3: Custom Pipeline","text":"<p>See the examples directory for more detailed examples: - <code>latex_loading_example.py</code> - Document loading and processing - <code>latex_retriever_example.py</code> - Search and retrieval - <code>advanced_usage.py</code> - Advanced features</p>"},{"location":"getting_started/#troubleshooting","title":"\ud83d\udc1b Troubleshooting","text":""},{"location":"getting_started/#common-issues","title":"Common Issues","text":"<p>Issue: \"Cannot connect to Weaviate\" <pre><code># Check if Weaviate is running\ncurl http://localhost:8080/v1/.well-known/ready\n\n# Restart Weaviate\ncd tools/database_server\n./database-manager.sh restart\n</code></pre></p> <p>Issue: \"Out of memory during embedding\" <pre><code># Reduce batch size\nembedder = EmbeddingEngine(\n    model_name=\"all-mpnet-base-v2\",\n    batch_size=16  # Default is 32\n)\n</code></pre></p> <p>Issue: \"Slow embedding generation\" <pre><code># Use GPU if available\nembedder = EmbeddingEngine(\n    model_name=\"all-mpnet-base-v2\",\n    device=\"cuda\"  # or \"cpu\"\n)\n</code></pre></p> <p>Issue: \"Poor search results\" <pre><code># Try hybrid search with different alpha values\nresults = kbm.search(\n    \"your query\",\n    strategy=SearchStrategy.HYBRID,\n    alpha=0.7  # Try values between 0.5-0.8\n)\n\n# Or increase chunk overlap\nkbm = KnowledgeBaseManager(\n    weaviate_url=\"http://localhost:8080\",\n    chunk_overlap=150  # Increase from default 100\n)\n</code></pre></p>"},{"location":"getting_started/#next-steps","title":"\ud83d\udcd6 Next Steps","text":"<ul> <li>Read the Design Decisions to understand how Ragora works</li> <li>Explore Design Decisions to learn about design choices</li> <li>Check API Reference for detailed API documentation</li> <li>See Examples for more usage examples</li> <li>Read Testing to learn about testing your RAG system</li> </ul>"},{"location":"getting_started/#getting-help","title":"\ud83c\udd98 Getting Help","text":"<ul> <li>Documentation: Browse the docs in this directory</li> <li>Examples: Check the examples directory</li> <li>Issues: Report bugs or request features on GitHub</li> <li>Discussions: Ask questions in GitHub Discussions</li> </ul>"},{"location":"getting_started/#related-documentation","title":"\ud83d\udd17 Related Documentation","text":"<ul> <li>Design Decisions - System architecture</li> <li>Design Decisions - Design rationale</li> <li>API Reference - Complete API docs</li> <li>Contributing - How to contribute</li> </ul>"},{"location":"onboarding/","title":"Team Onboarding Guide","text":"<p>Welcome to the Ragora development team! This guide will help you get up and running quickly with our development environment.</p>"},{"location":"onboarding/#quick-start-5-minutes","title":"\ud83c\udfaf Quick Start (5 minutes)","text":""},{"location":"onboarding/#prerequisites-check","title":"Prerequisites Check","text":"<ul> <li>[ ] Docker Desktop installed and running</li> <li>[ ] VS Code installed</li> <li>[ ] Dev Containers extension installed in VS Code</li> <li>[ ] GitHub account with repository access</li> </ul>"},{"location":"onboarding/#authentication-setup-if-needed","title":"Authentication Setup (if needed)","text":"<ul> <li>[ ] GitHub account added as collaborator to the repository</li> <li>[ ] If Docker image is private, you may need a Personal Access Token (see below)</li> </ul>"},{"location":"onboarding/#clone-and-open","title":"Clone and Open","text":"<pre><code>git clone https://github.com/vahidlari/aiapps.git\ncd aiapps\ncode .\n</code></pre>"},{"location":"onboarding/#open-in-devcontainer","title":"Open in DevContainer","text":"<ul> <li>When prompted, click \"Reopen in Container\"</li> <li>Or use <code>Ctrl+Shift+P</code> \u2192 \"Dev Containers: Reopen in Container\"</li> <li>Wait for the container to build (first time takes 5-10 minutes)</li> </ul>"},{"location":"onboarding/#verify-setup","title":"Verify Setup","text":"<pre><code># Check Python environment\npython --version  # Should show Python 3.11\n\n# Check if Ragora package is installed\npython -c \"import ragora; print('\u2705 Ragora installed successfully')\"\n</code></pre>"},{"location":"onboarding/#authentication-setup","title":"\ud83d\udd10 Authentication Setup","text":""},{"location":"onboarding/#repository-access","title":"Repository Access","text":"<ul> <li>Repository: The repository should be accessible to you as a collaborator</li> <li>No additional setup needed for public repositories</li> <li>For private repositories: Ensure you're added as a collaborator with appropriate permissions</li> </ul>"},{"location":"onboarding/#docker-image-access","title":"Docker Image Access","text":"<p>The DevContainer uses a Docker image from GitHub Container Registry. You may need authentication if the image is private:</p> <ol> <li>Create a Personal Access Token:</li> <li>Go to GitHub \u2192 Settings \u2192 Developer settings \u2192 Personal access tokens \u2192 Tokens (classic)</li> <li>Click \"Generate new token (classic)\"</li> <li>Select scopes: <code>read:packages</code></li> <li> <p>Copy the token (you won't see it again!)</p> </li> <li> <p>Authenticate Docker with GitHub: <pre><code># Login to GitHub Container Registry\necho \"YOUR_PAT_TOKEN\" | docker login ghcr.io -u YOUR_GITHUB_USERNAME --password-stdin\n</code></pre></p> </li> <li> <p>Alternative: Configure VS Code to use GitHub token:</p> </li> <li>In VS Code, go to Settings \u2192 Extensions \u2192 Dev Containers</li> <li>Add your GitHub token to the settings</li> <li>Or set environment variable: <code>GITHUB_TOKEN=your_token_here</code></li> </ol> <p>Troubleshooting Authentication: <pre><code># Test if you can pull the image manually\ndocker pull ghcr.io/vahidlari/aiapps/ai-dev:main-33e9578\n\n# If this fails with authentication error, you need the PAT setup above\n</code></pre></p>"},{"location":"onboarding/#running-examples","title":"\ud83e\uddea Running Examples","text":""},{"location":"onboarding/#latex-document-processing-and-vectorization","title":"LaTeX Document Processing and Vectorization","text":"<pre><code># Navigate to examples\ncd examples\n\n# Run LaTeX loading example\npython latex_loading_example.py\n\n# Run LaTeX retrieval example\npython latex_retriever_example.py\n</code></pre> <p>Note: You may need to update the URL for the Weaviate server, based on your own setup. The current implementation assumes that you are running the code in a devcontainer and a server is running outside of the devcontainer.</p>"},{"location":"onboarding/#running-tests","title":"\ud83e\uddea Running Tests","text":""},{"location":"onboarding/#run-test-suites","title":"Run Test Suites","text":"<pre><code># Navigate to Ragora directory\ncd ragora\n\n# Run all tests\npython -m pytest\n\n# Run specific test categories\npython -m pytest tests/unit/          # Unit tests only\npython -m pytest tests/integration/  # Integration tests only\n\n# Run with verbose output\npython -m pytest -v\n\n# Run specific test file\npython -m pytest tests/unit/test_rag_system.py\n</code></pre>"},{"location":"onboarding/#test-coverage","title":"Test Coverage","text":"<pre><code># Install coverage tools (if not already installed)\npip install pytest-cov\n\n# Run tests with coverage\npython -m pytest --cov=ragora --cov-report=html\n\n# View coverage report\nopen htmlcov/index.html  # macOS\nxdg-open htmlcov/index.html  # Linux\n</code></pre>"},{"location":"onboarding/#database-setup-optional","title":"\ud83d\uddc4\ufe0f Database Setup (Optional)","text":"<p>If you want to work with the full RAG system:</p> <pre><code># Navigate to database tools\ncd tools/database_server\n\n# Start Weaviate database server\n./database-manager.sh start\n\n# Check if it's running\n./database-manager.sh status\n\n# Stop when done\n./database-manager.sh stop\n</code></pre> <p>For more details, see <code>tools/database_server/README.md</code>.</p>"},{"location":"onboarding/#development-workflow","title":"\ud83d\udd27 Development Workflow","text":""},{"location":"onboarding/#code-quality-tools","title":"Code Quality Tools","text":"<p>The environment comes pre-configured with: - Black for code formatting (auto-runs on save) - Flake8 for linting - isort for import sorting</p>"},{"location":"onboarding/#git-workflow","title":"Git Workflow","text":"<pre><code># Create a new branch for your work\ngit checkout -b feature/your-feature-name\n\n# Make your changes, commit them\ngit add .\ngit commit -m \"feat: add your feature description\"\n\n# Push to GitHub\ngit push origin feature/your-feature-name\n\n# Create a Pull Request on GitHub\n</code></pre> <p>For commit message guidelines, see <code>docs/release.md</code>.</p>"},{"location":"onboarding/#adding-dependencies","title":"Adding Dependencies","text":"<pre><code># For Ragora package dependencies\ncd ragora\npip install your-new-package\npip freeze &gt; requirements.txt\n\n# For development environment dependencies\ncd tools/docker\n# Edit Pipfile to add new packages\n# The GitHub Actions will automatically update the Docker image\n</code></pre> <p>For more details, see <code>docs/development.md</code>.</p>"},{"location":"onboarding/#troubleshooting","title":"\ud83d\udc1b Troubleshooting","text":""},{"location":"onboarding/#common-issues","title":"Common Issues","text":"<p>DevContainer won't start: <pre><code># Check Docker is running\ndocker info\n\n# Rebuild the container\nCtrl+Shift+P \u2192 \"Dev Containers: Rebuild Container\"\n</code></pre></p> <p>Authentication errors when opening DevContainer: <pre><code># Test Docker image access\ndocker pull ghcr.io/vahidlari/aiapps/ai-dev:main-33e9578\n\n# If authentication fails, set up Personal Access Token (see Authentication Setup section)\necho \"YOUR_PAT_TOKEN\" | docker login ghcr.io -u YOUR_GITHUB_USERNAME --password-stdin\n</code></pre></p> <p>Tests failing: <pre><code># Verify test setup\npython tools/scripts/verify_test_setup.py\n\n# Check if all dependencies are installed\ncd ragora\npip install -e .\n</code></pre></p> <p>Database connection issues: <pre><code># Check if Weaviate is running\ncd tools/database_server\n./database-manager.sh status\n\n# Restart if needed\n./database-manager.sh restart\n</code></pre></p> <p>Import errors: <pre><code># Ensure Ragora is installed in development mode\ncd ragora\npip install -e .\n</code></pre></p>"},{"location":"onboarding/#learning-resources","title":"\ud83d\udcda Learning Resources","text":""},{"location":"onboarding/#understanding-the-codebase","title":"Understanding the Codebase","text":"<ol> <li>Start with Examples: Run the examples in <code>examples/</code> directory</li> <li>Read Ragora Docs: Continue through this site starting with the Getting Started guide for system architecture context</li> <li>Explore Tests: Look at <code>ragora/tests/</code> to understand expected behavior</li> </ol>"},{"location":"onboarding/#key-concepts","title":"Key Concepts","text":"<ul> <li>RAG System: Retrieval-Augmented Generation for LaTeX documents</li> <li>Three-Layer Architecture: DatabaseManager \u2192 VectorStore \u2192 Retriever</li> <li>Weaviate Integration: Vector database for document storage</li> <li>LaTeX Processing: Specialized document preprocessing for academic papers</li> </ul>"},{"location":"onboarding/#getting-help","title":"\ud83c\udd98 Getting Help","text":"<ul> <li>Documentation: Check the README files in each directory</li> <li>Issues: Create GitHub issues for bugs or questions</li> <li>Code Review: All changes go through Pull Request review process</li> <li>Team Chat: Use your team's communication channels for quick questions</li> </ul>"},{"location":"onboarding/#onboarding-checklist","title":"\u2705 Onboarding Checklist","text":"<ul> <li>[ ] DevContainer opens successfully</li> <li>[ ] Python 3.11 environment is active</li> <li>[ ] Ragora package imports without errors</li> <li>[ ] Examples run successfully</li> <li>[ ] Tests pass (at least the basic ones)</li> <li>[ ] Git is configured with your name and email</li> <li>[ ] You can create and push branches</li> <li>[ ] You understand the project structure</li> </ul> <p>\ud83c\udf89 Welcome to the team! You're ready to start contributing to Ragora.</p>"},{"location":"release/","title":"Release Process Guide","text":"<p>This guide explains how to use the milestone-driven release system for the Ragora project. The system automatically handles versioning, package publishing, and release management based on your commit messages.</p>"},{"location":"release/#overview","title":"\ud83c\udfaf Overview","text":"<p>The release system works by: 1. Analyzing your commits using conventional commit format 2. Determining version bumps automatically 3. Triggering releases when you close a milestone 4. Publishing packages to GitHub Package Registry and PyPI</p>"},{"location":"release/#how-to-write-commit-messages","title":"\ud83d\udcdd How to Write Commit Messages","text":""},{"location":"release/#understanding-conventional-commits","title":"Understanding Conventional Commits","text":"<p>Your commit messages should follow this format: <pre><code>type(scope): description\n\n[optional body]\n\n[optional footer(s)]\n</code></pre></p>"},{"location":"release/#commit-types-and-their-impact","title":"Commit Types and Their Impact","text":"Type Version Bump When to Use Example <code>feat:</code> Minor (0.1.0 \u2192 0.2.0) New features for users <code>feat: add user authentication</code> <code>fix:</code> Patch (0.1.0 \u2192 0.1.1) Bug fixes <code>fix: resolve login timeout issue</code> <code>perf:</code> Patch Performance improvements <code>perf: optimize database queries</code> <code>refactor:</code> Patch Code restructuring <code>refactor: simplify API endpoints</code> <code>style:</code> Patch Code formatting, no logic changes <code>style: format code with black</code> <code>docs:</code> Patch Documentation updates <code>docs: update API documentation</code> <code>test:</code> Patch Adding or updating tests <code>test: add unit tests for auth module</code> <code>build:</code> Patch Build system changes <code>build: update webpack configuration</code> <code>ci:</code> Patch CI/CD pipeline changes <code>ci: add automated testing workflow</code> <code>chore:</code> Patch Maintenance tasks <code>chore: update dependencies</code>"},{"location":"release/#breaking-changes-major-version-bump","title":"Breaking Changes (Major Version Bump)","text":"<p>For breaking changes that require a major version bump (0.1.0 \u2192 1.0.0), use one of these formats:</p> <pre><code># Option 1: Use exclamation mark\ngit commit -m \"feat!: redesign user API\"\n\n# Option 2: Use BREAKING CHANGE footer\ngit commit -m \"feat: add new authentication system\n\nBREAKING CHANGE: All API endpoints now require v2 authentication\"\n</code></pre>"},{"location":"release/#good-vs-bad-examples","title":"Good vs. Bad Examples","text":"<p>\u2705 Good commit messages: <pre><code>feat: add email notification system\nfix: resolve memory leak in data processor\ndocs: update installation instructions\nperf: optimize vector search algorithm\nfeat!: redesign API endpoints\n\nBREAKING CHANGE: Removed deprecated endpoints\n</code></pre></p> <p>\u274c Bad commit messages: <pre><code>fixed bug\nupdated stuff\nchanges\nWIP\nmore work\n</code></pre></p>"},{"location":"release/#how-to-trigger-releases","title":"\ud83d\ude80 How to Trigger Releases","text":""},{"location":"release/#method-1-automatic-release-recommended","title":"Method 1: Automatic Release (Recommended)","text":"<ol> <li>Create a milestone on GitHub:</li> <li>Go to Issues \u2192 Milestones</li> <li>Create a new milestone (e.g., \"v1.2.0\")</li> <li> <p>Add relevant issues and PRs to the milestone</p> </li> <li> <p>Make your commits using conventional commit format:    <pre><code>git add .\ngit commit -m \"feat: add new feature\"\ngit push\n</code></pre></p> </li> <li> <p>Close the milestone:</p> </li> <li>Go to the milestone page</li> <li>Click \"Close milestone\"</li> <li>The release will trigger automatically</li> </ol>"},{"location":"release/#method-2-manual-release","title":"Method 2: Manual Release","text":"<ol> <li>Go to Actions \u2192 Milestone-Driven Release</li> <li>Click Run workflow</li> <li>Optionally specify a milestone title</li> <li>Click Run workflow</li> </ol>"},{"location":"release/#method-3-dry-run-testing-mode","title":"Method 3: Dry Run (Testing Mode)","text":"<p>For testing the release workflow without actually publishing to PyPI:</p> <ol> <li>Go to Actions \u2192 Milestone-Driven Release</li> <li>Click Run workflow</li> <li>Check the \"Dry run mode\" checkbox</li> <li>Optionally specify a milestone title</li> <li>Click Run workflow</li> </ol> <p>What happens in dry run mode: - \u2705 Analyzes commits and determines the next version - \u2705 Builds Python packages (wheel + source distribution) - \u2705 Creates database server archives (tar.gz and zip) - \u2705 Uploads artifacts to GitHub Actions (downloadable for 90 days) - \u2705 Shows in logs what release notes would be generated - \u274c DOES NOT create git tags - \u274c DOES NOT create GitHub releases - \u274c DOES NOT publish to PyPI - \u274c DOES NOT update CHANGELOG.md in the repository</p> <p>Perfect for: - Testing the workflow without making any permanent changes - Verifying package builds correctly - Previewing what version would be released - Checking release notes generation - Training team members on the release process</p> <p>Note: Dry run mode does NOT create any releases or tags. All artifacts are uploaded to GitHub Actions and can be downloaded for inspection.</p>"},{"location":"release/#what-happens-during-a-release","title":"\ud83d\udd0d What Happens During a Release","text":""},{"location":"release/#step-1-commit-analysis","title":"Step 1: Commit Analysis","text":"<p>The system checks commits since the last tag for: - Conventional commit format - Breaking changes - Feature additions - Bug fixes</p>"},{"location":"release/#step-2-version-determination","title":"Step 2: Version Determination","text":"<p>Based on your commits, it determines the new version: - <code>feat:</code> \u2192 Minor version bump - <code>fix:</code> \u2192 Patch version bump - <code>BREAKING CHANGE</code> \u2192 Major version bump</p>"},{"location":"release/#step-3-release-creation","title":"Step 3: Release Creation","text":"<p>The system automatically: - Creates a Git tag (e.g., <code>v1.2.3</code>) - Builds Python packages (wheel + source) - Creates GitHub release with notes - Publishes to GitHub Package Registry - Publishes to PyPI (if configured) - Creates database server archive - Attaches milestone summary</p>"},{"location":"release/#step-4-what-gets-published","title":"Step 4: What Gets Published","text":"<p>Each release publishes the following artifacts:</p> <ol> <li>Git tag: <code>v1.2.3</code></li> <li>GitHub Release: With auto-generated notes and release assets</li> <li>Python Package (Ragora):</li> <li>Published to PyPI (<code>pip install ragora</code>)</li> <li>Attached to GitHub release as <code>.whl</code> and <code>.tar.gz</code> files</li> <li>Database Server Package:</li> <li><code>ragora-database-server.tar.gz</code> - Complete database server setup</li> <li><code>ragora-database-server.zip</code> - Windows-friendly format</li> <li>Users download this to deploy Weaviate locally</li> <li>Installation instructions: Added to release notes</li> <li>GitHub Pages site: The MkDocs workflow rebuilds and commits the static site into <code>docs/</code></li> </ol>"},{"location":"release/#documentation-publishing","title":"\ud83d\udcda Documentation Publishing","text":"<p>When a release is published (or the workflow is triggered manually), the <code>Generate Documentation</code> GitHub Action:</p> <ol> <li>Checks out the release tag to ensure the docs match the shipped code.</li> <li>Installs the MkDocs toolchain via <code>pip install -e \"ragora[docs]\"</code>.</li> <li>Builds the site with <code>mkdocs build</code>, which renders this documentation plus the    API reference generated from docstrings.</li> <li>Switches back to the default branch, replaces the contents of the <code>docs/</code>    directory, and commits the changes with a message derived from the release    tag.</li> </ol> <p>After the workflow finishes, the updated <code>docs/</code> directory is available on the default branch, and GitHub Pages automatically serves the new version at https://vahidlari.github.io/aiApps.</p>"},{"location":"release/#installing-released-packages","title":"\ud83d\udce6 Installing Released Packages","text":"<p>After a release, users can install Ragora and set up the database:</p>"},{"location":"release/#1-install-ragora-package","title":"1. Install Ragora Package","text":"<p>From PyPI (Recommended): <pre><code># Install latest version\npip install ragora\n\n# Install specific version\npip install ragora==1.2.3\n</code></pre></p> <p>From GitHub Releases: <pre><code># Install wheel directly\npip install https://github.com/vahidlari/aiapps/releases/download/v1.2.3/ragora-1.2.3-py3-none-any.whl\n</code></pre></p>"},{"location":"release/#2-download-database-server","title":"2. Download Database Server","text":"<p>Download the pre-configured database server from the release:</p> <pre><code># Download from GitHub releases\nwget https://github.com/vahidlari/aiapps/releases/download/v1.2.3/ragora-database-server.tar.gz\n\n# Extract and run\ntar -xzf ragora-database-server.tar.gz\ncd ragora-database-server\n./database-manager.sh start\n</code></pre> <p>Windows users: Download <code>ragora-database-server.zip</code> instead and extract using Windows tools.</p>"},{"location":"release/#troubleshooting","title":"\ud83d\udd27 Troubleshooting","text":""},{"location":"release/#no-release-created","title":"No Release Created?","text":"<p>Check these common issues:</p> <ol> <li> <p>Commit format: Ensure commits follow conventional format    <pre><code># Check recent commits\ngit log --oneline -5\n</code></pre></p> </li> <li> <p>Milestone status: Verify the milestone is closed</p> </li> <li>Workflow logs: Check Actions tab for error details</li> </ol>"},{"location":"release/#wrong-version-bump","title":"Wrong Version Bump?","text":"<ul> <li><code>feat:</code> commits should trigger minor version bumps</li> <li><code>fix:</code> commits should trigger patch version bumps</li> <li><code>BREAKING CHANGE</code> should trigger major version bumps</li> </ul>"},{"location":"release/#release-failed","title":"Release Failed?","text":"<ol> <li>Check GitHub Actions logs for specific errors</li> <li>Verify you have push permissions to the repository</li> <li>Ensure no conflicting tags exist</li> <li>Check PyPI credentials are configured correctly</li> </ol>"},{"location":"release/#best-practices","title":"\ud83d\udca1 Best Practices","text":""},{"location":"release/#commit-message-tips","title":"Commit Message Tips","text":"<ul> <li>Be descriptive but concise</li> <li>Use present tense (\"add feature\" not \"added feature\")</li> <li>Include scope when helpful: <code>feat(auth): add OAuth support</code></li> <li>Reference issues when relevant: <code>fix: resolve login bug (#123)</code></li> </ul>"},{"location":"release/#release-planning","title":"Release Planning","text":"<ul> <li>Group related changes into milestones</li> <li>Test thoroughly before closing milestones</li> <li>Use meaningful milestone names (e.g., \"v1.2.0 - User Management\")</li> <li>Keep milestones focused on single themes</li> </ul>"},{"location":"release/#version-strategy","title":"Version Strategy","text":"<ul> <li>Use semantic versioning for API compatibility</li> <li>Reserve major versions for breaking changes</li> <li>Use minor versions for new features</li> <li>Use patch versions for bug fixes</li> </ul>"},{"location":"release/#quick-reference","title":"\ud83d\udcda Quick Reference","text":""},{"location":"release/#commit-types-quick-guide","title":"Commit Types Quick Guide","text":"<pre><code># New feature (minor version)\ngit commit -m \"feat: add user dashboard\"\n\n# Bug fix (patch version)\ngit commit -m \"fix: resolve authentication bug\"\n\n# Breaking change (major version)\ngit commit -m \"feat!: redesign API\"\n\n# Documentation update (patch version)\ngit commit -m \"docs: update installation guide\"\n\n# Performance improvement (patch version)\ngit commit -m \"perf: optimize database queries\"\n</code></pre>"},{"location":"release/#release-workflow","title":"Release Workflow","text":"<ol> <li>Write conventional commits</li> <li>Create and assign milestone</li> <li>Close milestone \u2192 Automatic release</li> <li>Check GitHub Releases for new version</li> <li>Verify package on PyPI</li> </ol> <p>Testing the release workflow: - Use dry run mode to test without creating releases or publishing - Artifacts are built and uploaded to GitHub Actions for inspection - No tags, releases, or repository changes are made</p>"},{"location":"release/#getting-help","title":"\ud83c\udd98 Getting Help","text":"<ul> <li>Workflow logs: Check Actions tab for detailed error messages</li> <li>Conventional Commits: Official specification</li> <li>Semantic Versioning: SemVer guide</li> <li>GitHub Issues: Create an issue for bugs or questions</li> </ul>"},{"location":"testing/","title":"Testing Guide","text":"<p>This document provides comprehensive information about testing in Ragora, including test structure, running tests, and writing new tests.</p>"},{"location":"testing/#testing-philosophy","title":"\ud83c\udfaf Testing Philosophy","text":"<p>Ragora follows a comprehensive testing strategy with three levels of tests:</p> <ol> <li>Unit Tests: Test individual components in isolation</li> <li>Integration Tests: Test component interactions</li> <li>End-to-End Tests: Test complete workflows</li> </ol>"},{"location":"testing/#test-structure","title":"\ud83d\udcc1 Test Structure","text":"<pre><code>tests/\n\u251c\u2500\u2500 conftest.py                    # Pytest configuration and shared fixtures\n\u251c\u2500\u2500 run_tests.py                   # Test runner script\n\u251c\u2500\u2500 unit/                          # Unit tests for individual components\n\u2502   \u251c\u2500\u2500 test_data_chunker.py\n\u2502   \u251c\u2500\u2500 test_database_manager.py\n\u2502   \u251c\u2500\u2500 test_document_preprocessor.py\n\u2502   \u251c\u2500\u2500 test_embedding_engine.py\n\u2502   \u251c\u2500\u2500 test_email_utils.py\n\u2502   \u251c\u2500\u2500 test_knowledge_base_manager.py\n\u2502   \u251c\u2500\u2500 test_latex_parser.py\n\u2502   \u251c\u2500\u2500 test_retriever.py\n\u2502   \u2514\u2500\u2500 test_vector_store.py\n\u251c\u2500\u2500 integration/                   # Integration tests\n\u2502   \u251c\u2500\u2500 test_dbmng_retriever_vector_store.py\n\u2502   \u251c\u2500\u2500 test_document_parsing.py\n\u2502   \u251c\u2500\u2500 test_document_preprocessor.py\n\u2502   \u2514\u2500\u2500 test_rag_pipeline.py\n\u251c\u2500\u2500 fixtures/                      # Test data and sample files\n\u2502   \u251c\u2500\u2500 sample_latex.tex\n\u2502   \u251c\u2500\u2500 sample_bibliography.bib\n\u2502   \u2514\u2500\u2500 expected_outputs/\n\u2514\u2500\u2500 utils/                         # Test utilities\n    \u2514\u2500\u2500 test_helpers.py\n</code></pre>"},{"location":"testing/#running-tests","title":"\ud83d\ude80 Running Tests","text":""},{"location":"testing/#quick-start","title":"Quick Start","text":"<pre><code># Navigate to ragora directory\ncd ragora\n\n# Run all tests\npython -m pytest\n\n# Run with verbose output\npython -m pytest -v\n\n# Run with coverage\npython -m pytest --cov=ragora --cov-report=html\n</code></pre>"},{"location":"testing/#test-categories","title":"Test Categories","text":"<pre><code># Run unit tests only\npython -m pytest tests/unit/\n\n# Run integration tests only\npython -m pytest tests/integration/\n\n# Run specific test file\npython -m pytest tests/unit/test_data_chunker.py\n\n# Run specific test\npython -m pytest tests/unit/test_data_chunker.py::test_basic_chunking\n\n# Run tests matching pattern\npython -m pytest -k \"chunker\"\n</code></pre>"},{"location":"testing/#using-the-test-runner-script","title":"Using the Test Runner Script","text":"<pre><code># Run all tests\npython tests/run_tests.py\n\n# Run unit tests only\npython tests/run_tests.py --type unit\n\n# Run with coverage report\npython tests/run_tests.py --coverage\n\n# Run with HTML coverage report\npython tests/run_tests.py --html-coverage\n\n# Run tests in parallel (requires pytest-xdist)\npython tests/run_tests.py --parallel 4\n\n# Skip slow tests\npython tests/run_tests.py --fast\n</code></pre>"},{"location":"testing/#test-markers","title":"Test Markers","text":"<p>Tests can be marked for selective execution:</p> <pre><code># Run only unit tests\npython -m pytest -m unit\n\n# Run only integration tests\npython -m pytest -m integration\n\n# Skip slow tests\npython -m pytest -m \"not slow\"\n\n# Run tests for specific component\npython -m pytest -m retriever\n</code></pre>"},{"location":"testing/#writing-tests","title":"\ud83e\uddea Writing Tests","text":""},{"location":"testing/#unit-test-example","title":"Unit Test Example","text":"<pre><code>import pytest\nfrom ragora.core import DataChunker\n\nclass TestDataChunker:\n    \"\"\"Tests for the DataChunker class.\"\"\"\n\n    def setup_method(self):\n        \"\"\"Set up test fixtures.\"\"\"\n        self.chunker = DataChunker()\n        self.context = ChunkingContextBuilder().for_text().build()\n\n    def test_basic_chunking(self):\n        \"\"\"Test basic chunking functionality.\"\"\"\n        text = \"This is a test document. \" * 50\n        chunks = self.chunker.chunk(text, self.context)\n\n        assert len(chunks) &gt; 0\n        assert all(isinstance(chunk, DataChunk) for chunk in chunks)\n\n    def test_chunk_overlap(self):\n        \"\"\"Test that chunks have proper overlap.\"\"\"\n        text = \"Word \" * 100\n        chunks = self.chunker.chunk(text, self.context)\n\n        # Verify overlap exists between consecutive chunks\n        for i in range(len(chunks) - 1):\n            overlap_content = chunks[i].text[-20:]\n            assert overlap_content in chunks[i + 1].text\n\n    def test_empty_input(self):\n        \"\"\"Test handling of empty input.\"\"\"\n        chunks = self.chunker.chunk(\"\", self.context)\n        assert len(chunks) == 0\n\n    def test_very_short_text(self):\n        \"\"\"Test handling of text shorter than chunk size.\"\"\"\n        text = \"Short text.\"\n        chunks = self.chunker.chunk(text, self.context)\n\n        assert len(chunks) == 1\n        assert chunks[0].text == text\n\n    @pytest.mark.parametrize(\"chunk_size,overlap\", [\n        (256, 50),\n        (512, 100),\n        (1024, 150),\n    ])\n    def test_different_configurations(self, chunk_size, overlap):\n        \"\"\"Test chunking with different configurations.\"\"\"\n        from ragora import TextChunkingStrategy\n        custom_strategy = TextChunkingStrategy(chunk_size=chunk_size, overlap_size=overlap)\n        chunker = DataChunker(default_strategy=custom_strategy)\n        text = \"Test content. \" * 200\n\n        chunks = chunker.chunk(text, self.context)\n\n        assert len(chunks) &gt; 0\n        assert all(len(chunk.text) &lt;= chunk_size for chunk in chunks)\n</code></pre>"},{"location":"testing/#integration-test-example","title":"Integration Test Example","text":"<pre><code>import pytest\nfrom ragora import KnowledgeBaseManager\nfrom ragora.core import DatabaseManager\n\nclass TestRAGPipeline:\n    \"\"\"Integration tests for complete RAG pipeline.\"\"\"\n\n    @pytest.fixture\n    def db_manager(self):\n        \"\"\"Provide database manager fixture.\"\"\"\n        manager = DatabaseManager(url=\"http://localhost:8080\")\n        yield manager\n        # Cleanup after test\n        manager.delete_collection(\"TestDocs\")\n\n    @pytest.fixture\n    def knowledge_base(self, db_manager):\n        \"\"\"Provide knowledge base manager fixture.\"\"\"\n        return KnowledgeBaseManager(\n            weaviate_url=\"http://localhost:8080\",\n            class_name=\"TestDocs\",\n            embedding_model=\"all-MiniLM-L6-v2\",  # Smaller model for tests\n            chunk_size=256,\n            chunk_overlap=50\n        )\n\n    def test_document_ingestion_and_retrieval(self, knowledge_base, tmp_path):\n        \"\"\"Test complete document processing and retrieval.\"\"\"\n        # Create test document\n        doc_path = tmp_path / \"test.tex\"\n        doc_path.write_text(\"\"\"\n        \\\\documentclass{article}\n        \\\\begin{document}\n        \\\\section{Introduction}\n        This is a test document about machine learning.\n        \\\\end{document}\n        \"\"\")\n\n        # Process document\n        chunk_ids = knowledge_base.process_documents([str(doc_path)])\n        assert len(chunk_ids) &gt; 0\n\n        # Query for content\n        results = knowledge_base.query(\n            \"machine learning\",\n            search_type=\"hybrid\",\n            top_k=5\n        )\n\n        assert len(results['chunks']) &gt; 0\n        assert 'machine learning' in results['chunks'][0]['content'].lower()\n\n    def test_multiple_search_types(self, knowledge_base, tmp_path):\n        \"\"\"Test different search types produce results.\"\"\"\n        # Setup test data\n        doc_path = tmp_path / \"test.tex\"\n        doc_path.write_text(\"Test content about neural networks and deep learning.\")\n        knowledge_base.process_documents([str(doc_path)])\n\n        # Test semantic search\n        semantic_results = knowledge_base.query(\n            \"artificial intelligence\",\n            search_type=\"similar\",\n            top_k=3\n        )\n\n        # Test keyword search\n        keyword_results = knowledge_base.query(\n            \"neural networks\",\n            search_type=\"keyword\",\n            top_k=3\n        )\n\n        # Test hybrid search\n        hybrid_results = knowledge_base.query(\n            \"deep learning\",\n            search_type=\"hybrid\",\n            top_k=3\n        )\n\n        assert len(semantic_results['chunks']) &gt; 0\n        assert len(keyword_results['chunks']) &gt; 0\n        assert len(hybrid_results['chunks']) &gt; 0\n</code></pre>"},{"location":"testing/#using-fixtures","title":"Using Fixtures","text":"<pre><code>import pytest\nfrom pathlib import Path\n\n@pytest.fixture\ndef sample_latex_content():\n    \"\"\"Provide sample LaTeX content.\"\"\"\n    return \"\"\"\n    \\\\documentclass{article}\n    \\\\begin{document}\n    \\\\section{Test Section}\n    This is test content with an equation: $E = mc^2$\n    \\\\end{document}\n    \"\"\"\n\n@pytest.fixture\ndef sample_bibliography():\n    \"\"\"Provide sample bibliography content.\"\"\"\n    return \"\"\"\n    @article{einstein1905,\n        author = {Einstein, Albert},\n        title = {On the Electrodynamics of Moving Bodies},\n        year = {1905}\n    }\n    \"\"\"\n\n@pytest.fixture\ndef temp_latex_file(tmp_path, sample_latex_content):\n    \"\"\"Create temporary LaTeX file.\"\"\"\n    file_path = tmp_path / \"test.tex\"\n    file_path.write_text(sample_latex_content)\n    return file_path\n\ndef test_with_fixture(temp_latex_file):\n    \"\"\"Test using fixture.\"\"\"\n    from ragora.core import DocumentPreprocessor\n\n    preprocessor = DocumentPreprocessor()\n    document = preprocessor.parse_latex(str(temp_latex_file))\n\n    assert document is not None\n    assert document.title is not None\n</code></pre>"},{"location":"testing/#mocking-external-dependencies","title":"Mocking External Dependencies","text":"<pre><code>import pytest\nfrom unittest.mock import Mock, patch\nfrom ragora.core import Retriever\n\nclass TestRetrieverMocking:\n    \"\"\"Tests using mocks for external dependencies.\"\"\"\n\n    def test_search_with_mocked_database(self):\n        \"\"\"Test search with mocked database connection.\"\"\"\n        # Create mock database manager\n        mock_db = Mock()\n        mock_db.execute_query.return_value = [\n            {\n                'content': 'Test content',\n                'similarity_score': 0.95\n            }\n        ]\n\n        # Create retriever with mocked dependency\n        retriever = Retriever(db_manager=mock_db, class_name=\"TestDocs\")\n\n        # Perform search\n        with patch.object(retriever, '_execute_search', return_value=mock_db.execute_query()):\n            results = retriever.search_similar(\"test query\", top_k=5)\n\n        assert len(results) &gt; 0\n        assert results[0]['similarity_score'] == 0.95\n</code></pre>"},{"location":"testing/#parametrized-tests","title":"Parametrized Tests","text":"<pre><code>import pytest\nfrom ragora.core import EmbeddingEngine\n\n@pytest.mark.parametrize(\"model_name,expected_dim\", [\n    (\"all-MiniLM-L6-v2\", 384),\n    (\"all-mpnet-base-v2\", 768),\n    (\"multi-qa-MiniLM-L6-v2\", 384),\n])\ndef test_embedding_dimensions(model_name, expected_dim):\n    \"\"\"Test embedding dimensions for different models.\"\"\"\n    embedder = EmbeddingEngine(model_name=model_name)\n    text = \"Test sentence for embedding.\"\n\n    embedding = embedder.embed_text(text)\n\n    assert embedding.shape[0] == expected_dim\n</code></pre>"},{"location":"testing/#test-coverage","title":"\ud83d\udcca Test Coverage","text":""},{"location":"testing/#viewing-coverage","title":"Viewing Coverage","text":"<pre><code># Generate HTML coverage report\npython -m pytest --cov=ragora --cov-report=html\n\n# Open the report\nopen htmlcov/index.html  # macOS\nxdg-open htmlcov/index.html  # Linux\n</code></pre>"},{"location":"testing/#coverage-goals","title":"Coverage Goals","text":"<ul> <li>Overall Coverage: 80%+ for the entire codebase</li> <li>Core Modules: 90%+ coverage</li> <li>Utility Functions: 80%+ coverage</li> <li>Critical Paths: 100% coverage</li> </ul>"},{"location":"testing/#coverage-configuration","title":"Coverage Configuration","text":"<p>In <code>pytest.ini</code>:</p> <pre><code>[tool:pytest]\naddopts = \n    --cov=ragora\n    --cov-report=html\n    --cov-report=term-missing\n    --cov-fail-under=80\n</code></pre>"},{"location":"testing/#debugging-tests","title":"\ud83d\udc1b Debugging Tests","text":""},{"location":"testing/#running-tests-in-debug-mode","title":"Running Tests in Debug Mode","text":"<pre><code># Run with full output\npython -m pytest -vvv --tb=long\n\n# Run specific test with output\npython -m pytest tests/unit/test_chunker.py::test_basic -vvv -s\n\n# Drop into debugger on failure\npython -m pytest --pdb\n\n# Drop into debugger on first failure\npython -m pytest -x --pdb\n</code></pre>"},{"location":"testing/#using-vs-code-debugger","title":"Using VS Code Debugger","text":"<ol> <li>Set breakpoints in test code</li> <li>Open test file</li> <li>Click \"Debug Test\" in the testing panel</li> <li>Step through code with debugger</li> </ol>"},{"location":"testing/#logging-during-tests","title":"Logging During Tests","text":"<pre><code>import logging\n\ndef test_with_logging(caplog):\n    \"\"\"Test with captured log output.\"\"\"\n    caplog.set_level(logging.DEBUG)\n\n    # Your test code\n    from ragora.core import DataChunker\n    chunker = DataChunker()\n\n    # Check log output\n    assert \"Initializing chunker\" in caplog.text\n</code></pre>"},{"location":"testing/#performance-testing","title":"\u26a1 Performance Testing","text":""},{"location":"testing/#benchmarking","title":"Benchmarking","text":"<pre><code>import pytest\nimport time\n\ndef test_chunking_performance():\n    \"\"\"Benchmark chunking performance.\"\"\"\n    from ragora.core import DataChunker\n\n    chunker = DataChunker(chunk_size=768)\n    text = \"Test content. \" * 10000\n\n    start_time = time.time()\n    chunks = chunker.chunk_text(text)\n    duration = time.time() - start_time\n\n    assert duration &lt; 1.0  # Should complete in less than 1 second\n    assert len(chunks) &gt; 0\n</code></pre>"},{"location":"testing/#using-pytest-benchmark","title":"Using pytest-benchmark","text":"<pre><code># Install pytest-benchmark\npip install pytest-benchmark\n\n# Run benchmarks\npython -m pytest tests/benchmarks/ --benchmark-only\n</code></pre> <pre><code>def test_embedding_performance(benchmark):\n    \"\"\"Benchmark embedding generation.\"\"\"\n    from ragora.core import EmbeddingEngine\n\n    embedder = EmbeddingEngine(model_name=\"all-MiniLM-L6-v2\")\n    texts = [\"Test sentence\"] * 100\n\n    result = benchmark(embedder.embed_batch, texts)\n\n    assert len(result) == 100\n</code></pre>"},{"location":"testing/#continuous-integration","title":"\ud83d\udd04 Continuous Integration","text":""},{"location":"testing/#github-actions","title":"GitHub Actions","text":"<p>Tests run automatically on: - Every push to main - Every pull request - Nightly builds</p>"},{"location":"testing/#local-pre-commit-checks","title":"Local Pre-commit Checks","text":"<pre><code># Install pre-commit hooks\npip install pre-commit\npre-commit install\n\n# Run manually\npre-commit run --all-files\n</code></pre>"},{"location":"testing/#best-practices","title":"\ud83d\udcdd Best Practices","text":""},{"location":"testing/#test-organization","title":"Test Organization","text":"<ol> <li>One test file per module: Mirror source code structure</li> <li>Descriptive test names: Use clear, descriptive names</li> <li>Group related tests: Use classes to organize tests</li> <li>Use fixtures: Leverage pytest fixtures for setup</li> </ol>"},{"location":"testing/#test-quality","title":"Test Quality","text":"<ol> <li>Test edge cases: Include boundary conditions</li> <li>Test error handling: Verify exceptions are raised correctly</li> <li>Use assertions wisely: Make specific, meaningful assertions</li> <li>Clean up resources: Ensure proper cleanup after tests</li> </ol>"},{"location":"testing/#performance","title":"Performance","text":"<ol> <li>Mark slow tests: Use <code>@pytest.mark.slow</code> for long tests</li> <li>Use parallel execution: Run independent tests in parallel</li> <li>Optimize test data: Use minimal data that covers functionality</li> <li>Mock external services: Don't rely on external dependencies</li> </ol>"},{"location":"testing/#related-documentation","title":"\ud83d\udd17 Related Documentation","text":"<ul> <li>Contributing Guide - How to contribute</li> <li>Development Guide - Development workflow</li> <li>Design Decisions - System architecture</li> </ul>"},{"location":"testing/#getting-help","title":"\ud83c\udd98 Getting Help","text":"<ul> <li>Test failures: Check CI logs for details</li> <li>Writing tests: See examples in tests directory</li> <li>Test fixtures: Check conftest.py for available fixtures</li> <li>Questions: Ask in GitHub Issues or Discussions</li> </ul>"}]}